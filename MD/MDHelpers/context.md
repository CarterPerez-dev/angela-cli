# I couldnt give you all teh files i have currently in repository so i haev thsi file to provide you some conetxxt regaridng teh files you may not be able to directly see. Aswell as a directopry tree/structure/hiererechy
## heres a breif description of each .py file you cannot directly see / see the code in them
---
**File: `angela/workflows/sharing.py`**
`angela/workflows/sharing.py` facilitates sharing workflows by enabling their export into packaged `.angela-workflow` zip files and subsequent import into the Angela system. It defines a `WorkflowExportMetadata` Pydantic model to structure package information, including ID, name, version, author, timestamps, and a SHA-256 checksum generated by `hashlib` for data integrity. The `WorkflowSharingManager` class orchestrates the export process by packaging `workflow.json` (workflow data), `metadata.json`, and a `README.md` into a zip archive, and the import process by extracting, validating the checksum, and adding the workflow via `WorkflowManager`. Export functionality can optionally detect external dependencies like Python or Node.js versions by asynchronously running shell commands (e.g., `python --version`) and includes this in the metadata. The module robustly utilizes `tempfile` for temporary directories, `datetime` for timestamps, `uuid` for unique package IDs, and `pathlib` for filesystem path manipulations.
---
**File: `angela/workflows/manager.py` (inferred from context)**
The file `angela/workflows/manager.py` provides the core `WorkflowManager` class for defining, storing, retrieving, and executing reusable command sequences, known as workflows, within the Angela CLI. It utilizes Pydantic models, `WorkflowStep` (detailing command, explanation, optionality, confirmation needs) and `Workflow` (encompassing name, description, steps, variables, timestamps, tags, author), to structure workflow data. Workflows are persisted in a `workflows.json` file within the application's configuration directory (`CONFIG_DIR`), with the manager handling loading at startup and saving upon modification, including `datetime` to ISO format serialization. A key feature is the `define_workflow_from_natural_language` async method, which leverages an AI (Gemini client) and a `TaskPlanner` to convert user descriptions into structured workflow steps and identify potential variables. Workflow execution involves substituting provided variable values into command templates, converting the workflow into a `TaskPlan`, and then running this plan via the `task_planner`, supporting both regular execution and dry runs.
---
**File: `angela/ai/content_analyzer_extensions.py`**
The `angela/ai/content_analyzer_extensions.py` file introduces `EnhancedContentAnalyzer`, a class that extends the base `ContentAnalyzer` to provide specialized analysis for a wider range of file types and programming languages. It employs a `LANGUAGE_HANDLERS` dictionary to route file analysis requests to language-specific async methods, such as `_analyze_typescript` or `_analyze_json`, based on detected file information from `_get_file_info`. For instance, `_analyze_typescript` uses custom AI prompts for TypeScript code analysis via `_get_ai_analysis` (calling Gemini) and regex patterns (in `_extract_typescript_types`) to identify types and interfaces. Similarly, `_analyze_json` validates JSON content using `json.loads`, infers a basic schema through `_infer_json_schema` by recursively examining data types, and leverages AI for a human-readable structural analysis. If no specific handler is found for a language, the `EnhancedContentAnalyzer` falls back to the `analyze_content` method of its parent class, ensuring general analysis capabilities remain.
---
**File: `angela/ai/parser.py`**
The `angela/ai/parser.py` file is responsible for parsing responses from an AI model, aiming to convert potentially unstructured text into a structured `CommandSuggestion` object. It defines the `CommandSuggestion` Pydantic model, which specifies the expected fields: `intent`, `command`, `explanation`, and optional `additional_info`, ensuring data integrity and providing typed access. The core `parse_ai_response` function intelligently attempts to locate and extract JSON data from the AI's output, specifically looking for JSON within markdown code blocks (e.g., ```json ... ```) or assuming the entire response is JSON. After extracting the JSON string, it uses `json.loads` for parsing and then Pydantic for validation against the `CommandSuggestion` model, logging success or errors. In cases of `json.JSONDecodeError` or Pydantic `ValidationError`, a fallback mechanism employs regular expressions (`re.search`) to try and salvage at least the `command` string, enhancing the parser's resilience to malformed AI responses.
---
**File: `angela/ai/confidence.py`**
`angela/ai/confidence.py` introduces the `ConfidenceScorer` class, designed to evaluate and assign a numerical confidence score (ranging from 0.0 to 1.0) to AI-generated command suggestions. The primary method, `score_command_confidence`, aggregates scores from multiple weighted heuristics: `_check_history` (queries `history_manager` for command frequency and success rate), `_check_complexity` (compares token counts of request and command), `_check_entities` (basic check for entity type matches like files/dirs), and `_check_command_flags` (looks for unusual/conflicting flags). Each heuristic function, like `_check_complexity` which compares request and command token lengths, contributes a value that is then weighted into the final score. The entity check (`_check_entities`) uses simple string matching for terms like "file" or "directory" and `re.findall` for path patterns. The module ensures the final confidence score remains within the 0.0 to 1.0 range and logs the breakdown of contributing factors for debuggability.
---
**File: `angela/config.py` (inferred from content)**
This configuration management file, `angela/config.py`, establishes a `ConfigManager` class to handle application settings using TOML for file-based configuration and environment variables for sensitive data like API keys. It employs Pydantic models (`ApiConfig`, `UserConfig`, `AppConfig`) to define a clear structure for settings such as Gemini API keys, default project root (`Path`), `confirm_all_actions` (bool), and `debug` mode, ensuring type validation. The manager dynamically selects TOML parsing libraries (`tomllib` for Python 3.11+ or `tomli` for older versions, and `tomli-w` for writing), loading from a predefined `CONFIG_FILE` path and `.env` files via `python-dotenv`. `load_config` reads the TOML file, populates the Pydantic models, and gracefully handles potential `TOMLDecodeError` or missing files by falling back to defaults or saving a new default configuration. The `save_config` method serializes the current `AppConfig` model (converting `Path` objects to strings for TOML compatibility) back to the configuration file, while a global `config_manager` instance ensures the loaded configuration is immediately available upon module import.
---
**File: `angela/cli/files.py` (inferred from content)**
This file, `angela/cli/files.py`, defines a Typer-based command-line interface application for managing file and directory operations within the Angela CLI, offering an enhanced user experience through the `rich` library. It implements common filesystem commands such as `ls` (with detailed table views via `rich.Table` and color-coding), `mkdir`, `rmdir`, `touch`, `cat` (with syntax highlighting using `rich.Syntax` based on `context_manager.get_file_info`), `rm`, `cp`, `mv`, and `write` (with interactive content input via `rich.Prompt`). These commands primarily delegate their core logic to async functions from `angela.execution.filesystem` (e.g., `create_directory`, `read_file`) and use `angela.context.context_manager` for path resolution and file metadata. Advanced commands include `find` for pattern-based file searching via `context_manager.find_files` and `info` for displaying detailed file/directory information using `rich.Panel` and content previews. A crucial feature is the `rollback` command, which interacts with `angela.execution.rollback.rollback_manager` to list recent operations and allow users to undo them if backups are available, confirming actions with `rich.Confirm`.
---
**File: `angela/cli/workflows.py`**
This file, `angela/cli/workflows.py`, implements a Typer-based command-line interface for managing Angela workflows, allowing users to list, create, run, delete, show, export, and import these reusable command sequences. It relies on `angela.workflows.manager.workflow_manager` for core operations like defining workflows (interactively via `rich.Prompt` or from natural language in a file via `create`), executing them with variable substitution (`run`), and managing their lifecycle (`list`, `delete`, `show`). The `export` and `import` commands interface with `angela.workflows.sharing.workflow_sharing_manager` to package workflows into shareable `.angela-workflow` archives and to integrate received packages into the system, handling potential renames or replacements. User interaction is enhanced using the `rich` library, providing formatted tables for listing workflows (`rich.Table`), detailed panels for showing workflow steps via `terminal_formatter.display_workflow`, and interactive prompts/confirmations (`rich.Prompt`, `rich.Confirm`). The `run` command supports dry-run mode for previewing execution and accepts variables via command-line options (`--var NAME=VALUE`), which are then passed to the `workflow_manager` for execution within the current `context_manager` context.
---
**File: `angela/context/history.py`**
`angela/context/history.py` implements the `HistoryManager` class to record and analyze user command execution history, persisting data in `command_history.json` (for `CommandRecord`s) and `command_patterns.json` (for `CommandPattern`s) within the `CONFIG_DIR`. It uses a `CommandRecord` class to store detailed information about each command execution, including the command string, natural language request, success status, ISO-formatted timestamp, output, error, and risk level. The `CommandPattern` class tracks metrics like execution count, success rate, and last used timestamp for base commands (e.g., "git commit", extracted by `_extract_base_command`), which are updated via `_update_patterns` if `auto_learn_patterns` preference is enabled. `HistoryManager` loads history and patterns upon initialization, trims history based on `preferences_manager.preferences.context.max_history_items`, and provides methods to retrieve recent commands, query command frequency/success rates, and search for similar past commands using Jaccard similarity on tokenized natural requests. This historical data is crucial for features like adaptive confirmation scoring, command suggestions, and potentially for AI fine-tuning or error recovery within the Angela CLI.
---
**File: `angela/execution/rollback.py`**
This file, `angela/execution/rollback.py`, implements a `RollbackManager` to provide undo functionality for file and directory operations performed by the Angela CLI, storing its state in `operation_history.json`. It defines an `OperationRecord` class to store details of each recorded action, including its type (e.g., "create_file", "delete_directory"), parameters, ISO-formatted timestamp, and the path to any created backup within the `BACKUP_DIR`. The manager loads this history on initialization and saves updates when `record_operation` is called after a filesystem action. The `rollback_operation` async method is central to the undo logic: based on the `operation_type` and `backup_path` from the selected `OperationRecord`, it reverses the original action, such as deleting a created file or restoring a deleted file/directory from its backup using `shutil` functions like `copy2` or `copytree`. Users can view recent undoable operations (formatted by `_get_operation_description`) via `get_recent_operations`, and upon successful rollback, the manager truncates the history to reflect the undone state.
---
---
**File: `angela/safety/adaptive_confirmation.py`**
`angela/safety/adaptive_confirmation.py` implements an intelligent user confirmation system that adapts its prompting behavior based on command risk, execution history, and user preferences. It leverages `prompt_toolkit`'s `yes_no_dialog` for interactive user consent and `rich` library components (`Console`, `Panel`, `Syntax`, `Table`) for presenting detailed, styled information, including command syntax, risk levels (using `CONFIRMATION_STYLES`), impact analysis, and previews. The core async function `get_adaptive_confirmation` determines whether to auto-execute a command by consulting `preferences_manager` (for trusted commands) and `history_manager` (for frequency/success rate), or to proceed with explicit user prompting. It tailors the confirmation UI: `_get_detailed_confirmation` is used for high/critical risk operations showing comprehensive details and impact tables, while `_get_simple_confirmation` provides a more concise prompt for lower risks; dry runs (`_show_dry_run_preview`) bypass confirmation entirely. After a successful execution of certain commands, `offer_command_learning` may prompt the user to add the command to their trusted list, further personalizing the safety behavior.
---
**File: `angela/safety/classifier.py`**
`angela/safety/classifier.py` is responsible for assessing the potential danger of shell commands by classifying their risk level and analyzing their likely impact on the system. The `classify_command_risk` function determines a command's risk by matching it against a predefined dictionary of regular expressions, `RISK_PATTERNS` (mapping risk levels to regexes and reasons, e.g., `rm -rf` as CRITICAL) and `OVERRIDE_PATTERNS` (for special cases), categorizing it from "SAFE" to "CRITICAL" as defined in `angela.constants.RISK_LEVELS`. These patterns are designed to identify operations like file deletion, package management, privileged execution (`sudo`), or disk formatting, assigning appropriate risk scores. The `analyze_command_impact` function performs a lexical analysis of the command using `shlex.split` to tokenize it, then heuristically identifies potential operations (e.g., delete, create, read), affected files/directories, and flags if the command is destructive or modifies/creates files. This classification and impact analysis data is then consumed by other safety modules to determine the appropriate level of user confirmation and the details to display.
---
**File: `angela/safety/confirmation.py`**
`angela/safety/confirmation.py` manages the user interaction phase of the safety workflow, presenting detailed information about a command and prompting for explicit user approval before execution. The `requires_confirmation` function determines if a prompt is necessary by checking the command's risk level against `DEFAULT_CONFIRMATION_REQUIREMENTS` and global user settings like `config_manager.config.user.confirm_all_actions`. The `get_confirmation` async function orchestrates the display using the `rich` library, showing the command with `Syntax` highlighting, its `risk_level` (colored using `RISK_COLORS` and named via `RISK_LEVEL_NAMES`), the `risk_reason`, an impact analysis table generated by `format_impact_analysis`, and any available `preview`. It utilizes `rich.Panel` for structuring information clearly and `rich.Confirm.ask` to get a boolean (yes/no) response from the user regarding whether to proceed with the command. For "CRITICAL" risk operations or if `dry_run` is true, additional specific warnings or informational messages are displayed to ensure the user is fully aware of the context and potential consequences.
---
**File: `angela/safety/preview.py`**
`angela/safety/preview.py` is dedicated to generating predictive textual summaries of what shell commands are expected to do, without actually executing them, to aid user decision-making during safety checks. It features a main `generate_preview` async function that dispatches to command-specific async handlers (e.g., `preview_mkdir`, `preview_rm`, `preview_ls`) listed in the `PREVIEWABLE_COMMANDS` dictionary, based on the parsed command (tokenized using `shlex.split`). These specific preview functions, like `preview_rm` or `preview_cp`, analyze command arguments, check file/directory existence and types using `pathlib.Path`, expand glob patterns using `glob.glob`, and then construct a human-readable summary of intended actions, including warnings for overwrites or non-existent paths. For example, `preview_cat` estimates file size and line count for text files or warns about displaying binary content, while `preview_find` describes the search scope and criteria. If no specialized previewer exists for a command, `generic_preview` attempts to execute it with common dry-run flags (e.g., `--dry-run`, `--print`) using `execution_engine.execute_command`, capturing its output as the preview.
---
**File: `angela/safety/validator.py`**
`angela/safety/validator.py` enforces safety policies by validating commands and operations against a set of predefined rules and system constraints before they can proceed to execution. The `validate_command_safety` function scrutinizes raw shell commands, checking them against `DANGEROUS_PATTERNS` (a list of regexes for forbidden actions like `rm -rf /` or `mkfs /dev/sda`) and ensuring necessary superuser privileges (checked via `is_superuser` which uses `os.geteuid`, and `ROOT_PATTERNS` regex list) are met if the current user is not root. The `validate_operation` function handles abstracted operations (e.g., 'create_file', 'delete_directory'), leveraging `check_file_permission` (which employs `os.access`) to verify read/write permissions for specified `Path` objects and checking against deletion of system directories. It defines a custom `ValidationError` exception, although it is not explicitly raised in the provided snippet, it's implied for severe validation failures not handled by returning a boolean and message. This module acts as a critical first line of defense, aiming to prevent overtly harmful or permission-violating operations from even being considered for execution by the Angela CLI.
---
**File: `angela/execution/error_recovery.py`:**
The `angela/execution/error_recovery.py` file implements the `ErrorRecoveryManager` class, a sophisticated system designed to intelligently handle and attempt recovery from errors encountered during multi-step command executions within the Angela CLI. Its primary entry point, the async `handle_error` method, orchestrates a sequence involving error information extraction (command, stderr), detailed analysis via `_analyze_error` which uses an external `error_analyzer` and internal regex patterns from `_get_common_error_patterns`, and generation of potential `RecoveryStrategy` enums (like `RETRY`, `MODIFY_COMMAND`, `PREPARE_ENV`) through `_generate_recovery_strategies`. Strategy generation is multi-faceted: `_generate_recovery_strategies` first attempts to derive actions by parsing fix suggestions from the error analysis using regex in `_parse_fix_suggestion` and `_create_strategy_from_pattern_fix`, and if these heuristic methods yield insufficient results, it queries the `gemini_client` via `_generate_ai_recovery_strategies` with a structured JSON-expecting prompt for AI-driven solutions. These strategies, which are standard Python dictionaries adhering to a defined structure including type, command, description, and confidence, are then sorted by their confidence score, always including fallback options like simple retry or skipping the problematic step.
Automatic recovery, determined by `_can_auto_recover`, is attempted for high-confidence strategies or those with a proven success record tracked in the internal `_recovery_history` dictionary (which logs successful strategy applications like `{ "type:command": {"success_count": N}}`). The `_execute_recovery_strategy` async method performs the actual recovery by dispatching actions based on the strategy type, often involving command execution via the `angela.execution.engine.execution_engine`, where safety checks might be selectively skipped for retries or enforced for newly generated commands. Notably, strategies such as `PREPARE_ENV` can execute a preparatory command (e.g., `mkdir` for a missing directory, or `apt-get install` for a missing package) and, if successful and indicated by a `retry_original` flag within the strategy dictionary, will subsequently re-attempt the original failed command. If automatic recovery isn't viable or fails, `_guided_recovery` presents the generated strategies to the user via `terminal_formatter` for display and uses `prompt_toolkit.input_dialog` to capture their choice, subsequently executing the selected strategy. The system thus combines heuristic rule-based error matching, AI-powered suggestion generation, a learning mechanism from past successful recoveries, and user-guided intervention to maximize the chances of successful task completion.
----------
**Summary for `BackgroundMonitor.py`:**
This Python module implements an asynchronous `BackgroundMonitor` class for the Angela CLI, designed to proactively assist users by observing system state and activities through concurrent, restartable `asyncio` tasks. It actively monitors Git repository status by periodically running `git status -s`, analyzing changes like modified, untracked, or deleted files, and then generating contextual suggestions for commits or additions if significant activity is detected, subject to a cooldown period and repetition avoidance. The monitor also tracks file modifications within the project, identified by `_find_source_files`, and upon detecting changes, it invokes language-specific checkers such as `python -m py_compile` and `flake8` for Python or `node --check` and `eslint` for JavaScript to report syntax errors and linting issues. System resource monitoring is partially implemented, focusing on disk usage by executing platform-specific commands (`wmic` or `df`) via an asynchronous `_run_command` utility, and it alerts the user if usage exceeds a threshold and has significantly increased. All suggestions are managed to prevent repetition using a set of seen suggestions and are displayed via `terminal_formatter`, with overall monitoring controlled by `start_monitoring` and `stop_monitoring` methods that manage the lifecycle of the underlying `asyncio` tasks.
**Summary for `ProjectInference.py`**
The `ProjectInference` Python module provides advanced, asynchronous capabilities to analyze a given project directory, aiming to deduce its primary type, technological stack, dependencies, and structural characteristics using file system inspection and pattern matching. It determines the project type (e.g., Python, Node, Java) by scoring matches against predefined `PROJECT_SIGNATURES` that include characteristic files (like `requirements.txt` or `package.json`), directories (e.g., `venv`, `node_modules`), and common file extensions, capable of identifying mixed-type projects by combining high-scoring candidates. Framework detection is achieved by cross-referencing project files and contents against `FRAMEWORK_SIGNATURES` (e.g., identifying Django via `manage.py` or React via `package.json` dependencies) and by directly parsing dependency lists from files like `requirements.txt` or `package.json` using dedicated analyzer methods. The module meticulously extracts project dependencies by parsing specific manifest files corresponding to the detected project type, such as `requirements.txt`, `setup.py`, and `pyproject.toml` for Python projects, or `package.json` for Node.js projects, detailing dependency names, version specifiers, and source files. It identifies and lists important project files, including signature files that confirmed the project type, common documentation like READMEs and LICENSEs, and attempts to locate potential entry point files (e.g., `main.py`, `index.js`) based on conventional naming within the project structure. Project structure analysis involves counting files by extension, identifying prominent subdirectories (ignoring common ones like `.git` or `node_modules`), and generating a hierarchical, depth-limited tree representation of the directory layout using the recursive `_generate_directory_structure` method. All inferred information, including project root, type, detected files, frameworks, dependencies, and structural details, is compiled into a comprehensive dictionary, with results cached per project root path to optimize subsequent analyses of the same project.
**`angela/cli/file_extensions.py`**
This module extends Angela's command-line interface (CLI) with advanced file-related functionalities, operating within the broader "Angela" application by interfacing with its context management, file resolution, and activity tracking systems. Its primary purpose is to empower users with sophisticated commands for resolving ambiguous file references, extracting file paths from text, viewing recently or frequently accessed files, and inspecting detailed project information. Technically, it leverages `typer` for command-line argument parsing and command definition, and `rich` for creating user-friendly, formatted console output like tables and panels, while also using `asyncio` to run asynchronous operations provided by other Angela modules. Key commands include `resolve` which uses `file_resolver.resolve_reference` and logs views with `file_activity_tracker`, and `extract` which processes text to find and display file references. The `recent` and `active` commands query the `file_activity_tracker` to present historical file interaction data in structured tables. Finally, the `project` command utilizes `context_manager` and `context_enhancer` to gather and present a rich summary of the current project's attributes, dependencies, and structure.
**`angela/cli/files.py`**
This file defines core file and directory manipulation commands for the Angela CLI, offering an enhanced, context-aware alternative to standard shell utilities by integrating with Angela's `context_manager` and `rollback_manager`. It aims to provide a comprehensive suite of operations such as listing (`ls`), creating (`mkdir`, `touch`), deleting (`rmdir`, `rm`), copying (`cp`), moving (`mv`), reading (`cat`), and writing (`write`) files, all augmented with rich console output and Angela's operational oversight. The module heavily relies on `typer` for its command structure and `rich` for visually appealing outputs, including tables, syntax-highlighted file previews, and interactive prompts; asynchronous filesystem operations are imported from `angela.execution.filesystem`. Commands like `ls` offer detailed views with file types and sizes, while `cat` provides syntax highlighting based on language detection from `context_manager`. Operations such as `mkdir` or `rm` include safety features like `--dry-run` and interact with `rollback_manager` to allow for undoing actions. Furthermore, it includes a `find` command for pattern-based file searching and an `info` command to display detailed metadata and previews for specified files or directories.
**`angela/context/history.py`**
The `angela/context/history.py` module provides the `HistoryManager` class, a crucial component for logging and analyzing user command interactions within the Angela ecosystem, supporting features like command suggestions and usage pattern identification. Its purpose is to persistently record details of each executed command—including the raw command, natural language query, success status, output, and risk level—and to derive actionable insights from this historical data. Technical implementation involves `CommandRecord` and `CommandPattern` data classes, with history and learned patterns stored in JSON files (`command_history.json`, `command_patterns.json`) managed by `config_manager` and influenced by `preferences_manager`. The `add_command` method logs new entries and triggers `_update_patterns` which uses `_extract_base_command` to intelligently group commands (e.g., "git commit") and update their frequency and success rates. Retrieval methods like `get_recent_commands`, `get_command_frequency`, and `get_command_success_rate` allow access to this data. Advanced analysis functions include `search_similar_command` using Jaccard similarity on natural language requests and `get_common_command_contexts` to identify typical command sequences.
**`angela/context/file_activity.py`**
This module, `angela/context/file_activity.py`, implements the `FileActivityTracker` to monitor and log interactions with files and directories within the Angela environment, providing a basis for features like "recently used files" and project activity analysis. Its core purpose is to capture various file events such as creations, modifications, deletions, and views, associating them with metadata like timestamps, the triggering command, and custom details for later retrieval and analysis. The system uses an `ActivityType` enum to classify events and a `FileActivity` class to structure logged data, which is maintained in an in-memory list with a configurable maximum size and integrated with `session_manager` to enrich Angela's session context. The `track_activity` method and its specialized wrappers (e.g., `track_file_creation`) are central to logging, appending new `FileActivity` objects and updating the session. Users can query this log via methods like `get_recent_activities`, which returns time-sorted activities filterable by type, and `get_most_active_files`, which aggregates data to highlight frequently accessed files. The `FileActivity` class supports dictionary conversion for serialization, although the primary activity list is currently managed in memory.
---
**`angela/context/preferences.py`**
This module provides a `PreferencesManager` class to handle user-configurable settings for the Angela application, influencing behavior related to command trust, UI presentation, and context management. It utilizes Pydantic `BaseModel`s (`TrustPreferences`, `UIPreferences`, `ContextPreferences`, nested under `UserPreferences`) to define a structured, validated schema for all preferences, which are persistently stored and retrieved from a `preferences.json` file located via `config_manager`. The `PreferencesManager` loads these settings upon initialization, creates a default file if one doesn't exist, and provides methods to update and save any changes back to the JSON file. Key functionalities include the `should_auto_execute` method, which determines if a command requires user confirmation based on its risk level (from `angela.constants.RISK_LEVELS`) and the user's `TrustPreferences`, including lists of explicitly trusted or untrusted commands. Users can dynamically modify these trusted/untrusted command lists through dedicated methods like `add_trusted_command`. A global instance, `preferences_manager`, makes these settings readily accessible throughout the Angela application, allowing other components to adapt their behavior accordingly.
---
**1. `angela/ai/analyzer.py`**
This module implements an `ErrorAnalyzer` class within Angela's AI capabilities, tasked with diagnosing command-line execution errors to offer users insightful feedback and potential solutions. It operates by matching error messages against a predefined list of `ERROR_PATTERNS` (regex, explanations, suggestions), analyzing command syntax with `shlex`, and checking for issues related to file references like non-existence or permission problems. The analyzer also consults the `history_manager` to find previously successful fixes for similar errors, enabling a degree of learning. Key methods like `_extract_key_error` simplify verbose errors, while `_check_file_references` intelligently suggests corrections for mistyped paths by looking for similar filenames in the parent directory. The `_analyze_command_structure` method identifies common syntactic pitfalls, such as missing arguments or malformed flags. Finally, `generate_fix_suggestions` consolidates all findings into a de-duplicated list of actionable advice for the user.
-----
**`angela/ai/content_analyzer.py` (ContentAnalyzer)**
The `angela/ai/content_analyzer.py` module provides the `ContentAnalyzer` class, empowering Angela with AI-driven functionalities to understand, summarize, manipulate, and search within file contents based on natural language instructions. It interfaces with an AI service (`gemini_client`), constructing detailed, asynchronous prompts that incorporate file content (truncated for token limits), detected file type (via `detect_file_type`), and the user's specific request. Core asynchronous methods include `analyze_content` for deep understanding, `summarize_content` for brevity, `manipulate_content` which attempts to apply changes and generates a `difflib` diff, and `search_content` for natural language querying of file text. Private methods like `_build_analysis_prompt` tailor AI requests for different file types and tasks, while `_extract_modified_content` and `_parse_search_results` robustly handle parsing the AI's textual output, often looking for markdown code blocks or specific line number patterns. This system allows Angela to offer intelligent assistance directly related to the substance of user files.
----
**`angela/ai/intent_analyzer.py` (IntentAnalyzer)**
This module defines the `IntentAnalyzer` for Angela's natural language understanding, designed to interpret user requests, identify the core intent (e.g., "file_search", "git_operation"), extract relevant entities, and manage ambiguity, potentially through interactive clarification. It employs request normalization by correcting common misspellings defined in `SPELLING_VARIATIONS` and then uses `difflib.SequenceMatcher` for fuzzy matching against predefined `INTENT_PATTERNS` to determine the most likely intent and a confidence score, outputting an `IntentAnalysisResult` Pydantic model. Entity extraction, performed by `_extract_entities`, uses intent-specific regular expressions to capture parameters like file paths or search terms from the normalized input. If ambiguity arises (e.g., multiple intents with close scores), the `get_interactive_disambiguation` method can leverage `prompt_toolkit.radiolist_dialog` to ask the user for clarification, refining the analysis. This system aims for robust interpretation of user commands, accommodating variations and offering a mechanism for resolving uncertainty.
----
**`angela/execution/hooks.py` (ExecutionHooks)**
The `angela/execution/hooks.py` module introduces the `ExecutionHooks` class, which integrates into Angela's command execution pipeline to automatically track file activities and enrich contextual understanding without explicit logging at every interaction point. It provides asynchronous `pre_execute_command` and `post_execute_command` methods that analyze command strings and their output for file paths using string parsing and regex, subsequently logging interactions like views, creations, or modifications with the `file_activity_tracker` using appropriate `ActivityType` enums. Specific common commands (e.g., `cat`, `rm`, `cp`, `echo >`) are explicitly handled in `post_execute_command` to infer the correct activity type, resolving paths against the current working directory from the provided context. Furthermore, `post_execute_file_operation` is tailored for Angela's internal filesystem calls, ensuring actions like `create_file` or `write_file` are accurately logged, thus building a comprehensive history of file interactions.
----
**`angela/context/file_detector.py`**
This module is crucial for Angela's contextual awareness, providing the `detect_file_type` function to identify file characteristics such as general type (e.g., image, text, source_code), specific programming language, MIME type, and binary status. It employs a multi-layered detection strategy, using Python's `mimetypes` library, extensive predefined dictionaries like `LANGUAGE_EXTENSIONS` (e.g., `.py` to Python) and `FILENAME_MAPPING` (e.g., `Dockerfile` to Docker), and checking for common `SHEBANG_PATTERNS` in the first line of text files. A binary check is performed by searching for null bytes in an initial chunk of the file, and the module also offers a `get_content_preview` function to display the beginning of text files. This detailed file information is then used by other Angela components for tasks like syntax highlighting, forming appropriate AI prompts, or deciding on safe file handling procedures.
----
Okay, here are the high-level, contextual explanations for the requested files, adhering to the sentence limits.
**File: `angela/intent/enhanced_task_planner.py` (10 Sentences)**
This file, located at `angela/intent/enhanced_task_planner.py`, defines the core logic for executing complex, multi-step tasks within the Angela CLI. Its primary purpose is to orchestrate advanced plans generated by the AI, going beyond simple command sequences. It introduces robust support for diverse step types including shell commands (`COMMAND`), sandboxed code execution (`CODE` - Python, JS, Shell), file manipulations (`FILE`), API calls (`API`), conditional branching (`DECISION`), and loops (`LOOP`). Key classes like `StepExecutionContext`, `DataFlowVariable`, and `ExecutionResult` manage state and data flow between these varied steps. The `EnhancedTaskPlanner` class contains the main execution loop (`execute_advanced_plan`) which handles dependency resolution, step execution via specific methods like `_execute_code_step` or `_execute_api_step`, and variable passing using `${variable}` syntax. Security for code execution is addressed via validation (`_validate_code_security`) and a sandboxing setup (`_setup_code_sandbox`). It integrates with the `ErrorRecoveryManager` (`_attempt_recovery`) for resilience against step failures. It also connects with the `RollbackManager` to record actions within transactions. Ultimately, this module enables Angela to autonomously handle sophisticated user requests requiring intricate sequences of actions and dynamic control flow. The global `task_planner` instance is replaced by this enhanced version to integrate these capabilities seamlessly.
--------
**File: `angela/toolchain/package_managers.py` (8 Sentences)**
Located at `angela/toolchain/package_managers.py`, this file provides integration with various software package managers. Its main purpose is to allow Angela to detect the appropriate package manager for a project (like pip, npm, yarn, poetry, cargo) and use it to install necessary dependencies, often as part of automated project scaffolding or feature addition. The central class, `PackageManagerIntegration`, contains methods like `detect_package_manager` which checks for indicator files (e.g., `requirements.txt`, `package.json`, `Cargo.toml`) and `install_dependencies` which orchestrates the installation process. Specific internal methods like `_install_pip_dependencies`, `_install_npm_dependencies`, etc., handle the nuances of each manager. It interacts with the `execution_engine` to run the actual installation commands (e.g., `pip install <package>`, `npm install <package>`). It also includes logic to infer the project type if not explicitly provided, ensuring the correct manager is invoked. This module automates a crucial part of the development setup process.
----------
**File: `angela/cli/rollback_commands.py` (8 Sentences)**
This file, `angela/cli/rollback_commands.py`, defines the command-line interface for Angela's enhanced rollback system. Its purpose is to expose the functionality of the `RollbackManager` (`angela/execution/rollback.py`) directly to the user via `typer` commands. It includes commands like `list` (to view recent operations or transactions), `operation <ID>` (to roll back a single specific action), `transaction <ID>` (to roll back a group of related actions), and `last` (as a shortcut for the most recent operation or transaction). These commands interact asynchronously with the `rollback_manager` to fetch history and trigger rollback actions. The file uses the `rich` library to display tables and panels for presenting rollback information clearly. It also incorporates confirmation prompts (`rich.prompt.Confirm`) before executing potentially irreversible rollbacks, ensuring user control over the undo process.
------
**File: `angela/execution/filesystem.py` (8 Sentences)**
Located at `angela/execution/filesystem.py`, this module offers a safe and reliable abstraction layer for performing common file system operations within Angela. It provides asynchronous functions like `create_directory`, `delete_directory`, `create_file`, `read_file`, `write_file`, `delete_file`, `copy_file`, and `move_file`. A key feature is its integration with the safety system (`check_operation_safety`) to validate operations before execution and prevent unintended dangerous actions. It defines a custom `FileSystemError` for specific error handling. Crucially, for potentially destructive operations (delete, write, move), it interacts with the `RollbackManager` by creating backups (`_backup_file`, `_backup_directory`) in a temporary location (`BACKUP_DIR`), enabling these operations to be undone. It leverages Python's standard `pathlib`, `os`, and `shutil` modules for the underlying file manipulations.
------
**File: `angela/review/feedback.py` (8 Sentences)**
This file, `angela/review/feedback.py`, manages the processing of user feedback to iteratively refine generated code or modify existing project files. Its central component is the `FeedbackManager` class. The core function `process_feedback` takes user feedback text and original code, constructs a detailed prompt using `_build_improvement_prompt`, and leverages the AI client (`ai/client.py`) to generate an improved code version along with an explanation. It utilizes the `DiffManager` (`review/diff_manager.py`) to compute and present the differences between the original and improved code. The module also supports project-wide refinement (`refine_project`), optionally focusing on specific files, and applying these generated changes back to the filesystem (`apply_refinements`), potentially creating backups. It includes helper functions for language detection (`_get_language_from_extension`) and identifying relevant files based on feedback (`_find_relevant_files`).
-------
**File: `angela/review/diff_manager.py` (8 Sentences)**
Located at `angela/review/diff_manager.py`, this module is responsible for generating and applying differences (diffs) between text strings or file contents. The main class `DiffManager` uses Python's built-in `difflib` module to perform these comparisons. Its primary function, `generate_diff`, creates a standard unified diff output showing additions and deletions between two versions of text. It also provides methods for generating diffs directly between files (`generate_file_diff`), comparing entire directories (`generate_directory_diff`), and creating HTML-formatted diffs (`generate_html_diff`). Additionally, it includes an `apply_diff` method (though noted as potentially simplified) to patch original content using a provided diff string. This manager is primarily used by the `FeedbackManager` to visualize code changes suggested by the AI.
--------
**File: `angela/generation/documentation.py` (8 Sentences)**
This file, `angela/generation/documentation.py`, houses the `DocumentationGenerator` class, responsible for automatically creating various documentation files for software projects using AI. It offers functions like `generate_readme`, `generate_api_docs`, `generate_user_guide`, and `generate_contributing_guide`. The process typically involves analyzing the target project (`_analyze_project`) to gather context (like project type, files, dependencies), constructing specific prompts (`_build_readme_prompt`, etc.), and then querying the Gemini AI (`ai/client.py`) to generate the content in Markdown format. For API documentation, it includes basic code parsing helpers (`_parse_python_file`, `_parse_js_file`, `_parse_java_file`) to extract information about classes and functions to feed into the AI prompt. It uses `_extract_markdown_content` to clean up the AI's response, ensuring well-formatted documentation output.
------
**File: `angela/generation/frameworks.py` (8 Sentences)**
Located at `angela/generation/frameworks.py`, this file provides specialized generators for creating boilerplate project structures tailored to popular software frameworks like React, Django, Flask, Spring, etc. The core `FrameworkGenerator` class uses a dictionary (`_framework_generators`) to map framework names to specific generation methods (e.g., `_generate_react`, `_generate_django`). These methods define a standard file layout for the framework and typically use AI calls via `_generate_content` or `_generate_file_content` to populate these files with appropriate starter code and configuration. For frameworks without a dedicated generator, it falls back to a generic AI-driven approach (`_generate_generic`) to plan the structure. This module allows Angela to quickly scaffold new projects with conventional layouts, interacting closely with the main `CodeGenerationEngine`.
----------
**File: `angela/intent/planner.py`**
Located at `angela/intent/planner.py`, this module serves as the core task planning engine for the Angela CLI, responsible for decomposing high-level user goals into structured, executable plans. It defines Pydantic models for both basic sequential plans (`TaskPlan`, `PlanStep`) and more complex, potentially non-linear plans (`AdvancedTaskPlan`, `AdvancedPlanStep`) supporting various action types like commands, code execution, file operations, API calls, decisions, and loops (`PlanStepType`). The central `TaskPlanner` class determines the required plan complexity (`_determine_complexity`) and orchestrates the plan generation by interacting with the AI model (`ai/client.py`). It builds specific prompts (`_build_planning_prompt`, `_build_advanced_planning_prompt`) incorporating user context and parses the AI's JSON response (`_parse_plan_response`, `_parse_advanced_plan_response`) into the corresponding plan model. While the execution of *advanced* plans is delegated (primarily to `enhanced_task_planner.py`), this module contains the logic for generating both basic and advanced plans and executing basic sequential plans (`_execute_basic_plan`). It is invoked by the `Orchestrator` for requests identified as needing multi-step execution. This file essentially translates abstract user goals into concrete, step-by-step instructions for Angela to follow.
-----
# Current Project Tree/Structure
```bash
.

├── README.md
├── angela
│   ├── __init__.py
│   ├── __main__.py
│   ├── ai
│   │   ├── __init__.py
│   │   ├── analyzer.py
│   │   ├── client.py
│   │   ├── confidence.py
│   │   ├── content_analyzer.py
│   │   ├── content_analyzer_extensions.py
│   │   ├── file_integration.py
│   │   ├── intent_analyzer.py
│   │   ├── parser.py
│   │   └── prompts.py
│   ├── cli
│   │   ├── __init__.py
│   │   ├── files.py
│   │   ├── files_extensions.py
│   │   ├── generation.py
│   │   ├── main.py
│   │   └── workflows.py
│   ├── config.py
│   ├── constants.py
│   ├── context
│   │   ├── __init__.py
│   │   ├── enhancer.py
│   │   ├── file_activity.py
│   │   ├── file_detector.py
│   │   ├── file_resolver.py
│   │   ├── history.py
│   │   ├── manager.py
│   │   ├── preferences.py
│   │   ├── project_inference.py
│   │   └── session.py
│   ├── core
│   │   ├── __init__.py
│   │   ├── events.py
│   │   └── registry.py
│   ├── execution
│   │   ├── __init__.py
│   │   ├── adaptive_engine.py
│   │   ├── engine.py
│   │   ├── error_recovery.py
│   │   ├── filesystem.py
│   │   ├── hooks.py
│   │   ├── rollback.py
│   │   └── rollback_commands.py
│   ├── generation
│   │   ├── __init__.py
│   │   ├── architecture.py
│   │   ├── documentation.py
│   │   ├── engine.py
│   │   ├── frameworks.py
│   │   ├── planner.py
│   │   └── validators.py
│   ├── integrations
│   │   ├── __init__.py
│   │   └── enhanced_planner_integration.py
│   ├── intent
│   │   ├── __init__.py
│   │   ├── enhanced_task_planner.py
│   │   ├── models.py
│   │   └── planner.py
│   ├── interfaces
│   │   ├── __init__.py
│   │   ├── execution.py
│   │   └── safety.py
│   ├── monitoring
│   │   ├── __init__.py
│   │   ├── background.py
│   │   ├── network_monitor.py
│   │   └── notification_handler.py
│   ├── orchestrator.py
│   ├── review
│   │   ├── __init__.py
│   │   ├── diff_manager.py
│   │   └── feedback.py
│   ├── safety
│   │   ├── __init__.py
│   │   ├── adaptive_confirmation.py
│   │   ├── classifier.py
│   │   ├── confirmation.py
│   │   ├── preview.py
│   │   └── validator.py
│   ├── shell
│   │   ├── __init__.py
│   │   ├── advanced_formatter.py
│   │   ├── angela.bash
│   │   ├── angela.tmux
│   │   ├── angela.zsh
│   │   ├── angela_enhanced.bash
│   │   ├── angela_enhanced.zsh
│   │   ├── completion.py
│   │   ├── formatter.py
│   │   └── inline_feedback.py
│   ├── toolchain
│   │   ├── __init__.py
│   │   ├── ci_cd.py
│   │   ├── git.py
│   │   └── package_managers.py
│   ├── utils
│   │   ├── __init__.py
│   │   ├── enhanced_logging.py
│   │   └── logging.py
│   └── workflows
│       ├── __init__.py
│       ├── manager.py
│       └── sharing.py
├── pyproject.toml
├── pytest.ini
├── requirements.txt
├── scripts
│   ├── install.sh
│   └── uninstall.sh
├── setup.py
```
