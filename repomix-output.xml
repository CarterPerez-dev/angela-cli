This file is a merged representation of a subset of the codebase, containing files not matching ignore patterns, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching these patterns are excluded: **/__pycache__/**, **/.git/**, **/node_modules/**, **/.venv/**, **/target/**, **/dist/**, **/build/**, **/tests/**
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

<additional_info>

</additional_info>

</file_summary>

<directory_structure>
angela/
  ai/
    __init__.py
    analyzer.py
    client.py
    confidence.py
    content_analyzer_extensions.py
    content_analyzer.py
    enhanced_prompts.py
    file_integration.py
    intent_analyzer.py
    parser.py
    prompts.py
    semantic_analyzer.py
  cli/
    __init__.py
    docker.py
    files_extensions.py
    files.py
    generation.py
    main.py
    workflows.py
  context/
    __init__.py
    enhanced_file_activity.py
    enhancer.py
    file_activity.py
    file_detector.py
    file_resolver.py
    history.py
    manager.py
    preferences.py
    project_inference.py
    project_state_analyzer.py
    semantic_context_manager.py
    session.py
  core/
    __init__.py
    events.py
    registry.py
  execution/
    __init__.py
    adaptive_engine.py
    engine.py
    error_recovery.py
    filesystem.py
    hooks.py
    rollback_commands.py
    rollback.py
  generation/
    __init__.py
    architecture.py
    documentation.py
    engine.py
    frameworks.py
    planner.py
    validators.py
  integrations/
    __init__.py
    enhanced_planner_integration.py
    semantic_integration.py
  intent/
    __init__.py
    enhanced_task_planner.py
    models.py
    planner.py
    semantic_task_planner.py
  interfaces/
    __init__.py
    execution.py
    safety.py
  monitoring/
    __init__.py
    background.py
    network_monitor.py
    notification_handler.py
  review/
    __init__.py
    diff_manager.py
    feedback.py
  safety/
    __init__.py
    adaptive_confirmation.py
    classifier.py
    confirmation.py
    preview.py
    validator.py
  shell/
    __init__.py
    advanced_formatter.py
    angela_enhanced.bash
    angela_enhanced.zsh
    angela.bash
    angela.tmux
    angela.zsh
    completion.py
    formatter.py
    inline_feedback.py
  toolchain/
    __init__.py
    ci_cd.py
    docker.py
    git.py
    package_managers.py
  utils/
    __init__.py
    enhanced_logging.py
    logging.py
  workflows/
    __init__.py
    manager.py
    sharing.py
  __init__.py
  __main__.py
  config.py
  constants.py
  orchestrator.py
MD/
  ImplemenationsMD/
    Phase_5_implementation.md
    Phase_6_implementation.md
    planner_implementation.md
    rollback_implementation.md
    shell_enhancement.md
  MDHelpers/
    context.md
    Files.md
    Info.md
    tree.md
  PhasesMD/
    Phase1.md
    Phase2.md
    Phase3.md
    Phase4.md
    Phase5.md
    Phase6.md
    Phase7.md
  Next-Steps.md
scripts/
  install.sh
  uninstall.sh
.env.example
.gitignore
Makefile
pyproject.toml
pytest.ini
README.md
requirements.txt
setup.py
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="angela/ai/analyzer.py">
# angela/ai/analyzer.py

import re
import os
import sys
import shlex
from pathlib import Path
from typing import Dict, Any, Optional, List, Tuple, Union

from angela.context.history import history_manager
from angela.utils.logging import get_logger

logger = get_logger(__name__)

class ErrorAnalyzer:
    """Analyzer for command errors with fix suggestions."""
    
    # Common error patterns and their explanations/fixes
    ERROR_PATTERNS = [
        # File not found
        (r'No such file or directory', 'The specified file or directory does not exist', [
            'Check if the path is correct',
            'Use ls to view available files',
            'Use find to search for the file'
        ]),
        # Permission denied
        (r'Permission denied', 'You don\'t have sufficient permissions', [
            'Check file permissions with ls -l',
            'Use sudo for operations requiring elevated privileges',
            'Change permissions with chmod'
        ]),
        # Command not found
        (r'command not found', 'The command is not installed or not in PATH', [
            'Check if the command is installed',
            'Install the package containing the command',
            'Check your PATH environment variable'
        ]),
        # Syntax errors
        (r'syntax error', 'There\'s a syntax error in the command', [
            'Check for missing quotes or brackets',
            'Check the command documentation for correct syntax',
            'Simplify the command and try again'
        ]),
        # Network errors
        (r'(Connection refused|Network is unreachable)', 'Network connection issue', [
            'Check if the host is reachable',
            'Verify network connectivity',
            'Check if the service is running on the target host'
        ])
    ]
    
    def __init__(self):
        """Initialize the error analyzer."""
        self._logger = logger
    
    def analyze_error(self, command: str, error: str) -> Dict[str, Any]:
        """
        Analyze a command error and provide fix suggestions.
        
        Args:
            command: The failed command
            error: The error output
            
        Returns:
            Dictionary with analysis and suggestions
        """
        self._logger.debug(f"Analyzing error for command: {command}")
        
        # Extract the important parts of the error
        error_short = self._extract_key_error(error)
        
        # Check for known error patterns
        pattern_match = self._match_error_pattern(error)
        
        # Check command history for similar errors and their fixes
        historical_fixes = history_manager.find_error_patterns(error_short)
        
        # Analyze command structure for potential issues
        command_issues = self._analyze_command_structure(command)
        
        # Check for missing files or directories
        file_issues = self._check_file_references(command, error)
        
        # Build the response
        result = {
            "error_summary": error_short,
            "possible_cause": pattern_match[1] if pattern_match else "Unknown error",
            "fix_suggestions": pattern_match[2] if pattern_match else [],
            "historical_fixes": [fix for _, fix in historical_fixes],
            "command_issues": command_issues,
            "file_issues": file_issues
        }
        
        return result
    
    def _extract_key_error(self, error: str) -> str:
        """
        Extract the key part of an error message.
        
        Args:
            error: The full error output
            
        Returns:
            A shorter, more focused error message
        """
        # Split by lines and remove empty ones
        lines = [line.strip() for line in error.splitlines() if line.strip()]
        
        if not lines:
            return "Unknown error"
        
        # Check for common error patterns in the first few lines
        for line in lines[:3]:
            # Look for lines with "error" or "ERROR"
            if "error" in line.lower():
                return line
            
            # Look for lines with common error indicators
            for pattern, _, _ in self.ERROR_PATTERNS:
                if re.search(pattern, line, re.IGNORECASE):
                    return line
        
        # If no clear error pattern is found, return the first line
        return lines[0]
    
    def _match_error_pattern(self, error: str) -> Optional[Tuple[str, str, List[str]]]:
        """
        Match an error against known patterns.
        
        Args:
            error: The error output
            
        Returns:
            Tuple of (pattern, explanation, fixes) or None if no match
        """
        for pattern, explanation, fixes in self.ERROR_PATTERNS:
            if re.search(pattern, error, re.IGNORECASE):
                return (pattern, explanation, fixes)
        
        return None
    
    def _analyze_command_structure(self, command: str) -> List[str]:
        """
        Analyze command structure for potential issues.
        
        Args:
            command: The command string
            
        Returns:
            List of potential issues
        """
        issues = []
        
        # Check if the command is empty
        if not command.strip():
            issues.append("Command is empty")
            return issues
        
        try:
            # Try to parse the command with shlex
            tokens = shlex.split(command)
            
            # Check for basic command structure
            if not tokens:
                issues.append("Command parsing failed")
                return issues
            
            base_cmd = tokens[0]
            
            # Check for redirect without command
            if base_cmd in ['>', '>>', '<']:
                issues.append("Redirect symbol used as command")
            
            # Check for pipe without command
            if base_cmd == '|':
                issues.append("Pipe symbol used as command")
            
            # Check for unbalanced quotes (shlex would have raised an error)
            
            # Check for missing arguments in common commands
            if len(tokens) == 1:
                if base_cmd in ['cp', 'mv', 'ln']:
                    issues.append(f"{base_cmd} requires source and destination arguments")
                elif base_cmd in ['grep', 'sed', 'awk']:
                    issues.append(f"{base_cmd} requires a pattern and input")
            
            # Check for potentially incorrect flag formats
            for token in tokens[1:]:
                if token.startswith('-') and len(token) > 2 and not token.startswith('--'):
                    # Might be combining single-letter flags incorrectly
                    if any(not c.isalpha() for c in token[1:]):
                        issues.append(f"Potentially malformed flag: {token}")
            
        except ValueError as e:
            # This typically happens with unbalanced quotes
            issues.append(f"Command parsing error: {str(e)}")
        
        return issues
    
    def _check_file_references(self, command: str, error: str) -> List[Dict[str, Any]]:
        """
        Check for file references in the command that might be causing issues.
        
        Args:
            command: The command string
            error: The error output
            
        Returns:
            List of file issues
        """
        issues = []
        
        # Extract potential file paths from the command
        try:
            tokens = shlex.split(command)
            
            # Skip the command name
            potential_paths = []
            for token in tokens[1:]:
                # Skip options
                if token.startswith('-'):
                    continue
                
                # Skip operators
                if token in ['|', '>', '>>', '<', '&&', '||', ';']:
                    continue
                
                # Consider as potential path
                potential_paths.append(token)
            
            # Check if the paths exist
            for path_str in potential_paths:
                path = Path(path_str)
                
                # Only check if it looks like a path
                if '/' in path_str or '.' in path_str:
                    issue = {"path": path_str}
                    
                    if not path.exists():
                        issue["exists"] = False
                        issue["suggestion"] = f"File/directory does not exist: {path_str}"
                        
                        # Check for common typos
                        parent = path.parent
                        if parent.exists():
                            # Check for similar files in the same directory
                            similar_files = []
                            try:
                                for p in parent.iterdir():
                                    # Simple similarity: Levenshtein distance approximation
                                    if p.name.startswith(path.name[:2]) or p.name.endswith(path.name[-2:]):
                                        similar_files.append(p.name)
                            except (PermissionError, OSError):
                                pass
                            
                            if similar_files:
                                issue["similar_files"] = similar_files[:3]  # Limit to top 3
                        
                        issues.append(issue)
                    else:
                        # Check for permission issues
                        issue["exists"] = True
                        if "Permission denied" in error and not os.access(path, os.R_OK):
                            issue["permission"] = False
                            issue["suggestion"] = f"Permission denied for: {path_str}"
                            issues.append(issue)
        
        except Exception as e:
            logger.exception(f"Error checking file references: {str(e)}")
        
        return issues
    
    def generate_fix_suggestions(self, command: str, error: str) -> List[str]:
        """
        Generate fix suggestions for a failed command.
        
        Args:
            command: The failed command
            error: The error output
            
        Returns:
            List of suggested fixes
        """
        # Analyze the error
        analysis = self.analyze_error(command, error)
        
        # Combine all suggestions
        suggestions = []
        
        # Add suggestions from pattern matching
        suggestions.extend(analysis["fix_suggestions"])
        
        # Add suggestions from historical fixes
        if analysis["historical_fixes"]:
            for i, fix in enumerate(analysis["historical_fixes"], 1):
                suggestions.append(f"Previous fix: {fix}")
        
        # Add suggestions from command issues
        for issue in analysis["command_issues"]:
            if issue == "Command parsing failed":
                suggestions.append("Check for unbalanced quotes or special characters")
            elif "requires" in issue:
                suggestions.append(issue)  # Already a suggestion
            elif "flag" in issue:
                suggestions.append("Check command flags format")
        
        # Add suggestions from file issues
        for issue in analysis["file_issues"]:
            if "suggestion" in issue:
                suggestions.append(issue["suggestion"])
            
            if "similar_files" in issue:
                similar = ", ".join(issue["similar_files"])
                suggestions.append(f"Did you mean one of these: {similar}?")
        
        # Deduplicate suggestions
        unique_suggestions = []
        seen = set()
        for suggestion in suggestions:
            suggestion_key = suggestion.lower()
            if suggestion_key not in seen:
                seen.add(suggestion_key)
                unique_suggestions.append(suggestion)
        
        return unique_suggestions

# Global error analyzer instance
error_analyzer = ErrorAnalyzer()
</file>

<file path="angela/ai/confidence.py">
# angela/ai/confidence.py

import re
from typing import Dict, Any, List, Tuple, Optional

from angela.context.history import history_manager
from angela.utils.logging import get_logger

logger = get_logger(__name__)

class ConfidenceScorer:
    """
    System for scoring confidence in natural language understanding
    and command suggestions.
    """
    
    def __init__(self):
        """Initialize the confidence scorer."""
        self._logger = logger
    
    def score_command_confidence(
        self, 
        request: str, 
        command: str, 
        context: Dict[str, Any]
    ) -> float:
        """
        Score confidence in a command suggestion.
        
        Args:
            request: The original request
            command: The suggested command
            context: Context information
            
        Returns:
            Confidence score (0.0-1.0)
        """
        # Base confidence starts at 0.7 (moderate default)
        confidence = 0.7
        
        # 1. Check if similar commands have been used before
        historical_confidence = self._check_history(command)
        
        # 2. Check command complexity vs. request complexity
        complexity_confidence = self._check_complexity(request, command)
        
        # 3. Check for entity matches
        entity_confidence = self._check_entities(request, command, context)
        
        # 4. Check for flags/options that seem out of place
        flags_confidence = self._check_command_flags(command)
        
        # Combine all factors (with weights)
        confidence = (
            0.3 * historical_confidence + 
            0.3 * complexity_confidence + 
            0.3 * entity_confidence + 
            0.1 * flags_confidence
        )
        
        # Ensure we stay in valid range
        confidence = min(1.0, max(0.0, confidence))
        
        self._logger.debug(f"Command confidence: {confidence:.2f} (hist: {historical_confidence:.2f}, " 
                          f"comp: {complexity_confidence:.2f}, ent: {entity_confidence:.2f}, " 
                          f"flags: {flags_confidence:.2f})")
        
        return confidence
    
    def _check_history(self, command: str) -> float:
        """
        Check if similar commands have been used before.
        
        Args:
            command: The suggested command
            
        Returns:
            Confidence score component (0.0-1.0)
        """
        # Extract the base command (first word)
        base_command = command.split()[0] if command else ""
        
        # Get frequency of this base command
        frequency = history_manager.get_command_frequency(base_command)
        
        # Get success rate
        success_rate = history_manager.get_command_success_rate(base_command)
        
        # Calculate confidence based on frequency and success rate
        if frequency == 0:
            return 0.5  # Neutral for new commands
            
        # Scale based on frequency (up to 10 uses)
        frequency_factor = min(frequency / 10.0, 1.0)
        
        # Combine with success rate
        return 0.5 + (0.5 * frequency_factor * success_rate)
    
    def _check_complexity(self, request: str, command: str) -> float:
        """
        Check if command complexity matches request complexity.
        
        Args:
            request: The original request
            command: The suggested command
            
        Returns:
            Confidence score component (0.0-1.0)
        """
        # Simple heuristic: count tokens in request and command
        request_tokens = len(request.split())
        command_tokens = len(command.split())
        
        # Very simple requests should lead to simple commands
        if request_tokens <= 3 and command_tokens > 10:
            return 0.4  # Low confidence for complex command from simple request
            
        # Complex requests might lead to complex commands
        if request_tokens >= 10 and command_tokens <= 3:
            return 0.6  # Moderate confidence for simple command from complex request
            
        # Ideal ratio is roughly 1:1 to 1:2
        ratio = command_tokens / max(1, request_tokens)
        if 0.5 <= ratio <= 2.0:
            return 0.9  # High confidence when complexity matches
        elif 0.25 <= ratio <= 4.0:
            return 0.7  # Moderate confidence for reasonable mismatch
        else:
            return 0.5  # Low confidence for significant mismatch
    
    def _check_entities(
        self, 
        request: str, 
        command: str, 
        context: Dict[str, Any]
    ) -> float:
        """
        Check if entities in the request match those in the command.
        
        Args:
            request: The original request
            command: The suggested command
            context: Context information
            
        Returns:
            Confidence score component (0.0-1.0)
        """
        # Extract potential entities from request (simple approach)
        request_words = set(request.lower().split())
        
        # Check for important entities
        file_mentions = any(word in request_words for word in ["file", "files", "document", "text"])
        dir_mentions = any(word in request_words for word in ["directory", "folder", "dir"])
        
        # Check if command matches the entity types mentioned
        if file_mentions and not any(ext in command for ext in [".txt", ".md", ".py", ".js", ".html"]):
            return 0.5  # Request mentions files but command doesn't seem to deal with files
            
        if dir_mentions and not any(cmd in command for cmd in ["cd", "mkdir", "rmdir", "ls"]):
            return 0.6  # Request mentions directories but command doesn't seem to deal with directories
        
        # Check for specific paths or filenames
        # This is a simplified approach - real implementation would use regex
        path_pattern = r'[\w/\.-]+'
        request_paths = re.findall(path_pattern, request)
        command_paths = re.findall(path_pattern, command)
        
        if request_paths and not any(rp in command for rp in request_paths):
            return 0.7  # Paths mentioned in request don't appear in command
        
        # Default - reasonable confidence
        return 0.8
    
    def _check_command_flags(self, command: str) -> float:
        """
        Check for unusual flag combinations or invalid options.
        
        Args:
            command: The suggested command
            
        Returns:
            Confidence score component (0.0-1.0)
        """
        # This would ideally have a database of valid flags for common commands
        # For now, just do some basic checks
        
        # Check for potentially conflicting flags
        if "-r" in command and "--no-recursive" in command:
            return 0.3  # Conflicting flags
            
        if "-f" in command and "--interactive" in command:
            return 0.4  # Potentially conflicting (force vs. interactive)
        
        # Check for unusual combinations
        if "rm" in command and "-p" in command:
            return 0.5  # Unusual flag for rm
            
        if "cp" in command and "-l" in command:
            return 0.6  # Unusual flag for cp
        
        # Default - high confidence
        return 0.9

# Global confidence scorer instance
confidence_scorer = ConfidenceScorer()
</file>

<file path="angela/ai/enhanced_prompts.py">
"""
Enhanced prompt engineering for Angela CLI with semantic awareness.

This module extends Angela's prompting capabilities with semantic code understanding,
detailed project state, and nuanced user history for significantly more informed responses.
"""
import os
import re
import json
from pathlib import Path
from typing import Dict, Any, List, Tuple, Optional, Set, Union

from angela.utils.logging import get_logger
from angela.context.file_detector import detect_file_type
from angela.ai.prompts import (
    build_prompt, SYSTEM_INSTRUCTIONS, EXAMPLES, FILE_OPERATION_EXAMPLES,
    ENHANCED_PROJECT_CONTEXT, ERROR_ANALYSIS_PROMPT, MULTI_STEP_OPERATION_PROMPT,
    CODE_GENERATION_PROMPT, RECENT_FILES_CONTEXT, RESOLVED_FILES_CONTEXT,
    FILE_OPERATION_PROMPT_TEMPLATE
)
from angela.context.project_state_analyzer import project_state_analyzer
from angela.ai.semantic_analyzer import semantic_analyzer

logger = get_logger(__name__)

# Enhanced system instructions that highlight semantic understanding
ENHANCED_SYSTEM_INSTRUCTIONS = """
You are Angela, an AI-powered command-line assistant with deep semantic code understanding. 
You are integrated into the user's terminal shell and possess detailed awareness of the code structure, 
project state, and development history.

Your capabilities include:
1. Understanding code at a semantic level - functions, classes, dependencies, and architectural patterns
2. Being aware of the project's state including Git status, pending migrations, and build health
3. Tracking specific code entities (functions, classes, methods) across files
4. Interpreting user intentions in the context of their recent activity
5. Providing intelligent suggestions based on comprehensive project understanding
6. Translating high-level goals into precise, context-appropriate actions

You prioritize:
1. Precision in commands and file operations based on semantic understanding
2. Context-awareness that leverages project structure, state, and dependencies
3. Intelligent code modifications with an understanding of potential impacts
4. Helpful explanations that leverage code entity relationships
5. Proactive suggestions informed by project state (test failures, code quality issues, etc.)
"""

# Semantic code context template
SEMANTIC_CODE_CONTEXT = """
## Semantic Code Understanding
{entity_type}: {entity_name}
Location: {filename}:{line_start}-{line_end}
Summary: {summary}

Related Entities:
{related_entities}

Dependencies:
{dependencies}
"""

# Project state context template
PROJECT_STATE_CONTEXT = """
## Project State
Git Status: {git_status}
Branch: {branch} {remote_state}
Changes: {has_changes} {change_details}

Build Status: {build_status}
Tests: {test_status}
Dependencies: {dependencies_status}

Issues:
{issues_summary}
"""

# Enhanced task planning prompt template
SEMANTIC_TASK_PLANNING_PROMPT = """
I'm going to help you plan a complex task with deep awareness of the project's semantic structure and state.

Project Code Context:
{semantic_code_context}

Project State:
{project_state_context}

Recent Activity:
{recent_activity}

For this request:
"{request}"

Let me break this down into well-structured, semantically-aware steps that account for:
1. Dependencies between code components
2. Potential impacts of changes
3. Current project state considerations
4. Error handling for each step
5. Verification steps after critical operations

Here's my detailed plan:
"""

# Enhanced code manipulation prompt template
SEMANTIC_CODE_MANIPULATION_PROMPT = """
I need to modify code with a detailed understanding of its semantic structure and implications.

## Entity to Modify
{entity_type}: {entity_name}
Purpose: {entity_summary}
Dependencies: {entity_dependencies}
Referenced by: {entity_references}

## Desired Modification
"{instruction}"

## Approach
I'll make this change while:
1. Preserving the function's contract with callers
2. Maintaining consistent error handling
3. Respecting existing patterns
4. Updating related documentation
5. Considering potential impacts on dependent code

## Modified Code
```{language}
{modified_code}
```
"""

# Template for summarizing recent coding activity
CODING_HISTORY_CONTEXT = """
## Recent Coding Activity
Recently Modified Entities:
{recent_entities}

Coding Patterns:
{coding_patterns}

Frequent Operations:
{common_operations}
"""

async def build_enhanced_prompt(
    request: str, 
    context: Dict[str, Any],
    similar_command: Optional[str] = None,
    intent_result: Optional[Dict[str, Any]] = None,
    entity_name: Optional[str] = None
) -> str:
    """
    Build an enhanced prompt for the Gemini API with semantic code understanding
    and project state awareness.
    
    Args:
        request: The user request
        context: Context information about the current environment
        similar_command: Optional similar command from history
        intent_result: Optional intent analysis result
        entity_name: Optional specific code entity to focus on
        
    Returns:
        A prompt string for the AI service with enhanced semantic context
    """
    logger.debug("Building enhanced prompt with semantic awareness")
    
    # Start with basic context information
    enhanced_context = f"Current working directory: {context.get('cwd', 'unknown')}\n"
    
    # Add project root if available
    project_root = context.get('project_root')
    if project_root:
        enhanced_context += f"Project root: {project_root}\n"
        
        # Add project type if available
        project_type = context.get('project_type', 'unknown')
        enhanced_context += f"Project type: {project_type}\n"
        
        # Get enhanced project state if available
        try:
            project_state = await project_state_analyzer.get_project_state(project_root)
            
            # Add Git status
            git_state = project_state.get('git_state', {})
            if git_state.get('is_git_repo', False):
                # Format Git status information
                branch = git_state.get('current_branch', 'unknown')
                has_changes = git_state.get('has_changes', False)
                
                # Format remote state information
                remote_state = git_state.get('remote_state', {})
                remote_info = ""
                if remote_state:
                    ahead = remote_state.get('ahead', 0)
                    behind = remote_state.get('behind', 0)
                    
                    if ahead > 0 and behind > 0:
                        remote_info = f"(ahead {ahead}, behind {behind})"
                    elif ahead > 0:
                        remote_info = f"(ahead {ahead})"
                    elif behind > 0:
                        remote_info = f"(behind {behind})"
                
                # Format change details
                change_details = ""
                if has_changes:
                    modified_count = len(git_state.get('modified_files', []))
                    untracked_count = len(git_state.get('untracked_files', []))
                    staged_count = len(git_state.get('staged_files', []))
                    
                    details = []
                    if modified_count > 0:
                        details.append(f"{modified_count} modified")
                    if untracked_count > 0:
                        details.append(f"{untracked_count} untracked")
                    if staged_count > 0:
                        details.append(f"{staged_count} staged")
                    
                    change_details = f"({', '.join(details)})"
                
                # Add Git information to context
                enhanced_context += PROJECT_STATE_CONTEXT.format(
                    git_status="Active repository" if git_state.get('is_git_repo', False) else "Not a Git repository",
                    branch=branch,
                    remote_state=remote_info,
                    has_changes="With uncommitted changes" if has_changes else "Clean working directory",
                    change_details=change_details,
                    build_status=f"System: {project_state.get('build_status', {}).get('system', 'unknown')}",
                    test_status=f"Framework: {project_state.get('test_status', {}).get('framework', 'unknown')}",
                    dependencies_status=f"Manager: {project_state.get('dependencies', {}).get('package_manager', 'unknown')}",
                    issues_summary=_format_issues_summary(project_state)
                )
            
            # Add build status
            build_status = project_state.get('build_status', {})
            if build_status.get('build_system_detected', False):
                enhanced_context += f"Build system: {build_status.get('system', 'unknown')}\n"
                
                if build_status.get('last_build'):
                    enhanced_context += f"Last build: {build_status.get('last_build')}\n"
            
            # Add test status
            test_status = project_state.get('test_status', {})
            if test_status.get('test_framework_detected', False):
                enhanced_context += f"Test framework: {test_status.get('framework', 'unknown')}\n"
                enhanced_context += f"Test files: {test_status.get('test_files_count', 0)}\n"
                
                if test_status.get('coverage'):
                    enhanced_context += f"Test coverage: {test_status.get('coverage', {}).get('percentage')}%\n"
            
            # Add dependency information
            dependencies = project_state.get('dependencies', {})
            if dependencies.get('has_dependencies', False):
                enhanced_context += f"Package manager: {dependencies.get('package_manager', 'unknown')}\n"
                enhanced_context += f"Dependencies: {dependencies.get('dependencies_count', 0)} main, {dependencies.get('dev_dependencies_count', 0)} dev\n"
                
                if dependencies.get('outdated_packages'):
                    outdated_count = len(dependencies.get('outdated_packages', []))
                    enhanced_context += f"Outdated packages: {outdated_count}\n"
        
        except Exception as e:
            logger.error(f"Error getting project state: {str(e)}")
    
    # Add semantic code information if a specific entity is provided
    if entity_name and project_root:
        try:
            entity_info = await semantic_analyzer.analyze_entity_usage(entity_name, project_root)
            
            if entity_info.get('found', False):
                entity_type = entity_info.get('type', 'unknown')
                filename = entity_info.get('filename', 'unknown')
                line_start = entity_info.get('line_start', 0)
                line_end = entity_info.get('line_end', 0)
                
                # Generate a summary of the entity
                summary = await semantic_analyzer.summarize_code_entity(entity_name, project_root)
                
                # Format related entities
                related = entity_info.get('related_entities', [])
                related_entities = ""
                if related:
                    related_entities = "\n".join([
                        f"- {r.get('name')} ({r.get('relationship')})"
                        for r in related[:5]  # Limit to 5 for brevity
                    ])
                else:
                    related_entities = "None detected"
                
                # Format dependencies
                dependencies = entity_info.get('details', {}).get('dependencies', [])
                dependencies_str = ", ".join(dependencies) if dependencies else "None detected"
                
                # Add semantic information to context
                enhanced_context += SEMANTIC_CODE_CONTEXT.format(
                    entity_type=entity_type.capitalize(),
                    entity_name=entity_name,
                    filename=Path(filename).name,
                    line_start=line_start,
                    line_end=line_end,
                    summary=summary,
                    related_entities=related_entities,
                    dependencies=dependencies_str
                )
        
        except Exception as e:
            logger.error(f"Error getting semantic code information: {str(e)}")
    
    # Add information about the current file if available
    current_file = context.get('current_file')
    if current_file:
        file_path = current_file.get('path')
        enhanced_context += f"Current file: {file_path}\n"
        
        # Try to get semantic information about the current file
        if project_root and file_path:
            try:
                file_path_obj = Path(file_path)
                module = await semantic_analyzer.analyze_file(file_path_obj)
                
                if module:
                    # Add basic module information
                    enhanced_context += f"File type: {module.language} module\n"
                    enhanced_context += f"Functions: {len(module.functions)}\n"
                    enhanced_context += f"Classes: {len(module.classes)}\n"
                    
                    # Add key entities in the file
                    if module.functions or module.classes:
                        enhanced_context += "Key entities:\n"
                        
                        # List top classes
                        for class_name in list(module.classes.keys())[:3]:
                            cls = module.classes[class_name]
                            method_count = len(cls.methods)
                            enhanced_context += f"- Class {class_name} ({method_count} methods)\n"
                        
                        # List top functions
                        for func_name in list(module.functions.keys())[:3]:
                            func = module.functions[func_name]
                            enhanced_context += f"- Function {func_name}({', '.join(func.params)})\n"
            except Exception as e:
                logger.error(f"Error analyzing current file: {str(e)}")
    
    # Add recent file activity information
    recent_files = context.get('recent_files', {})
    if recent_files:
        accessed_files = recent_files.get('accessed', [])
        active_files = recent_files.get('active_files', [])
        
        if accessed_files or active_files:
            enhanced_context += "Recent file activity:\n"
            
            if accessed_files:
                enhanced_context += f"- Accessed: {', '.join([Path(f).name for f in accessed_files[:3]])}\n"
            
            if active_files:
                enhanced_context += f"- Most active: {', '.join([f.get('name', 'unknown') for f in active_files[:3]])}\n"
    
    # Add intent analysis if available
    if intent_result:
        enhanced_context += "\nIntent analysis:\n"
        enhanced_context += f"- Intent type: {intent_result.get('intent_type', 'unknown')}\n"
        enhanced_context += f"- Confidence: {intent_result.get('confidence', 0.0):.2f}\n"
        
        # Add extracted entities
        if intent_result.get("entities"):
            enhanced_context += "- Extracted entities:\n"
            for key, value in intent_result.get("entities", {}).items():
                enhanced_context += f"  - {key}: {value}\n"
    
    # Add similar command suggestion if available
    if similar_command:
        enhanced_context += f"\nYou previously suggested this similar command: {similar_command}\n"
    
    # Add examples for few-shot learning
    examples = "\nExamples:\n"
    
    # Add standard examples
    for example in EXAMPLES:
        examples += f"\nUser request: {example['request']}\n"
        examples += f"Context: {example['context']}\n"
        examples += f"Response: {example['response']}\n"
    
    # Define the expected response format
    response_format = """
Expected response format (valid JSON):
{
    "intent": "the_classified_intent",
    "command": "the_suggested_command",
    "explanation": "explanation of what the command does, including semantic considerations",
    "confidence": 0.85, /* Optional confidence score from 0.0 to 1.0 */
    "semantic_insights": "insights about code/project impacts (optional)",
    "additional_info": "any additional information (optional)"
}
"""
    
    # Build the complete prompt
    prompt = f"{ENHANCED_SYSTEM_INSTRUCTIONS}\n\n{enhanced_context}\n\n{examples}\n\n{response_format}\n\nUser request: {request}\n\nResponse:"
    
    logger.debug(f"Built enhanced prompt with length: {len(prompt)}")
    return prompt

def _format_issues_summary(project_state: Dict[str, Any]) -> str:
    """Format a summary of project issues for the prompt."""
    todo_items = project_state.get('todo_items', [])
    code_quality = project_state.get('code_quality', {})
    issues_count = code_quality.get('issues_count', 0)
    high_priority_issues = code_quality.get('high_priority_issues', [])
    
    summary = []
    
    if todo_items:
        todo_count = len(todo_items)
        fixme_count = sum(1 for item in todo_items if item.get('type') == 'FIXME')
        summary.append(f"{todo_count} TODOs ({fixme_count} FIXMEs)")
    
    if issues_count > 0:
        summary.append(f"{issues_count} linting issues")
    
    if high_priority_issues:
        summary.append(f"{len(high_priority_issues)} high-priority issues")
    
    if not summary:
        return "No significant issues detected"
    
    return ", ".join(summary)

async def build_semantic_code_manipulation_prompt(
    entity_name: str,
    instruction: str,
    project_root: Union[str, Path],
    modified_code: Optional[str] = None
) -> str:
    """
    Build a prompt for modifying code with semantic understanding.
    
    Args:
        entity_name: Name of the entity to modify
        instruction: The modification instruction
        project_root: Path to the project root
        modified_code: Optional modified code to include
        
    Returns:
        A prompt string for code manipulation
    """
    logger.debug(f"Building semantic code manipulation prompt for {entity_name}")
    
    try:
        # Get semantic information about the entity
        entity_info = await semantic_analyzer.analyze_entity_usage(entity_name, project_root)
        
        if not entity_info.get('found', False):
            return f"Could not find entity '{entity_name}' in the project."
        
        # Get entity information
        entity_type = entity_info.get('type', 'unknown')
        filename = entity_info.get('filename', 'unknown')
        line_start = entity_info.get('line_start', 0)
        line_end = entity_info.get('line_end', 0)
        
        # Get a summary of the entity
        entity_summary = await semantic_analyzer.summarize_code_entity(entity_name, project_root)
        
        # Get the entity's code if not provided
        if not modified_code:
            original_code = await semantic_analyzer.get_entity_code(entity_name, project_root)
            modified_code = original_code
        
        # Get file type
        file_info = detect_file_type(Path(filename))
        language = file_info.get('language', '').lower()
        
        # Format references
        related = entity_info.get('related_entities', [])
        references = []
        
        for r in related:
            if r.get('relationship') == 'called_by':
                references.append(f"{r.get('name')} calls this {entity_type}")
            elif r.get('relationship') == 'extended_by':
                references.append(f"{r.get('name')} extends this {entity_type}")
        
        references_str = "\n".join([f"- {ref}" for ref in references]) if references else "None detected"
        
        # Format dependencies
        dependencies = []
        
        if entity_type == 'function' or entity_type == 'method':
            for called in entity_info.get('details', {}).get('called_functions', []):
                dependencies.append(f"Calls {called}")
        
        elif entity_type == 'class':
            for base in entity_info.get('base_classes', []):
                dependencies.append(f"Extends {base}")
        
        dependencies_str = "\n".join([f"- {dep}" for dep in dependencies]) if dependencies else "None detected"
        
        # Build the prompt
        prompt = SEMANTIC_CODE_MANIPULATION_PROMPT.format(
            entity_type=entity_type.capitalize(),
            entity_name=entity_name,
            entity_summary=entity_summary,
            entity_dependencies=dependencies_str,
            entity_references=references_str,
            instruction=instruction,
            language=language,
            modified_code=modified_code
        )
        
        return prompt
    
    except Exception as e:
        logger.error(f"Error building semantic code manipulation prompt: {str(e)}")
        return f"Error building semantic code manipulation prompt: {str(e)}"

async def build_semantic_task_planning_prompt(
    request: str,
    context: Dict[str, Any],
    entity_names: Optional[List[str]] = None
) -> str:
    """
    Build a prompt for task planning with semantic understanding.
    
    Args:
        request: The user request
        context: Context information
        entity_names: Optional list of entity names to focus on
        
    Returns:
        A prompt string for task planning
    """
    logger.debug("Building semantic task planning prompt")
    
    project_root = context.get('project_root')
    if not project_root:
        return build_prompt(request, context)  # Fall back to regular prompt
    
    # Build semantic code context
    semantic_code_context = ""
    
    if entity_names:
        for entity_name in entity_names:
            try:
                entity_info = await semantic_analyzer.analyze_entity_usage(entity_name, project_root)
                
                if entity_info.get('found', False):
                    entity_type = entity_info.get('type', 'unknown')
                    filename = entity_info.get('filename', 'unknown')
                    
                    # Get a summary of the entity
                    summary = await semantic_analyzer.summarize_code_entity(entity_name, project_root)
                    
                    semantic_code_context += f"{entity_type.capitalize()}: {entity_name} in {Path(filename).name}\n"
                    semantic_code_context += f"Summary: {summary}\n\n"
            except Exception as e:
                logger.error(f"Error getting semantic info for {entity_name}: {str(e)}")
    
    # Get project state context
    project_state_context = ""
    
    try:
        # Get project state
        project_state = await project_state_analyzer.get_project_state(project_root)
        
        # Format Git information
        git_state = project_state.get('git_state', {})
        if git_state.get('is_git_repo', False):
            branch = git_state.get('current_branch', 'unknown')
            has_changes = git_state.get('has_changes', False)
            
            project_state_context += f"Git: Branch {branch}, "
            project_state_context += "Uncommitted changes" if has_changes else "Clean working directory"
            project_state_context += "\n"
        
        # Add build status
        build_status = project_state.get('build_status', {})
        if build_status.get('build_system_detected', False):
            project_state_context += f"Build: {build_status.get('system', 'unknown')}"
            
            if build_status.get('last_build'):
                project_state_context += f", Last build at {build_status.get('last_build')}"
            
            project_state_context += "\n"
        
        # Add test status
        test_status = project_state.get('test_status', {})
        if test_status.get('test_framework_detected', False):
            project_state_context += f"Tests: {test_status.get('framework', 'unknown')}, "
            project_state_context += f"{test_status.get('test_files_count', 0)} test files"
            
            if test_status.get('coverage'):
                project_state_context += f", {test_status.get('coverage', {}).get('percentage')}% coverage"
            
            project_state_context += "\n"
        
        # Add code quality issues
        code_quality = project_state.get('code_quality', {})
        if code_quality.get('linting_setup_detected', False):
            project_state_context += f"Linting: {code_quality.get('linter', 'unknown')}, "
            project_state_context += f"{code_quality.get('issues_count', 0)} issues"
            project_state_context += "\n"
        
        # Add TODO items
        todo_items = project_state.get('todo_items', [])
        if todo_items:
            project_state_context += f"TODOs: {len(todo_items)} items "
            
            # Count by type
            todo_counts = {}
            for item in todo_items:
                item_type = item.get('type', 'unknown')
                if item_type not in todo_counts:
                    todo_counts[item_type] = 0
                todo_counts[item_type] += 1
            
            type_counts = [f"{count} {type_}" for type_, count in todo_counts.items()]
            project_state_context += f"({', '.join(type_counts)})"
            project_state_context += "\n"
    
    except Exception as e:
        logger.error(f"Error getting project state: {str(e)}")
    
    # Get recent activity information
    recent_activity = ""
    
    # Add recent file activity
    recent_files = context.get('recent_files', {})
    if recent_files:
        accessed = recent_files.get('accessed', [])
        if accessed:
            recent_activity += "Recently accessed files:\n"
            for file_path in accessed[:5]:
                recent_activity += f"- {Path(file_path).name}\n"
    
    # Add recent commands
    session = context.get('session', {})
    recent_commands = session.get('recent_commands', [])
    if recent_commands:
        recent_activity += "\nRecent commands:\n"
        for cmd in recent_commands[:5]:
            recent_activity += f"- {cmd}\n"
    
    # Build the prompt
    prompt = SEMANTIC_TASK_PLANNING_PROMPT.format(
        semantic_code_context=semantic_code_context or "No specific code entities focused on.",
        project_state_context=project_state_context or "No detailed project state available.",
        recent_activity=recent_activity or "No recent activity recorded.",
        request=request
    )
    
    return prompt
</file>

<file path="angela/ai/file_integration.py">
"""
Integration module for AI-powered file operations.

This module bridges the AI suggestions with actual file operations,
extracting file operations from commands and executing them safely.
"""
import re
import shlex
from pathlib import Path
from typing import Dict, Any, List, Tuple, Optional

from angela.execution.filesystem import (
    create_directory, delete_directory, create_file, read_file,
    write_file, delete_file, copy_file, move_file, FileSystemError
)
from angela.utils.logging import get_logger

logger = get_logger(__name__)

# Patterns for file operation commands
FILE_OPERATION_PATTERNS = [
    # mkdir patterns
    (r"^mkdir\s+(-p\s+)?(.+)$", "create_directory"),
    
    # rmdir and rm -r patterns
    (r"^rmdir\s+(.+)$", "delete_directory"),
    (r"^rm\s+(-r|-rf|--recursive)\s+(.+)$", "delete_directory"),
    
    # touch patterns
    (r"^touch\s+(.+)$", "create_file"),
    
    # cat/less/more patterns (read)
    (r"^(cat|less|more|head|tail)\s+(.+)$", "read_file"),
    
    # echo > patterns (write)
    (r"^echo\s+(.+)\s+>\s+(.+)$", "write_file"),
    (r"^echo\s+(.+)\s+>>\s+(.+)$", "append_file"),
    
    # rm patterns
    (r"^rm\s+(?!-r|--recursive)(.+)$", "delete_file"),
    
    # cp patterns
    (r"^cp\s+(?!-r|--recursive)(.+?)\s+(.+)$", "copy_file"),
    
    # mv patterns
    (r"^mv\s+(.+?)\s+(.+)$", "move_file"),
]

# Specific operation extractors
async def extract_mkdir_operation(command: str) -> Tuple[str, Dict[str, Any]]:
    """Extract mkdir operation parameters from a command."""
    tokens = shlex.split(command)
    
    # Check for -p/--parents flag
    parents = "-p" in tokens or "--parents" in tokens
    
    # Get directory paths
    paths = []
    for arg in tokens[1:]:
        if not arg.startswith("-"):
            paths.append(arg)
    
    return "create_directory", {"path": paths[0] if paths else ".", "parents": parents}


async def extract_rmdir_operation(command: str) -> Tuple[str, Dict[str, Any]]:
    """Extract rmdir operation parameters from a command."""
    tokens = shlex.split(command)
    
    # Check for recursive flag in rm commands
    recursive = any(flag in tokens for flag in ["-r", "-rf", "--recursive", "-R"])
    force = any(flag in tokens for flag in ["-f", "-rf", "--force"])
    
    # Get directory paths
    paths = []
    for arg in tokens[1:]:
        if not arg.startswith("-"):
            paths.append(arg)
    
    return "delete_directory", {
        "path": paths[0] if paths else ".",
        "recursive": recursive,
        "force": force
    }


async def extract_touch_operation(command: str) -> Tuple[str, Dict[str, Any]]:
    """Extract touch operation parameters from a command."""
    tokens = shlex.split(command)
    
    # Get file paths
    paths = []
    for arg in tokens[1:]:
        if not arg.startswith("-"):
            paths.append(arg)
    
    return "create_file", {"path": paths[0] if paths else ".", "content": None}


async def extract_cat_operation(command: str) -> Tuple[str, Dict[str, Any]]:
    """Extract cat operation parameters from a command."""
    tokens = shlex.split(command)
    
    # Get file paths
    paths = []
    for arg in tokens[1:]:
        if not arg.startswith("-"):
            paths.append(arg)
    
    # Check for binary flag
    binary = "-b" in tokens or "--binary" in tokens
    
    return "read_file", {"path": paths[0] if paths else ".", "binary": binary}


async def extract_echo_write_operation(command: str) -> Tuple[str, Dict[str, Any]]:
    """Extract echo write operation parameters from a command."""
    # Determine if this is append (>>) or overwrite (>)
    append = ">>" in command
    
    # Split by redirection operator
    parts = command.split(">>" if append else ">", 1)
    
    # Extract the echo part and the file path
    echo_part = parts[0].strip()[5:]  # Remove 'echo ' prefix
    file_path = parts[1].strip()
    
    # Handle quoted content
    if echo_part.startswith('"') and echo_part.endswith('"'):
        content = echo_part[1:-1]
    elif echo_part.startswith("'") and echo_part.endswith("'"):
        content = echo_part[1:-1]
    else:
        content = echo_part
    
    return "write_file", {
        "path": file_path,
        "content": content,
        "append": append
    }


async def extract_rm_operation(command: str) -> Tuple[str, Dict[str, Any]]:
    """Extract rm operation parameters from a command."""
    tokens = shlex.split(command)
    
    # Check for force flag
    force = "-f" in tokens or "--force" in tokens
    
    # Get file paths
    paths = []
    for arg in tokens[1:]:
        if not arg.startswith("-"):
            paths.append(arg)
    
    return "delete_file", {"path": paths[0] if paths else ".", "force": force}


async def extract_cp_operation(command: str) -> Tuple[str, Dict[str, Any]]:
    """Extract cp operation parameters from a command."""
    tokens = shlex.split(command)
    
    # Check for force/overwrite flag
    overwrite = "-f" in tokens or "--force" in tokens
    
    # Get source and destination
    args = [arg for arg in tokens[1:] if not arg.startswith("-")]
    
    if len(args) >= 2:
        source = args[0]
        destination = args[-1]  # Last argument is always the destination
    else:
        # Not enough arguments
        raise ValueError("cp command requires source and destination")
    
    return "copy_file", {
        "source": source,
        "destination": destination,
        "overwrite": overwrite
    }


async def extract_mv_operation(command: str) -> Tuple[str, Dict[str, Any]]:
    """Extract mv operation parameters from a command."""
    tokens = shlex.split(command)
    
    # Check for force/overwrite flag
    overwrite = "-f" in tokens or "--force" in tokens
    
    # Get source and destination
    args = [arg for arg in tokens[1:] if not arg.startswith("-")]
    
    if len(args) >= 2:
        source = args[0]
        destination = args[-1]  # Last argument is always the destination
    else:
        # Not enough arguments
        raise ValueError("mv command requires source and destination")
    
    return "move_file", {
        "source": source,
        "destination": destination,
        "overwrite": overwrite
    }


# Operation extractors mapping
OPERATION_EXTRACTORS = {
    "mkdir": extract_mkdir_operation,
    "rmdir": extract_rmdir_operation,
    "rm": extract_rmdir_operation if "-r" in "{command}" or "--recursive" in "{command}" else extract_rm_operation,
    "touch": extract_touch_operation,
    "cat": extract_cat_operation,
    "less": extract_cat_operation,
    "more": extract_cat_operation,
    "head": extract_cat_operation,
    "tail": extract_cat_operation,
    "echo": extract_echo_write_operation,
    "cp": extract_cp_operation,
    "mv": extract_mv_operation,
}


async def extract_file_operation(command: str) -> Optional[Tuple[str, Dict[str, Any]]]:
    """
    Extract file operation details from a command string.
    
    Args:
        command: The shell command to analyze.
        
    Returns:
        A tuple of (operation_type, parameters) or None if not a file operation.
    """
    try:
        # Get the base command
        tokens = shlex.split(command)
        if not tokens:
            return None
        
        base_cmd = tokens[0]
        
        # Check if this is a known file operation
        if base_cmd in OPERATION_EXTRACTORS:
            # Use the specific extractor for this command
            extractor = OPERATION_EXTRACTORS[base_cmd]
            
            # For rm, we need to check if it's recursive
            if base_cmd == "rm":
                if any(flag in tokens for flag in ["-r", "-rf", "--recursive", "-R"]):
                    return await extract_rmdir_operation(command)
                else:
                    return await extract_rm_operation(command)
            
            # For other commands, use the registered extractor
            return await extractor(command)
        
        # Fall back to pattern matching
        for pattern, operation_type in FILE_OPERATION_PATTERNS:
            match = re.match(pattern, command)
            if match:
                # Basic extraction based on pattern groups
                if operation_type == "create_directory":
                    return operation_type, {"path": match.group(2), "parents": bool(match.group(1))}
                elif operation_type == "delete_directory":
                    return operation_type, {"path": match.group(1), "recursive": "-r" in command or "-rf" in command}
                elif operation_type == "create_file":
                    return operation_type, {"path": match.group(1), "content": None}
                elif operation_type == "read_file":
                    return operation_type, {"path": match.group(2)}
                elif operation_type == "write_file":
                    return operation_type, {"path": match.group(2), "content": match.group(1), "append": False}
                elif operation_type == "append_file":
                    return operation_type, {"path": match.group(2), "content": match.group(1), "append": True}
                elif operation_type == "delete_file":
                    return operation_type, {"path": match.group(1)}
                elif operation_type == "copy_file":
                    parts = match.group(1).rsplit(" ", 1)
                    if len(parts) == 2:
                        return operation_type, {"source": parts[0], "destination": parts[1]}
                elif operation_type == "move_file":
                    parts = match.group(1).rsplit(" ", 1)
                    if len(parts) == 2:
                        return operation_type, {"source": parts[0], "destination": parts[1]}
        
        # Not a file operation
        return None
    
    except Exception as e:
        logger.exception(f"Error extracting file operation from '{command}': {str(e)}")
        return None


async def execute_file_operation(
    operation_type: str, 
    parameters: Dict[str, Any],
    dry_run: bool = False
) -> Dict[str, Any]:
    """
    Execute a file operation based on type and parameters.
    
    Args:
        operation_type: The type of file operation.
        parameters: Parameters for the operation.
        dry_run: Whether to simulate the operation without making changes.
        
    Returns:
        A dictionary with the operation results.
    """
    try:
        logger.info(f"Executing file operation: {operation_type}")
        logger.debug(f"Parameters: {parameters}")
        
        result = {
            "operation": operation_type,
            "parameters": parameters,
            "success": False,
            "dry_run": dry_run,
        }
        
        # Execute the appropriate operation
        if operation_type == "create_directory":
            path = parameters.get("path")
            parents = parameters.get("parents", True)
            
            success = await create_directory(path, parents=parents, dry_run=dry_run)
            result["success"] = success
            
        elif operation_type == "delete_directory":
            path = parameters.get("path")
            recursive = parameters.get("recursive", False)
            force = parameters.get("force", False)
            
            success = await delete_directory(
                path, recursive=recursive, force=force, dry_run=dry_run
            )
            result["success"] = success
            
        elif operation_type == "create_file":
            path = parameters.get("path")
            content = parameters.get("content")
            
            success = await create_file(path, content=content, dry_run=dry_run)
            result["success"] = success
            
        elif operation_type == "read_file":
            path = parameters.get("path")
            binary = parameters.get("binary", False)
            
            content = await read_file(path, binary=binary)
            result["content"] = content
            result["success"] = True
            
        elif operation_type == "write_file":
            path = parameters.get("path")
            content = parameters.get("content", "")
            append = parameters.get("append", False)
            
            success = await write_file(
                path, content, append=append, dry_run=dry_run
            )
            result["success"] = success
            
        elif operation_type == "delete_file":
            path = parameters.get("path")
            force = parameters.get("force", False)
            
            success = await delete_file(path, force=force, dry_run=dry_run)
            result["success"] = success
            
        elif operation_type == "copy_file":
            source = parameters.get("source")
            destination = parameters.get("destination")
            overwrite = parameters.get("overwrite", False)
            
            success = await copy_file(
                source, destination, overwrite=overwrite, dry_run=dry_run
            )
            result["success"] = success
            
        elif operation_type == "move_file":
            source = parameters.get("source")
            destination = parameters.get("destination")
            overwrite = parameters.get("overwrite", False)
            
            success = await move_file(
                source, destination, overwrite=overwrite, dry_run=dry_run
            )
            result["success"] = success
            
        else:
            logger.warning(f"Unknown file operation: {operation_type}")
            result["error"] = f"Unknown file operation: {operation_type}"
        
        return result
        
    except FileSystemError as e:
        logger.exception(f"Error executing file operation: {str(e)}")
        return {
            "operation": operation_type,
            "parameters": parameters,
            "success": False,
            "error": str(e),
            "dry_run": dry_run,
        }
    except Exception as e:
        logger.exception(f"Unexpected error in file operation: {str(e)}")
        return {
            "operation": operation_type,
            "parameters": parameters,
            "success": False,
            "error": f"Unexpected error: {str(e)}",
            "dry_run": dry_run,
        }
</file>

<file path="angela/ai/intent_analyzer.py">
# angela/ai/intent_analyzer.py

import re
import difflib
from typing import Dict, Any, List, Tuple, Optional
from pydantic import BaseModel

from angela.ai.confidence import confidence_scorer
from angela.context.history import history_manager
from angela.utils.logging import get_logger

logger = get_logger(__name__)

class IntentAnalysisResult(BaseModel):
    """Model for intent analysis results."""
    original_request: str
    normalized_request: str
    intent_type: str
    confidence: float
    entities: Dict[str, Any] = {}
    disambiguation_needed: bool = False
    possible_intents: List[Tuple[str, float]] = []

class IntentAnalyzer:
    """
    Enhanced intent analyzer with fuzzy matching and tolerance for
    misspellings and ambiguity.
    """
    
    # Define known intent patterns with examples
    INTENT_PATTERNS = {
        "file_search": [
            "find files", "search for files", "locate files", 
            "show me files", "list files matching"
        ],
        "directory_operation": [
            "create directory", "make folder", "create folder", 
            "remove directory", "delete folder"
        ],
        "file_operation": [
            "create file", "edit file", "delete file", "write to file",
            "read file", "show file contents", "copy file", "move file"
        ],
        "system_info": [
            "show system info", "check disk space", "memory usage",
            "cpu usage", "system status", "show processes"
        ],
        "git_operation": [
            "git status", "git commit", "git push", "git pull",
            "create branch", "switch branch", "merge branch"
        ],
        # Add more intent patterns as needed
    }
    
    # Common misspellings and variations
    SPELLING_VARIATIONS = {
        "directory": ["dir", "folder", "direcotry", "directroy"],
        "file": ["flie", "fil", "document"],
        "create": ["make", "creat", "crate", "new"],
        "delete": ["remove", "del", "rm", "erase"],
        "search": ["find", "look for", "locate", "seek"],
        # Add more variations
    }
    
    def __init__(self):
        """Initialize the intent analyzer."""
        self._logger = logger
    
    def normalize_request(self, request: str) -> str:
        """
        Normalize the request by fixing common misspellings and variations.
        
        Args:
            request: The original request string
            
        Returns:
            Normalized request string
        """
        normalized = request.lower()
        
        # Replace common variations with standard terms
        for standard, variations in self.SPELLING_VARIATIONS.items():
            for variation in variations:
                # Use word boundary regex to avoid partial replacements
                pattern = r'\b' + re.escape(variation) + r'\b'
                normalized = re.sub(pattern, standard, normalized)
        
        self._logger.debug(f"Normalized request: '{request}' -> '{normalized}'")
        return normalized
    
    def analyze_intent(self, request: str) -> IntentAnalysisResult:
        """
        Analyze the intent of a request with enhanced tolerance for
        variations and ambiguity.
        
        Args:
            request: The original request string
            
        Returns:
            IntentAnalysisResult with the analysis
        """
        # Normalize the request
        normalized = self.normalize_request(request)
        
        # Find closest matching intents
        matches = []
        for intent_type, patterns in self.INTENT_PATTERNS.items():
            # Calculate best match score for this intent type
            best_score = 0
            for pattern in patterns:
                similarity = difflib.SequenceMatcher(None, normalized, pattern).ratio()
                if similarity > best_score:
                    best_score = similarity
            
            # Add to matches if score is above threshold
            if best_score > 0.6:  # Adjust threshold as needed
                matches.append((intent_type, best_score))
        
        # Sort matches by confidence score
        matches.sort(key=lambda x: x[1], reverse=True)
        
        # Check if we have a clear winner or need disambiguation
        if not matches:
            # No clear intent - low confidence fallback to generic
            return IntentAnalysisResult(
                original_request=request,
                normalized_request=normalized,
                intent_type="unknown",
                confidence=0.3,
                disambiguation_needed=True
            )
        
        top_intent, top_score = matches[0]
        
        # Extract entities based on the intent type
        entities = self._extract_entities(normalized, top_intent)
        
        # Check if disambiguation is needed
        disambiguation_needed = False
        if len(matches) > 1:
            second_intent, second_score = matches[1]
            # If top two scores are close, disambiguation might be needed
            if top_score - second_score < 0.15:
                disambiguation_needed = True
                self._logger.debug(f"Ambiguous intent: {top_intent} ({top_score:.2f}) vs {second_intent} ({second_score:.2f})")
        
        # Create the result
        result = IntentAnalysisResult(
            original_request=request,
            normalized_request=normalized,
            intent_type=top_intent,
            confidence=top_score,
            entities=entities,
            disambiguation_needed=disambiguation_needed,
            possible_intents=matches[:3]  # Keep top 3 for disambiguation
        )
        
        self._logger.info(f"Intent analysis: {top_intent} (confidence: {top_score:.2f})")
        return result
    
    def _extract_entities(self, normalized: str, intent_type: str) -> Dict[str, Any]:
        """
        Extract entities from the request based on intent type.
        
        Args:
            normalized: The normalized request string
            intent_type: The type of intent
            
        Returns:
            Dictionary of extracted entities
        """
        entities = {}
        
        # Extract entities based on intent type
        if intent_type == "file_search":
            # Extract file patterns
            pattern_match = re.search(r'matching (.+?)(?: in | with | containing |$)', normalized)
            if pattern_match:
                entities["pattern"] = pattern_match.group(1)
            
            # Extract directory to search in
            dir_match = re.search(r'in (?:directory |folder |)([\w\./]+)', normalized)
            if dir_match:
                entities["directory"] = dir_match.group(1)
                
        elif intent_type == "file_operation" or intent_type == "directory_operation":
            # Extract file/directory names
            path_match = re.search(r'(?:file|directory|folder) (?:called |named |)["\'"]?([\w\./]+)["\'"]?', normalized)
            if path_match:
                entities["path"] = path_match.group(1)
                
            # Extract content if applicable
            content_match = re.search(r'with (?:content |text |)["\'](.*?)["\']', normalized)
            if content_match:
                entities["content"] = content_match.group(1)
        
        # Add more entity extraction rules for other intent types
        
        return entities
    
    async def get_interactive_disambiguation(self, result: IntentAnalysisResult) -> IntentAnalysisResult:
        """
        Get user clarification for ambiguous intent.
        
        Args:
            result: The initial analysis result
            
        Returns:
            Updated analysis result after disambiguation
        """
        # Only disambiguate if confidence is low or explicitly needed
        if result.confidence > 0.7 and not result.disambiguation_needed:
            return result
        
        self._logger.info(f"Getting disambiguation for intent: {result.intent_type}")
        
        # Import here to avoid circular imports
        from prompt_toolkit.shortcuts import radiolist_dialog
        from prompt_toolkit.styles import Style
        
        # Create options for disambiguation
        options = []
        for intent_type, score in result.possible_intents:
            # Create a human-readable description for each intent
            description = self._get_intent_description(intent_type, result.entities)
            options.append((intent_type, description))
        
        # Add a "none of these" option
        options.append(("none", "None of these - let me rephrase"))
        
        # Create dialog style
        dialog_style = Style.from_dict({
            'dialog': 'bg:#222222',
            'dialog.body': 'bg:#222222 #ffffff',
            'dialog.border': '#888888',
            'button': 'bg:#222222 #ffffff',
            'button.focused': 'bg:#0969DA #ffffff',
        })
        
        # Show the dialog
        selected_intent = radiolist_dialog(
            title="Clarification Needed",
            text=f"I'm not sure what you meant by: '{result.original_request}'\nPlease select what you intended:",
            values=options,
            style=dialog_style
        ).run()
        
        # If user selected a specific intent, update the result
        if selected_intent and selected_intent != "none":
            # Find the score for the selected intent
            selected_score = 0.85  # Default to high confidence since user confirmed
            for intent, score in result.possible_intents:
                if intent == selected_intent:
                    selected_score = max(0.85, score)  # At least 0.85 confidence
                    break
                    
            # Update the result
            result.intent_type = selected_intent
            result.confidence = selected_score
            result.disambiguation_needed = False
            
            # Re-extract entities based on the new intent
            result.entities = self._extract_entities(result.normalized_request, selected_intent)
            
            self._logger.info(f"Intent clarified: {selected_intent} (confidence: {selected_score:.2f})")
        
        return result
    
    def _get_intent_description(self, intent_type: str, entities: Dict[str, Any]) -> str:
        """
        Create a human-readable description for an intent.
        
        Args:
            intent_type: The type of intent
            entities: Extracted entities
            
        Returns:
            Human-readable description
        """
        if intent_type == "file_search":
            pattern = entities.get("pattern", "files")
            directory = entities.get("directory", "current directory")
            return f"Search for {pattern} in {directory}"
            
        elif intent_type == "file_operation":
            path = entities.get("path", "a file")
            if "create" in path or "make" in path:
                return f"Create a new file: {path}"
            elif "delete" in path or "remove" in path:
                return f"Delete file: {path}"
            else:
                return f"Perform operation on file: {path}"
                
        elif intent_type == "directory_operation":
            path = entities.get("path", "a directory")
            if "create" in path or "make" in path:
                return f"Create a new directory: {path}"
            elif "delete" in path or "remove" in path:
                return f"Delete directory: {path}"
            else:
                return f"Perform operation on directory: {path}"
                
        elif intent_type == "system_info":
            return "Show system information"
            
        elif intent_type == "git_operation":
            return "Perform Git operation"
            
        # Fallback for unknown intent types
        return f"Intent: {intent_type}"

# Global intent analyzer instance
intent_analyzer = IntentAnalyzer()
</file>

<file path="angela/ai/parser.py">
# angela/ai/parser.py
import json
from typing import Dict, Any, Optional

from pydantic import BaseModel, Field, ValidationError

from angela.utils.logging import get_logger

logger = get_logger(__name__)

class CommandSuggestion(BaseModel):
    """Model for a command suggestion from the AI."""
    intent: str = Field(..., description="The classified intent of the user's request")
    command: str = Field(..., description="The suggested shell command")
    explanation: str = Field(..., description="Explanation of what the command does")
    additional_info: Optional[str] = Field(None, description="Any additional information")

# Update in angela/ai/parser.py
def parse_ai_response(response_text: str) -> CommandSuggestion:
    """Parse the AI response into a structured format."""
    try:
        # Try to extract JSON from the response
        json_str = None
        
        # Check for JSON in markdown code block with language specifier
        if "```json" in response_text and "```" in response_text.split("```json")[1]:
            json_str = response_text.split("```json")[1].split("```")[0].strip()
        # Check for JSON in regular markdown code block
        elif "```" in response_text and "```" in response_text.split("```")[1]:
            # Try without language specifier
            json_str = response_text.split("```")[1].strip()
        else:
            # Assume the entire response is JSON
            json_str = response_text.strip()
        
        # Parse the JSON
        data = json.loads(json_str)
        
        # Validate with Pydantic model
        suggestion = CommandSuggestion(**data)
        
        logger.debug(f"Successfully parsed AI response: {suggestion}")
        return suggestion
    
    except (json.JSONDecodeError, ValidationError) as e:
        logger.error(f"Failed to parse AI response: {str(e)}")
        logger.debug(f"Raw response: {response_text}")
        
        # Fallback: Try to extract just the command if JSON parsing fails
        try:
            import re
            # Improve the regex pattern to better match different formats
            command_match = re.search(r'command["\']?\s*:\s*["\']?(.*?)["\']?[,}]', response_text)
            if command_match:
                # Extract just the command value, not the whole match
                command = command_match.group(1).strip()
                # Remove any trailing quotes
                if command.endswith('"') or command.endswith("'"):
                    command = command[:-1]
                logger.debug(f"Extracted command using regex: {command}")
                return CommandSuggestion(
                    intent="unknown",
                    command=command,
                    explanation="Command extracted from incomplete response."
                )
        except Exception as regex_error:
            logger.error(f"Regex extraction also failed: {str(regex_error)}")
        
        raise ValueError(f"Could not parse AI response: {str(e)}")
</file>

<file path="angela/cli/docker.py">
"""
CLI commands for Docker integration in Angela CLI.

This module provides CLI commands for interacting with Docker and Docker Compose
through Angela CLI. It allows users to manage containers, images, and Docker-related
files from the command line.
"""
import asyncio
import os
from pathlib import Path
from typing import List, Optional

import typer
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.syntax import Syntax
from rich.progress import Progress, SpinnerColumn, TextColumn

from angela.toolchain.docker import docker_integration
from angela.context import context_manager
from angela.utils.logging import get_logger

logger = get_logger(__name__)
console = Console()

# Create the Typer app for Docker commands
app = typer.Typer(help="Docker and Docker Compose commands")


@app.command("status")
async def docker_status():
    """Show Docker and Docker Compose availability status."""
    with Progress(
        SpinnerColumn(),
        TextColumn("[bold blue]Checking Docker status...[/bold blue]"),
        console=console
    ) as progress:
        task = progress.add_task("Checking", total=1)
        
        # Check Docker availability
        docker_available = await docker_integration.is_docker_available()
        
        # Check Docker Compose availability
        compose_available = await docker_integration.is_docker_compose_available()
        
        progress.update(task, completed=1)
    
    # Display status
    table = Table(title="Docker Status")
    table.add_column("Component", style="cyan")
    table.add_column("Status", style="green")
    
    table.add_row(
        "Docker",
        "[green]Available[/green]" if docker_available else "[red]Not Available[/red]"
    )
    table.add_row(
        "Docker Compose",
        "[green]Available[/green]" if compose_available else "[red]Not Available[/red]"
    )
    
    console.print(table)
    
    if not docker_available:
        console.print("[yellow]Docker is not available. Install Docker to use these features.[/yellow]")
    elif not compose_available:
        console.print("[yellow]Docker Compose is not available. Install Docker Compose for multi-container support.[/yellow]")


@app.command("ps")
async def list_containers(
    all_containers: bool = typer.Option(False, "--all", "-a", help="Show all containers (including stopped)"),
    quiet: bool = typer.Option(False, "--quiet", "-q", help="Only display container IDs")
):
    """List Docker containers."""
    with Progress(
        SpinnerColumn(),
        TextColumn("[bold blue]Listing containers...[/bold blue]"),
        console=console
    ) as progress:
        task = progress.add_task("Listing", total=1)
        
        result = await docker_integration.list_containers(all_containers)
        
        progress.update(task, completed=1)
    
    if result["success"]:
        containers = result["containers"]
        
        if not containers:
            console.print("[yellow]No containers found.[/yellow]")
            return
        
        if quiet:
            for container in containers:
                if "id" in container:
                    console.print(container["id"])
        else:
            table = Table(title=f"{'All' if all_containers else 'Running'} Containers")
            
            # Determine columns based on the first container's structure
            if containers:
                first_container = containers[0]
                
                # Common columns
                table.add_column("ID", style="cyan", no_wrap=True)
                table.add_column("Name", style="green")
                table.add_column("Image", style="blue")
                table.add_column("Status", style="yellow")
                
                # Additional columns if available
                if "ports" in first_container:
                    table.add_column("Ports", style="magenta")
                
                # Add rows
                for container in containers:
                    # Extract values (handle different formats)
                    container_id = container.get("id", container.get("ID", ""))
                    # Show short ID
                    if len(container_id) > 12:
                        container_id = container_id[:12]
                    
                    name = container.get("names", container.get("Names", "")).lstrip('/')
                    if isinstance(name, list):
                        name = ", ".join(name)
                    
                    image = container.get("image", container.get("Image", ""))
                    status = container.get("status", container.get("Status", ""))
                    
                    # Build row
                    row = [container_id, name, image, status]
                    
                    # Add ports if available
                    if "ports" in first_container:
                        ports = container.get("ports", container.get("Ports", ""))
                        if isinstance(ports, list):
                            ports = ", ".join(ports)
                        row.append(ports)
                    
                    table.add_row(*row)
            
            console.print(table)
    else:
        console.print(f"[red]Error listing containers: {result.get('error', 'Unknown error')}[/red]")


@app.command("logs")
async def show_container_logs(
    container: str = typer.Argument(..., help="Container ID or name"),
    follow: bool = typer.Option(False, "--follow", "-f", help="Follow log output"),
    tail: Optional[int] = typer.Option(None, "--tail", "-n", help="Number of lines to show from the end"),
    timestamps: bool = typer.Option(False, "--timestamps", "-t", help="Show timestamps")
):
    """Show logs from a Docker container."""
    with Progress(
        SpinnerColumn(),
        TextColumn(f"[bold blue]Getting logs for container {container}...[/bold blue]"),
        console=console
    ) as progress:
        task = progress.add_task("Getting logs", total=1)
        
        result = await docker_integration.get_container_logs(
            container_id_or_name=container,
            tail=tail,
            follow=follow,
            timestamps=timestamps
        )
        
        progress.update(task, completed=1)
    
    if result["success"]:
        logs = result.get("logs", "")
        
        if not logs.strip():
            console.print("[yellow]No logs available for this container.[/yellow]")
            return
        
        console.print(Panel(
            logs,
            title=f"Logs for container: {container}",
            expand=False,
            border_style="blue"
        ))
        
        if result.get("truncated", False):
            console.print("[yellow]Log output truncated due to size or streaming timeout.[/yellow]")
    else:
        console.print(f"[red]Error getting container logs: {result.get('error', 'Unknown error')}[/red]")


@app.command("start")
async def start_container(container: str = typer.Argument(..., help="Container ID or name")):
    """Start a Docker container."""
    with Progress(
        SpinnerColumn(),
        TextColumn(f"[bold blue]Starting container {container}...[/bold blue]"),
        console=console
    ) as progress:
        task = progress.add_task("Starting", total=1)
        
        result = await docker_integration.start_container(container)
        
        progress.update(task, completed=1)
    
    if result["success"]:
        console.print(f"[green]Container {container} started successfully.[/green]")
    else:
        console.print(f"[red]Error starting container: {result.get('error', 'Unknown error')}[/red]")


@app.command("stop")
async def stop_container(
    container: str = typer.Argument(..., help="Container ID or name"),
    timeout: int = typer.Option(10, "--timeout", "-t", help="Timeout in seconds before killing the container")
):
    """Stop a Docker container."""
    with Progress(
        SpinnerColumn(),
        TextColumn(f"[bold blue]Stopping container {container}...[/bold blue]"),
        console=console
    ) as progress:
        task = progress.add_task("Stopping", total=1)
        
        result = await docker_integration.stop_container(container, timeout)
        
        progress.update(task, completed=1)
    
    if result["success"]:
        console.print(f"[green]Container {container} stopped successfully.[/green]")
    else:
        console.print(f"[red]Error stopping container: {result.get('error', 'Unknown error')}[/red]")


@app.command("restart")
async def restart_container(
    container: str = typer.Argument(..., help="Container ID or name"),
    timeout: int = typer.Option(10, "--timeout", "-t", help="Timeout in seconds before killing the container")
):
    """Restart a Docker container."""
    with Progress(
        SpinnerColumn(),
        TextColumn(f"[bold blue]Restarting container {container}...[/bold blue]"),
        console=console
    ) as progress:
        task = progress.add_task("Restarting", total=1)
        
        result = await docker_integration.restart_container(container, timeout)
        
        progress.update(task, completed=1)
    
    if result["success"]:
        console.print(f"[green]Container {container} restarted successfully.[/green]")
    else:
        console.print(f"[red]Error restarting container: {result.get('error', 'Unknown error')}[/red]")


@app.command("rm")
async def remove_container(
    container: str = typer.Argument(..., help="Container ID or name"),
    force: bool = typer.Option(False, "--force", "-f", help="Force removal of running container"),
    volumes: bool = typer.Option(False, "--volumes", "-v", help="Remove anonymous volumes")
):
    """Remove a Docker container."""
    with Progress(
        SpinnerColumn(),
        TextColumn(f"[bold blue]Removing container {container}...[/bold blue]"),
        console=console
    ) as progress:
        task = progress.add_task("Removing", total=1)
        
        result = await docker_integration.remove_container(container, force, volumes)
        
        progress.update(task, completed=1)
    
    if result["success"]:
        console.print(f"[green]Container {container} removed successfully.[/green]")
    else:
        console.print(f"[red]Error removing container: {result.get('error', 'Unknown error')}[/red]")


@app.command("images")
async def list_images(
    all_images: bool = typer.Option(False, "--all", "-a", help="Show all images (including intermediates)"),
    quiet: bool = typer.Option(False, "--quiet", "-q", help="Only display image IDs")
):
    """List Docker images."""
    with Progress(
        SpinnerColumn(),
        TextColumn("[bold blue]Listing images...[/bold blue]"),
        console=console
    ) as progress:
        task = progress.add_task("Listing", total=1)
        
        result = await docker_integration.list_images(all_images)
        
        progress.update(task, completed=1)
    
    if result["success"]:
        images = result["images"]
        
        if not images:
            console.print("[yellow]No images found.[/yellow]")
            return
        
        if quiet:
            for image in images:
                if "id" in image:
                    console.print(image["id"])
        else:
            table = Table(title="Docker Images")
            
            # Add columns
            table.add_column("Repository", style="cyan")
            table.add_column("Tag", style="green")
            table.add_column("ID", style="blue", no_wrap=True)
            table.add_column("Created", style="yellow")
            table.add_column("Size", style="magenta")
            
            # Add rows
            for image in images:
                # Extract values (handle different formats)
                repository = image.get("repository", image.get("Repository", "<none>"))
                tag = image.get("tag", image.get("Tag", "<none>"))
                image_id = image.get("id", image.get("ID", ""))
                # Show short ID
                if len(image_id) > 12:
                    image_id = image_id[:12]
                
                created = image.get("created", image.get("Created", ""))
                size = image.get("size", image.get("Size", ""))
                
                table.add_row(repository, tag, image_id, created, size)
            
            console.print(table)
    else:
        console.print(f"[red]Error listing images: {result.get('error', 'Unknown error')}[/red]")


@app.command("rmi")
async def remove_image(
    image: str = typer.Argument(..., help="Image ID or name"),
    force: bool = typer.Option(False, "--force", "-f", help="Force removal")
):
    """Remove a Docker image."""
    with Progress(
        SpinnerColumn(),
        TextColumn(f"[bold blue]Removing image {image}...[/bold blue]"),
        console=console
    ) as progress:
        task = progress.add_task("Removing", total=1)
        
        result = await docker_integration.remove_image(image, force)
        
        progress.update(task, completed=1)
    
    if result["success"]:
        console.print(f"[green]Image {image} removed successfully.[/green]")
    else:
        console.print(f"[red]Error removing image: {result.get('error', 'Unknown error')}[/red]")


@app.command("pull")
async def pull_image(image: str = typer.Argument(..., help="Image name to pull")):
    """Pull a Docker image."""
    with Progress(
        SpinnerColumn(),
        TextColumn(f"[bold blue]Pulling image {image}...[/bold blue]"),
        console=console
    ) as progress:
        task = progress.add_task("Pulling", total=1)
        
        result = await docker_integration.pull_image(image)
        
        progress.update(task, completed=1)
    
    if result["success"]:
        console.print(f"[green]Image {image} pulled successfully.[/green]")
    else:
        console.print(f"[red]Error pulling image: {result.get('error', 'Unknown error')}[/red]")


@app.command("build")
async def build_image(
    context_path: str = typer.Argument(".", help="Path to build context"),
    tag: Optional[str] = typer.Option(None, "--tag", "-t", help="Tag for the built image"),
    dockerfile: Optional[str] = typer.Option(None, "--file", "-f", help="Path to Dockerfile"),
    no_cache: bool = typer.Option(False, "--no-cache", help="Do not use cache when building")
):
    """Build a Docker image."""
    # Resolve path
    path = Path(context_path).absolute()
    if not path.exists() or not path.is_dir():
        console.print(f"[red]Error: Build context does not exist or is not a directory: {path}[/red]")
        return
    
    with Progress(
        SpinnerColumn(),
        TextColumn(f"[bold blue]Building Docker image from {path}...[/bold blue]"),
        console=console
    ) as progress:
        task = progress.add_task("Building", total=1)
        
        result = await docker_integration.build_image(
            context_path=path,
            tag=tag,
            dockerfile=dockerfile,
            no_cache=no_cache
        )
        
        progress.update(task, completed=1)
    
    if result["success"]:
        image_id = result.get("image_id", "")
        tag_str = f" with tag {tag}" if tag else ""
        
        console.print(f"[green]Image built successfully{tag_str}.[/green]")
        if image_id:
            console.print(f"[green]Image ID: {image_id}[/green]")
    else:
        console.print(f"[red]Error building image: {result.get('error', 'Unknown error')}[/red]")


@app.command("run")
async def run_container(
    image: str = typer.Argument(..., help="Docker image to run"),
    command: Optional[str] = typer.Argument(None, help="Command to run in the container"),
    name: Optional[str] = typer.Option(None, "--name", help="Container name"),
    ports: List[str] = typer.Option([], "--port", "-p", help="Port mappings (host:container)"),
    volumes: List[str] = typer.Option([], "--volume", "-v", help="Volume mappings (host:container)"),
    environment: List[str] = typer.Option([], "--env", "-e", help="Environment variables (KEY=VALUE)"),
    detach: bool = typer.Option(True, "--detach", "-d", help="Run in background"),
    remove: bool = typer.Option(False, "--rm", help="Remove container when it exits"),
    network: Optional[str] = typer.Option(None, "--network", help="Connect to network"),
    interactive: bool = typer.Option(False, "--interactive", "-i", help="Interactive mode")
):
    """Run a Docker container."""
    # Parse environment variables
    env_dict = {}
    for env in environment:
        parts = env.split("=", 1)
        if len(parts) == 2:
            env_dict[parts[0]] = parts[1]
    
    with Progress(
        SpinnerColumn(),
        TextColumn(f"[bold blue]Running container from image {image}...[/bold blue]"),
        console=console
    ) as progress:
        task = progress.add_task("Running", total=1)
        
        result = await docker_integration.run_container(
            image=image,
            command=command,
            name=name,
            ports=ports,
            volumes=volumes,
            environment=env_dict,
            detach=detach,
            remove=remove,
            network=network,
            interactive=interactive
        )
        
        progress.update(task, completed=1)
    
    if result["success"]:
        if detach:
            container_id = result.get("container_id", "")
            if container_id:
                console.print(f"[green]Container started in detached mode with ID: {container_id}[/green]")
            else:
                console.print(f"[green]Container started in detached mode.[/green]")
        else:
            console.print(f"[green]Container executed successfully.[/green]")
    else:
        console.print(f"[red]Error running container: {result.get('error', 'Unknown error')}[/red]")


@app.command("exec")
async def exec_in_container(
    container: str = typer.Argument(..., help="Container ID or name"),
    command: str = typer.Argument(..., help="Command to execute"),
    interactive: bool = typer.Option(False, "--interactive", "-i", help="Interactive mode")
):
    """Execute a command in a running container."""
    with Progress(
        SpinnerColumn(),
        TextColumn(f"[bold blue]Executing command in container {container}...[/bold blue]"),
        console=console
    ) as progress:
        task = progress.add_task("Executing", total=1)
        
        result = await docker_integration.exec_in_container(
            container_id_or_name=container,
            command=command,
            interactive=interactive
        )
        
        progress.update(task, completed=1)
    
    if result["success"]:
        output = result.get("output", "")
        if output.strip():
            console.print(Panel(
                output,
                title=f"Command output from {container}",
                expand=False,
                border_style="blue"
            ))
        else:
            console.print(f"[green]Command executed successfully with no output.[/green]")
    else:
        console.print(f"[red]Error executing command: {result.get('error', 'Unknown error')}[/red]")


# Docker Compose commands

@app.command("compose-up")
async def compose_up(
    compose_file: Optional[str] = typer.Option(None, "--file", "-f", help="Path to docker-compose.yml"),
    directory: Optional[str] = typer.Option(None, "--dir", help="Project directory (default: current directory)"),
    detach: bool = typer.Option(True, "--detach", "-d", help="Run in background"),
    build: bool = typer.Option(False, "--build", help="Build images before starting"),
    no_recreate: bool = typer.Option(False, "--no-recreate", help="Don't recreate containers"),
    force_recreate: bool = typer.Option(False, "--force-recreate", help="Force recreate containers"),
    services: List[str] = typer.Argument(None, help="Services to start (default: all)")
):
    """Start services using Docker Compose."""
    # Resolve directory
    if directory:
        dir_path = Path(directory).absolute()
    else:
        dir_path = context_manager.cwd
    
    if not dir_path.exists() or not dir_path.is_dir():
        console.print(f"[red]Error: Project directory does not exist or is not a directory: {dir_path}[/red]")
        return
    
    with Progress(
        SpinnerColumn(),
        TextColumn("[bold blue]Starting Docker Compose services...[/bold blue]"),
        console=console
    ) as progress:
        task = progress.add_task("Starting", total=1)
        
        result = await docker_integration.compose_up(
            compose_file=compose_file,
            project_directory=dir_path,
            detach=detach,
            build=build,
            no_recreate=no_recreate,
            force_recreate=force_recreate,
            services=services
        )
        
        progress.update(task, completed=1)
    
    if result["success"]:
        console.print(f"[green]Docker Compose services started successfully.[/green]")
        console.print(f"[green]Use 'angela docker compose-ps' to check service status.[/green]")
    else:
        console.print(f"[red]Error starting Docker Compose services: {result.get('error', 'Unknown error')}[/red]")
        
        # Show command for debugging
        if "command" in result:
            console.print(f"[yellow]Command: {result['command']}[/yellow]")


@app.command("compose-down")
async def compose_down(
    compose_file: Optional[str] = typer.Option(None, "--file", "-f", help="Path to docker-compose.yml"),
    directory: Optional[str] = typer.Option(None, "--dir", help="Project directory (default: current directory)"),
    remove_images: bool = typer.Option(False, "--rmi", help="Remove images"),
    remove_volumes: bool = typer.Option(False, "--volumes", "-v", help="Remove volumes"),
    remove_orphans: bool = typer.Option(False, "--remove-orphans", help="Remove orphaned containers")
):
    """Stop and remove Docker Compose services."""
    # Resolve directory
    if directory:
        dir_path = Path(directory).absolute()
    else:
        dir_path = context_manager.cwd
    
    if not dir_path.exists() or not dir_path.is_dir():
        console.print(f"[red]Error: Project directory does not exist or is not a directory: {dir_path}[/red]")
        return
    
    with Progress(
        SpinnerColumn(),
        TextColumn("[bold blue]Stopping Docker Compose services...[/bold blue]"),
        console=console
    ) as progress:
        task = progress.add_task("Stopping", total=1)
        
        result = await docker_integration.compose_down(
            compose_file=compose_file,
            project_directory=dir_path,
            remove_images=remove_images,
            remove_volumes=remove_volumes,
            remove_orphans=remove_orphans
        )
        
        progress.update(task, completed=1)
    
    if result["success"]:
        console.print(f"[green]Docker Compose services stopped successfully.[/green]")
    else:
        console.print(f"[red]Error stopping Docker Compose services: {result.get('error', 'Unknown error')}[/red]")


@app.command("compose-ps")
async def compose_ps(
    compose_file: Optional[str] = typer.Option(None, "--file", "-f", help="Path to docker-compose.yml"),
    directory: Optional[str] = typer.Option(None, "--dir", help="Project directory (default: current directory)"),
    all_services: bool = typer.Option(False, "--all", "-a", help="Show stopped services"),
    services: List[str] = typer.Argument(None, help="Services to show (default: all)")
):
    """List Docker Compose services."""
    # Resolve directory
    if directory:
        dir_path = Path(directory).absolute()
    else:
        dir_path = context_manager.cwd
    
    if not dir_path.exists() or not dir_path.is_dir():
        console.print(f"[red]Error: Project directory does not exist or is not a directory: {dir_path}[/red]")
        return
    
    with Progress(
        SpinnerColumn(),
        TextColumn("[bold blue]Listing Docker Compose services...[/bold blue]"),
        console=console
    ) as progress:
        task = progress.add_task("Listing", total=1)
        
        result = await docker_integration.compose_ps(
            compose_file=compose_file,
            project_directory=dir_path,
            services=services,
            all_services=all_services
        )
        
        progress.update(task, completed=1)
    
    if result["success"]:
        if not result.get("services"):
            console.print("[yellow]No Docker Compose services found.[/yellow]")
            return
        
        # Display raw output for simplicity, as format can vary
        console.print(result["raw_output"])
    else:
        console.print(f"[red]Error listing Docker Compose services: {result.get('error', 'Unknown error')}[/red]")


@app.command("compose-logs")
async def compose_logs(
    compose_file: Optional[str] = typer.Option(None, "--file", "-f", help="Path to docker-compose.yml"),
    directory: Optional[str] = typer.Option(None, "--dir", help="Project directory (default: current directory)"),
    follow: bool = typer.Option(False, "--follow", help="Follow log output"),
    tail: Optional[int] = typer.Option(None, "--tail", help="Number of lines to show from the end"),
    timestamps: bool = typer.Option(False, "--timestamps", help="Show timestamps"),
    services: List[str] = typer.Argument(None, help="Services to show logs for (default: all)")
):
    """View logs from Docker Compose services."""
    # Resolve directory
    if directory:
        dir_path = Path(directory).absolute()
    else:
        dir_path = context_manager.cwd
    
    if not dir_path.exists() or not dir_path.is_dir():
        console.print(f"[red]Error: Project directory does not exist or is not a directory: {dir_path}[/red]")
        return
    
    with Progress(
        SpinnerColumn(),
        TextColumn("[bold blue]Getting Docker Compose logs...[/bold blue]"),
        console=console
    ) as progress:
        task = progress.add_task("Getting logs", total=1)
        
        result = await docker_integration.compose_logs(
            compose_file=compose_file,
            project_directory=dir_path,
            services=services,
            follow=follow,
            tail=tail,
            timestamps=timestamps
        )
        
        progress.update(task, completed=1)
    
    if result["success"]:
        logs = result.get("logs", "")
        
        if not logs.strip():
            console.print("[yellow]No logs available for these services.[/yellow]")
            return
        
        console.print(Panel(
            logs,
            title="Docker Compose Logs",
            expand=False,
            border_style="blue"
        ))
        
        if result.get("truncated", False):
            console.print("[yellow]Log output truncated due to size or streaming timeout.[/yellow]")
    else:
        console.print(f"[red]Error getting Docker Compose logs: {result.get('error', 'Unknown error')}[/red]")


# Dockerfile and docker-compose.yml generation commands

@app.command("generate-dockerfile")
async def generate_dockerfile(
    directory: str = typer.Argument(".", help="Project directory"),
    output: Optional[str] = typer.Option(None, "--output", "-o", help="Output file path"),
    overwrite: bool = typer.Option(False, "--overwrite", help="Overwrite existing file")
):
    """Generate a Dockerfile for a project."""
    # Resolve directory
    dir_path = Path(directory).absolute()
    if not dir_path.exists() or not dir_path.is_dir():
        console.print(f"[red]Error: Project directory does not exist or is not a directory: {dir_path}[/red]")
        return
    
    with Progress(
        SpinnerColumn(),
        TextColumn(f"[bold blue]Generating Dockerfile for {dir_path}...[/bold blue]"),
        console=console
    ) as progress:
        task = progress.add_task("Generating", total=1)
        
        result = await docker_integration.generate_dockerfile(
            project_directory=dir_path,
            output_file=output,
            overwrite=overwrite
        )
        
        progress.update(task, completed=1)
    
    if result["success"]:
        dockerfile_path = result["dockerfile_path"]
        content = result.get("content", "")
        
        console.print(f"[green]Dockerfile generated successfully at {dockerfile_path}[/green]")
        
        # Display the content
        console.print(Syntax(
            content,
            "dockerfile",
            theme="monokai",
            word_wrap=True,
            line_numbers=True
        ))
    else:
        if "already exists" in result.get("error", ""):
            console.print(f"[yellow]{result['error']} Use --overwrite to replace it.[/yellow]")
        else:
            console.print(f"[red]Error generating Dockerfile: {result.get('error', 'Unknown error')}[/red]")


@app.command("generate-compose")
async def generate_docker_compose(
    directory: str = typer.Argument(".", help="Project directory"),
    output: Optional[str] = typer.Option(None, "--output", "-o", help="Output file path"),
    overwrite: bool = typer.Option(False, "--overwrite", help="Overwrite existing file"),
    include_databases: bool = typer.Option(True, "--databases/--no-databases", help="Include detected database services")
):
    """Generate a docker-compose.yml file for a project."""
    # Resolve directory
    dir_path = Path(directory).absolute()
    if not dir_path.exists() or not dir_path.is_dir():
        console.print(f"[red]Error: Project directory does not exist or is not a directory: {dir_path}[/red]")
        return
    
    with Progress(
        SpinnerColumn(),
        TextColumn(f"[bold blue]Generating docker-compose.yml for {dir_path}...[/bold blue]"),
        console=console
    ) as progress:
        task = progress.add_task("Generating", total=1)
        
        result = await docker_integration.generate_docker_compose(
            project_directory=dir_path,
            output_file=output,
            overwrite=overwrite,
            include_databases=include_databases
        )
        
        progress.update(task, completed=1)
    
    if result["success"]:
        compose_file_path = result["compose_file_path"]
        content = result.get("content", "")
        services = result.get("services_included", [])
        
        console.print(f"[green]docker-compose.yml generated successfully at {compose_file_path}[/green]")
        console.print(f"[green]Services included: {', '.join(services)}[/green]")
        
        # Display the content
        console.print(Syntax(
            content,
            "yaml",
            theme="monokai",
            word_wrap=True,
            line_numbers=True
        ))
    else:
        if "already exists" in result.get("error", ""):
            console.print(f"[yellow]{result['error']} Use --overwrite to replace it.[/yellow]")
        else:
            console.print(f"[red]Error generating docker-compose.yml: {result.get('error', 'Unknown error')}[/red]")


@app.command("generate-dockerignore")
async def generate_dockerignore(
    directory: str = typer.Argument(".", help="Project directory"),
    output: Optional[str] = typer.Option(None, "--output", "-o", help="Output file path"),
    overwrite: bool = typer.Option(False, "--overwrite", help="Overwrite existing file")
):
    """Generate a .dockerignore file for a project."""
    # Resolve directory
    dir_path = Path(directory).absolute()
    if not dir_path.exists() or not dir_path.is_dir():
        console.print(f"[red]Error: Project directory does not exist or is not a directory: {dir_path}[/red]")
        return
    
    with Progress(
        SpinnerColumn(),
        TextColumn(f"[bold blue]Generating .dockerignore for {dir_path}...[/bold blue]"),
        console=console
    ) as progress:
        task = progress.add_task("Generating", total=1)
        
        result = await docker_integration.generate_dockerignore(
            project_directory=dir_path,
            output_file=output,
            overwrite=overwrite
        )
        
        progress.update(task, completed=1)
    
    if result["success"]:
        dockerignore_path = result["path"]
        content = result.get("content", "")
        
        console.print(f"[green].dockerignore generated successfully at {dockerignore_path}[/green]")
        
        # Display the content
        console.print(Syntax(
            content,
            "gitignore",
            theme="monokai",
            word_wrap=True,
            line_numbers=True
        ))
    else:
        if "already exists" in result.get("error", ""):
            console.print(f"[yellow]{result['error']} Use --overwrite to replace it.[/yellow]")
        else:
            console.print(f"[red]Error generating .dockerignore: {result.get('error', 'Unknown error')}[/red]")


@app.command("setup")
async def setup_docker_project(
    directory: str = typer.Argument(".", help="Project directory"),
    dockerfile: bool = typer.Option(True, "--dockerfile/--no-dockerfile", help="Generate Dockerfile"),
    compose: bool = typer.Option(True, "--compose/--no-compose", help="Generate docker-compose.yml"),
    dockerignore: bool = typer.Option(True, "--dockerignore/--no-dockerignore", help="Generate .dockerignore"),
    overwrite: bool = typer.Option(False, "--overwrite", help="Overwrite existing files"),
    databases: bool = typer.Option(True, "--databases/--no-databases", help="Include detected database services"),
    build: bool = typer.Option(False, "--build", help="Build Docker image after setup")
):
    """Set up a complete Docker environment for a project."""
    # Resolve directory
    dir_path = Path(directory).absolute()
    if not dir_path.exists() or not dir_path.is_dir():
        console.print(f"[red]Error: Project directory does not exist or is not a directory: {dir_path}[/red]")
        return
    
    with Progress(
        SpinnerColumn(),
        TextColumn(f"[bold blue]Setting up Docker environment for {dir_path}...[/bold blue]"),
        console=console
    ) as progress:
        task = progress.add_task("Setting up", total=1)
        
        result = await docker_integration.setup_docker_project(
            project_directory=dir_path,
            generate_dockerfile=dockerfile,
            generate_compose=compose,
            generate_dockerignore=dockerignore,
            overwrite=overwrite,
            include_databases=databases,
            build_image=build
        )
        
        progress.update(task, completed=1)
    
    if result["success"]:
        files_generated = result.get("files_generated", [])
        console.print(f"[green]Docker environment setup completed successfully.[/green]")
        
        if files_generated:
            console.print("[green]Files generated:[/green]")
            for file_path in files_generated:
                console.print(f"[green]- {file_path}[/green]")
        
        if build and result.get("build_image", {}).get("success", False):
            console.print("[green]Docker image built successfully.[/green]")
        elif build and result.get("build_warnings"):
            console.print(f"[yellow]Warning during image build: {result['build_warnings']}[/yellow]")
    else:
        console.print(f"[red]Error setting up Docker environment: {result.get('error', 'Unknown error')}[/red]")
        
        # Show detailed results if available
        if "dockerfile" in result and not result["dockerfile"].get("success", False):
            console.print(f"[red]Dockerfile error: {result['dockerfile'].get('error', 'Unknown error')}[/red]")
        
        if "docker_compose" in result and not result["docker_compose"].get("success", False):
            console.print(f"[red]docker-compose.yml error: {result['docker_compose'].get('error', 'Unknown error')}[/red]")
        
        if "dockerignore" in result and not result["dockerignore"].get("success", False):
            console.print(f"[red].dockerignore error: {result['dockerignore'].get('error', 'Unknown error')}[/red]")


@app.command("info")
async def info():
    """Display detailed information about the Docker setup."""
    with Progress(
        SpinnerColumn(),
        TextColumn("[bold blue]Getting Docker information...[/bold blue]"),
        console=console
    ) as progress:
        task = progress.add_task("Getting info", total=1)
        
        # Check Docker and Docker Compose availability
        docker_available = await docker_integration.is_docker_available()
        compose_available = await docker_integration.is_docker_compose_available()
        
        # Execute docker info command if available
        docker_info_output = ""
        if docker_available:
            stdout, stderr, exit_code = await execution_engine.execute_command(
                "docker info",
                check_safety=True
            )
            if exit_code == 0:
                docker_info_output = stdout
        
        progress.update(task, completed=1)
    
    # Display information
    if docker_available:
        console.print(Panel(
            docker_info_output,
            title="Docker Information",
            expand=False,
            border_style="blue"
        ))
        
        console.print(f"Docker Compose: {'[green]Available[/green]' if compose_available else '[red]Not Available[/red]'}")
    else:
        console.print("[red]Docker is not available. Install Docker to use these features.[/red]")


# Run the app directly when this module is executed
if __name__ == "__main__":
    app()
</file>

<file path="angela/cli/files_extensions.py">
"""
CLI extensions for file resolution and activity tracking.

This module extends the files command with advanced file resolution features.
"""
import asyncio
from pathlib import Path
from typing import Optional, List

import typer
from rich.console import Console
from rich.panel import Panel
from rich.table import Table
from rich.text import Text
from rich import print as rich_print

from angela.context import context_manager, file_resolver, file_activity_tracker, ActivityType
from angela.utils.logging import get_logger

logger = get_logger(__name__)
console = Console()

# Create a Typer app for files extensions
app = typer.Typer(name="files", help="Advanced file operations")


@app.command("resolve")
def resolve_file(
    reference: str = typer.Argument(..., help="File reference to resolve"),
    scope: str = typer.Option(
        "all", "--scope", "-s", 
        help="Search scope (project, directory, all)"
    ),
):
    """Resolve a file reference to an actual file path."""
    # Get the current context
    context = context_manager.get_context_dict()
    
    # Convert scope
    search_scope = None
    if scope == "project":
        search_scope = "project"
    elif scope == "directory":
        search_scope = "directory"
    
    # Run the resolver
    try:
        path = asyncio.run(file_resolver.resolve_reference(
            reference,
            context,
            search_scope=search_scope
        ))
        
        if path:
            # Show the resolved path
            console.print(Panel(
                f"Resolved '[bold]{reference}[/bold]' to:\n[green]{path}[/green]",
                title="File Resolution",
                border_style="green"
            ))
            
            # Track as viewed file
            file_activity_tracker.track_file_viewing(path, None, {
                "reference": reference,
                "resolved_via": "cli"
            })
        else:
            # Show not found message
            console.print(Panel(
                f"Could not resolve '[bold]{reference}[/bold]' to a file or directory.",
                title="File Resolution",
                border_style="yellow"
            ))
            
            # Show suggestions based on the scope
            if search_scope == "project" and context.get("project_root"):
                # Suggest listing files in project
                console.print("Try using 'angela files find' to search for files in the project.")
            elif search_scope == "directory":
                # Suggest listing files in directory
                console.print("Try using 'angela files ls' to list files in the current directory.")
            else:
                # Suggest other scopes
                console.print("Try using '--scope project' or '--scope directory' to narrow the search.")
    
    except Exception as e:
        logger.exception(f"Error resolving file reference: {str(e)}")
        console.print(f"[bold red]Error:[/bold red] {str(e)}")


@app.command("extract")
def extract_references(
    text: str = typer.Argument(..., help="Text containing file references"),
):
    """Extract and resolve file references from text."""
    # Get the current context
    context = context_manager.get_context_dict()
    
    # Run the extractor
    try:
        references = asyncio.run(file_resolver.extract_references(text, context))
        
        if references:
            # Create a table for the results
            table = Table(title="Extracted File References")
            table.add_column("Reference", style="cyan")
            table.add_column("Resolved Path", style="green")
            table.add_column("Status", style="yellow")
            
            for reference, path in references:
                if path:
                    status = "[green]Found[/green]"
                    path_str = str(path)
                    
                    # Track as viewed file
                    file_activity_tracker.track_file_viewing(path, None, {
                        "reference": reference,
                        "extracted_via": "cli"
                    })
                else:
                    status = "[yellow]Not Found[/yellow]"
                    path_str = "[italic]Not resolved[/italic]"
                
                table.add_row(reference, path_str, status)
            
            console.print(table)
        else:
            # Show not found message
            console.print(Panel(
                f"No file references found in the text.",
                title="File References",
                border_style="yellow"
            ))
    
    except Exception as e:
        logger.exception(f"Error extracting file references: {str(e)}")
        console.print(f"[bold red]Error:[/bold red] {str(e)}")


@app.command("recent")
def recent_files(
    limit: int = typer.Option(10, "--limit", "-n", help="Number of files to show"),
    activity_type: Optional[str] = typer.Option(
        None, "--type", "-t", 
        help="Filter by activity type (viewed, created, modified, deleted)"
    ),
):
    """Show recently accessed files."""
    try:
        # Convert activity type
        activity_types = None
        if activity_type:
            try:
                activity_types = [ActivityType(activity_type)]
            except ValueError:
                console.print(f"[yellow]Invalid activity type: {activity_type}[/yellow]")
                console.print("Available types: viewed, created, modified, deleted")
                return
        
        # Get recent activities
        activities = file_activity_tracker.get_recent_activities(
            limit=limit,
            activity_types=activity_types
        )
        
        if activities:
            # Create a table for the results
            table = Table(title=f"Recent File Activities (Last {len(activities)})")
            table.add_column("File", style="cyan")
            table.add_column("Activity", style="green")
            table.add_column("Time", style="yellow")
            table.add_column("Command", style="blue")
            
            for activity in activities:
                # Format the file name and path
                file_name = activity.get("name", "unknown")
                file_path = activity.get("path", "unknown")
                file_str = f"{file_name}\n[dim]{file_path}[/dim]"
                
                # Format activity type
                activity_type = activity.get("activity_type", "unknown")
                if activity_type == "viewed":
                    activity_str = "[blue]Viewed[/blue]"
                elif activity_type == "created":
                    activity_str = "[green]Created[/green]"
                elif activity_type == "modified":
                    activity_str = "[yellow]Modified[/yellow]"
                elif activity_type == "deleted":
                    activity_str = "[red]Deleted[/red]"
                else:
                    activity_str = activity_type.capitalize()
                
                # Format time
                time_str = activity.get("datetime", "unknown")
                if "T" in time_str:
                    time_str = time_str.replace("T", " ").split(".")[0]  # Simplify timestamp
                
                # Format command (truncate if too long)
                command = activity.get("command", "")
                if command and len(command) > 40:
                    command = command[:37] + "..."
                
                table.add_row(file_str, activity_str, time_str, command)
            
            console.print(table)
        else:
            # Show no activities message
            console.print(Panel(
                f"No file activities tracked yet.",
                title="Recent Files",
                border_style="yellow"
            ))
            
            # Show help message
            console.print("File activities are tracked when you interact with files using Angela.")
            console.print("Try viewing or manipulating some files first.")
    
    except Exception as e:
        logger.exception(f"Error retrieving recent files: {str(e)}")
        console.print(f"[bold red]Error:[/bold red] {str(e)}")


@app.command("active")
def most_active_files(
    limit: int = typer.Option(5, "--limit", "-n", help="Number of files to show"),
):
    """Show most actively used files."""
    try:
        # Get most active files
        active_files = file_activity_tracker.get_most_active_files(limit=limit)
        
        if active_files:
            # Create a table for the results
            table = Table(title=f"Most Active Files (Top {len(active_files)})")
            table.add_column("File", style="cyan")
            table.add_column("Activity Count", style="green")
            table.add_column("Last Activity", style="yellow")
            table.add_column("Activity Types", style="blue")
            
            for file_info in active_files:
                # Format the file name and path
                file_name = file_info.get("name", "unknown")
                file_path = file_info.get("path", "unknown")
                file_str = f"{file_name}\n[dim]{file_path}[/dim]"
                
                # Format activity count
                count = file_info.get("count", 0)
                
                # Format last activity time
                last_activity = file_info.get("last_activity", 0)
                if last_activity:
                    from datetime import datetime
                    time_str = datetime.fromtimestamp(last_activity).isoformat()
                    if "T" in time_str:
                        time_str = time_str.replace("T", " ").split(".")[0]  # Simplify timestamp
                else:
                    time_str = "Unknown"
                
                # Format activity types
                activities = file_info.get("activities", [])
                activities_str = ", ".join(a.capitalize() for a in activities)
                
                table.add_row(file_str, str(count), time_str, activities_str)
            
            console.print(table)
        else:
            # Show no activities message
            console.print(Panel(
                f"No file activities tracked yet.",
                title="Most Active Files",
                border_style="yellow"
            ))
            
            # Show help message
            console.print("File activities are tracked when you interact with files using Angela.")
            console.print("Try viewing or manipulating some files first.")
    
    except Exception as e:
        logger.exception(f"Error retrieving most active files: {str(e)}")
        console.print(f"[bold red]Error:[/bold red] {str(e)}")


@app.command("project")
def show_project_info():
    """Show detected project information."""
    try:
        # Get the current context
        context = context_manager.get_context_dict()
        
        # Check if in a project
        if not context.get("project_root"):
            console.print(Panel(
                "Not currently in a project directory.",
                title="Project Information",
                border_style="yellow"
            ))
            return
        
        # Get enhanced project info
        from angela.context.enhancer import context_enhancer
        
        # Enrich context
        enriched = asyncio.run(context_enhancer.enrich_context(context))
        project_info = enriched.get("enhanced_project", {})
        
        if project_info:
            # Create a panel for the project information
            project_type = project_info.get("type", "Unknown")
            project_root = context.get("project_root", "Unknown")
            
            content = f"[bold]Project Type:[/bold] {project_type}\n"
            content += f"[bold]Project Root:[/bold] {project_root}\n\n"
            
            # Add frameworks if available
            if project_info.get("frameworks"):
                frameworks = list(project_info["frameworks"].keys())
                content += f"[bold]Frameworks:[/bold] {', '.join(frameworks)}\n"
            
            # Add dependencies if available
            if project_info.get("dependencies") and project_info["dependencies"].get("top_dependencies"):
                deps = project_info["dependencies"]["top_dependencies"]
                content += f"[bold]Top Dependencies:[/bold] {', '.join(deps[:5])}"
                if len(deps) > 5:
                    content += f" and {len(deps) - 5} more"
                content += f" (Total: {project_info['dependencies'].get('total', 0)})\n"
            
            # Add important files if available
            if project_info.get("important_files") and project_info["important_files"].get("paths"):
                files = project_info["important_files"]["paths"]
                content += f"[bold]Important Files:[/bold]\n"
                for f in files[:5]:
                    content += f"• {f}\n"
                if len(files) > 5:
                    content += f"• ... and {len(files) - 5} more\n"
            
            # Add structure info if available
            if project_info.get("structure"):
                structure = project_info["structure"]
                content += f"\n[bold]Project Structure:[/bold]\n"
                content += f"• Total Files: {structure.get('total_files', 'Unknown')}\n"
                
                if structure.get("main_directories"):
                    content += f"• Main Directories: {', '.join(structure['main_directories'])}\n"
                
                if structure.get("file_counts"):
                    content += f"• Top File Types:\n"
                    sorted_types = sorted(
                        structure["file_counts"].items(), 
                        key=lambda x: x[1], 
                        reverse=True
                    )
                    for ext, count in sorted_types[:5]:
                        content += f"  - {ext}: {count}\n"
            
            console.print(Panel(
                content,
                title=f"Project Information: {project_type}",
                border_style="green",
                expand=False
            ))
        else:
            # Show no project info message
            console.print(Panel(
                f"No enhanced project information available.",
                title="Project Information",
                border_style="yellow"
            ))
            
            # Show basic project info
            console.print(f"[bold]Project Root:[/bold] {context.get('project_root', 'Unknown')}")
            console.print(f"[bold]Project Type:[/bold] {context.get('project_type', 'Unknown')}")
    
    except Exception as e:
        logger.exception(f"Error retrieving project information: {str(e)}")
        console.print(f"[bold red]Error:[/bold red] {str(e)}")
</file>

<file path="angela/cli/files.py">
"""
File operation commands for Angela CLI.

This module provides CLI commands for file and directory operations.
"""
import os
import sys
import asyncio
from pathlib import Path
from typing import List, Optional, Tuple

import typer
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.syntax import Syntax
from rich.markup import escape
from rich.text import Text
from rich.prompt import Prompt, Confirm
from rich.filesize import decimal as format_size

from angela.context import context_manager
from angela.execution.filesystem import (
    create_directory, delete_directory, create_file, read_file,
    write_file, delete_file, copy_file, move_file, FileSystemError
)
from angela.execution.rollback import rollback_manager
from angela.utils.logging import get_logger

logger = get_logger(__name__)
console = Console()

# Create the file operations app
app = typer.Typer(help="Angela's file operations")


@app.command("ls")
def list_directory(
    path: str = typer.Argument(
        None, help="Directory to list (defaults to current directory)"
    ),
    all: bool = typer.Option(
        False, "--all", "-a", help="Include hidden files"
    ),
    long: bool = typer.Option(
        False, "--long", "-l", help="Show detailed information"
    ),
):
    """List directory contents with enhanced formatting."""
    try:
        dir_path = Path(path) if path else context_manager.cwd
        
        if not dir_path.exists():
            console.print(f"[bold red]Error:[/bold red] Path not found: {dir_path}")
            sys.exit(1)
        
        if not dir_path.is_dir():
            console.print(f"[bold red]Error:[/bold red] Not a directory: {dir_path}")
            sys.exit(1)
        
        # Get directory contents
        contents = context_manager.get_directory_contents(dir_path, include_hidden=all)
        
        if not contents:
            console.print(f"Directory is empty: {dir_path}")
            return
        
        # Display in table format if long listing is requested
        if long:
            table = Table(title=f"Contents of {dir_path}")
            table.add_column("Name", style="cyan")
            table.add_column("Type", style="green")
            table.add_column("Size", style="blue", justify="right")
            table.add_column("Language", style="magenta")
            
            for item in contents:
                name = item["name"]
                
                # Add indicator for directories
                if item["is_dir"]:
                    name = f"{name}/"
                
                # Format size
                size = format_size(item["size"]) if "size" in item else ""
                
                # Get type and language
                item_type = item.get("type", "unknown")
                language = item.get("language", "")
                
                table.add_row(name, item_type, size, language)
            
            console.print(table)
        
        # Simple listing
        else:
            for item in contents:
                name = item["name"]
                
                # Color and format based on type
                if item["is_dir"]:
                    console.print(f"[bold blue]{name}/[/bold blue]", end="  ")
                elif item.get("language"):
                    console.print(f"[green]{name}[/green]", end="  ")
                elif item.get("binary", False):
                    console.print(f"[dim]{name}[/dim]", end="  ")
                else:
                    console.print(name, end="  ")
            
            # End with a newline
            console.print()
        
    except Exception as e:
        logger.exception(f"Error listing directory: {str(e)}")
        console.print(f"[bold red]Error:[/bold red] {str(e)}")
        sys.exit(1)


@app.command("mkdir")
def make_directory(
    path: str = typer.Argument(..., help="Directory to create"),
    parents: bool = typer.Option(
        True, "--parents/--no-parents", "-p", help="Create parent directories if needed"
    ),
    dry_run: bool = typer.Option(
        False, "--dry-run", help="Show what would happen without making changes"
    ),
):
    """Create a directory."""
    try:
        # Run the operation
        success = asyncio.run(create_directory(path, parents=parents, dry_run=dry_run))
        
        if success:
            if dry_run:
                console.print(f"[bold blue]DRY RUN:[/bold blue] Would create directory: {path}")
            else:
                console.print(f"[bold green]Created directory:[/bold green] {path}")
        else:
            console.print(f"[bold yellow]Operation cancelled.[/bold yellow]")
            sys.exit(1)
        
    except FileSystemError as e:
        logger.exception(f"Error creating directory: {str(e)}")
        console.print(f"[bold red]Error:[/bold red] {str(e)}")
        sys.exit(1)


@app.command("rmdir")
def remove_directory(
    path: str = typer.Argument(..., help="Directory to remove"),
    recursive: bool = typer.Option(
        False, "--recursive", "-r", help="Recursively remove directories and their contents"
    ),
    force: bool = typer.Option(
        False, "--force", "-f", help="Ignore nonexistent files"
    ),
    dry_run: bool = typer.Option(
        False, "--dry-run", help="Show what would happen without making changes"
    ),
):
    """Remove a directory."""
    try:
        # Run the operation
        success = asyncio.run(delete_directory(
            path, recursive=recursive, force=force, dry_run=dry_run
        ))
        
        if success:
            if dry_run:
                console.print(f"[bold blue]DRY RUN:[/bold blue] Would remove directory: {path}")
            else:
                console.print(f"[bold green]Removed directory:[/bold green] {path}")
        else:
            console.print(f"[bold yellow]Operation cancelled.[/bold yellow]")
            sys.exit(1)
        
    except FileSystemError as e:
        logger.exception(f"Error removing directory: {str(e)}")
        console.print(f"[bold red]Error:[/bold red] {str(e)}")
        sys.exit(1)


@app.command("touch")
def touch_file(
    path: str = typer.Argument(..., help="File to create or update timestamp"),
    dry_run: bool = typer.Option(
        False, "--dry-run", help="Show what would happen without making changes"
    ),
):
    """Create a new file or update file timestamp."""
    try:
        # Run the operation (with no content for touch)
        success = asyncio.run(create_file(path, content=None, dry_run=dry_run))
        
        if success:
            if dry_run:
                console.print(f"[bold blue]DRY RUN:[/bold blue] Would touch file: {path}")
            else:
                console.print(f"[bold green]Touched file:[/bold green] {path}")
        else:
            console.print(f"[bold yellow]Operation cancelled.[/bold yellow]")
            sys.exit(1)
        
    except FileSystemError as e:
        logger.exception(f"Error touching file: {str(e)}")
        console.print(f"[bold red]Error:[/bold red] {str(e)}")
        sys.exit(1)


@app.command("cat")
def cat_file(
    path: str = typer.Argument(..., help="File to display"),
    binary: bool = typer.Option(
        False, "--binary", "-b", help="Display binary content"
    ),
    syntax: bool = typer.Option(
        True, "--syntax/--no-syntax", help="Syntax highlighting"
    ),
):
    """Display file contents."""
    try:
        file_path = Path(path)
        
        # Get file info to determine syntax highlighting
        file_info = context_manager.get_file_info(file_path)
        
        # Read the file
        content = asyncio.run(read_file(path, binary=binary))
        
        # Display the content
        if binary:
            # For binary files, just show a hexdump-like output
            console.print(Panel(
                escape(repr(content[:1000])) + ("..." if len(content) > 1000 else ""),
                title=f"Binary content of {path}",
                subtitle=f"Showing first 1000 bytes of {len(content)} total bytes",
                expand=False
            ))
        elif syntax and file_info.get("language") and not binary:
            # Determine the language for syntax highlighting
            lang = file_info.get("language", "").lower()
            if "python" in lang:
                lang = "python"
            elif "javascript" in lang:
                lang = "javascript"
            elif "html" in lang:
                lang = "html"
            elif "css" in lang:
                lang = "css"
            elif "json" in lang:
                lang = "json"
            elif "yaml" in lang:
                lang = "yaml"
            elif "markdown" in lang:
                lang = "markdown"
            elif "bash" in lang or "shell" in lang:
                lang = "bash"
            else:
                lang = "text"
            
            # Display with syntax highlighting
            console.print(Syntax(
                content,
                lang,
                theme="monokai",
                line_numbers=True,
                word_wrap=True
            ))
        else:
            # Simple text display
            console.print(content)
        
    except FileSystemError as e:
        logger.exception(f"Error reading file: {str(e)}")
        console.print(f"[bold red]Error:[/bold red] {str(e)}")
        sys.exit(1)


@app.command("rm")
def remove_file(
    path: str = typer.Argument(..., help="File to remove"),
    force: bool = typer.Option(
        False, "--force", "-f", help="Ignore nonexistent files"
    ),
    dry_run: bool = typer.Option(
        False, "--dry-run", help="Show what would happen without making changes"
    ),
):
    """Remove a file."""
    try:
        # Run the operation
        success = asyncio.run(delete_file(path, force=force, dry_run=dry_run))
        
        if success:
            if dry_run:
                console.print(f"[bold blue]DRY RUN:[/bold blue] Would remove file: {path}")
            else:
                console.print(f"[bold green]Removed file:[/bold green] {path}")
        else:
            console.print(f"[bold yellow]Operation cancelled.[/bold yellow]")
            sys.exit(1)
        
    except FileSystemError as e:
        logger.exception(f"Error removing file: {str(e)}")
        console.print(f"[bold red]Error:[/bold red] {str(e)}")
        sys.exit(1)


@app.command("cp")
def copy_file_command(
    source: str = typer.Argument(..., help="Source file to copy"),
    destination: str = typer.Argument(..., help="Destination path"),
    force: bool = typer.Option(
        False, "--force", "-f", help="Overwrite destination if it exists"
    ),
    dry_run: bool = typer.Option(
        False, "--dry-run", help="Show what would happen without making changes"
    ),
):
    """Copy a file."""
    try:
        # Run the operation
        success = asyncio.run(copy_file(
            source, destination, overwrite=force, dry_run=dry_run
        ))
        
        if success:
            if dry_run:
                console.print(f"[bold blue]DRY RUN:[/bold blue] Would copy {source} to {destination}")
            else:
                console.print(f"[bold green]Copied:[/bold green] {source} -> {destination}")
        else:
            console.print(f"[bold yellow]Operation cancelled.[/bold yellow]")
            sys.exit(1)
        
    except FileSystemError as e:
        logger.exception(f"Error copying file: {str(e)}")
        console.print(f"[bold red]Error:[/bold red] {str(e)}")
        sys.exit(1)


@app.command("mv")
def move_file_command(
    source: str = typer.Argument(..., help="Source file to move"),
    destination: str = typer.Argument(..., help="Destination path"),
    force: bool = typer.Option(
        False, "--force", "-f", help="Overwrite destination if it exists"
    ),
    dry_run: bool = typer.Option(
        False, "--dry-run", help="Show what would happen without making changes"
    ),
):
    """Move a file."""
    try:
        # Run the operation
        success = asyncio.run(move_file(
            source, destination, overwrite=force, dry_run=dry_run
        ))
        
        if success:
            if dry_run:
                console.print(f"[bold blue]DRY RUN:[/bold blue] Would move {source} to {destination}")
            else:
                console.print(f"[bold green]Moved:[/bold green] {source} -> {destination}")
        else:
            console.print(f"[bold yellow]Operation cancelled.[/bold yellow]")
            sys.exit(1)
        
    except FileSystemError as e:
        logger.exception(f"Error moving file: {str(e)}")
        console.print(f"[bold red]Error:[/bold red] {str(e)}")
        sys.exit(1)


@app.command("write")
def write_file_command(
    path: str = typer.Argument(..., help="File to write to"),
    content: str = typer.Option(
        None, "--content", "-c", help="Content to write (if not provided, will prompt)"
    ),
    append: bool = typer.Option(
        False, "--append", "-a", help="Append to file instead of overwriting"
    ),
    dry_run: bool = typer.Option(
        False, "--dry-run", help="Show what would happen without making changes"
    ),
):
    """Write content to a file."""
    try:
        # If content is not provided, prompt for it
        if content is None:
            console.print(f"Enter content for {path} (press Ctrl+D on a new line to finish):")
            lines = []
            try:
                while True:
                    line = input()
                    lines.append(line)
            except EOFError:
                pass
            content = "\n".join(lines)
        
        # Run the operation
        success = asyncio.run(write_file(
            path, content, append=append, dry_run=dry_run
        ))
        
        if success:
            if dry_run:
                mode = "append to" if append else "write to"
                console.print(f"[bold blue]DRY RUN:[/bold blue] Would {mode} file: {path}")
            else:
                mode = "Appended to" if append else "Wrote to"
                console.print(f"[bold green]{mode} file:[/bold green] {path}")
        else:
            console.print(f"[bold yellow]Operation cancelled.[/bold yellow]")
            sys.exit(1)
        
    except FileSystemError as e:
        logger.exception(f"Error writing file: {str(e)}")
        console.print(f"[bold red]Error:[/bold red] {str(e)}")
        sys.exit(1)


@app.command("find")
def find_files(
    pattern: str = typer.Argument(..., help="Pattern to search for"),
    path: str = typer.Option(
        ".", "--path", "-p", help="Directory to search in"
    ),
    include_hidden: bool = typer.Option(
        False, "--hidden", "-a", help="Include hidden files"
    ),
):
    """Find files matching a pattern."""
    try:
        base_dir = Path(path)
        if not base_dir.exists() or not base_dir.is_dir():
            console.print(f"[bold red]Error:[/bold red] Not a valid directory: {path}")
            sys.exit(1)
        
        # Find files matching the pattern
        matches = context_manager.find_files(
            pattern, base_dir=base_dir, include_hidden=include_hidden
        )
        
        if not matches:
            console.print(f"No files found matching pattern: {pattern}")
            return
        
        # Display results
        console.print(f"Found {len(matches)} files matching '{pattern}':")
        
        for match in matches:
            # Get file info
            file_info = context_manager.get_file_info(match)
            
            # Format the output
            if file_info.get("is_dir", False):
                console.print(f"[bold blue]{match}/[/bold blue]")
            elif file_info.get("language"):
                lang = file_info.get("language", "")
                console.print(f"[green]{match}[/green] - [magenta]{lang}[/magenta]")
            else:
                console.print(str(match))
        
    except Exception as e:
        logger.exception(f"Error finding files: {str(e)}")
        console.print(f"[bold red]Error:[/bold red] {str(e)}")
        sys.exit(1)


@app.command("rollback")
def rollback_command(
    list_only: bool = typer.Option(
        False, "--list", "-l", help="List recent operations without rolling back"
    ),
    operation_id: int = typer.Option(
        None, "--id", help="ID of the specific operation to roll back"
    ),
):
    """Roll back a previous file operation."""
    try:
        # Get recent operations
        operations = asyncio.run(rollback_manager.get_recent_operations())
        
        if not operations:
            console.print("No operations available for rollback.")
            return
        
        # If list_only is specified, just show the operations
        if list_only:
            table = Table(title="Recent Operations")
            table.add_column("ID", style="cyan")
            table.add_column("Timestamp", style="blue")
            table.add_column("Operation", style="green")
            table.add_column("Description")
            table.add_column("Can Rollback", style="magenta")
            
            for op in operations:
                can_rollback = "✓" if op["can_rollback"] else "✗"
                table.add_row(
                    str(op["id"]),
                    op["timestamp"],
                    op["operation_type"],
                    op["description"],
                    can_rollback
                )
            
            console.print(table)
            return
        
        # If no ID is provided, show the list and prompt for one
        if operation_id is None:
            table = Table(title="Recent Operations")
            table.add_column("ID", style="cyan")
            table.add_column("Timestamp", style="blue")
            table.add_column("Description")
            table.add_column("Can Rollback", style="magenta")
            
            for op in operations:
                can_rollback = "✓" if op["can_rollback"] else "✗"
                table.add_row(
                    str(op["id"]),
                    op["timestamp"],
                    op["description"],
                    can_rollback
                )
            
            console.print(table)
            
            # Prompt for the operation ID
            operation_id = int(Prompt.ask("Enter the ID of the operation to roll back"))
        
        # Check if the operation ID is valid
        valid_ids = [op["id"] for op in operations]
        if operation_id not in valid_ids:
            console.print(f"[bold red]Error:[/bold red] Invalid operation ID: {operation_id}")
            sys.exit(1)
        
        # Check if the operation can be rolled back
        operation = next(op for op in operations if op["id"] == operation_id)
        if not operation["can_rollback"]:
            console.print(f"[bold red]Error:[/bold red] Operation cannot be rolled back: {operation['description']}")
            sys.exit(1)
        
        # Confirm the rollback
        confirmed = Confirm.ask(f"Roll back operation: {operation['description']}?")
        if not confirmed:
            console.print("Rollback cancelled.")
            return
        
        # Perform the rollback
        success = asyncio.run(rollback_manager.rollback_operation(operation_id))
        
        if success:
            console.print(f"[bold green]Successfully rolled back:[/bold green] {operation['description']}")
        else:
            console.print(f"[bold red]Failed to roll back operation.[/bold red]")
            sys.exit(1)
        
    except Exception as e:
        logger.exception(f"Error during rollback: {str(e)}")
        console.print(f"[bold red]Error:[/bold red] {str(e)}")
        sys.exit(1)


@app.command("info")
def file_info(
    path: str = typer.Argument(
        None, help="File to get information about (defaults to current directory)"
    ),
    preview: bool = typer.Option(
        True, "--preview/--no-preview", help="Show file content preview"
    ),
):
    """Show detailed information about a file or directory."""
    try:
        file_path = Path(path) if path else context_manager.cwd
        
        if not file_path.exists():
            console.print(f"[bold red]Error:[/bold red] Path not found: {file_path}")
            sys.exit(1)
        
        # Get file information
        file_info = context_manager.get_file_info(file_path)
        
        # Display information
        console.print(Panel(
            f"[bold]Path:[/bold] {file_info['path']}\n"
            f"[bold]Type:[/bold] {file_info.get('type', 'unknown')}\n"
            + (f"[bold]Language:[/bold] {file_info.get('language', 'N/A')}\n" if file_info.get('language') else "")
            + (f"[bold]MIME Type:[/bold] {file_info.get('mime_type', 'N/A')}\n" if file_info.get('mime_type') else "")
            + (f"[bold]Size:[/bold] {format_size(file_info.get('size', 0))}\n" if 'size' in file_info else "")
            + (f"[bold]Binary:[/bold] {'Yes' if file_info.get('binary', False) else 'No'}\n" if not file_info.get('is_dir', False) else ""),
            title=f"Information for {file_path.name}",
            expand=False
        ))
        
        # Show content preview for files
        if preview and not file_info.get('is_dir', False) and not file_info.get('binary', False):
            content_preview = context_manager.get_file_preview(file_path)
            
            if content_preview:
                # Try to determine the language for syntax highlighting
                lang = "text"
                if file_info.get("language"):
                    lang_name = file_info.get("language", "").lower()
                    if "python" in lang_name:
                        lang = "python"
                    elif "javascript" in lang_name:
                        lang = "javascript"
                    elif "html" in lang_name:
                        lang = "html"
                    elif "css" in lang_name:
                        lang = "css"
                    elif "json" in lang_name:
                        lang = "json"
                    elif "yaml" in lang_name:
                        lang = "yaml"
                    elif "markdown" in lang_name:
                        lang = "markdown"
                    elif "bash" in lang_name or "shell" in lang_name:
                        lang = "bash"
                
                console.print(Panel(
                    Syntax(
                        content_preview,
                        lang,
                        theme="monokai",
                        line_numbers=True,
                        word_wrap=True
                    ),
                    title="Content Preview",
                    expand=False
                ))
        
    except Exception as e:
        logger.exception(f"Error getting file information: {str(e)}")
        console.print(f"[bold red]Error:[/bold red] {str(e)}")
        sys.exit(1)
</file>

<file path="angela/context/enhanced_file_activity.py">
"""
Enhanced file activity tracking for Angela CLI.

This module extends the basic file activity tracking to include fine-grained
tracking of specific code entities (functions, classes, methods) being modified,
providing deeper contextual awareness.
"""
import os
import re
import time
import difflib
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List, Tuple, Optional, Set, Union
from dataclasses import dataclass
from enum import Enum

from angela.utils.logging import get_logger
from angela.context.file_activity import file_activity_tracker, ActivityType
from angela.ai.semantic_analyzer import semantic_analyzer, Module, Function, Class

logger = get_logger(__name__)

class EntityType(str, Enum):
    """Types of code entities that can be tracked."""
    FUNCTION = "function"
    METHOD = "method"
    CLASS = "class"
    VARIABLE = "variable"
    IMPORT = "import"
    DOCSTRING = "docstring"
    PARAMETER = "parameter"
    UNKNOWN = "unknown"

@dataclass
class EntityActivity:
    """Represents an activity on a specific code entity."""
    entity_name: str
    entity_type: EntityType
    activity_type: ActivityType
    file_path: Path
    timestamp: float
    line_start: int
    line_end: int
    details: Dict[str, Any]
    before_content: Optional[str] = None
    after_content: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization."""
        return {
            "entity_name": self.entity_name,
            "entity_type": self.entity_type,
            "activity_type": self.activity_type,
            "file_path": str(self.file_path),
            "timestamp": self.timestamp,
            "datetime": datetime.fromtimestamp(self.timestamp).isoformat(),
            "line_start": self.line_start,
            "line_end": self.line_end,
            "details": self.details,
            "has_content_diff": self.before_content is not None and self.after_content is not None
        }

class EnhancedFileActivityTracker:
    """
    Enhanced tracker for file activities that includes code entity tracking.
    
    This class extends the basic file activity tracking to include:
    1. Function/method modification tracking
    2. Class structure changes
    3. Import statement changes
    4. Semantic diffs between versions
    """
    
    def __init__(self):
        """Initialize the enhanced file activity tracker."""
        self._logger = logger
        self._entity_activities: List[EntityActivity] = []
        self._max_activities = 100
        self._file_snapshots: Dict[str, Dict[str, Any]] = {}
        
        # Keep track of the last analyzed version of each file
        self._last_analyzed_modules: Dict[str, Module] = {}
        
        # Regular expressions for quick entity detection
        self._function_pattern = re.compile(r'(?:async\s+)?(?:def|function)\s+(\w+)\s*\(')
        self._class_pattern = re.compile(r'class\s+(\w+)\s*(?:\(|:)')
        self._import_pattern = re.compile(r'(?:import|from)\s+(\w+)')
    
    async def track_entity_changes(
        self, 
        file_path: Union[str, Path], 
        new_content: str = None,
        activity_type: ActivityType = ActivityType.MODIFIED,
        details: Dict[str, Any] = None
    ) -> List[EntityActivity]:
        """
        Track changes to specific entities within a file.
        
        Args:
            file_path: Path to the file being modified
            new_content: New content of the file (if None, will read from disk)
            activity_type: Type of activity
            details: Additional details about the activity
            
        Returns:
            List of entity activities detected
        """
        path_obj = Path(file_path)
        
        # Skip if file doesn't exist (or is being created)
        if not path_obj.exists() and activity_type != ActivityType.CREATED:
            return []
        
        # Skip binary files
        if self._is_binary_file(path_obj):
            return []
        
        # Get new content
        if new_content is None:
            try:
                with open(path_obj, 'r', encoding='utf-8', errors='replace') as f:
                    new_content = f.read()
            except Exception as e:
                self._logger.error(f"Error reading file {path_obj}: {str(e)}")
                return []
        
        # Get old content from snapshot or disk
        old_content = self._get_previous_content(path_obj)
        
        # If file is new or we don't have previous content
        if old_content is None:
            # This is a new file or we don't have previous content
            # Analyze it as a whole
            entity_activities = await self._analyze_new_file(path_obj, new_content, activity_type, details or {})
            
            # Update the snapshot
            self._update_file_snapshot(path_obj, new_content)
            
            return entity_activities
        
        # Skip if content hasn't changed
        if old_content == new_content:
            return []
        
        # Detect changed entities
        entity_activities = await self._detect_entity_changes(path_obj, old_content, new_content, details or {})
        
        # Update the snapshot
        self._update_file_snapshot(path_obj, new_content)
        
        return entity_activities
    
    def _is_binary_file(self, file_path: Path) -> bool:
        """Check if a file is binary."""
        try:
            with open(file_path, 'rb') as f:
                chunk = f.read(1024)
                return b'\0' in chunk
        except Exception:
            return False
    
    def _get_previous_content(self, file_path: Path) -> Optional[str]:
        """Get the previous content of a file from snapshot."""
        path_str = str(file_path)
        
        if path_str in self._file_snapshots:
            return self._file_snapshots[path_str].get('content')
        
        return None
    
    def _update_file_snapshot(self, file_path: Path, content: str) -> None:
        """Update the snapshot of a file."""
        path_str = str(file_path)
        
        self._file_snapshots[path_str] = {
            'content': content,
            'timestamp': time.time()
        }
    
    async def _analyze_new_file(
        self,
        file_path: Path,
        content: str,
        activity_type: ActivityType,
        details: Dict[str, Any]
    ) -> List[EntityActivity]:
        """
        Analyze a new file to detect all entities.
        
        Args:
            file_path: Path to the file
            content: Content of the file
            activity_type: Type of activity
            details: Additional details
            
        Returns:
            List of entity activities
        """
        # Use semantic analyzer to extract entities
        try:
            module = await semantic_analyzer.analyze_file(file_path)
            
            if not module:
                return []
            
            # Store module for later comparisons
            self._last_analyzed_modules[str(file_path)] = module
            
            entity_activities = []
            
            # Track classes
            for class_name, class_obj in module.classes.items():
                entity_activities.append(EntityActivity(
                    entity_name=class_name,
                    entity_type=EntityType.CLASS,
                    activity_type=activity_type,
                    file_path=file_path,
                    timestamp=time.time(),
                    line_start=class_obj.line_start,
                    line_end=class_obj.line_end,
                    details={
                        **details,
                        'methods_count': len(class_obj.methods),
                        'attributes_count': len(class_obj.attributes),
                        'base_classes': class_obj.base_classes
                    },
                    before_content=None,
                    after_content=self._extract_entity_content(content, class_obj.line_start, class_obj.line_end)
                ))
                
                # Track methods
                for method_name, method_obj in class_obj.methods.items():
                    entity_activities.append(EntityActivity(
                        entity_name=f"{class_name}.{method_name}",
                        entity_type=EntityType.METHOD,
                        activity_type=activity_type,
                        file_path=file_path,
                        timestamp=time.time(),
                        line_start=method_obj.line_start,
                        line_end=method_obj.line_end,
                        details={
                            **details,
                            'params': method_obj.params,
                            'class_name': class_name,
                            'return_type': method_obj.return_type
                        },
                        before_content=None,
                        after_content=self._extract_entity_content(content, method_obj.line_start, method_obj.line_end)
                    ))
            
            # Track functions
            for func_name, func_obj in module.functions.items():
                entity_activities.append(EntityActivity(
                    entity_name=func_name,
                    entity_type=EntityType.FUNCTION,
                    activity_type=activity_type,
                    file_path=file_path,
                    timestamp=time.time(),
                    line_start=func_obj.line_start,
                    line_end=func_obj.line_end,
                    details={
                        **details,
                        'params': func_obj.params,
                        'return_type': func_obj.return_type
                    },
                    before_content=None,
                    after_content=self._extract_entity_content(content, func_obj.line_start, func_obj.line_end)
                ))
            
            # Track imports
            for import_name, import_obj in module.imports.items():
                entity_activities.append(EntityActivity(
                    entity_name=import_name,
                    entity_type=EntityType.IMPORT,
                    activity_type=activity_type,
                    file_path=file_path,
                    timestamp=time.time(),
                    line_start=import_obj.line_start,
                    line_end=import_obj.line_end,
                    details={
                        **details,
                        'import_path': import_obj.import_path,
                        'is_from': import_obj.is_from
                    },
                    before_content=None,
                    after_content=self._extract_entity_content(content, import_obj.line_start, import_obj.line_end)
                ))
            
            # Store entity activities
            self._store_entity_activities(entity_activities)
            
            return entity_activities
            
        except Exception as e:
            self._logger.error(f"Error analyzing new file {file_path}: {str(e)}")
            return []
    
    async def _detect_entity_changes(
        self,
        file_path: Path,
        old_content: str,
        new_content: str,
        details: Dict[str, Any]
    ) -> List[EntityActivity]:
        """
        Detect changes to specific entities between file versions.
        
        Args:
            file_path: Path to the file
            old_content: Previous content of the file
            new_content: New content of the file
            details: Additional details
            
        Returns:
            List of entity activities
        """
        entity_activities = []
        
        # Use semantic analyzer to extract entities from both versions
        try:
            # Create a temporary file for the old content
            old_temp_path = file_path.with_suffix(f"{file_path.suffix}.old")
            with open(old_temp_path, 'w', encoding='utf-8') as f:
                f.write(old_content)
            
            # Analyze old and new versions
            old_module = await semantic_analyzer.analyze_file(old_temp_path)
            
            # Remove temporary file
            os.unlink(old_temp_path)
            
            # If we already have the old module analyzed, use it
            path_str = str(file_path)
            if path_str in self._last_analyzed_modules:
                old_module = self._last_analyzed_modules[path_str]
            
            # Analyze new version
            new_module = await semantic_analyzer.analyze_file(file_path)
            
            if not old_module or not new_module:
                # Fall back to diff-based detection
                return await self._detect_changes_by_diff(file_path, old_content, new_content, details)
            
            # Store new module for later comparisons
            self._last_analyzed_modules[path_str] = new_module
            
            # Compare classes
            entity_activities.extend(self._compare_classes(
                file_path, old_module, new_module, old_content, new_content, details
            ))
            
            # Compare standalone functions
            entity_activities.extend(self._compare_functions(
                file_path, old_module, new_module, old_content, new_content, details
            ))
            
            # Compare imports
            entity_activities.extend(self._compare_imports(
                file_path, old_module, new_module, old_content, new_content, details
            ))
            
            # Compare docstring
            if old_module.docstring != new_module.docstring:
                entity_activities.append(EntityActivity(
                    entity_name="module_docstring",
                    entity_type=EntityType.DOCSTRING,
                    activity_type=ActivityType.MODIFIED,
                    file_path=file_path,
                    timestamp=time.time(),
                    line_start=1,
                    line_end=1 + (new_module.docstring or "").count('\n'),
                    details=details,
                    before_content=old_module.docstring,
                    after_content=new_module.docstring
                ))
            
            # Fall back to diff-based detection if no entities were detected
            if not entity_activities:
                entity_activities = await self._detect_changes_by_diff(file_path, old_content, new_content, details)
            
            # Store entity activities
            self._store_entity_activities(entity_activities)
            
            return entity_activities
            
        except Exception as e:
            self._logger.error(f"Error analyzing entity changes in {file_path}: {str(e)}")
            
            # Fall back to diff-based detection
            return await self._detect_changes_by_diff(file_path, old_content, new_content, details)
    
    def _compare_classes(
        self,
        file_path: Path,
        old_module: Module,
        new_module: Module,
        old_content: str,
        new_content: str,
        details: Dict[str, Any]
    ) -> List[EntityActivity]:
        """
        Compare classes between module versions.
        
        Args:
            file_path: Path to the file
            old_module: Previous module
            new_module: New module
            old_content: Previous content
            new_content: New content
            details: Additional details
            
        Returns:
            List of entity activities
        """
        entity_activities = []
        
        # Check for added classes
        for class_name, new_class in new_module.classes.items():
            if class_name not in old_module.classes:
                # Class was added
                entity_activities.append(EntityActivity(
                    entity_name=class_name,
                    entity_type=EntityType.CLASS,
                    activity_type=ActivityType.CREATED,
                    file_path=file_path,
                    timestamp=time.time(),
                    line_start=new_class.line_start,
                    line_end=new_class.line_end,
                    details={
                        **details,
                        'methods_count': len(new_class.methods),
                        'attributes_count': len(new_class.attributes),
                        'base_classes': new_class.base_classes
                    },
                    before_content=None,
                    after_content=self._extract_entity_content(new_content, new_class.line_start, new_class.line_end)
                ))
                continue
            
            # Class exists in both - check for changes
            old_class = old_module.classes[class_name]
            
            # Check if class definition changed
            class_changed = (
                old_class.base_classes != new_class.base_classes or
                old_class.docstring != new_class.docstring or
                old_class.decorators != new_class.decorators
            )
            
            if class_changed:
                entity_activities.append(EntityActivity(
                    entity_name=class_name,
                    entity_type=EntityType.CLASS,
                    activity_type=ActivityType.MODIFIED,
                    file_path=file_path,
                    timestamp=time.time(),
                    line_start=new_class.line_start,
                    line_end=new_class.line_end,
                    details={
                        **details,
                        'methods_count': len(new_class.methods),
                        'attributes_count': len(new_class.attributes),
                        'old_base_classes': old_class.base_classes,
                        'new_base_classes': new_class.base_classes
                    },
                    before_content=self._extract_entity_content(old_content, old_class.line_start, old_class.line_end),
                    after_content=self._extract_entity_content(new_content, new_class.line_start, new_class.line_end)
                ))
            
            # Check for added/modified methods
            for method_name, new_method in new_class.methods.items():
                if method_name not in old_class.methods:
                    # Method was added
                    entity_activities.append(EntityActivity(
                        entity_name=f"{class_name}.{method_name}",
                        entity_type=EntityType.METHOD,
                        activity_type=ActivityType.CREATED,
                        file_path=file_path,
                        timestamp=time.time(),
                        line_start=new_method.line_start,
                        line_end=new_method.line_end,
                        details={
                            **details,
                            'params': new_method.params,
                            'class_name': class_name,
                            'return_type': new_method.return_type
                        },
                        before_content=None,
                        after_content=self._extract_entity_content(new_content, new_method.line_start, new_method.line_end)
                    ))
                    continue
                
                # Method exists in both - check for changes
                old_method = old_class.methods[method_name]
                method_changed = (
                    old_method.params != new_method.params or
                    old_method.return_type != new_method.return_type or
                    old_method.docstring != new_method.docstring or
                    self._extract_entity_content(old_content, old_method.line_start, old_method.line_end) !=
                    self._extract_entity_content(new_content, new_method.line_start, new_method.line_end)
                )
                
                if method_changed:
                    entity_activities.append(EntityActivity(
                        entity_name=f"{class_name}.{method_name}",
                        entity_type=EntityType.METHOD,
                        activity_type=ActivityType.MODIFIED,
                        file_path=file_path,
                        timestamp=time.time(),
                        line_start=new_method.line_start,
                        line_end=new_method.line_end,
                        details={
                            **details,
                            'old_params': old_method.params,
                            'new_params': new_method.params,
                            'class_name': class_name,
                            'old_return_type': old_method.return_type,
                            'new_return_type': new_method.return_type
                        },
                        before_content=self._extract_entity_content(old_content, old_method.line_start, old_method.line_end),
                        after_content=self._extract_entity_content(new_content, new_method.line_start, new_method.line_end)
                    ))
            
            # Check for removed methods
            for method_name in old_class.methods:
                if method_name not in new_class.methods:
                    # Method was removed
                    old_method = old_class.methods[method_name]
                    entity_activities.append(EntityActivity(
                        entity_name=f"{class_name}.{method_name}",
                        entity_type=EntityType.METHOD,
                        activity_type=ActivityType.DELETED,
                        file_path=file_path,
                        timestamp=time.time(),
                        line_start=old_method.line_start,
                        line_end=old_method.line_end,
                        details={
                            **details,
                            'params': old_method.params,
                            'class_name': class_name,
                            'return_type': old_method.return_type
                        },
                        before_content=self._extract_entity_content(old_content, old_method.line_start, old_method.line_end),
                        after_content=None
                    ))
        
        # Check for removed classes
        for class_name, old_class in old_module.classes.items():
            if class_name not in new_module.classes:
                # Class was removed
                entity_activities.append(EntityActivity(
                    entity_name=class_name,
                    entity_type=EntityType.CLASS,
                    activity_type=ActivityType.DELETED,
                    file_path=file_path,
                    timestamp=time.time(),
                    line_start=old_class.line_start,
                    line_end=old_class.line_end,
                    details={
                        **details,
                        'methods_count': len(old_class.methods),
                        'attributes_count': len(old_class.attributes),
                        'base_classes': old_class.base_classes
                    },
                    before_content=self._extract_entity_content(old_content, old_class.line_start, old_class.line_end),
                    after_content=None
                ))
        
        return entity_activities
    
    def _compare_functions(
        self,
        file_path: Path,
        old_module: Module,
        new_module: Module,
        old_content: str,
        new_content: str,
        details: Dict[str, Any]
    ) -> List[EntityActivity]:
        """
        Compare standalone functions between module versions.
        
        Args:
            file_path: Path to the file
            old_module: Previous module
            new_module: New module
            old_content: Previous content
            new_content: New content
            details: Additional details
            
        Returns:
            List of entity activities
        """
        entity_activities = []
        
        # Check for added functions
        for func_name, new_func in new_module.functions.items():
            if func_name not in old_module.functions:
                # Function was added
                entity_activities.append(EntityActivity(
                    entity_name=func_name,
                    entity_type=EntityType.FUNCTION,
                    activity_type=ActivityType.CREATED,
                    file_path=file_path,
                    timestamp=time.time(),
                    line_start=new_func.line_start,
                    line_end=new_func.line_end,
                    details={
                        **details,
                        'params': new_func.params,
                        'return_type': new_func.return_type
                    },
                    before_content=None,
                    after_content=self._extract_entity_content(new_content, new_func.line_start, new_func.line_end)
                ))
                continue
            
            # Function exists in both - check for changes
            old_func = old_module.functions[func_name]
            func_changed = (
                old_func.params != new_func.params or
                old_func.return_type != new_func.return_type or
                old_func.docstring != new_func.docstring or
                self._extract_entity_content(old_content, old_func.line_start, old_func.line_end) !=
                self._extract_entity_content(new_content, new_func.line_start, new_func.line_end)
            )
            
            if func_changed:
                entity_activities.append(EntityActivity(
                    entity_name=func_name,
                    entity_type=EntityType.FUNCTION,
                    activity_type=ActivityType.MODIFIED,
                    file_path=file_path,
                    timestamp=time.time(),
                    line_start=new_func.line_start,
                    line_end=new_func.line_end,
                    details={
                        **details,
                        'old_params': old_func.params,
                        'new_params': new_func.params,
                        'old_return_type': old_func.return_type,
                        'new_return_type': new_func.return_type
                    },
                    before_content=self._extract_entity_content(old_content, old_func.line_start, old_func.line_end),
                    after_content=self._extract_entity_content(new_content, new_func.line_start, new_func.line_end)
                ))
        
        # Check for removed functions
        for func_name, old_func in old_module.functions.items():
            if func_name not in new_module.functions:
                # Function was removed
                entity_activities.append(EntityActivity(
                    entity_name=func_name,
                    entity_type=EntityType.FUNCTION,
                    activity_type=ActivityType.DELETED,
                    file_path=file_path,
                    timestamp=time.time(),
                    line_start=old_func.line_start,
                    line_end=old_func.line_end,
                    details={
                        **details,
                        'params': old_func.params,
                        'return_type': old_func.return_type
                    },
                    before_content=self._extract_entity_content(old_content, old_func.line_start, old_func.line_end),
                    after_content=None
                ))
        
        return entity_activities
    
    def _compare_imports(
        self,
        file_path: Path,
        old_module: Module,
        new_module: Module,
        old_content: str,
        new_content: str,
        details: Dict[str, Any]
    ) -> List[EntityActivity]:
        """
        Compare imports between module versions.
        
        Args:
            file_path: Path to the file
            old_module: Previous module
            new_module: New module
            old_content: Previous content
            new_content: New content
            details: Additional details
            
        Returns:
            List of entity activities
        """
        entity_activities = []
        
        # Check for added imports
        for import_name, new_import in new_module.imports.items():
            if import_name not in old_module.imports:
                # Import was added
                entity_activities.append(EntityActivity(
                    entity_name=import_name,
                    entity_type=EntityType.IMPORT,
                    activity_type=ActivityType.CREATED,
                    file_path=file_path,
                    timestamp=time.time(),
                    line_start=new_import.line_start,
                    line_end=new_import.line_end,
                    details={
                        **details,
                        'import_path': new_import.import_path,
                        'is_from': new_import.is_from
                    },
                    before_content=None,
                    after_content=self._extract_entity_content(new_content, new_import.line_start, new_import.line_end)
                ))
                continue
            
            # Import exists in both - check for changes
            old_import = old_module.imports[import_name]
            import_changed = (
                old_import.import_path != new_import.import_path or
                old_import.is_from != new_import.is_from or
                old_import.alias != new_import.alias
            )
            
            if import_changed:
                entity_activities.append(EntityActivity(
                    entity_name=import_name,
                    entity_type=EntityType.IMPORT,
                    activity_type=ActivityType.MODIFIED,
                    file_path=file_path,
                    timestamp=time.time(),
                    line_start=new_import.line_start,
                    line_end=new_import.line_end,
                    details={
                        **details,
                        'old_import_path': old_import.import_path,
                        'new_import_path': new_import.import_path,
                        'old_is_from': old_import.is_from,
                        'new_is_from': new_import.is_from
                    },
                    before_content=self._extract_entity_content(old_content, old_import.line_start, old_import.line_end),
                    after_content=self._extract_entity_content(new_content, new_import.line_start, new_import.line_end)
                ))
        
        # Check for removed imports
        for import_name, old_import in old_module.imports.items():
            if import_name not in new_module.imports:
                # Import was removed
                entity_activities.append(EntityActivity(
                    entity_name=import_name,
                    entity_type=EntityType.IMPORT,
                    activity_type=ActivityType.DELETED,
                    file_path=file_path,
                    timestamp=time.time(),
                    line_start=old_import.line_start,
                    line_end=old_import.line_end,
                    details={
                        **details,
                        'import_path': old_import.import_path,
                        'is_from': old_import.is_from
                    },
                    before_content=self._extract_entity_content(old_content, old_import.line_start, old_import.line_end),
                    after_content=None
                ))
        
        return entity_activities
    
    async def _detect_changes_by_diff(
        self,
        file_path: Path,
        old_content: str,
        new_content: str,
        details: Dict[str, Any]
    ) -> List[EntityActivity]:
        """
        Use diff to detect changes when semantic analysis fails.
        
        Args:
            file_path: Path to the file
            old_content: Previous content
            new_content: New content
            details: Additional details
            
        Returns:
            List of entity activities
        """
        if not old_content or not new_content:
            return []
        
        entity_activities = []
        
        # Generate diff
        diff = list(difflib.unified_diff(
            old_content.splitlines(),
            new_content.splitlines(),
            n=3  # Context lines
        ))
        
        if not diff:
            return []
        
        # Extract chunks of changes
        current_chunk = []
        chunks = []
        
        for line in diff:
            if line.startswith('@@'):
                if current_chunk:
                    chunks.append(current_chunk)
                current_chunk = [line]
            elif current_chunk:
                current_chunk.append(line)
        
        if current_chunk:
            chunks.append(current_chunk)
        
        # Process each chunk to detect entity changes
        for chunk in chunks:
            if not chunk:
                continue
            
            # Parse chunk header to get line numbers
            header = chunk[0]
            match = re.search(r'@@ -(\d+),(\d+) \+(\d+),(\d+) @@', header)
            if not match:
                continue
            
            old_start, old_count = int(match.group(1)), int(match.group(2))
            new_start, new_count = int(match.group(3)), int(match.group(4))
            
            # Get the chunk content
            chunk_content = chunk[1:]
            
            # Try to identify entities in this chunk
            entity_activity = self._identify_entity_in_diff_chunk(
                file_path, old_content, new_content, old_start, old_count, new_start, new_count, chunk_content, details
            )
            
            if entity_activity:
                entity_activities.append(entity_activity)
            else:
                # Fall back to a generic line range activity
                entity_activities.append(EntityActivity(
                    entity_name=f"line_range_{new_start}_{new_start + new_count}",
                    entity_type=EntityType.UNKNOWN,
                    activity_type=ActivityType.MODIFIED,
                    file_path=file_path,
                    timestamp=time.time(),
                    line_start=new_start,
                    line_end=new_start + new_count,
                    details=details,
                    before_content="\n".join(old_content.splitlines()[old_start-1:old_start+old_count-1]),
                    after_content="\n".join(new_content.splitlines()[new_start-1:new_start+new_count-1])
                ))
        
        # Store entity activities
        self._store_entity_activities(entity_activities)
        
        return entity_activities
    
    def _identify_entity_in_diff_chunk(
        self,
        file_path: Path,
        old_content: str,
        new_content: str,
        old_start: int,
        old_count: int,
        new_start: int,
        new_count: int,
        chunk_content: List[str],
        details: Dict[str, Any]
    ) -> Optional[EntityActivity]:
        """
        Try to identify what entity was modified in a diff chunk.
        
        Args:
            file_path: Path to the file
            old_content: Previous content
            new_content: New content
            old_start: Starting line in old content (1-based)
            old_count: Number of lines in old content
            new_start: Starting line in new content (1-based)
            new_count: Number of lines in new content
            chunk_content: Content of the diff chunk
            details: Additional details
            
        Returns:
            EntityActivity if identified, None otherwise
        """
        # Get the surrounding context from old and new content
        old_context_start = max(1, old_start - 10)
        old_context_end = min(len(old_content.splitlines()), old_start + old_count + 10)
        old_context = old_content.splitlines()[old_context_start-1:old_context_end]
        
        new_context_start = max(1, new_start - 10)
        new_context_end = min(len(new_content.splitlines()), new_start + new_count + 10)
        new_context = new_content.splitlines()[new_context_start-1:new_context_end]
        
        # Check for function definitions
        for i, line in enumerate(old_context):
            match = self._function_pattern.search(line)
            if match:
                func_start = old_context_start + i
                if old_start <= func_start <= old_start + old_count:
                    # Function was modified or deleted
                    func_name = match.group(1)
                    
                    # Look for the same function in new content
                    found_in_new = False
                    new_func_start = 0
                    
                    for j, new_line in enumerate(new_context):
                        new_match = self._function_pattern.search(new_line)
                        if new_match and new_match.group(1) == func_name:
                            found_in_new = True
                            new_func_start = new_context_start + j
                            break
                    
                    activity_type = ActivityType.MODIFIED if found_in_new else ActivityType.DELETED
                    
                    # Estimate function end
                    old_func_end = self._estimate_entity_end(old_content, func_start)
                    new_func_end = self._estimate_entity_end(new_content, new_func_start) if found_in_new else 0
                    
                    return EntityActivity(
                        entity_name=func_name,
                        entity_type=EntityType.FUNCTION,
                        activity_type=activity_type,
                        file_path=file_path,
                        timestamp=time.time(),
                        line_start=new_func_start if found_in_new else func_start,
                        line_end=new_func_end if found_in_new else old_func_end,
                        details=details,
                        before_content=self._extract_entity_content(old_content, func_start, old_func_end),
                        after_content=self._extract_entity_content(new_content, new_func_start, new_func_end) if found_in_new else None
                    )
        
        # Check for new functions in the new content
        for i, line in enumerate(new_context):
            match = self._function_pattern.search(line)
            if match:
                func_start = new_context_start + i
                if new_start <= func_start <= new_start + new_count:
                    # New function was added
                    func_name = match.group(1)
                    
                    # Check if this function exists in old content
                    found_in_old = False
                    for old_line in old_context:
                        old_match = self._function_pattern.search(old_line)
                        if old_match and old_match.group(1) == func_name:
                            found_in_old = True
                            break
                    
                    if not found_in_old:
                        # Estimate function end
                        func_end = self._estimate_entity_end(new_content, func_start)
                        
                        return EntityActivity(
                            entity_name=func_name,
                            entity_type=EntityType.FUNCTION,
                            activity_type=ActivityType.CREATED,
                            file_path=file_path,
                            timestamp=time.time(),
                            line_start=func_start,
                            line_end=func_end,
                            details=details,
                            before_content=None,
                            after_content=self._extract_entity_content(new_content, func_start, func_end)
                        )
        
        # Check for class definitions
        for i, line in enumerate(old_context):
            match = self._class_pattern.search(line)
            if match:
                class_start = old_context_start + i
                if old_start <= class_start <= old_start + old_count:
                    # Class was modified or deleted
                    class_name = match.group(1)
                    
                    # Look for the same class in new content
                    found_in_new = False
                    new_class_start = 0
                    
                    for j, new_line in enumerate(new_context):
                        new_match = self._class_pattern.search(new_line)
                        if new_match and new_match.group(1) == class_name:
                            found_in_new = True
                            new_class_start = new_context_start + j
                            break
                    
                    activity_type = ActivityType.MODIFIED if found_in_new else ActivityType.DELETED
                    
                    # Estimate class end
                    old_class_end = self._estimate_entity_end(old_content, class_start)
                    new_class_end = self._estimate_entity_end(new_content, new_class_start) if found_in_new else 0
                    
                    return EntityActivity(
                        entity_name=class_name,
                        entity_type=EntityType.CLASS,
                        activity_type=activity_type,
                        file_path=file_path,
                        timestamp=time.time(),
                        line_start=new_class_start if found_in_new else class_start,
                        line_end=new_class_end if found_in_new else old_class_end,
                        details=details,
                        before_content=self._extract_entity_content(old_content, class_start, old_class_end),
                        after_content=self._extract_entity_content(new_content, new_class_start, new_class_end) if found_in_new else None
                    )
        
        # Check for new classes in the new content
        for i, line in enumerate(new_context):
            match = self._class_pattern.search(line)
            if match:
                class_start = new_context_start + i
                if new_start <= class_start <= new_start + new_count:
                    # New class was added
                    class_name = match.group(1)
                    
                    # Check if this class exists in old content
                    found_in_old = False
                    for old_line in old_context:
                        old_match = self._class_pattern.search(old_line)
                        if old_match and old_match.group(1) == class_name:
                            found_in_old = True
                            break
                    
                    if not found_in_old:
                        # Estimate class end
                        class_end = self._estimate_entity_end(new_content, class_start)
                        
                        return EntityActivity(
                            entity_name=class_name,
                            entity_type=EntityType.CLASS,
                            activity_type=ActivityType.CREATED,
                            file_path=file_path,
                            timestamp=time.time(),
                            line_start=class_start,
                            line_end=class_end,
                            details=details,
                            before_content=None,
                            after_content=self._extract_entity_content(new_content, class_start, class_end)
                        )
        
        # Check for import statements
        for i, line in enumerate(old_context):
            match = self._import_pattern.search(line)
            if match:
                import_start = old_context_start + i
                if old_start <= import_start <= old_start + old_count:
                    # Import was modified or deleted
                    import_name = match.group(1)
                    
                    # Look for the same import in new content
                    found_in_new = False
                    new_import_start = 0
                    
                    for j, new_line in enumerate(new_context):
                        new_match = self._import_pattern.search(new_line)
                        if new_match and new_match.group(1) == import_name:
                            found_in_new = True
                            new_import_start = new_context_start + j
                            break
                    
                    activity_type = ActivityType.MODIFIED if found_in_new else ActivityType.DELETED
                    
                    return EntityActivity(
                        entity_name=import_name,
                        entity_type=EntityType.IMPORT,
                        activity_type=activity_type,
                        file_path=file_path,
                        timestamp=time.time(),
                        line_start=new_import_start if found_in_new else import_start,
                        line_end=new_import_start if found_in_new else import_start,
                        details=details,
                        before_content=line.strip(),
                        after_content=new_context[new_import_start - new_context_start].strip() if found_in_new else None
                    )
        
        # Check for new imports in the new content
        for i, line in enumerate(new_context):
            match = self._import_pattern.search(line)
            if match:
                import_start = new_context_start + i
                if new_start <= import_start <= new_start + new_count:
                    # New import was added
                    import_name = match.group(1)
                    
                    # Check if this import exists in old content
                    found_in_old = False
                    for old_line in old_context:
                        old_match = self._import_pattern.search(old_line)
                        if old_match and old_match.group(1) == import_name:
                            found_in_old = True
                            break
                    
                    if not found_in_old:
                        return EntityActivity(
                            entity_name=import_name,
                            entity_type=EntityType.IMPORT,
                            activity_type=ActivityType.CREATED,
                            file_path=file_path,
                            timestamp=time.time(),
                            line_start=import_start,
                            line_end=import_start,
                            details=details,
                            before_content=None,
                            after_content=line.strip()
                        )
        
        return None
    
    def _extract_entity_content(self, content: str, start_line: int, end_line: int) -> str:
        """
        Extract entity content from a file.
        
        Args:
            content: File content
            start_line: Starting line number (1-based)
            end_line: Ending line number (1-based)
            
        Returns:
            Extracted content
        """
        if not content:
            return ""
        
        lines = content.splitlines()
        
        # Adjust line numbers to be within bounds
        start_idx = max(0, start_line - 1)
        end_idx = min(len(lines), end_line)
        
        return "\n".join(lines[start_idx:end_idx])
    
    def _estimate_entity_end(self, content: str, start_line: int) -> int:
        """
        Estimate the ending line number of an entity.
        
        Args:
            content: File content
            start_line: Starting line number (1-based)
            
        Returns:
            Estimated ending line number (1-based)
        """
        lines = content.splitlines()
        
        # Adjust line number to be within bounds
        start_idx = max(0, start_line - 1)
        
        if start_idx >= len(lines):
            return start_line
        
        # Count indentation of the entity definition line
        first_line = lines[start_idx]
        indent_match = re.match(r'^(\s*)', first_line)
        base_indent = len(indent_match.group(1)) if indent_match else 0
        
        # Find the first line with the same or less indentation
        for i in range(start_idx + 1, len(lines)):
            line = lines[i]
            
            # Skip empty lines
            if not line.strip():
                continue
            
            # Check indentation
            indent_match = re.match(r'^(\s*)', line)
            indent = len(indent_match.group(1)) if indent_match else 0
            
            if indent <= base_indent:
                return i + 1  # 1-based line number
        
        # If we reach the end of the file, return the last line number
        return len(lines)
    
    def _store_entity_activities(self, entity_activities: List[EntityActivity]) -> None:
        """
        Store entity activities and log them to the basic file activity tracker.
        
        Args:
            entity_activities: List of entity activities to store
        """
        # Add to the entity activities list
        self._entity_activities.extend(entity_activities)
        
        # Trim if needed
        if len(self._entity_activities) > self._max_activities:
            self._entity_activities = self._entity_activities[-self._max_activities:]
        
        # Log to the basic file activity tracker
        for activity in entity_activities:
            entity_str = f"{activity.entity_type.value}:{activity.entity_name}"
            
            # Track in the basic file activity tracker
            file_activity_tracker.track_activity(
                path=activity.file_path,
                activity_type=activity.activity_type,
                details={
                    "entity_name": activity.entity_name,
                    "entity_type": activity.entity_type.value,
                    "line_start": activity.line_start,
                    "line_end": activity.line_end,
                    **activity.details
                }
            )
            
            # Log the activity
            self._logger.debug(
                f"Tracked {activity.activity_type.value} of {entity_str} "
                f"in {activity.file_path.name}:{activity.line_start}-{activity.line_end}"
            )
    
    def get_recent_entity_activities(
        self,
        limit: int = 10,
        entity_types: Optional[List[EntityType]] = None,
        activity_types: Optional[List[ActivityType]] = None
    ) -> List[Dict[str, Any]]:
        """
        Get recent entity activities.
        
        Args:
            limit: Maximum number of activities to return
            entity_types: Optional filter for entity types
            activity_types: Optional filter for activity types
            
        Returns:
            List of entity activities as dictionaries
        """
        # Apply filters
        filtered = self._entity_activities
        
        if entity_types:
            filtered = [a for a in filtered if a.entity_type in entity_types]
        
        if activity_types:
            filtered = [a for a in filtered if a.activity_type in activity_types]
        
        # Sort by timestamp (newest first)
        sorted_activities = sorted(filtered, key=lambda a: a.timestamp, reverse=True)
        
        # Convert to dictionaries
        return [a.to_dict() for a in sorted_activities[:limit]]
    
    def get_entity_activities_by_name(
        self,
        entity_name: str,
        limit: int = 10
    ) -> List[Dict[str, Any]]:
        """
        Get activities for a specific entity.
        
        Args:
            entity_name: Name of the entity
            limit: Maximum number of activities to return
            
        Returns:
            List of entity activities as dictionaries
        """
        # Filter by entity name
        filtered = [a for a in self._entity_activities if a.entity_name == entity_name]
        
        # Sort by timestamp (newest first)
        sorted_activities = sorted(filtered, key=lambda a: a.timestamp, reverse=True)
        
        # Convert to dictionaries
        return [a.to_dict() for a in sorted_activities[:limit]]
    
    def get_most_active_entities(self, limit: int = 5) -> List[Dict[str, Any]]:
        """
        Get the most actively modified entities.
        
        Args:
            limit: Maximum number of entities to return
            
        Returns:
            List of entities with activity counts
        """
        # Count activities by entity
        entity_counts = {}
        
        for activity in self._entity_activities:
            key = f"{activity.entity_type.value}:{activity.entity_name}"
            
            if key not in entity_counts:
                entity_counts[key] = {
                    "entity_name": activity.entity_name,
                    "entity_type": activity.entity_type.value,
                    "count": 0,
                    "last_activity": None,
                    "activity_types": set()
                }
            
            entity_counts[key]["count"] += 1
            entity_counts[key]["activity_types"].add(activity.activity_type.value)
            
            # Update last activity if newer
            if entity_counts[key]["last_activity"] is None or activity.timestamp > entity_counts[key]["last_activity"]:
                entity_counts[key]["last_activity"] = activity.timestamp
                entity_counts[key]["file_path"] = str(activity.file_path)
                entity_counts[key]["line_start"] = activity.line_start
                entity_counts[key]["line_end"] = activity.line_end
        
        # Convert to list and sort by count
        result = []
        for key, entity_info in entity_counts.items():
            # Convert activity types set to list
            entity_info["activity_types"] = list(entity_info["activity_types"])
            
            # Add formatted timestamp
            if entity_info["last_activity"]:
                entity_info["last_activity_time"] = datetime.fromtimestamp(entity_info["last_activity"]).isoformat()
            
            result.append(entity_info)
        
        result.sort(key=lambda x: x["count"], reverse=True)
        
        return result[:limit]
    
    def clear_activities(self) -> None:
        """Clear all tracked activities."""
        self._entity_activities.clear()
        self._file_snapshots.clear()
        self._last_analyzed_modules.clear()
        self._logger.debug("Cleared all entity activities and snapshots")
    
    def get_entity_history(self, entity_name: str, entity_type: Optional[EntityType] = None) -> List[Dict[str, Any]]:
        """
        Get the complete history of changes for a specific entity.
        
        Args:
            entity_name: Name of the entity
            entity_type: Optional entity type filter
            
        Returns:
            List of activities for the entity, ordered by time
        """
        # Filter activities
        filtered = [a for a in self._entity_activities if a.entity_name == entity_name]
        
        if entity_type:
            filtered = [a for a in filtered if a.entity_type == entity_type]
        
        # Sort by timestamp (oldest first for history)
        sorted_activities = sorted(filtered, key=lambda a: a.timestamp)
        
        # Convert to dictionaries
        return [a.to_dict() for a in sorted_activities]

# Global enhanced file activity tracker instance
enhanced_file_activity_tracker = EnhancedFileActivityTracker()
</file>

<file path="angela/context/enhancer.py">
"""
Enhanced project context management for Angela CLI.

This module provides advanced context enrichment by integrating project inference,
dependency detection, and file activity tracking to provide a richer context
for AI interactions.
"""
import asyncio
from typing import Dict, Any, Optional, List, Set
from pathlib import Path

from angela.context import context_manager
from angela.context.project_inference import project_inference
from angela.context.session import session_manager
from angela.config import config_manager
from angela.utils.logging import get_logger

logger = get_logger(__name__)

class ContextEnhancer:
    """
    Enhanced context manager that enriches context with project information,
    dependency detection, and recent activity tracking.
    """
    
    def __init__(self):
        """Initialize the context enhancer."""
        self._logger = logger
        self._project_info_cache = {}  # Cache project info by path
        self._file_activity_cache = {}  # Cache recent file activity
    
    async def enrich_context(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """
        Enrich the context with additional information.
        
        Args:
            context: The base context to enrich
            
        Returns:
            The enriched context
        """
        self._logger.debug("Enriching context with additional information")
        
        # Start with a copy of the original context
        enriched = dict(context)
        
        # Add enhanced project information if in a project
        if context.get("project_root"):
            await self._add_project_info(enriched, context["project_root"])
        
        # Add recent file activity
        await self._add_recent_file_activity(enriched)
        
        # Add file reference context
        await self._add_file_reference_context(enriched)
        
        self._logger.debug(f"Context enriched with {len(enriched) - len(context)} additional keys")
        return enriched
    
    async def _add_project_info(self, context: Dict[str, Any], project_root: str) -> None:
        """
        Add enhanced project information to the context.
        
        Args:
            context: The context to enrich
            project_root: The path to the project root
        """
        self._logger.debug(f"Adding project info for {project_root}")
        
        try:
            # Check cache first
            if project_root in self._project_info_cache:
                project_info = self._project_info_cache[project_root]
                self._logger.debug(f"Using cached project info for {project_root}")
            else:
                # Get project info from project_inference
                project_info = await project_inference.infer_project_info(Path(project_root))
                # Cache the result
                self._project_info_cache[project_root] = project_info
                self._logger.debug(f"Inferred project info for {project_root}")
            
            # Add project info to context
            context["enhanced_project"] = {
                "type": project_info.get("project_type", "unknown"),
                "frameworks": project_info.get("detected_frameworks", {}),
                "dependencies": self._format_dependencies(project_info.get("dependencies", [])),
                "important_files": self._format_important_files(project_info.get("detected_files", [])),
                "structure": self._summarize_structure(project_info.get("structure", {}))
            }
            
            self._logger.debug(f"Added enhanced project info to context: {context['enhanced_project']['type']}")
        except Exception as e:
            self._logger.error(f"Error adding project info: {str(e)}")
    
    def _format_dependencies(self, dependencies: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Format dependencies for inclusion in context.
        
        Args:
            dependencies: List of dependency information
            
        Returns:
            Formatted dependency information
        """
        # Group dependencies by type
        dependency_types = {}
        
        for dep in dependencies:
            dep_type = dep.get("type", "unknown")
            if dep_type not in dependency_types:
                dependency_types[dep_type] = []
            
            dependency_types[dep_type].append({
                "name": dep.get("name", "unknown"),
                "version": dep.get("version_spec", "")
            })
        
        # Return summary with counts
        return {
            "types": list(dependency_types.keys()),
            "counts": {t: len(deps) for t, deps in dependency_types.items()},
            "total": len(dependencies),
            "top_dependencies": [d.get("name", "unknown") for d in dependencies[:10]]
        }
    
    def _format_important_files(self, files: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Format important files for inclusion in context.
        
        Args:
            files: List of important file information
            
        Returns:
            Formatted important file information
        """
        # Group files by type
        file_types = {}
        paths = []
        
        for file in files:
            file_type = file.get("type", "unknown")
            if file_type not in file_types:
                file_types[file_type] = []
            
            file_types[file_type].append(file.get("path", "unknown"))
            paths.append(file.get("path", "unknown"))
        
        # Return summary
        return {
            "types": list(file_types.keys()),
            "counts": {t: len(files) for t, files in file_types.items()},
            "total": len(files),
            "paths": paths
        }
    
    def _summarize_structure(self, structure: Dict[str, Any]) -> Dict[str, Any]:
        """
        Summarize project structure for inclusion in context.
        
        Args:
            structure: Project structure information
            
        Returns:
            Summarized structure information
        """
        # Extract key information from structure
        if not structure:
            return {}
        
        # Return summary
        return {
            "file_counts": structure.get("file_counts", {}),
            "total_files": structure.get("total_files", 0),
            "main_directories": [d.get("name", "") for d in structure.get("main_directories", [])]
        }
    
    async def _add_recent_file_activity(self, context: Dict[str, Any]) -> None:
        """
        Add recent file activity to the context.
        
        Args:
            context: The context to enrich
        """
        self._logger.debug("Adding recent file activity to context")
        
        try:
            # Get recent file activities from session
            session = session_manager.get_context()
            entities = session.get("entities", {})
            
            # Filter for file-related entities
            file_entities = {
                name: entity for name, entity in entities.items()
                if entity.get("type") in ["file", "directory", "recent_file"]
            }
            
            # Get recent file activities from history
            recent_activities = []
            
            # Format and add to context
            context["recent_files"] = {
                "accessed": [entity.get("value", "") for name, entity in file_entities.items()],
                "activities": recent_activities,
                "count": len(file_entities)
            }
            
            self._logger.debug(f"Added {len(file_entities)} recent files to context")
        except Exception as e:
            self._logger.error(f"Error adding recent file activity: {str(e)}")
    
    async def _add_file_reference_context(self, context: Dict[str, Any]) -> None:
        """
        Add file reference context information.
        
        Args:
            context: The context to enrich
        """
        self._logger.debug("Adding file reference context")
        
        try:
            # Get current working directory
            cwd = context.get("cwd", "")
            if not cwd:
                return
            
            # List files in the current directory
            cwd_path = Path(cwd)
            files = list(cwd_path.glob("*"))
            
            # Format file information
            file_info = {
                "files": [f.name for f in files if f.is_file()],
                "directories": [f.name for f in files if f.is_dir()],
                "total": len(files)
            }
            
            # Add to context
            context["file_reference"] = file_info
            
            self._logger.debug(f"Added file reference context with {len(files)} files")
        except Exception as e:
            self._logger.error(f"Error adding file reference context: {str(e)}")
    
    def clear_cache(self) -> None:
        """Clear the context enhancer cache."""
        self._logger.debug("Clearing context enhancer cache")
        self._project_info_cache.clear()
        self._file_activity_cache.clear()

# Global context enhancer instance
context_enhancer = ContextEnhancer()
</file>

<file path="angela/context/file_activity.py">
"""
File activity tracking for Angela CLI.

This module provides functionality to track file activities such as access,
modification, and creation, and to maintain a history of these activities.
"""
import os
import time
from datetime import datetime
from enum import Enum
from pathlib import Path
from typing import Dict, Any, Optional, List, Set, Union

from angela.context.session import session_manager
from angela.utils.logging import get_logger

logger = get_logger(__name__)

class ActivityType(str, Enum):
    """Types of file activities."""
    CREATED = "created"
    MODIFIED = "modified"
    DELETED = "deleted"
    VIEWED = "viewed"
    EXECUTED = "executed"
    ANALYZED = "analyzed"
    OTHER = "other"

class FileActivity:
    """Represents a file activity with related metadata."""
    
    def __init__(
        self,
        path: Union[str, Path],
        activity_type: ActivityType,
        timestamp: Optional[float] = None,
        command: Optional[str] = None,
        details: Optional[Dict[str, Any]] = None
    ):
        """
        Initialize a file activity.
        
        Args:
            path: Path to the file/directory
            activity_type: Type of activity
            timestamp: Optional timestamp (defaults to current time)
            command: Optional command that triggered the activity
            details: Optional additional details
        """
        self.path = Path(path) if isinstance(path, str) else path
        self.activity_type = activity_type
        self.timestamp = timestamp or time.time()
        self.command = command
        self.details = details or {}
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization."""
        return {
            "path": str(self.path),
            "name": self.path.name,
            "activity_type": self.activity_type.value,
            "timestamp": self.timestamp,
            "datetime": datetime.fromtimestamp(self.timestamp).isoformat(),
            "command": self.command,
            "details": self.details
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'FileActivity':
        """Create from dictionary."""
        return cls(
            path=data["path"],
            activity_type=ActivityType(data["activity_type"]),
            timestamp=data["timestamp"],
            command=data.get("command"),
            details=data.get("details", {})
        )


class FileActivityTracker:
    """
    Tracker for file activities with session integration.
    
    Provides methods to:
    1. Track file activities (creation, modification, etc.)
    2. Retrieve recent file activities
    3. Integrate with session management
    """
    
    def __init__(self, max_activities: int = 100):
        """
        Initialize the file activity tracker.
        
        Args:
            max_activities: Maximum number of activities to track
        """
        self._logger = logger
        self._activities: List[FileActivity] = []
        self._max_activities = max_activities
    
    def track_activity(
        self,
        path: Union[str, Path],
        activity_type: ActivityType,
        command: Optional[str] = None,
        details: Optional[Dict[str, Any]] = None
    ) -> None:
        """
        Track a file activity.
        
        Args:
            path: Path to the file/directory
            activity_type: Type of activity
            command: Optional command that triggered the activity
            details: Optional additional details
        """
        # Create a new activity
        activity = FileActivity(
            path=path,
            activity_type=activity_type,
            command=command,
            details=details
        )
        
        # Add to the activity list
        self._activities.append(activity)
        
        # Trim if needed
        if len(self._activities) > self._max_activities:
            self._activities = self._activities[-self._max_activities:]
        
        # Update session
        self._update_session(activity)
        
        self._logger.debug(f"Tracked {activity_type.value} activity for {path}")
    
    def track_file_creation(
        self,
        path: Union[str, Path],
        command: Optional[str] = None,
        details: Optional[Dict[str, Any]] = None
    ) -> None:
        """
        Track file creation.
        
        Args:
            path: Path to the created file
            command: Optional command that triggered the creation
            details: Optional additional details
        """
        self.track_activity(
            path=path,
            activity_type=ActivityType.CREATED,
            command=command,
            details=details
        )
    
    def track_file_modification(
        self,
        path: Union[str, Path],
        command: Optional[str] = None,
        details: Optional[Dict[str, Any]] = None
    ) -> None:
        """
        Track file modification.
        
        Args:
            path: Path to the modified file
            command: Optional command that triggered the modification
            details: Optional additional details
        """
        self.track_activity(
            path=path,
            activity_type=ActivityType.MODIFIED,
            command=command,
            details=details
        )
    
    def track_file_deletion(
        self,
        path: Union[str, Path],
        command: Optional[str] = None,
        details: Optional[Dict[str, Any]] = None
    ) -> None:
        """
        Track file deletion.
        
        Args:
            path: Path to the deleted file
            command: Optional command that triggered the deletion
            details: Optional additional details
        """
        self.track_activity(
            path=path,
            activity_type=ActivityType.DELETED,
            command=command,
            details=details
        )
    
    def track_file_viewing(
        self,
        path: Union[str, Path],
        command: Optional[str] = None,
        details: Optional[Dict[str, Any]] = None
    ) -> None:
        """
        Track file viewing.
        
        Args:
            path: Path to the viewed file
            command: Optional command that triggered the viewing
            details: Optional additional details
        """
        self.track_activity(
            path=path,
            activity_type=ActivityType.VIEWED,
            command=command,
            details=details
        )
    
    def get_recent_activities(
        self,
        limit: int = 10,
        activity_types: Optional[List[ActivityType]] = None
    ) -> List[Dict[str, Any]]:
        """
        Get recent file activities.
        
        Args:
            limit: Maximum number of activities to return
            activity_types: Optional filter for activity types
            
        Returns:
            List of activities as dictionaries
        """
        # Apply filters
        filtered = self._activities
        if activity_types:
            filtered = [a for a in filtered if a.activity_type in activity_types]
        
        # Sort by timestamp (newest first)
        sorted_activities = sorted(filtered, key=lambda a: a.timestamp, reverse=True)
        
        # Convert to dictionaries
        return [a.to_dict() for a in sorted_activities[:limit]]
    
    def get_activities_for_path(
        self,
        path: Union[str, Path],
        limit: int = 10
    ) -> List[Dict[str, Any]]:
        """
        Get activities for a specific path.
        
        Args:
            path: Path to get activities for
            limit: Maximum number of activities to return
            
        Returns:
            List of activities as dictionaries
        """
        path_obj = Path(path) if isinstance(path, str) else path
        
        # Filter by path
        path_activities = [a for a in self._activities if a.path == path_obj]
        
        # Sort by timestamp (newest first)
        sorted_activities = sorted(path_activities, key=lambda a: a.timestamp, reverse=True)
        
        # Convert to dictionaries
        return [a.to_dict() for a in sorted_activities[:limit]]
    
    def get_most_active_files(self, limit: int = 5) -> List[Dict[str, Any]]:
        """
        Get the most actively used files.
        
        Args:
            limit: Maximum number of files to return
            
        Returns:
            List of files with activity counts
        """
        # Count activities by path
        path_counts = {}
        for activity in self._activities:
            path_str = str(activity.path)
            if path_str not in path_counts:
                path_counts[path_str] = {
                    "path": path_str,
                    "name": activity.path.name,
                    "count": 0,
                    "last_activity": None,
                    "activities": set()
                }
            
            path_counts[path_str]["count"] += 1
            path_counts[path_str]["activities"].add(activity.activity_type.value)
            
            # Update last activity if newer
            if path_counts[path_str]["last_activity"] is None or \
               activity.timestamp > path_counts[path_str]["last_activity"]:
                path_counts[path_str]["last_activity"] = activity.timestamp
        
        # Convert to list and sort by count (highest first)
        result = []
        for path_info in path_counts.values():
            # Convert activities set to list
            path_info["activities"] = list(path_info["activities"])
            result.append(path_info)
        
        result.sort(key=lambda x: x["count"], reverse=True)
        
        return result[:limit]
    
    def clear_activities(self) -> None:
        """Clear all tracked activities."""
        self._activities.clear()
        self._logger.debug("Cleared all file activities")
    
    def _update_session(self, activity: FileActivity) -> None:
        """
        Update session with file activity.
        
        Args:
            activity: The file activity to add to the session
        """
        try:
            # Add to session as an entity
            path_name = activity.path.name
            entity_name = f"file:{path_name}"
            
            session_manager.add_entity(
                name=entity_name,
                entity_type="file",
                value=str(activity.path)
            )
            
            # Also add with activity type
            activity_entity_name = f"{activity.activity_type.value}_file:{path_name}"
            session_manager.add_entity(
                name=activity_entity_name,
                entity_type=f"{activity.activity_type.value}_file",
                value=str(activity.path)
            )
        except Exception as e:
            self._logger.error(f"Error updating session with file activity: {str(e)}")

# Global file activity tracker instance
file_activity_tracker = FileActivityTracker()
</file>

<file path="angela/context/file_resolver.py">
"""
File reference resolution for Angela CLI.

This module provides functionality to resolve file references from natural
language queries, using a combination of techniques such as exact matching,
fuzzy matching, pattern matching, and context-aware resolution.
"""
import os
import re
import difflib
from pathlib import Path
from typing import Dict, Any, Optional, List, Tuple, Union, Set

from angela.context import context_manager
from angela.context.session import session_manager
from angela.utils.logging import get_logger

logger = get_logger(__name__)

class FileResolver:
    """
    Resolver for file references in natural language queries.
    
    Provides multiple strategies for resolving file references:
    1. Exact path matching
    2. Fuzzy name matching
    3. Pattern matching
    4. Context-aware resolution (recent files, project files)
    5. Special references (current file, last modified file)
    """
    
    def __init__(self):
        """Initialize the file resolver."""
        self._logger = logger
        self._threshold = 0.6  # Threshold for fuzzy matching
    
    async def resolve_reference(
        self, 
        reference: str, 
        context: Dict[str, Any],
        search_scope: Optional[str] = None
    ) -> Optional[Path]:
        """
        Resolve a file reference to an actual file path.
        
        Args:
            reference: The file reference to resolve
            context: Context information
            search_scope: Optional scope for the search (project, directory, recent)
            
        Returns:
            Path object if found, None otherwise
        """
        self._logger.info(f"Resolving file reference: '{reference}'")
        
        # Strip quotes if present
        reference = reference.strip('\'"')
        
        # If reference is empty or None, return None
        if not reference:
            return None
        
        # Try resolving with each strategy in order
        resolved = await self._resolve_exact_path(reference, context)
        if resolved:
            self._logger.debug(f"Resolved via exact path: {resolved}")
            self._record_resolution(reference, resolved, "exact_path")
            return resolved
        
        resolved = await self._resolve_special_reference(reference, context)
        if resolved:
            self._logger.debug(f"Resolved via special reference: {resolved}")
            self._record_resolution(reference, resolved, "special_reference")
            return resolved
        
        resolved = await self._resolve_recent_file(reference, context)
        if resolved:
            self._logger.debug(f"Resolved via recent file: {resolved}")
            self._record_resolution(reference, resolved, "recent_file")
            return resolved
        
        resolved = await self._resolve_fuzzy_match(reference, context, search_scope)
        if resolved:
            self._logger.debug(f"Resolved via fuzzy match: {resolved}")
            self._record_resolution(reference, resolved, "fuzzy_match")
            return resolved
        
        resolved = await self._resolve_pattern_match(reference, context, search_scope)
        if resolved:
            self._logger.debug(f"Resolved via pattern match: {resolved}")
            self._record_resolution(reference, resolved, "pattern_match")
            return resolved
        
        # If all strategies fail, log and return None
        self._logger.warning(f"Could not resolve file reference: '{reference}'")
        return None
    
    async def extract_references(
        self, 
        text: str,
        context: Dict[str, Any]
    ) -> List[Tuple[str, Optional[Path]]]:
        """
        Extract and resolve file references from text.
        
        Args:
            text: The text to extract references from
            context: Context information
            
        Returns:
            List of (reference, resolved_path) tuples
        """
        self._logger.info(f"Extracting file references from: '{text}'")
        
        # Define patterns for finding file references
        patterns = [
            # Quoted paths
            r'["\']([^"\']+?\.[a-zA-Z0-9]+)["\']',
            # File/folder with extension
            r'\b([a-zA-Z0-9_\-/\.]+\.[a-zA-Z0-9]+)\b',
            # References to files/folders
            r'(?:file|folder|directory|script|code|document)\s+["\']?([^\s"\']+)["\']?',
            # References with in/from/to
            r'(?:in|from|to)\s+["\']?([^\s"\']+)["\']?',
        ]
        
        references = []
        
        # Extract references using each pattern
        for pattern in patterns:
            for match in re.finditer(pattern, text, re.IGNORECASE):
                reference = match.group(1)
                # Skip if reference is already in the list
                if any(ref == reference for ref, _ in references):
                    continue
                
                # Try to resolve the reference
                resolved = await self.resolve_reference(reference, context)
                references.append((reference, resolved))
        
        self._logger.debug(f"Extracted {len(references)} file references")
        return references
    
    async def _resolve_exact_path(
        self, 
        reference: str, 
        context: Dict[str, Any]
    ) -> Optional[Path]:
        """
        Resolve a reference as an exact path.
        
        Args:
            reference: The reference to resolve
            context: Context information
            
        Returns:
            Path object if found, None otherwise
        """
        # Try as absolute path
        path = Path(reference)
        if path.is_absolute() and path.exists():
            return path
        
        # Try relative to current directory
        cwd_path = Path(context["cwd"]) / reference
        if cwd_path.exists():
            return cwd_path
        
        # Try relative to project root if available
        if context.get("project_root"):
            proj_path = Path(context["project_root"]) / reference
            if proj_path.exists():
                return proj_path
        
        return None
    
    async def _resolve_special_reference(
        self, 
        reference: str, 
        context: Dict[str, Any]
    ) -> Optional[Path]:
        """
        Resolve special references like "current file", "last modified", etc.
        
        Args:
            reference: The reference to resolve
            context: Context information
            
        Returns:
            Path object if found, None otherwise
        """
        # Handle various special references
        lowercase_ref = reference.lower()
        
        # Current file
        if lowercase_ref in ["current file", "this file", "current"]:
            if context.get("current_file") and "path" in context["current_file"]:
                return Path(context["current_file"]["path"])
        
        # Last modified file (via session)
        if lowercase_ref in ["last file", "last modified", "previous file"]:
            session = session_manager.get_context()
            entities = session.get("entities", {})
            
            # Look for the most recent file entity
            last_file = None
            last_time = None
            
            for name, entity in entities.items():
                if entity.get("type") in ["file", "recent_file"]:
                    entity_time = entity.get("created")
                    if entity_time and (not last_time or entity_time > last_time):
                        last_time = entity_time
                        last_file = entity.get("value")
            
            if last_file:
                return Path(last_file)
        
        return None
    
    async def _resolve_recent_file(
        self, 
        reference: str, 
        context: Dict[str, Any]
    ) -> Optional[Path]:
        """
        Resolve a reference against recently used files.
        
        Args:
            reference: The reference to resolve
            context: Context information
            
        Returns:
            Path object if found, None otherwise
        """
        # Get recent files from session
        session = session_manager.get_context()
        entities = session.get("entities", {})
        
        # Filter for file entities
        file_entities = {
            name: entity for name, entity in entities.items()
            if entity.get("type") in ["file", "directory", "recent_file"]
        }
        
        # Look for exact matches first
        for name, entity in file_entities.items():
            path = Path(entity.get("value", ""))
            if path.name.lower() == reference.lower():
                return path
        
        # Then try fuzzy matches
        for name, entity in file_entities.items():
            path = Path(entity.get("value", ""))
            similarity = difflib.SequenceMatcher(None, path.name.lower(), reference.lower()).ratio()
            if similarity >= self._threshold:
                return path
        
        return None
    
    async def _resolve_fuzzy_match(
        self, 
        reference: str, 
        context: Dict[str, Any],
        search_scope: Optional[str] = None
    ) -> Optional[Path]:
        """
        Resolve a reference using fuzzy matching.
        
        Args:
            reference: The reference to resolve
            context: Context information
            search_scope: Optional scope for the search
            
        Returns:
            Path object if found, None otherwise
        """
        paths_to_check = []
        
        # Get paths based on search scope
        if search_scope == "project" and context.get("project_root"):
            # Get all files in the project
            project_path = Path(context["project_root"])
            paths_to_check.extend(project_path.glob("**/*"))
        elif search_scope == "directory":
            # Get all files in the current directory
            cwd_path = Path(context["cwd"])
            paths_to_check.extend(cwd_path.glob("*"))
        else:
            # Default: check both current directory and project root
            cwd_path = Path(context["cwd"])
            paths_to_check.extend(cwd_path.glob("*"))
            
            if context.get("project_root"):
                project_path = Path(context["project_root"])
                
                # Only search project root if different from current directory
                if project_path != cwd_path:
                    # Get direct children of project root
                    paths_to_check.extend(project_path.glob("*"))
                    
                    # Add common directories like src, lib, test
                    common_dirs = ["src", "lib", "test", "tests", "docs", "app", "bin"]
                    for dirname in common_dirs:
                        dir_path = project_path / dirname
                        if dir_path.exists() and dir_path.is_dir():
                            paths_to_check.extend(dir_path.glob("*"))
        
        # Deduplicate paths
        paths_to_check = list(set(paths_to_check))
        
        # Sort paths by the similarity of their name to the reference
        matches = []
        for path in paths_to_check:
            similarity = difflib.SequenceMatcher(None, path.name.lower(), reference.lower()).ratio()
            if similarity >= self._threshold:
                matches.append((path, similarity))
        
        # Sort by similarity (highest first)
        matches.sort(key=lambda x: x[1], reverse=True)
        
        # Return the best match if any
        if matches:
            return matches[0][0]
        
        return None
    
    async def _resolve_pattern_match(
        self, 
        reference: str, 
        context: Dict[str, Any],
        search_scope: Optional[str] = None
    ) -> Optional[Path]:
        """
        Resolve a reference using pattern matching.
        
        Args:
            reference: The reference to resolve
            context: Context information
            search_scope: Optional scope for the search
            
        Returns:
            Path object if found, None otherwise
        """
        # Try to interpret the reference as a glob pattern
        base_paths = []
        
        # Determine base paths based on search scope
        if search_scope == "project" and context.get("project_root"):
            base_paths.append(Path(context["project_root"]))
        elif search_scope == "directory":
            base_paths.append(Path(context["cwd"]))
        else:
            # Default: check both current directory and project root
            base_paths.append(Path(context["cwd"]))
            if context.get("project_root"):
                project_path = Path(context["project_root"])
                if project_path != Path(context["cwd"]):
                    base_paths.append(project_path)
        
        # Try each base path
        for base_path in base_paths:
            # Try with wildcard prefix/suffix if needed
            patterns_to_try = [
                reference,  # As-is
                f"*{reference}*",  # Wildcard prefix and suffix
                f"*{reference}",  # Wildcard prefix
                f"{reference}*"  # Wildcard suffix
            ]
            
            for pattern in patterns_to_try:
                try:
                    # Use glob to find matching files
                    matches = list(base_path.glob(pattern))
                    if matches:
                        return matches[0]  # Return the first match
                except Exception:
                    # Invalid pattern, try the next one
                    continue
        
        return None
    
    def _record_resolution(
        self, 
        reference: str, 
        resolved_path: Path, 
        method: str
    ) -> None:
        """
        Record a successful resolution for learning.
        
        Args:
            reference: The original reference
            resolved_path: The resolved path
            method: The method used for resolution
        """
        # Store in session for future reference
        try:
            session_manager.add_entity(
                name=f"file_ref:{reference}",
                entity_type="file_reference",
                value=str(resolved_path)
            )
            
            # Also store as a recent file
            session_manager.add_entity(
                name=f"recent_file:{resolved_path.name}",
                entity_type="recent_file",
                value=str(resolved_path)
            )
        except Exception as e:
            self._logger.error(f"Error recording resolution: {str(e)}")

# Global file resolver instance
file_resolver = FileResolver()
</file>

<file path="angela/context/history.py">
# angela/context/history.py

import json
import os
import re
from pathlib import Path
from typing import Dict, Any, Optional, List, Tuple
from datetime import datetime, timedelta
from collections import Counter, defaultdict

from angela.config import config_manager
from angela.utils.logging import get_logger
from angela.context.preferences import preferences_manager

logger = get_logger(__name__)

class CommandRecord:
    """Record of a command execution."""
    
    def __init__(
        self,
        command: str,
        natural_request: str,
        success: bool,
        timestamp: Optional[datetime] = None,
        output: Optional[str] = None,
        error: Optional[str] = None,
        risk_level: int = 0
    ):
        self.command = command
        self.natural_request = natural_request
        self.success = success
        self.timestamp = timestamp or datetime.now()
        self.output = output
        self.error = error
        self.risk_level = risk_level
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert the record to a dictionary for storage."""
        return {
            "command": self.command,
            "natural_request": self.natural_request,
            "success": self.success,
            "timestamp": self.timestamp.isoformat(),
            "output": self.output,
            "error": self.error,
            "risk_level": self.risk_level
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'CommandRecord':
        """Create a record from a dictionary."""
        return cls(
            command=data["command"],
            natural_request=data["natural_request"],
            success=data["success"],
            timestamp=datetime.fromisoformat(data["timestamp"]),
            output=data.get("output"),
            error=data.get("error"),
            risk_level=data.get("risk_level", 0)
        )


class CommandPattern:
    """Pattern of commands executed by the user."""
    
    def __init__(self, base_command: str, count: int = 1, success_rate: float = 1.0):
        self.base_command = base_command
        self.count = count
        self.success_rate = success_rate
        self.last_used = datetime.now()
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert the pattern to a dictionary for storage."""
        return {
            "base_command": self.base_command,
            "count": self.count,
            "success_rate": self.success_rate,
            "last_used": self.last_used.isoformat()
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'CommandPattern':
        """Create a pattern from a dictionary."""
        pattern = cls(
            base_command=data["base_command"],
            count=data["count"],
            success_rate=data["success_rate"]
        )
        pattern.last_used = datetime.fromisoformat(data["last_used"])
        return pattern


class HistoryManager:
    """Manager for command history and pattern analysis."""
    
    def __init__(self):
        """Initialize the history manager."""
        self._history_file = config_manager.CONFIG_DIR / "command_history.json"
        self._patterns_file = config_manager.CONFIG_DIR / "command_patterns.json"
        self._history: List[CommandRecord] = []
        self._patterns: Dict[str, CommandPattern] = {}
        self._load_history()
        self._load_patterns()
    
    def _load_history(self) -> None:
        """Load history from file."""
        try:
            if self._history_file.exists():
                with open(self._history_file, "r") as f:
                    data = json.load(f)
                    self._history = [CommandRecord.from_dict(item) for item in data]
                logger.debug(f"Loaded {len(self._history)} history items")
                
                # Trim history if needed
                max_items = preferences_manager.preferences.context.max_history_items
                if len(self._history) > max_items:
                    self._history = self._history[-max_items:]
                    self._save_history()  # Save the trimmed history
            else:
                logger.debug("No history file found")
        except Exception as e:
            logger.error(f"Error loading history: {e}")
            self._history = []
    
    def _load_patterns(self) -> None:
        """Load command patterns from file."""
        try:
            if self._patterns_file.exists():
                with open(self._patterns_file, "r") as f:
                    data = json.load(f)
                    self._patterns = {k: CommandPattern.from_dict(v) for k, v in data.items()}
                logger.debug(f"Loaded {len(self._patterns)} command patterns")
            else:
                logger.debug("No patterns file found")
        except Exception as e:
            logger.error(f"Error loading patterns: {e}")
            self._patterns = {}
    
    def _save_history(self) -> None:
        """Save history to file."""
        try:
            self._history_file.parent.mkdir(parents=True, exist_ok=True)
            with open(self._history_file, "w") as f:
                json.dump([item.to_dict() for item in self._history], f, indent=2)
            logger.debug(f"Saved history with {len(self._history)} items")
        except Exception as e:
            logger.error(f"Error saving history: {e}")
    
    def _save_patterns(self) -> None:
        """Save command patterns to file."""
        try:
            self._patterns_file.parent.mkdir(parents=True, exist_ok=True)
            with open(self._patterns_file, "w") as f:
                json.dump({k: v.to_dict() for k, v in self._patterns.items()}, f, indent=2)
            logger.debug(f"Saved {len(self._patterns)} command patterns")
        except Exception as e:
            logger.error(f"Error saving patterns: {e}")
    
    def add_command(
        self, 
        command: str, 
        natural_request: str, 
        success: bool,
        output: Optional[str] = None,
        error: Optional[str] = None,
        risk_level: int = 0
    ) -> None:
        """
        Add a command to the history.
        
        Args:
            command: The shell command executed
            natural_request: The natural language request
            success: Whether the command executed successfully
            output: Command output (if any)
            error: Command error (if any)
            risk_level: Risk level of the command
        """
        # Create and add the record
        record = CommandRecord(
            command=command,
            natural_request=natural_request,
            success=success,
            output=output,
            error=error,
            risk_level=risk_level
        )
        self._history.append(record)
        
        # Save the updated history
        self._save_history()
        
        # Update patterns if enabled
        if preferences_manager.preferences.context.auto_learn_patterns:
            self._update_patterns(record)
    
    def _extract_base_command(self, command: str) -> str:
        """
        Extract the base command without arguments.
        
        Args:
            command: The full command string
            
        Returns:
            The base command
        """
        # Extract the first word (command name)
        base = command.strip().split()[0]
        
        # For some commands, include the first argument if it's an operation
        if base in ["git", "docker", "npm", "pip", "apt", "apt-get"]:
            parts = command.strip().split()
            if len(parts) > 1 and not parts[1].startswith("-"):
                base = f"{base} {parts[1]}"
        
        return base
    
    def _update_patterns(self, record: CommandRecord) -> None:
        """
        Update command patterns based on a new record.
        
        Args:
            record: The command record
        """
        base_command = self._extract_base_command(record.command)
        
        if base_command in self._patterns:
            # Update existing pattern
            pattern = self._patterns[base_command]
            pattern.count += 1
            pattern.last_used = record.timestamp
            
            # Update success rate
            success_weight = 1.0 / pattern.count  # Weight of the new record
            pattern.success_rate = (
                (pattern.success_rate * (1 - success_weight)) + 
                (1.0 if record.success else 0.0) * success_weight
            )
        else:
            # Create new pattern
            self._patterns[base_command] = CommandPattern(
                base_command=base_command,
                count=1,
                success_rate=1.0 if record.success else 0.0
            )
        
        # Save updated patterns
        self._save_patterns()
    
    def get_recent_commands(self, limit: int = 10) -> List[CommandRecord]:
        """
        Get the most recent commands.
        
        Args:
            limit: Maximum number of commands to return
            
        Returns:
            List of recent CommandRecord objects
        """
        return self._history[-limit:]
    
    def get_command_frequency(self, command: str) -> int:
        """
        Get the frequency of a command.
        
        Args:
            command: The command to check
            
        Returns:
            The number of times the command has been executed
        """
        base_command = self._extract_base_command(command)
        pattern = self._patterns.get(base_command)
        return pattern.count if pattern else 0
    
    def get_command_success_rate(self, command: str) -> float:
        """
        Get the success rate of a command.
        
        Args:
            command: The command to check
            
        Returns:
            The success rate (0.0-1.0) or 0.0 if command not found
        """
        base_command = self._extract_base_command(command)
        pattern = self._patterns.get(base_command)
        return pattern.success_rate if pattern else 0.0
    
    def search_similar_command(self, request: str) -> Optional[str]:
        """
        Search for a similar command in history based on natural language request.
        
        Args:
            request: The natural language request
            
        Returns:
            A similar command if found, None otherwise
        """
        # Simple similarity: lowercase and remove punctuation
        request = re.sub(r'[^\w\s]', '', request.lower())
        
        for record in reversed(self._history):  # Start from most recent
            historical_request = re.sub(r'[^\w\s]', '', record.natural_request.lower())
            
            # Check for significant overlap in words
            request_words = set(request.split())
            historical_words = set(historical_request.split())
            
            # Calculate Jaccard similarity
            if request_words and historical_words:
                intersection = request_words.intersection(historical_words)
                union = request_words.union(historical_words)
                similarity = len(intersection) / len(union)
                
                # If similarity is high enough, return this command
                if similarity > 0.6:
                    return record.command
        
        return None
    
    def find_error_patterns(self, error: str) -> List[Tuple[str, str]]:
        """
        Find patterns in error messages and corresponding fixes.
        
        Args:
            error: The error message
            
        Returns:
            List of (failed_command, successful_fix) tuples
        """
        error_patterns = []
        
        # Find failed commands with this error
        for i, record in enumerate(self._history):
            if not record.success and record.error and error in record.error:
                # Look ahead for successful fixes
                for j in range(i+1, min(i+5, len(self._history))):
                    if self._history[j].success:
                        error_patterns.append((record.command, self._history[j].command))
                        break
        
        return error_patterns
    
    def get_common_command_contexts(self) -> Dict[str, List[str]]:
        """
        Get common command sequences or contexts.
        
        Returns:
            Dict mapping commands to commonly following commands
        """
        context_map = defaultdict(Counter)
        
        # Analyze command sequences
        for i in range(1, len(self._history)):
            prev_cmd = self._extract_base_command(self._history[i-1].command)
            curr_cmd = self._extract_base_command(self._history[i].command)
            context_map[prev_cmd][curr_cmd] += 1
        
        # Convert to more usable format
        result = {}
        for cmd, followers in context_map.items():
            # Get the most common followers
            result[cmd] = [cmd for cmd, count in followers.most_common(3)]
        
        return result

# Global history manager instance
history_manager = HistoryManager()
</file>

<file path="angela/context/preferences.py">
# angela/context/preferences.py

import json
import os
from pathlib import Path
from typing import Dict, Any, Optional, List
from pydantic import BaseModel, Field

from angela.config import config_manager
from angela.constants import RISK_LEVELS
from angela.utils.logging import get_logger

logger = get_logger(__name__)

class TrustPreferences(BaseModel):
    """Model for user trust preferences."""
    default_trust_level: int = Field(4, description="Default trust level (0-4)")
    auto_execute_safe: bool = Field(True, description="Auto-execute SAFE operations")
    auto_execute_low: bool = Field(True, description="Auto-execute LOW risk operations")
    auto_execute_medium: bool = Field(False, description="Auto-execute MEDIUM risk operations")
    auto_execute_high: bool = Field(False, description="Auto-execute HIGH risk operations")
    auto_execute_critical: bool = Field(False, description="Auto-execute CRITICAL risk operations")
    trusted_commands: List[str] = Field(default_factory=list, description="Commands that are always trusted")
    untrusted_commands: List[str] = Field(default_factory=list, description="Commands that require confirmation")

class UIPreferences(BaseModel):
    """Model for UI preferences."""
    show_command_preview: bool = Field(True, description="Show command preview before execution")
    show_impact_analysis: bool = Field(True, description="Show impact analysis for commands")
    use_rich_output: bool = Field(True, description="Use rich formatted output")
    verbose_feedback: bool = Field(True, description="Show detailed execution feedback")
    use_spinners: bool = Field(True, description="Show spinners for long-running operations")

class ContextPreferences(BaseModel):
    """Model for context preferences."""
    remember_session_context: bool = Field(True, description="Maintain context between commands")
    max_history_items: int = Field(50, description="Maximum number of history items to remember")
    auto_learn_patterns: bool = Field(True, description="Automatically learn command patterns")

class UserPreferences(BaseModel):
    """User preferences model."""
    trust: TrustPreferences = Field(default_factory=TrustPreferences, description="Trust settings")
    ui: UIPreferences = Field(default_factory=UIPreferences, description="UI settings")
    context: ContextPreferences = Field(default_factory=ContextPreferences, description="Context settings")

class PreferencesManager:
    """Manager for user preferences."""
    
    def __init__(self):
        """Initialize the preferences manager."""
        self._prefs = UserPreferences()
        self._prefs_file = config_manager.CONFIG_DIR / "preferences.json"
        self._load_preferences()
    
    def _load_preferences(self) -> None:
        """Load preferences from file."""
        try:
            if self._prefs_file.exists():
                with open(self._prefs_file, "r") as f:
                    data = json.load(f)
                    self._prefs = UserPreferences.parse_obj(data)
                logger.debug(f"Loaded preferences from {self._prefs_file}")
            else:
                logger.debug("No preferences file found, using defaults")
                self._save_preferences()  # Create the file with defaults
        except Exception as e:
            logger.error(f"Error loading preferences: {e}")
    
    def _save_preferences(self) -> None:
        """Save preferences to file."""
        try:
            with open(self._prefs_file, "w") as f:
                json.dump(self._prefs.dict(), f, indent=2)
            logger.debug(f"Saved preferences to {self._prefs_file}")
        except Exception as e:
            logger.error(f"Error saving preferences: {e}")
    
    def update_preferences(self, **kwargs) -> None:
        """Update preferences with provided values."""
        if not kwargs:
            return
            
        # Handle nested preferences
        for section in ["trust", "ui", "context"]:
            section_data = kwargs.pop(section, None)
            if section_data and isinstance(section_data, dict):
                for k, v in section_data.items():
                    setattr(getattr(self._prefs, section), k, v)
        
        # Handle top-level preferences
        for k, v in kwargs.items():
            setattr(self._prefs, k, v)
        
        self._save_preferences()
    
    def should_auto_execute(self, risk_level: int, command: str) -> bool:
        """
        Determine if a command should be auto-executed based on risk level
        and user preferences.
        
        Args:
            risk_level: The risk level of the command
            command: The command string
            
        Returns:
            True if should auto-execute, False if confirmation needed
        """
        # Check if the command is explicitly trusted or untrusted
        if command in self._prefs.trust.trusted_commands:
            return True
        if command in self._prefs.trust.untrusted_commands:
            return False
        
        # Check based on risk level
        if risk_level == RISK_LEVELS["SAFE"]:
            return self._prefs.trust.auto_execute_safe
        elif risk_level == RISK_LEVELS["LOW"]:
            return self._prefs.trust.auto_execute_low
        elif risk_level == RISK_LEVELS["MEDIUM"]:
            return self._prefs.trust.auto_execute_medium
        elif risk_level == RISK_LEVELS["HIGH"]:
            return self._prefs.trust.auto_execute_high
        elif risk_level == RISK_LEVELS["CRITICAL"]:
            return self._prefs.trust.auto_execute_critical
        
        # Default to require confirmation
        return False
    
    def add_trusted_command(self, command: str) -> None:
        """Add a command to the trusted commands list."""
        if command not in self._prefs.trust.trusted_commands:
            self._prefs.trust.trusted_commands.append(command)
            # Remove from untrusted if present
            if command in self._prefs.trust.untrusted_commands:
                self._prefs.trust.untrusted_commands.remove(command)
            self._save_preferences()
    
    def add_untrusted_command(self, command: str) -> None:
        """Add a command to the untrusted commands list."""
        if command not in self._prefs.trust.untrusted_commands:
            self._prefs.trust.untrusted_commands.append(command)
            # Remove from trusted if present
            if command in self._prefs.trust.trusted_commands:
                self._prefs.trust.trusted_commands.remove(command)
            self._save_preferences()
    
    @property
    def preferences(self) -> UserPreferences:
        """Get the current preferences."""
        return self._prefs

# Create a global instance of the preferences manager
preferences_manager = PreferencesManager()
</file>

<file path="angela/context/project_inference.py">
# angela/context/project_inference.py

import os
import glob
import json
import re
import asyncio
from pathlib import Path
from typing import Dict, Any, List, Set, Optional, Tuple

from angela.utils.logging import get_logger

logger = get_logger(__name__)

class ProjectInference:
    """
    Advanced project type and structure inference.
    
    This class provides:
    1. Detection of project type based on files and structure
    2. Inference of project dependencies
    3. Identification of important project files
    4. Framework and technology detection
    """
    
    # Project type signatures
    PROJECT_SIGNATURES = {
        "python": {
            "files": ["requirements.txt", "setup.py", "pyproject.toml", "Pipfile"],
            "directories": ["venv", ".venv", "env", ".env"],
            "extensions": [".py", ".pyi", ".pyx"]
        },
        "node": {
            "files": ["package.json", "package-lock.json", "yarn.lock", "node_modules"],
            "extensions": [".js", ".jsx", ".ts", ".tsx"]
        },
        "rust": {
            "files": ["Cargo.toml", "Cargo.lock"],
            "directories": ["src", "target"],
            "extensions": [".rs"]
        },
        "go": {
            "files": ["go.mod", "go.sum"],
            "directories": ["pkg", "cmd"],
            "extensions": [".go"]
        },
        "java": {
            "files": ["pom.xml", "build.gradle", "gradlew", "settings.gradle"],
            "directories": ["src/main/java", "target", "build"],
            "extensions": [".java", ".class", ".jar"]
        },
        "dotnet": {
            "files": [".csproj", ".sln", "packages.config"],
            "directories": ["bin", "obj"],
            "extensions": [".cs", ".vb", ".fs"]
        },
        "php": {
            "files": ["composer.json", "composer.lock"],
            "directories": ["vendor"],
            "extensions": [".php"]
        },
        "ruby": {
            "files": ["Gemfile", "Gemfile.lock", "Rakefile"],
            "directories": ["lib", "bin"],
            "extensions": [".rb"]
        },
        "flutter": {
            "files": ["pubspec.yaml", "pubspec.lock"],
            "directories": ["lib", "android", "ios"],
            "extensions": [".dart"]
        },
        "docker": {
            "files": ["Dockerfile", "docker-compose.yml", "docker-compose.yaml"],
            "extensions": []
        },
        "web": {
            "files": ["index.html", "style.css", "script.js"],
            "extensions": [".html", ".htm", ".css", ".js"]
        }
    }
    
    # Framework signatures
    FRAMEWORK_SIGNATURES = {
        "python": {
            "django": ["manage.py", "settings.py", "wsgi.py", "asgi.py"],
            "flask": ["app.py", "wsgi.py", "requirements.txt"],
            "fastapi": ["main.py", "app.py", "api.py"],
            "tornado": ["server.py", "app.py"],
            "sqlalchemy": ["models.py", "database.py"],
            "pytest": ["conftest.py", "test_*.py", "pytest.ini"],
            "jupyter": [".ipynb"],
            "pandas": ["*.csv", "*.xlsx"],
            "tensorflow": ["model.h5", "keras"]
        },
        "node": {
            "react": ["react", "jsx", "tsx", "components"],
            "vue": ["vue.config.js", "Vue", "components"],
            "angular": ["angular.json", "app.module.ts"],
            "express": ["app.js", "routes", "middleware"],
            "nextjs": ["next.config.js", "pages", "public"],
            "gatsby": ["gatsby-config.js", "gatsby-node.js"],
            "electron": ["electron", "main.js", "renderer.js"]
        },
        "web": {
            "bootstrap": ["bootstrap"],
            "tailwind": ["tailwind.config.js", "tailwindcss"],
            "jquery": ["jquery"]
        }
    }
    
    def __init__(self):
        """Initialize the project inference system."""
        self._logger = logger
        self._cache = {}  # Cache inference results
    
    async def infer_project_info(self, project_root: Path) -> Dict[str, Any]:
        """
        Infer detailed information about a project.
        
        Args:
            project_root: The project root directory
            
        Returns:
            Dictionary with project information
        """
        # Check cache first
        cache_key = str(project_root)
        if cache_key in self._cache:
            return self._cache[cache_key]
        
        self._logger.info(f"Inferring project information for {project_root}")
        
        # Basic project type detection
        project_type = await self._detect_project_type(project_root)
        
        # Get more detailed information
        result = {
            "project_root": str(project_root),
            "project_type": project_type,
            "detected_files": await self._list_important_files(project_root, project_type),
            "detected_frameworks": await self._detect_frameworks(project_root, project_type),
            "dependencies": await self._detect_dependencies(project_root, project_type),
            "structure": await self._analyze_project_structure(project_root, project_type)
        }
        
        # Cache the result
        self._cache[cache_key] = result
        
        return result
    
    async def _detect_project_type(self, project_root: Path) -> str:
        """
        Detect the primary type of a project.
        
        Args:
            project_root: The project root directory
            
        Returns:
            Project type string
        """
        # Count signature matches for each project type
        scores = {}
        
        for project_type, signature in self.PROJECT_SIGNATURES.items():
            score = 0
            
            # Check for signature files
            for file_pattern in signature.get("files", []):
                # Handle glob patterns
                if "*" in file_pattern:
                    matches = list(project_root.glob(file_pattern))
                    score += len(matches)
                else:
                    if (project_root / file_pattern).exists():
                        score += 3  # Higher weight for exact file matches
                        
            # Check for signature directories
            for dir_pattern in signature.get("directories", []):
                # Handle glob patterns
                if "*" in dir_pattern:
                    matches = list(project_root.glob(dir_pattern))
                    score += len(matches)
                else:
                    if (project_root / dir_pattern).exists() and (project_root / dir_pattern).is_dir():
                        score += 2  # Medium weight for directory matches
            
            # Check for file extensions
            for ext in signature.get("extensions", []):
                # Count files with this extension
                count = len(list(project_root.glob(f"**/*{ext}")))
                score += min(count, 10)  # Cap at 10 to avoid skewing
            
            scores[project_type] = score
        
        # Get the project type with the highest score
        if not scores:
            return "unknown"
        
        # If multiple project types have similar scores, handle mixed projects
        max_score = max(scores.values())
        candidates = [pt for pt, score in scores.items() if score >= max_score * 0.7]
        
        if len(candidates) > 1:
            # Special case: For web + node, prefer node as it's more specific
            if "web" in candidates and "node" in candidates:
                return "node"
            
            # Return composite project type for truly mixed projects
            return "+".join(candidates)
        
        # Return the highest scoring project type
        return max(scores.items(), key=lambda x: x[1])[0]
    
    async def _list_important_files(self, project_root: Path, project_type: str) -> List[Dict[str, Any]]:
        """
        List important files in the project.
        
        Args:
            project_root: The project root directory
            project_type: The detected project type
            
        Returns:
            List of important file information
        """
        important_files = []
        
        # Handle composite project types
        if "+" in project_type:
            types = project_type.split("+")
            for pt in types:
                important_files.extend(await self._list_important_files(project_root, pt))
            return important_files
        
        # Get signatures for this project type
        signature = self.PROJECT_SIGNATURES.get(project_type, {})
        
        # Check for signature files
        for file_pattern in signature.get("files", []):
            # Handle glob patterns
            if "*" in file_pattern:
                for file_path in project_root.glob(file_pattern):
                    if file_path.is_file():
                        important_files.append({
                            "path": str(file_path.relative_to(project_root)),
                            "type": "signature_file",
                            "project_type": project_type
                        })
            else:
                file_path = project_root / file_pattern
                if file_path.exists() and file_path.is_file():
                    important_files.append({
                        "path": str(file_path.relative_to(project_root)),
                        "type": "signature_file",
                        "project_type": project_type
                    })
        
        # Add common important files for any project
        common_files = ["README.md", "LICENSE", ".gitignore", "CHANGELOG.md"]
        for file_name in common_files:
            file_path = project_root / file_name
            if file_path.exists() and file_path.is_file():
                important_files.append({
                    "path": file_name,
                    "type": "documentation"
                })
        
        # Add project-specific logic
        if project_type == "python":
            # Look for main Python modules
            for file_path in project_root.glob("**/*.py"):
                if file_path.name == "__main__.py" or file_path.name == "main.py":
                    important_files.append({
                        "path": str(file_path.relative_to(project_root)),
                        "type": "entry_point"
                    })
        
        elif project_type == "node":
            # Look for main JavaScript/TypeScript files
            for pattern in ["index.js", "main.js", "server.js", "app.js", "index.ts", "main.ts"]:
                for file_path in project_root.glob(f"**/{pattern}"):
                    # Skip node_modules
                    if "node_modules" not in str(file_path):
                        important_files.append({
                            "path": str(file_path.relative_to(project_root)),
                            "type": "entry_point"
                        })
        
        # Add more project-specific logic as needed
        
        return important_files
    
    async def _detect_frameworks(self, project_root: Path, project_type: str) -> Dict[str, float]:
        """
        Detect frameworks and technologies used in the project.
        
        Args:
            project_root: The project root directory
            project_type: The detected project type
            
        Returns:
            Dictionary of framework names and confidence scores
        """
        frameworks = {}
        
        # Handle composite project types
        if "+" in project_type:
            types = project_type.split("+")
            for pt in types:
                frameworks.update(await self._detect_frameworks(project_root, pt))
            return frameworks
        
        # Get framework signatures for this project type
        if project_type in self.FRAMEWORK_SIGNATURES:
            for framework, patterns in self.FRAMEWORK_SIGNATURES[project_type].items():
                matches = 0
                total_patterns = len(patterns)
                
                for pattern in patterns:
                    # Handle glob patterns
                    if "*" in pattern:
                        files = list(project_root.glob(f"**/{pattern}"))
                        if files:
                            matches += 1
                    else:
                        # Check for exact file match
                        for file_path in project_root.glob("**/*"):
                            if pattern in file_path.name or pattern in str(file_path):
                                matches += 1
                                break
                
                # Calculate confidence score
                if total_patterns > 0 and matches > 0:
                    confidence = min(matches / total_patterns, 1.0)
                    if confidence >= 0.3:  # Threshold for reporting
                        frameworks[framework] = confidence
        
        # Check dependencies if we have appropriate files
        if project_type == "python":
            requirements_path = project_root / "requirements.txt"
            if requirements_path.exists():
                frameworks.update(await self._analyze_python_requirements(requirements_path))
            
        elif project_type == "node":
            package_json_path = project_root / "package.json"
            if package_json_path.exists():
                frameworks.update(await self._analyze_package_json(package_json_path))
        
        return frameworks
    
    async def _detect_dependencies(self, project_root: Path, project_type: str) -> List[Dict[str, Any]]:
        """
        Detect dependencies of the project.
        
        Args:
            project_root: The project root directory
            project_type: The detected project type
            
        Returns:
            List of dependencies with metadata
        """
        dependencies = []
        
        # Handle composite project types
        if "+" in project_type:
            types = project_type.split("+")
            for pt in types:
                dependencies.extend(await self._detect_dependencies(project_root, pt))
            return dependencies
        
        # Extract dependencies based on project type
        if project_type == "python":
            # Check requirements.txt
            requirements_path = project_root / "requirements.txt"
            if requirements_path.exists():
                dependencies.extend(await self._extract_python_requirements(requirements_path))
            
            # Check setup.py
            setup_py_path = project_root / "setup.py"
            if setup_py_path.exists():
                dependencies.extend(await self._extract_python_setup_dependencies(setup_py_path))
                
            # Check pyproject.toml
            pyproject_path = project_root / "pyproject.toml"
            if pyproject_path.exists():
                dependencies.extend(await self._extract_pyproject_dependencies(pyproject_path))
                
        elif project_type == "node":
            # Check package.json
            package_json_path = project_root / "package.json"
            if package_json_path.exists():
                dependencies.extend(await self._extract_node_dependencies(package_json_path))
                
        # Add more project types as needed
        
        return dependencies
    
    async def _analyze_project_structure(self, project_root: Path, project_type: str) -> Dict[str, Any]:
        """
        Analyze the structure of the project.
        
        Args:
            project_root: The project root directory
            project_type: The detected project type
            
        Returns:
            Dictionary with structure information
        """
        # Count files by type
        file_counts = {}
        
        # Walk the directory tree
        for root, dirs, files in os.walk(project_root):
            # Skip hidden directories and common exclude patterns
            dirs[:] = [d for d in dirs if not d.startswith(".") and d not in ["node_modules", "venv", "__pycache__", "build", "dist"]]
            
            for file in files:
                # Get file extension
                _, ext = os.path.splitext(file)
                if ext:
                    if ext not in file_counts:
                        file_counts[ext] = 0
                    file_counts[ext] += 1
        
        # Identify main directories
        main_dirs = []
        for item in project_root.iterdir():
            if item.is_dir() and not item.name.startswith(".") and item.name not in ["node_modules", "venv", "__pycache__"]:
                main_dirs.append({
                    "name": item.name,
                    "path": str(item.relative_to(project_root)),
                    "file_count": sum(1 for _ in item.glob("**/*") if _.is_file())
                })
        
        # Sort by file count
        main_dirs.sort(key=lambda x: x["file_count"], reverse=True)
        
        return {
            "file_counts": file_counts,
            "main_directories": main_dirs[:5],  # Top 5 directories
            "total_files": sum(file_counts.values()),
            "directory_structure": await self._generate_directory_structure(project_root)
        }
    
    async def _generate_directory_structure(self, project_root: Path, max_depth: int = 3) -> Dict[str, Any]:
        """
        Generate a hierarchical representation of the directory structure.
        
        Args:
            project_root: The project root directory
            max_depth: Maximum depth to traverse
            
        Returns:
            Dictionary representing the directory structure
        """
        def _build_tree(path: Path, current_depth: int) -> Dict[str, Any]:
            if current_depth > max_depth:
                return {"type": "directory", "name": path.name, "truncated": True}
            
            result = {"type": "directory", "name": path.name, "children": []}
            
            try:
                # List directory contents
                items = list(path.iterdir())
                
                # Skip large directories
                if len(items) > 50:
                    result["children"].append({"type": "info", "name": f"{len(items)} items (too many to show)"})
                    return result
                
                # Add directories first
                for item in sorted([i for i in items if i.is_dir()], key=lambda x: x.name):
                    # Skip hidden directories and common excludes
                    if item.name.startswith(".") or item.name in ["node_modules", "venv", "__pycache__", "build", "dist"]:
                        continue
                    
                    child = _build_tree(item, current_depth + 1)
                    result["children"].append(child)
                
                # Then add files
                for item in sorted([i for i in items if i.is_file()], key=lambda x: x.name):
                    # Skip hidden files
                    if item.name.startswith("."):
                        continue
                    
                    result["children"].append({"type": "file", "name": item.name})
                
                return result
            except PermissionError:
                result["children"].append({"type": "error", "name": "Permission denied"})
                return result
        
        return _build_tree(project_root, 0)
    
    async def _analyze_python_requirements(self, requirements_path: Path) -> Dict[str, float]:
        """
        Analyze Python requirements.txt for frameworks.
        
        Args:
            requirements_path: Path to requirements.txt
            
        Returns:
            Dictionary of framework names and confidence scores
        """
        frameworks = {}
        
        # Framework indicators in requirements
        framework_indicators = {
            "django": "django",
            "flask": "flask",
            "fastapi": "fastapi",
            "tornado": "tornado",
            "sqlalchemy": "sqlalchemy",
            "pytest": "pytest",
            "pandas": "pandas",
            "numpy": "numpy",
            "tensorflow": "tensorflow",
            "pytorch": "torch",
            "jupyter": "jupyter"
        }
        
        try:
            with open(requirements_path, "r") as f:
                requirements = f.read()
                
            for framework, indicator in framework_indicators.items():
                pattern = rf"\b{re.escape(indicator)}[>=<~!]"
                if re.search(pattern, requirements, re.IGNORECASE):
                    frameworks[framework] = 1.0  # High confidence for direct dependencies
        except Exception as e:
            self._logger.error(f"Error analyzing requirements.txt: {str(e)}")
        
        return frameworks
    
    async def _analyze_package_json(self, package_json_path: Path) -> Dict[str, float]:
        """
        Analyze package.json for frameworks.
        
        Args:
            package_json_path: Path to package.json
            
        Returns:
            Dictionary of framework names and confidence scores
        """
        frameworks = {}
        
        # Framework indicators in package.json
        framework_indicators = {
            "react": ["react", "react-dom"],
            "vue": ["vue"],
            "angular": ["@angular/core"],
            "express": ["express"],
            "nextjs": ["next"],
            "gatsby": ["gatsby"],
            "electron": ["electron"]
        }
        
        try:
            with open(package_json_path, "r") as f:
                package_data = json.load(f)
            
            # Check dependencies and devDependencies
            all_deps = {}
            all_deps.update(package_data.get("dependencies", {}))
            all_deps.update(package_data.get("devDependencies", {}))
            
            for framework, indicators in framework_indicators.items():
                if any(dep in all_deps for dep in indicators):
                    frameworks[framework] = 1.0  # High confidence for direct dependencies
        except Exception as e:
            self._logger.error(f"Error analyzing package.json: {str(e)}")
        
        return frameworks
    
    async def _extract_python_requirements(self, requirements_path: Path) -> List[Dict[str, Any]]:
        """
        Extract dependencies from requirements.txt.
        
        Args:
            requirements_path: Path to requirements.txt
            
        Returns:
            List of dependencies
        """
        dependencies = []
        
        try:
            with open(requirements_path, "r") as f:
                for line in f:
                    line = line.strip()
                    
                    # Skip comments and empty lines
                    if not line or line.startswith("#"):
                        continue
                    
                    # Parse requirement
                    parts = re.split(r"[>=<~!]", line, 1)
                    name = parts[0].strip()
                    version_spec = line[len(name):].strip() if len(parts) > 1 else ""
                    
                    dependencies.append({
                        "name": name,
                        "version_spec": version_spec,
                        "type": "python",
                        "source": "requirements.txt"
                    })
        except Exception as e:
            self._logger.error(f"Error extracting Python requirements: {str(e)}")
        
        return dependencies
    
    async def _extract_python_setup_dependencies(self, setup_py_path: Path) -> List[Dict[str, Any]]:
        """
        Extract dependencies from setup.py.
        
        Args:
            setup_py_path: Path to setup.py
            
        Returns:
            List of dependencies
        """
        dependencies = []
        
        try:
            with open(setup_py_path, "r") as f:
                setup_content = f.read()
            
            # Look for install_requires
            install_requires_match = re.search(r"install_requires\s*=\s*\[(.*?)\]", setup_content, re.DOTALL)
            if install_requires_match:
                requires_text = install_requires_match.group(1)
                
                # Extract individual requirements
                for req_match in re.finditer(r"[\"']([^\"']+)[\"']", requires_text):
                    req = req_match.group(1)
                    
                    # Parse requirement
                    parts = re.split(r"[>=<~!]", req, 1)
                    name = parts[0].strip()
                    version_spec = req[len(name):].strip() if len(parts) > 1 else ""
                    
                    dependencies.append({
                        "name": name,
                        "version_spec": version_spec,
                        "type": "python",
                        "source": "setup.py"
                    })
        except Exception as e:
            self._logger.error(f"Error extracting setup.py dependencies: {str(e)}")
        
        return dependencies
    
    async def _extract_pyproject_dependencies(self, pyproject_path: Path) -> List[Dict[str, Any]]:
        """
        Extract dependencies from pyproject.toml.
        
        Args:
            pyproject_path: Path to pyproject.toml
            
        Returns:
            List of dependencies
        """
        dependencies = []
        
        try:
            # Simple parsing of dependencies from pyproject.toml
            with open(pyproject_path, "r") as f:
                content = f.read()
            
            # Look for dependencies section
            deps_match = re.search(r"dependencies\s*=\s*\[(.*?)\]", content, re.DOTALL)
            if deps_match:
                deps_text = deps_match.group(1)
                
                # Extract individual dependencies
                for dep_match in re.finditer(r"[\"']([^\"']+)[\"']", deps_text):
                    dep = dep_match.group(1)
                    
                    # Parse requirement
                    parts = re.split(r"[>=<~!]", dep, 1)
                    name = parts[0].strip()
                    version_spec = dep[len(name):].strip() if len(parts) > 1 else ""
                    
                    dependencies.append({
                        "name": name,
                        "version_spec": version_spec,
                        "type": "python",
                        "source": "pyproject.toml"
                    })
        except Exception as e:
            self._logger.error(f"Error extracting pyproject.toml dependencies: {str(e)}")
        
        return dependencies
    
    async def _extract_node_dependencies(self, package_json_path: Path) -> List[Dict[str, Any]]:
        """
        Extract dependencies from package.json.
        
        Args:
            package_json_path: Path to package.json
            
        Returns:
            List of dependencies
        """
        dependencies = []
        
        try:
            with open(package_json_path, "r") as f:
                package_data = json.load(f)
            
            # Process dependencies
            for dep_type in ["dependencies", "devDependencies"]:
                deps = package_data.get(dep_type, {})
                for name, version in deps.items():
                    dependencies.append({
                        "name": name,
                        "version_spec": version,
                        "type": "node",
                        "dev": dep_type == "devDependencies",
                        "source": "package.json"
                    })
        except Exception as e:
            self._logger.error(f"Error extracting Node.js dependencies: {str(e)}")
        
        return dependencies

# Global project inference instance
project_inference = ProjectInference()
</file>

<file path="angela/context/project_state_analyzer.py">
"""
Project state analysis for Angela CLI.

This module extends Angela's context awareness by providing detailed information
about the current state of the project, including Git status, pending migrations,
test coverage, and build health.
"""
import os
import re
import json
import asyncio
import subprocess
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple, Set, Union
from datetime import datetime

from angela.utils.logging import get_logger
from angela.context.project_inference import project_inference
from angela.execution.engine import execution_engine

logger = get_logger(__name__)

class ProjectStateAnalyzer:
    """
    Project state analyzer that provides detailed information about the
    current state of the project beyond basic type detection.
    
    This class tracks:
    1. Git state (current branch, pending changes, stashes)
    2. Test coverage status
    3. Build health
    4. Pending migrations
    5. Dependency health (outdated packages, vulnerabilities)
    6. Linting/code quality issues
    7. TODO/FIXME comments
    """
    
    def __init__(self):
        """Initialize the project state analyzer."""
        self._logger = logger
        self._cache = {}  # Cache for state information
        self._cache_valid_time = 60  # Seconds before cache is invalid
        self._last_analysis_time = {}  # Timestamp of last analysis per project
    
    async def get_project_state(self, project_root: Union[str, Path]) -> Dict[str, Any]:
        """
        Get detailed information about the current state of the project.
        
        Args:
            project_root: Path to the project root directory
            
        Returns:
            Dictionary with project state information
        """
        path_obj = Path(project_root)
        path_str = str(path_obj)
        
        # Check if we have recent cached information
        if path_str in self._cache:
            # Check if the cache is still valid
            cache_age = datetime.now().timestamp() - self._last_analysis_time.get(path_str, 0)
            if cache_age < self._cache_valid_time:
                self._logger.debug(f"Using cached project state for {path_str} (age: {cache_age:.1f}s)")
                return self._cache[path_str]
        
        self._logger.info(f"Analyzing project state for {path_str}")
        
        # First, get basic project information
        try:
            basic_info = await project_inference.infer_project_info(path_obj)
        except Exception as e:
            self._logger.error(f"Error getting basic project info: {str(e)}")
            basic_info = {"project_type": "unknown"}
        
        # Initialize state information
        state_info = {
            "project_root": path_str,
            "project_type": basic_info.get("project_type", "unknown"),
            "analysis_time": datetime.now().isoformat(),
            "git_state": {},
            "test_status": {},
            "build_status": {},
            "migrations": {},
            "dependencies": {},
            "code_quality": {},
            "todo_items": []
        }
        
        # Analyze different aspects of the project state in parallel
        tasks = [
            self._analyze_git_state(path_obj),
            self._analyze_test_status(path_obj, basic_info.get("project_type", "unknown")),
            self._analyze_build_status(path_obj, basic_info.get("project_type", "unknown")),
            self._analyze_migrations(path_obj, basic_info.get("project_type", "unknown")),
            self._analyze_dependencies(path_obj, basic_info.get("project_type", "unknown")),
            self._analyze_code_quality(path_obj, basic_info.get("project_type", "unknown")),
            self._find_todo_items(path_obj)
        ]
        
        # Execute all tasks
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Process results
        if not isinstance(results[0], Exception):
            state_info["git_state"] = results[0] or {}
        if not isinstance(results[1], Exception):
            state_info["test_status"] = results[1] or {}
        if not isinstance(results[2], Exception):
            state_info["build_status"] = results[2] or {}
        if not isinstance(results[3], Exception):
            state_info["migrations"] = results[3] or {}
        if not isinstance(results[4], Exception):
            state_info["dependencies"] = results[4] or {}
        if not isinstance(results[5], Exception):
            state_info["code_quality"] = results[5] or {}
        if not isinstance(results[6], Exception):
            state_info["todo_items"] = results[6] or []
        
        # Cache the result
        self._cache[path_str] = state_info
        self._last_analysis_time[path_str] = datetime.now().timestamp()
        
        return state_info
    
    async def _analyze_git_state(self, project_root: Path) -> Dict[str, Any]:
        """
        Analyze the Git state of the project.
        
        Args:
            project_root: Path to the project root
            
        Returns:
            Dictionary with Git state information
        """
        result = {
            "is_git_repo": False,
            "current_branch": None,
            "has_changes": False,
            "untracked_files": [],
            "modified_files": [],
            "staged_files": [],
            "stashes": [],
            "remote_state": {},
            "recent_commits": []
        }
        
        # Check if this is a Git repository
        git_dir = project_root / ".git"
        if not git_dir.exists():
            return result
        
        result["is_git_repo"] = True
        
        try:
            # Get current branch
            stdout, stderr, return_code = await execution_engine.execute_command(
                command=f"cd {project_root} && git branch --show-current",
                check_safety=False
            )
            
            if return_code == 0 and stdout.strip():
                result["current_branch"] = stdout.strip()
            
            # Get git status
            stdout, stderr, return_code = await execution_engine.execute_command(
                command=f"cd {project_root} && git status --porcelain",
                check_safety=False
            )
            
            if return_code == 0:
                result["has_changes"] = bool(stdout.strip())
                
                # Parse status output
                for line in stdout.splitlines():
                    if not line.strip():
                        continue
                    
                    # Parse status code and filename
                    status_code = line[:2]
                    file_path = line[3:].strip()
                    
                    if status_code.startswith('??'):
                        # Untracked file
                        result["untracked_files"].append(file_path)
                    elif status_code.startswith('M'):
                        # Modified file
                        result["modified_files"].append(file_path)
                    elif status_code.startswith('A') or status_code.startswith('R'):
                        # Staged file (added or renamed)
                        result["staged_files"].append(file_path)
            
            # Get stash list
            stdout, stderr, return_code = await execution_engine.execute_command(
                command=f"cd {project_root} && git stash list",
                check_safety=False
            )
            
            if return_code == 0 and stdout.strip():
                # Parse stash list
                for line in stdout.splitlines():
                    match = re.match(r'stash@{(\d+)}: (.*)', line)
                    if match:
                        stash_id = match.group(1)
                        stash_description = match.group(2)
                        result["stashes"].append({
                            "id": stash_id,
                            "description": stash_description
                        })
            
            # Check remote state
            stdout, stderr, return_code = await execution_engine.execute_command(
                command=f"cd {project_root} && git status -sb",
                check_safety=False
            )
            
            if return_code == 0 and stdout.strip():
                # Parse first line for branch and tracking info
                first_line = stdout.splitlines()[0]
                
                # Check for ahead/behind information
                ahead_match = re.search(r'ahead (\d+)', first_line)
                behind_match = re.search(r'behind (\d+)', first_line)
                
                result["remote_state"] = {
                    "tracking": "origin" in first_line,
                    "ahead": int(ahead_match.group(1)) if ahead_match else 0,
                    "behind": int(behind_match.group(1)) if behind_match else 0
                }
            
            # Get recent commits
            stdout, stderr, return_code = await execution_engine.execute_command(
                command=f"cd {project_root} && git log -n 5 --pretty=format:'%h|%an|%s|%cr'",
                check_safety=False
            )
            
            if return_code == 0 and stdout.strip():
                for line in stdout.splitlines():
                    parts = line.split('|', 3)
                    if len(parts) == 4:
                        commit_hash, author, message, time = parts
                        result["recent_commits"].append({
                            "hash": commit_hash,
                            "author": author,
                            "message": message,
                            "time": time
                        })
            
            return result
            
        except Exception as e:
            self._logger.error(f"Error analyzing Git state: {str(e)}")
            return result
    
    async def _analyze_test_status(self, project_root: Path, project_type: str) -> Dict[str, Any]:
        """
        Analyze the test status of the project.
        
        Args:
            project_root: Path to the project root
            project_type: Type of the project
            
        Returns:
            Dictionary with test status information
        """
        result = {
            "test_framework_detected": False,
            "framework": None,
            "test_files_count": 0,
            "last_run": None,
            "coverage": None,
            "failing_tests": [],
            "performance_issues": []
        }
        
        # Look for test frameworks based on project type
        if "python" in project_type:
            # Check for pytest
            pytest_file = project_root / "pytest.ini"
            conftest_file = project_root / "conftest.py"
            
            if pytest_file.exists() or conftest_file.exists() or list(project_root.glob("**/test_*.py")):
                result["test_framework_detected"] = True
                result["framework"] = "pytest"
                
                # Count test files
                test_files = list(project_root.glob("**/test_*.py"))
                result["test_files_count"] = len(test_files)
                
                # Look for coverage file
                coverage_file = project_root / ".coverage"
                coverage_xml = project_root / "coverage.xml"
                
                if coverage_file.exists() or coverage_xml.exists():
                    # Try to get coverage info
                    if coverage_xml.exists():
                        try:
                            import xml.etree.ElementTree as ET
                            tree = ET.parse(coverage_xml)
                            root = tree.getroot()
                            
                            # Get coverage percentage
                            coverage_attr = root.get('line-rate')
                            if coverage_attr:
                                coverage_percentage = float(coverage_attr) * 100
                                result["coverage"] = {
                                    "percentage": coverage_percentage,
                                    "report_path": str(coverage_xml.relative_to(project_root))
                                }
                        except Exception as e:
                            self._logger.error(f"Error parsing coverage XML: {str(e)}")
            
            # Check for unittest
            elif list(project_root.glob("**/test*.py")):
                result["test_framework_detected"] = True
                result["framework"] = "unittest"
                
                # Count test files
                test_files = list(project_root.glob("**/test*.py"))
                result["test_files_count"] = len(test_files)
        
        elif "node" in project_type or "javascript" in project_type or "typescript" in project_type:
            # Check for Jest
            jest_config = project_root / "jest.config.js"
            package_json = project_root / "package.json"
            
            if jest_config.exists() or (package_json.exists() and "jest" in open(package_json).read()):
                result["test_framework_detected"] = True
                result["framework"] = "jest"
                
                # Count test files
                test_files = list(project_root.glob("**/*.test.js")) + list(project_root.glob("**/*.test.ts"))
                result["test_files_count"] = len(test_files)
                
                # Look for coverage directory
                coverage_dir = project_root / "coverage"
                if coverage_dir.exists():
                    try:
                        coverage_summary = coverage_dir / "coverage-summary.json"
                        if coverage_summary.exists():
                            with open(coverage_summary) as f:
                                coverage_data = json.load(f)
                                
                                if "total" in coverage_data and "lines" in coverage_data["total"]:
                                    coverage_percentage = coverage_data["total"]["lines"]["pct"]
                                    result["coverage"] = {
                                        "percentage": coverage_percentage,
                                        "report_path": str(coverage_summary.relative_to(project_root))
                                    }
                    except Exception as e:
                        self._logger.error(f"Error parsing Jest coverage: {str(e)}")
            
            # Check for Mocha
            elif package_json.exists() and "mocha" in open(package_json).read():
                result["test_framework_detected"] = True
                result["framework"] = "mocha"
                
                # Count test files
                test_files = list(project_root.glob("**/test/**/*.js")) + list(project_root.glob("**/test/**/*.ts"))
                result["test_files_count"] = len(test_files)
        
        elif "java" in project_type:
            # Check for JUnit
            if list(project_root.glob("**/src/test/**/*.java")):
                result["test_framework_detected"] = True
                result["framework"] = "junit"
                
                # Count test files
                test_files = list(project_root.glob("**/src/test/**/*.java"))
                result["test_files_count"] = len(test_files)
        
        return result
    
    async def _analyze_build_status(self, project_root: Path, project_type: str) -> Dict[str, Any]:
        """
        Analyze the build status of the project.
        
        Args:
            project_root: Path to the project root
            project_type: Type of the project
            
        Returns:
            Dictionary with build status information
        """
        result = {
            "build_system_detected": False,
            "system": None,
            "last_build": None,
            "artifacts": [],
            "problems": []
        }
        
        if "python" in project_type:
            # Check for setuptools
            setup_py = project_root / "setup.py"
            pyproject_toml = project_root / "pyproject.toml"
            
            if setup_py.exists():
                result["build_system_detected"] = True
                result["system"] = "setuptools"
                
                # Check for dist directory
                dist_dir = project_root / "dist"
                if dist_dir.exists():
                    # Get artifact files
                    artifacts = list(dist_dir.glob("*.whl")) + list(dist_dir.glob("*.tar.gz"))
                    
                    if artifacts:
                        result["artifacts"] = [str(a.relative_to(project_root)) for a in artifacts]
                        
                        # Get the most recent artifact's timestamp
                        most_recent = max(artifacts, key=lambda p: p.stat().st_mtime)
                        result["last_build"] = datetime.fromtimestamp(most_recent.stat().st_mtime).isoformat()
            
            elif pyproject_toml.exists():
                result["build_system_detected"] = True
                
                # Determine build system from pyproject.toml
                try:
                    import tomli
                    with open(pyproject_toml, "rb") as f:
                        pyproject_data = tomli.load(f)
                    
                    if "build-system" in pyproject_data:
                        build_backend = pyproject_data["build-system"].get("build-backend", "")
                        
                        if "setuptools" in build_backend:
                            result["system"] = "setuptools"
                        elif "poetry" in build_backend:
                            result["system"] = "poetry"
                        elif "flit" in build_backend:
                            result["system"] = "flit"
                        elif "hatchling" in build_backend:
                            result["system"] = "hatch"
                        else:
                            result["system"] = build_backend
                except Exception as e:
                    self._logger.error(f"Error parsing pyproject.toml: {str(e)}")
                    result["system"] = "unknown-pyproject"
                
                # Check for dist directory
                dist_dir = project_root / "dist"
                if dist_dir.exists():
                    # Get artifact files
                    artifacts = list(dist_dir.glob("*.whl")) + list(dist_dir.glob("*.tar.gz"))
                    
                    if artifacts:
                        result["artifacts"] = [str(a.relative_to(project_root)) for a in artifacts]
                        
                        # Get the most recent artifact's timestamp
                        most_recent = max(artifacts, key=lambda p: p.stat().st_mtime)
                        result["last_build"] = datetime.fromtimestamp(most_recent.stat().st_mtime).isoformat()
        
        elif "node" in project_type or "javascript" in project_type or "typescript" in project_type:
            # Check for various build systems
            package_json = project_root / "package.json"
            
            if package_json.exists():
                result["build_system_detected"] = True
                
                # Determine build system from package.json
                try:
                    with open(package_json) as f:
                        package_data = json.load(f)
                    
                    if "scripts" in package_data:
                        scripts = package_data["scripts"]
                        
                        if "build" in scripts:
                            build_script = scripts["build"]
                            
                            if "webpack" in build_script:
                                result["system"] = "webpack"
                            elif "rollup" in build_script:
                                result["system"] = "rollup"
                            elif "parcel" in build_script:
                                result["system"] = "parcel"
                            elif "tsc" in build_script:
                                result["system"] = "typescript"
                            elif "next build" in build_script:
                                result["system"] = "next.js"
                            elif "vue-cli-service build" in build_script:
                                result["system"] = "vue-cli"
                            elif "ng build" in build_script:
                                result["system"] = "angular-cli"
                            else:
                                result["system"] = "npm-script"
                except Exception as e:
                    self._logger.error(f"Error parsing package.json: {str(e)}")
                    result["system"] = "npm"
                
                # Check for build artifacts
                build_dir = project_root / "build"
                dist_dir = project_root / "dist"
                
                if build_dir.exists():
                    artifacts = list(build_dir.glob("**/*.*"))
                    if artifacts:
                        result["artifacts"] = [str(a.relative_to(project_root)) for a in artifacts[:5]]  # Limit to 5
                        
                        # Get the most recent artifact's timestamp
                        most_recent = max(artifacts, key=lambda p: p.stat().st_mtime)
                        result["last_build"] = datetime.fromtimestamp(most_recent.stat().st_mtime).isoformat()
                
                elif dist_dir.exists():
                    artifacts = list(dist_dir.glob("**/*.*"))
                    if artifacts:
                        result["artifacts"] = [str(a.relative_to(project_root)) for a in artifacts[:5]]  # Limit to 5
                        
                        # Get the most recent artifact's timestamp
                        most_recent = max(artifacts, key=lambda p: p.stat().st_mtime)
                        result["last_build"] = datetime.fromtimestamp(most_recent.stat().st_mtime).isoformat()
        
        elif "java" in project_type:
            # Check for Maven and Gradle
            pom_xml = project_root / "pom.xml"
            gradle_build = project_root / "build.gradle"
            
            if pom_xml.exists():
                result["build_system_detected"] = True
                result["system"] = "maven"
                
                # Check for target directory
                target_dir = project_root / "target"
                if target_dir.exists():
                    jar_files = list(target_dir.glob("*.jar"))
                    war_files = list(target_dir.glob("*.war"))
                    
                    artifacts = jar_files + war_files
                    if artifacts:
                        result["artifacts"] = [str(a.relative_to(project_root)) for a in artifacts]
                        
                        # Get the most recent artifact's timestamp
                        most_recent = max(artifacts, key=lambda p: p.stat().st_mtime)
                        result["last_build"] = datetime.fromtimestamp(most_recent.stat().st_mtime).isoformat()
            
            elif gradle_build.exists():
                result["build_system_detected"] = True
                result["system"] = "gradle"
                
                # Check for build directory
                build_dir = project_root / "build"
                if build_dir.exists():
                    jar_files = list(build_dir.glob("**/*.jar"))
                    war_files = list(build_dir.glob("**/*.war"))
                    
                    artifacts = jar_files + war_files
                    if artifacts:
                        result["artifacts"] = [str(a.relative_to(project_root)) for a in artifacts]
                        
                        # Get the most recent artifact's timestamp
                        most_recent = max(artifacts, key=lambda p: p.stat().st_mtime)
                        result["last_build"] = datetime.fromtimestamp(most_recent.stat().st_mtime).isoformat()
        
        return result
    
    async def _analyze_migrations(self, project_root: Path, project_type: str) -> Dict[str, Any]:
        """
        Analyze the migration status of the project.
        
        Args:
            project_root: Path to the project root
            project_type: Type of the project
            
        Returns:
            Dictionary with migration status information
        """
        result = {
            "has_migrations": False,
            "framework": None,
            "migration_files": [],
            "pending_migrations": []
        }
        
        if "python" in project_type:
            # Check for Django migrations
            migrations_dirs = list(project_root.glob("**/migrations"))
            
            if migrations_dirs:
                result["has_migrations"] = True
                result["framework"] = "django"
                
                # Get migration files
                migration_files = []
                for migrations_dir in migrations_dirs:
                    files = list(migrations_dir.glob("*.py"))
                    migration_files.extend([str(f.relative_to(project_root)) for f in files if f.name != "__init__.py"])
                
                result["migration_files"] = migration_files
                
                # Try to detect pending migrations using Django
                manage_py = project_root / "manage.py"
                if manage_py.exists():
                    try:
                        stdout, stderr, return_code = await execution_engine.execute_command(
                            command=f"cd {project_root} && python manage.py showmigrations",
                            check_safety=False
                        )
                        
                        if return_code == 0:
                            # Parse output to find pending migrations
                            pending = []
                            current_app = None
                            
                            for line in stdout.splitlines():
                                if not line.strip():
                                    continue
                                
                                if not line.startswith(' '):
                                    # This is an app name
                                    current_app = line.strip()
                                elif line.strip().startswith('[ ]'):
                                    # This is a pending migration
                                    migration_name = line.strip()[4:].strip()
                                    if current_app:
                                        pending.append(f"{current_app}/{migration_name}")
                            
                            result["pending_migrations"] = pending
                    except Exception as e:
                        self._logger.error(f"Error detecting Django pending migrations: {str(e)}")
            
            # Check for Alembic migrations (SQLAlchemy)
            alembic_ini = project_root / "alembic.ini"
            if alembic_ini.exists():
                alembic_dir = None
                
                # Try to find migrations directory from alembic.ini
                try:
                    with open(alembic_ini) as f:
                        for line in f:
                            if line.startswith('script_location = '):
                                alembic_dir = line.split('=')[1].strip()
                                break
                except Exception:
                    pass
                
                if alembic_dir:
                    alembic_path = project_root / alembic_dir / "versions"
                    if alembic_path.exists():
                        result["has_migrations"] = True
                        result["framework"] = "alembic"
                        
                        # Get migration files
                        migration_files = list(alembic_path.glob("*.py"))
                        result["migration_files"] = [str(f.relative_to(project_root)) for f in migration_files]
                        
                        # Try to detect pending migrations
                        try:
                            stdout, stderr, return_code = await execution_engine.execute_command(
                                command=f"cd {project_root} && alembic current",
                                check_safety=False
                            )
                            
                            if return_code == 0:
                                # Get current revision
                                current_revision = None
                                if stdout.strip():
                                    current_revision = stdout.strip().split(' ')[0]
                                
                                # Get available revisions
                                available_revisions = []
                                for file in migration_files:
                                    # Extract revision ID from filename
                                    revision_match = re.match(r'(\w+)_', file.stem)
                                    if revision_match:
                                        available_revisions.append(revision_match.group(1))
                                
                                # If we have a current revision, find pending ones
                                if current_revision and current_revision in available_revisions:
                                    current_index = available_revisions.index(current_revision)
                                    pending_revisions = available_revisions[current_index+1:]
                                    
                                    result["pending_migrations"] = [
                                        str((alembic_path / f"{rev}_something.py").relative_to(project_root))
                                        for rev in pending_revisions
                                    ]
                        except Exception as e:
                            self._logger.error(f"Error detecting Alembic pending migrations: {str(e)}")
        
        elif "node" in project_type or "javascript" in project_type:
            # Check for Sequelize migrations
            migrations_dir = project_root / "migrations"
            if migrations_dir.exists() and migrations_dir.is_dir():
                # Look for a Sequelize config file
                config_file = project_root / "config" / "config.json"
                sequelize_rc = project_root / ".sequelizerc"
                
                if config_file.exists() or sequelize_rc.exists():
                    result["has_migrations"] = True
                    result["framework"] = "sequelize"
                    
                    # Get migration files
                    migration_files = list(migrations_dir.glob("*.js"))
                    result["migration_files"] = [str(f.relative_to(project_root)) for f in migration_files]
        
        elif "ruby" in project_type or "rails" in project_type:
            # Check for Rails migrations
            migrations_dir = project_root / "db" / "migrate"
            if migrations_dir.exists() and migrations_dir.is_dir():
                result["has_migrations"] = True
                result["framework"] = "rails"
                
                # Get migration files
                migration_files = list(migrations_dir.glob("*.rb"))
                result["migration_files"] = [str(f.relative_to(project_root)) for f in migration_files]
                
                # Try to detect pending migrations
                try:
                    stdout, stderr, return_code = await execution_engine.execute_command(
                        command=f"cd {project_root} && rake db:migrate:status",
                        check_safety=False
                    )
                    
                    if return_code == 0:
                        # Parse output to find pending migrations
                        pending = []
                        
                        for line in stdout.splitlines():
                            if line.strip().startswith('down '):
                                # This is a pending migration
                                migration_info = line.strip()[5:].strip()
                                migration_match = re.search(r'(\d+)_([a-z_]+)\.rb', migration_info)
                                if migration_match:
                                    pending.append(f"db/migrate/{migration_match.group(0)}")
                        
                        result["pending_migrations"] = pending
                except Exception as e:
                    self._logger.error(f"Error detecting Rails pending migrations: {str(e)}")
        
        return result
    
    async def _analyze_dependencies(self, project_root: Path, project_type: str) -> Dict[str, Any]:
        """
        Analyze the dependency health of the project.
        
        Args:
            project_root: Path to the project root
            project_type: Type of the project
            
        Returns:
            Dictionary with dependency health information
        """
        result = {
            "has_dependencies": False,
            "dependency_file": None,
            "package_manager": None,
            "dependencies_count": 0,
            "dev_dependencies_count": 0,
            "outdated_packages": [],
            "vulnerable_packages": []
        }
        
        if "python" in project_type:
            # Check for pip requirements
            requirements_txt = project_root / "requirements.txt"
            pipfile = project_root / "Pipfile"
            pyproject_toml = project_root / "pyproject.toml"
            
            if requirements_txt.exists():
                result["has_dependencies"] = True
                result["dependency_file"] = str(requirements_txt.relative_to(project_root))
                result["package_manager"] = "pip"
                
                # Count dependencies
                try:
                    with open(requirements_txt) as f:
                        deps = [line.strip() for line in f if line.strip() and not line.strip().startswith('#')]
                        result["dependencies_count"] = len(deps)
                except Exception as e:
                    self._logger.error(f"Error reading requirements.txt: {str(e)}")
                
                # Try to find outdated packages
                try:
                    stdout, stderr, return_code = await execution_engine.execute_command(
                        command=f"cd {project_root} && pip list --outdated --format=json",
                        check_safety=False
                    )
                    
                    if return_code == 0 and stdout.strip():
                        try:
                            outdated = json.loads(stdout)
                            result["outdated_packages"] = [
                                {
                                    "name": pkg["name"],
                                    "current_version": pkg["version"],
                                    "latest_version": pkg["latest_version"]
                                }
                                for pkg in outdated
                            ]
                        except json.JSONDecodeError:
                            pass
                except Exception as e:
                    self._logger.error(f"Error checking for outdated packages: {str(e)}")
            
            elif pipfile.exists():
                result["has_dependencies"] = True
                result["dependency_file"] = str(pipfile.relative_to(project_root))
                result["package_manager"] = "pipenv"
                
                # Try to get dependency info from Pipfile.lock
                pipfile_lock = project_root / "Pipfile.lock"
                if pipfile_lock.exists():
                    try:
                        with open(pipfile_lock) as f:
                            lock_data = json.load(f)
                            
                            if "default" in lock_data:
                                result["dependencies_count"] = len(lock_data["default"])
                            
                            if "develop" in lock_data:
                                result["dev_dependencies_count"] = len(lock_data["develop"])
                    except Exception as e:
                        self._logger.error(f"Error reading Pipfile.lock: {str(e)}")
            
            elif pyproject_toml.exists():
                result["has_dependencies"] = True
                result["dependency_file"] = str(pyproject_toml.relative_to(project_root))
                
                # Try to determine the package manager
                try:
                    import tomli
                    with open(pyproject_toml, "rb") as f:
                        pyproject_data = tomli.load(f)
                    
                    if "build-system" in pyproject_data:
                        build_backend = pyproject_data["build-system"].get("build-backend", "")
                        
                        if "poetry" in build_backend:
                            result["package_manager"] = "poetry"
                        else:
                            result["package_manager"] = "pip"
                    
                    # Count dependencies
                    if "project" in pyproject_data and "dependencies" in pyproject_data["project"]:
                        if isinstance(pyproject_data["project"]["dependencies"], list):
                            result["dependencies_count"] = len(pyproject_data["project"]["dependencies"])
                    
                    # Count dev dependencies
                    if "project" in pyproject_data and "optional-dependencies" in pyproject_data["project"]:
                        if "dev" in pyproject_data["project"]["optional-dependencies"]:
                            result["dev_dependencies_count"] = len(pyproject_data["project"]["optional-dependencies"]["dev"])
                
                except Exception as e:
                    self._logger.error(f"Error reading pyproject.toml: {str(e)}")
        
        elif "node" in project_type or "javascript" in project_type or "typescript" in project_type:
            # Check for NPM/Yarn dependencies
            package_json = project_root / "package.json"
            
            if package_json.exists():
                result["has_dependencies"] = True
                result["dependency_file"] = str(package_json.relative_to(project_root))
                
                # Determine package manager
                yarn_lock = project_root / "yarn.lock"
                package_lock = project_root / "package-lock.json"
                
                if yarn_lock.exists():
                    result["package_manager"] = "yarn"
                else:
                    result["package_manager"] = "npm"
                
                # Count dependencies
                try:
                    with open(package_json) as f:
                        package_data = json.load(f)
                        
                        if "dependencies" in package_data:
                            result["dependencies_count"] = len(package_data["dependencies"])
                        
                        if "devDependencies" in package_data:
                            result["dev_dependencies_count"] = len(package_data["devDependencies"])
                except Exception as e:
                    self._logger.error(f"Error reading package.json: {str(e)}")
                
                # Try to find outdated packages
                npm_cmd = "npm" if result["package_manager"] == "npm" else "yarn"
                try:
                    stdout, stderr, return_code = await execution_engine.execute_command(
                        command=f"cd {project_root} && {npm_cmd} outdated --json",
                        check_safety=False
                    )
                    
                    if return_code == 0 and stdout.strip():
                        try:
                            outdated = json.loads(stdout)
                            
                            if isinstance(outdated, dict):
                                result["outdated_packages"] = [
                                    {
                                        "name": pkg_name,
                                        "current_version": pkg_info.get("current", "unknown"),
                                        "latest_version": pkg_info.get("latest", "unknown")
                                    }
                                    for pkg_name, pkg_info in outdated.items()
                                ]
                        except json.JSONDecodeError:
                            pass
                except Exception as e:
                    self._logger.error(f"Error checking for outdated packages: {str(e)}")
        
        elif "java" in project_type:
            # Check for Maven dependencies
            pom_xml = project_root / "pom.xml"
            gradle_build = project_root / "build.gradle"
            
            if pom_xml.exists():
                result["has_dependencies"] = True
                result["dependency_file"] = str(pom_xml.relative_to(project_root))
                result["package_manager"] = "maven"
                
                # Try to count dependencies using basic XML parsing
                try:
                    import xml.etree.ElementTree as ET
                    tree = ET.parse(pom_xml)
                    root = tree.getroot()
                    
                    # Add namespace to XML tags
                    ns = {"mvn": "http://maven.apache.org/POM/4.0.0"}
                    
                    # Count dependencies
                    dependencies = root.findall(".//mvn:dependencies/mvn:dependency", ns)
                    result["dependencies_count"] = len(dependencies)
                except Exception as e:
                    self._logger.error(f"Error parsing pom.xml: {str(e)}")
            
            elif gradle_build.exists():
                result["has_dependencies"] = True
                result["dependency_file"] = str(gradle_build.relative_to(project_root))
                result["package_manager"] = "gradle"
                
                # Count dependencies using a simple regex
                try:
                    with open(gradle_build) as f:
                        content = f.read()
                        
                        # Count dependencies
                        dependency_matches = re.findall(r"implementation ['\"]([^'\"]+?)['\"]", content)
                        result["dependencies_count"] = len(dependency_matches)
                        
                        # Count dev dependencies
                        test_matches = re.findall(r"testImplementation ['\"]([^'\"]+?)['\"]", content)
                        result["dev_dependencies_count"] = len(test_matches)
                except Exception as e:
                    self._logger.error(f"Error reading build.gradle: {str(e)}")
        
        return result
    
    async def _analyze_code_quality(self, project_root: Path, project_type: str) -> Dict[str, Any]:
        """
        Analyze the code quality of the project.
        
        Args:
            project_root: Path to the project root
            project_type: Type of the project
            
        Returns:
            Dictionary with code quality information
        """
        result = {
            "linting_setup_detected": False,
            "linter": None,
            "formatter": None,
            "issues_count": 0,
            "issues_by_type": {},
            "high_priority_issues": []
        }
        
        if "python" in project_type:
            # Check for Python linters
            flake8_config = project_root / ".flake8"
            pylintrc = project_root / ".pylintrc"
            mypy_ini = project_root / "mypy.ini"
            
            if flake8_config.exists():
                result["linting_setup_detected"] = True
                result["linter"] = "flake8"
                
                # Try to run flake8 to get issue count
                try:
                    stdout, stderr, return_code = await execution_engine.execute_command(
                        command=f"cd {project_root} && flake8 --max-line-length=120 --count",
                        check_safety=False
                    )
                    
                    if return_code == 0 and stdout.strip():
                        # Last line contains the issue count
                        result["issues_count"] = int(stdout.strip().splitlines()[-1])
                except Exception as e:
                    self._logger.error(f"Error running flake8: {str(e)}")
            
            elif pylintrc.exists():
                result["linting_setup_detected"] = True
                result["linter"] = "pylint"
            
            # Check for Python formatters
            black_config = project_root / "pyproject.toml"
            if black_config.exists():
                try:
                    import tomli
                    with open(black_config, "rb") as f:
                        config_data = tomli.load(f)
                    
                    if "tool" in config_data and "black" in config_data["tool"]:
                        result["formatter"] = "black"
                except Exception:
                    pass
            
            isort_config = project_root / ".isort.cfg"
            if isort_config.exists():
                if result["formatter"]:
                    result["formatter"] += "+isort"
                else:
                    result["formatter"] = "isort"
        
        elif "node" in project_type or "javascript" in project_type or "typescript" in project_type:
            # Check for JS/TS linters
            eslintrc = any(
                (project_root / f).exists() 
                for f in [".eslintrc", ".eslintrc.js", ".eslintrc.json", ".eslintrc.yml"]
            )
            
            if eslintrc:
                result["linting_setup_detected"] = True
                result["linter"] = "eslint"
                
                # Try to run eslint to get issue count
                try:
                    stdout, stderr, return_code = await execution_engine.execute_command(
                        command=f"cd {project_root} && npx eslint . --max-warnings=9999 -f json",
                        check_safety=False
                    )
                    
                    if return_code == 0 and stdout.strip():
                        try:
                            lint_results = json.loads(stdout)
                            
                            # Count issues
                            total_issues = sum(len(file_result.get("messages", [])) for file_result in lint_results)
                            result["issues_count"] = total_issues
                            
                            # Count by severity
                            severity_counts = {"error": 0, "warning": 0, "info": 0}
                            
                            for file_result in lint_results:
                                for msg in file_result.get("messages", []):
                                    severity = msg.get("severity")
                                    if severity == 2:
                                        severity_counts["error"] += 1
                                    elif severity == 1:
                                        severity_counts["warning"] += 1
                                    else:
                                        severity_counts["info"] += 1
                            
                            result["issues_by_type"] = severity_counts
                            
                            # Collect high-priority issues
                            for file_result in lint_results:
                                for msg in file_result.get("messages", []):
                                    if msg.get("severity") == 2:  # Error
                                        result["high_priority_issues"].append({
                                            "file": file_result.get("filePath", "unknown"),
                                            "line": msg.get("line", 0),
                                            "column": msg.get("column", 0),
                                            "message": msg.get("message", "Unknown error"),
                                            "rule": msg.get("ruleId", "unknown")
                                        })
                                        
                                        # Limit to 10 issues
                                        if len(result["high_priority_issues"]) >= 10:
                                            break
                                
                                if len(result["high_priority_issues"]) >= 10:
                                    break
                        except json.JSONDecodeError:
                            pass
                except Exception as e:
                    self._logger.error(f"Error running eslint: {str(e)}")
            
            # Check for tslint
            tslint_json = project_root / "tslint.json"
            if tslint_json.exists():
                result["linting_setup_detected"] = True
                result["linter"] = "tslint"
            
            # Check for formatters
            prettier_config = any(
                (project_root / f).exists() 
                for f in [".prettierrc", ".prettierrc.js", ".prettierrc.json", ".prettier.config.js"]
            )
            
            if prettier_config:
                result["formatter"] = "prettier"
        
        elif "java" in project_type:
            # Check for Java linters
            checkstyle_xml = project_root / "checkstyle.xml"
            pmd_xml = project_root / "pmd.xml"
            
            if checkstyle_xml.exists():
                result["linting_setup_detected"] = True
                result["linter"] = "checkstyle"
            
            elif pmd_xml.exists():
                result["linting_setup_detected"] = True
                result["linter"] = "pmd"
        
        return result
    
    async def _find_todo_items(self, project_root: Path) -> List[Dict[str, Any]]:
        """
        Find TODO and FIXME comments in the project.
        
        Args:
            project_root: Path to the project root
            
        Returns:
            List of dictionaries with todo items
        """
        # List of file extensions to search
        extensions = [
            ".py", ".js", ".jsx", ".ts", ".tsx", ".java", ".c", ".cpp", ".h", ".cs", 
            ".rb", ".php", ".go", ".rs", ".swift", ".kt", ".scala", ".html", ".css", 
            ".scss", ".less", ".md", ".txt", ".sh", ".bat", ".ps1"
        ]
        
        # Patterns to search for
        todo_patterns = [
            r'(?://|#|<!--|;|/\*)\s*TODO\s*(?:\(([^)]+)\)\s*)?:?\s*(.*?)(?:\*/|-->)?$',
            r'(?://|#|<!--|;|/\*)\s*FIXME\s*(?:\(([^)]+)\)\s*)?:?\s*(.*?)(?:\*/|-->)?$',
            r'(?://|#|<!--|;|/\*)\s*HACK\s*(?:\(([^)]+)\)\s*)?:?\s*(.*?)(?:\*/|-->)?$',
            r'(?://|#|<!--|;|/\*)\s*BUG\s*(?:\(([^)]+)\)\s*)?:?\s*(.*?)(?:\*/|-->)?$',
            r'(?://|#|<!--|;|/\*)\s*NOTE\s*(?:\(([^)]+)\)\s*)?:?\s*(.*?)(?:\*/|-->)?$'
        ]
        
        # Exclude patterns
        exclude_patterns = [
            "node_modules", "__pycache__", ".git", "venv", ".venv", "env", 
            "build", "dist", "target", "bin", "obj", ".pytest_cache"
        ]
        
        # Result list
        todo_items = []
        
        # Find files to search
        for ext in extensions:
            files = []
            for file in project_root.glob(f"**/*{ext}"):
                # Skip excluded directories
                if any(excl in str(file) for excl in exclude_patterns):
                    continue
                files.append(file)
            
            # Limit to 1000 files to avoid excessive processing
            if len(files) > 1000:
                files = files[:1000]
            
            # Search each file
            for file in files:
                try:
                    with open(file, 'r', encoding='utf-8', errors='ignore') as f:
                        for i, line in enumerate(f, 1):
                            for pattern in todo_patterns:
                                matches = re.search(pattern, line)
                                if matches:
                                    # Extract todo info
                                    assignee = matches.group(1) if matches.lastindex >= 1 else None
                                    text = matches.group(2) if matches.lastindex >= 2 else matches.group(0)
                                    
                                    # Determine todo type
                                    todo_type = None
                                    if "TODO" in line:
                                        todo_type = "TODO"
                                    elif "FIXME" in line:
                                        todo_type = "FIXME"
                                    elif "HACK" in line:
                                        todo_type = "HACK"
                                    elif "BUG" in line:
                                        todo_type = "BUG"
                                    elif "NOTE" in line:
                                        todo_type = "NOTE"
                                    
                                    # Add to result
                                    todo_items.append({
                                        "type": todo_type,
                                        "text": text.strip(),
                                        "file": str(file.relative_to(project_root)),
                                        "line": i,
                                        "assignee": assignee.strip() if assignee else None
                                    })
                except Exception as e:
                    self._logger.error(f"Error searching for todos in {file}: {str(e)}")
        
        # Sort by file and line number
        todo_items.sort(key=lambda item: (item["file"], item["line"]))
        
        # Limit to 100 items to avoid excessive data
        return todo_items[:100]
    
    async def get_detailed_git_status(self, project_root: Union[str, Path]) -> Dict[str, Any]:
        """
        Get detailed information about the Git status of the project.
        
        Args:
            project_root: Path to the project root
            
        Returns:
            Dictionary with detailed Git information
        """
        path_obj = Path(project_root)
        
        # Get basic project state
        project_state = await self.get_project_state(path_obj)
        git_state = project_state.get("git_state", {})
        
        if not git_state.get("is_git_repo", False):
            return {"is_git_repo": False}
        
        # Add more detailed Git information
        result = dict(git_state)
        
        try:
            # Get the git log graph
            stdout, stderr, return_code = await execution_engine.execute_command(
                command=f"cd {path_obj} && git log --graph --oneline --decorate -n 10",
                check_safety=False
            )
            
            if return_code == 0 and stdout.strip():
                result["log_graph"] = stdout.strip()
            
            # Get branch info
            stdout, stderr, return_code = await execution_engine.execute_command(
                command=f"cd {path_obj} && git branch -vv",
                check_safety=False
            )
            
            if return_code == 0 and stdout.strip():
                branches = []
                for line in stdout.splitlines():
                    if not line.strip():
                        continue
                    
                    # Parse branch line
                    is_current = line.startswith('*')
                    branch_line = line[2:].strip()
                    
                    # Extract branch name and info
                    parts = branch_line.split(' ', 1)
                    if len(parts) == 2:
                        branch_name = parts[0]
                        branch_info = parts[1].strip()
                        
                        # Extract tracking info
                        tracking_match = re.search(r'\[(.*?)\]', branch_info)
                        tracking_info = tracking_match.group(1) if tracking_match else None
                        
                        branches.append({
                            "name": branch_name,
                            "is_current": is_current,
                            "tracking_info": tracking_info,
                            "info": branch_info
                        })
                
                result["branches"] = branches
            
            # Get remote info
            stdout, stderr, return_code = await execution_engine.execute_command(
                command=f"cd {path_obj} && git remote -v",
                check_safety=False
            )
            
            if return_code == 0 and stdout.strip():
                remotes = {}
                for line in stdout.splitlines():
                    if not line.strip():
                        continue
                    
                    # Parse remote line
                    parts = line.split()
                    if len(parts) >= 2:
                        remote_name = parts[0]
                        remote_url = parts[1]
                        remote_type = parts[2][1:-1] if len(parts) >= 3 else "fetch"
                        
                        if remote_name not in remotes:
                            remotes[remote_name] = {}
                        
                        remotes[remote_name][remote_type] = remote_url
                
                result["remotes"] = remotes
            
            # Get git config for the repo
            stdout, stderr, return_code = await execution_engine.execute_command(
                command=f"cd {path_obj} && git config --local --list",
                check_safety=False
            )
            
            if return_code == 0 and stdout.strip():
                git_config = {}
                for line in stdout.splitlines():
                    if not line.strip() or '=' not in line:
                        continue
                    
                    key, value = line.split('=', 1)
                    git_config[key.strip()] = value.strip()
                
                # Extract useful config values
                config_extract = {}
                
                # User info
                if "user.name" in git_config:
                    config_extract["user.name"] = git_config["user.name"]
                if "user.email" in git_config:
                    config_extract["user.email"] = git_config["user.email"]
                
                # Branch default
                if "init.defaultBranch" in git_config:
                    config_extract["default_branch"] = git_config["init.defaultBranch"]
                
                # Pull strategy
                if "pull.rebase" in git_config:
                    config_extract["pull_strategy"] = "rebase" if git_config["pull.rebase"] == "true" else "merge"
                
                result["config"] = config_extract
            
            return result
            
        except Exception as e:
            self._logger.error(f"Error getting detailed Git status: {str(e)}")
            return git_state
    
    async def get_project_tasks(self, project_root: Union[str, Path]) -> Dict[str, Any]:
        """
        Get a list of tasks (todos, issues, pending features, etc.) for the project.
        
        Args:
            project_root: Path to the project root
            
        Returns:
            Dictionary with project tasks
        """
        path_obj = Path(project_root)
        
        # Get the project state
        project_state = await self.get_project_state(path_obj)
        
        # Extract todo items
        todo_items = project_state.get("todo_items", [])
        
        # Look for task files
        tasks_files = []
        for file in ["TODO.md", "TODO.txt", "TASKS.md", "ROADMAP.md"]:
            task_file = path_obj / file
            if task_file.exists():
                tasks_files.append(str(task_file.relative_to(path_obj)))
        
        # Look for GitHub/GitLab issue templates
        issue_templates = []
        for template_dir in [".github/ISSUE_TEMPLATE", ".gitlab/issue_templates"]:
            template_path = path_obj / template_dir
            if template_path.exists() and template_path.is_dir():
                for template_file in template_path.glob("*.md"):
                    issue_templates.append(str(template_file.relative_to(path_obj)))
        
        # Combine everything into a tasks summary
        return {
            "todo_items": todo_items,
            "tasks_files": tasks_files,
            "issue_templates": issue_templates,
            "pending_migrations": project_state.get("migrations", {}).get("pending_migrations", []),
            "failing_tests": project_state.get("test_status", {}).get("failing_tests", []),
            "high_priority_issues": project_state.get("code_quality", {}).get("high_priority_issues", [])
        }

# Global project state analyzer instance
project_state_analyzer = ProjectStateAnalyzer()
</file>

<file path="angela/context/semantic_context_manager.py">
"""
Semantic context management for Angela CLI.

This module integrates and manages all semantic understanding components,
providing a unified interface for accessing rich contextual information
about code, project state, and user intentions.
"""
import os
import asyncio
import traceback
from pathlib import Path
from typing import Dict, Any, List, Optional, Set, Union
from datetime import datetime

from angela.utils.logging import get_logger
from angela.context.manager import context_manager
from angela.context.file_activity import file_activity_tracker
from angela.context.project_state_analyzer import project_state_analyzer
from angela.ai.semantic_analyzer import semantic_analyzer
from angela.core.registry import registry

logger = get_logger(__name__)

class SemanticContextManager:
    """
    Central manager for all semantic context information.
    
    This class integrates:
    1. Code semantic analysis (functions, classes, relationships)
    2. Project state information (git status, migrations, dependencies)
    3. File activity tracking (down to function/class level)
    4. User intention mapping based on history and current context
    
    It provides a unified interface for AI components to access rich
    contextual information for more informed responses.
    """
    
    def __init__(self):
        """Initialize the semantic context manager."""
        self._logger = logger
        self._analysis_cache = {}  # Cache of semantic analysis results
        self._last_analysis_time = {}  # Timestamp of last analysis
        self._active_analyses = set()  # Currently running analyses
        self._analysis_valid_time = 300  # Seconds before a cached analysis is invalid
        
        # Project module cache - maps project root to module info
        self._project_modules = {}
        
        # Map of file paths to functions and classes
        self._entity_map = {}  # Maps "function_name" -> file_path
        self._recent_entity_usages = []  # List of recently used entities
        
        # Register this service
        registry.register("semantic_context_manager", self)
    
    async def refresh_context(self, force: bool = False) -> None:
        """
        Refresh the semantic context for the current project.
        
        Args:
            force: Whether to force a refresh even if the cache is valid
        """
        # Get the current project root
        project_root = context_manager.project_root
        if not project_root:
            self._logger.debug("No project root detected, skipping semantic context refresh")
            return
        
        # Check if we need to refresh
        if not force and project_root in self._last_analysis_time:
            last_time = self._last_analysis_time[project_root]
            age = datetime.now().timestamp() - last_time
            if age < self._analysis_valid_time:
                self._logger.debug(f"Using cached semantic analysis for {project_root} (age: {age:.1f}s)")
                return
        
        # Don't start multiple analyses for the same project
        if project_root in self._active_analyses:
            self._logger.debug(f"Analysis already in progress for {project_root}")
            return
            
        self._active_analyses.add(project_root)
        
        try:
            self._logger.info(f"Refreshing semantic context for {project_root}")
            
            # Get project state asynchronously
            project_state_task = asyncio.create_task(
                project_state_analyzer.get_project_state(project_root)
            )
            
            # Start semantic analysis of key files asynchronously
            semantic_analysis_task = asyncio.create_task(
                self._analyze_key_files(project_root)
            )
            
            # Wait for both tasks to complete
            project_state, semantic_analysis = await asyncio.gather(
                project_state_task, 
                semantic_analysis_task
            )
            
            # Store the results
            self._analysis_cache[project_root] = {
                "project_state": project_state,
                "semantic_analysis": semantic_analysis,
                "timestamp": datetime.now().isoformat()
            }
            
            self._last_analysis_time[project_root] = datetime.now().timestamp()
            self._logger.info(f"Semantic context refresh completed for {project_root}")
            
        except Exception as e:
            self._logger.exception(f"Error refreshing semantic context: {str(e)}")
        finally:
            self._active_analyses.remove(project_root)
    
    async def _analyze_key_files(self, project_root: Path) -> Dict[str, Any]:
        """
        Analyze the key files in the project.
        
        Args:
            project_root: The project root path
            
        Returns:
            Dictionary with semantic analysis information
        """
        # Get key files to analyze
        key_files = await self._identify_key_files(project_root)
        
        # Perform semantic analysis
        modules = {}
        for file_path in key_files:
            try:
                module = await semantic_analyzer.analyze_file(file_path)
                if module:
                    modules[str(file_path)] = module
            except Exception as e:
                self._logger.error(f"Error analyzing file {file_path}: {str(e)}")
        
        # Update the entity map
        self._update_entity_map(modules)
        
        # Store the modules for this project
        self._project_modules[str(project_root)] = modules
        
        # Calculate project-wide metrics
        metrics = semantic_analyzer.calculate_project_metrics(modules)
        
        # Return summary
        return {
            "analyzed_files_count": len(modules),
            "entities": {
                "functions": sum(len(module.functions) for module in modules.values()),
                "classes": sum(len(module.classes) for module in modules.values()),
                "variables": sum(len(module.variables) for module in modules.values())
            },
            "metrics": metrics,
            "key_files": [str(f) for f in key_files[:10]]  # Include only the first 10 for brevity
        }
    
    def _update_entity_map(self, modules: Dict[str, Any]) -> None:
        """
        Update the entity map with the analyzed modules.
        
        Args:
            modules: Dictionary of modules
        """
        for file_path, module in modules.items():
            # Add functions
            for func_name, func in module.functions.items():
                self._entity_map[func_name] = file_path
            
            # Add classes
            for class_name, cls in module.classes.items():
                self._entity_map[class_name] = file_path
                
                # Add methods with class prefix
                for method_name in cls.methods:
                    qualified_name = f"{class_name}.{method_name}"
                    self._entity_map[qualified_name] = file_path
    
    async def _identify_key_files(self, project_root: Path) -> List[Path]:
        """
        Identify the key files in the project for analysis.
        
        Prioritizes:
        1. Recently accessed files
        2. Files with the most activity
        3. Entry point files (main.py, index.js, etc.)
        4. Config and initialization files
        
        Args:
            project_root: The project root path
            
        Returns:
            List of file paths
        """
        key_files = set()
        
        # Get recently accessed files
        recent_activities = file_activity_tracker.get_recent_activities(limit=20)
        for activity in recent_activities:
            file_path = Path(activity["path"])
            if file_path.exists() and file_path.is_file():
                key_files.add(file_path)
        
        # Get most active files
        active_files = file_activity_tracker.get_most_active_files(limit=20)
        for file_info in active_files:
            file_path = Path(file_info["path"])
            if file_path.exists() and file_path.is_file():
                key_files.add(file_path)
        
        # Find entry point files
        entry_point_patterns = [
            "main.py", "__main__.py", "app.py", "index.js", "server.js",
            "index.ts", "App.tsx", "App.jsx", "Main.java", "Program.cs"
        ]
        
        for pattern in entry_point_patterns:
            for file_path in project_root.glob(f"**/{pattern}"):
                if file_path.exists() and file_path.is_file():
                    key_files.add(file_path)
        
        # Find config and initialization files
        config_patterns = [
            "config.py", "settings.py", "constants.py", "__init__.py",
            "package.json", "tsconfig.json", ".eslintrc.js", "webpack.config.js",
            "Dockerfile", "docker-compose.yml", "requirements.txt", "pyproject.toml"
        ]
        
        for pattern in config_patterns:
            for file_path in project_root.glob(f"**/{pattern}"):
                if file_path.exists() and file_path.is_file():
                    key_files.add(file_path)
        
        # Limit to 100 files to avoid excessive analysis
        return list(key_files)[:100]
    
    async def get_enriched_context(self) -> Dict[str, Any]:
        """
        Get an enriched context dictionary with semantic information.
        
        Returns:
            Dictionary with enriched context information
        """
        project_root = context_manager.project_root
        if not project_root:
            return {"semantic_context_available": False}
        
        # Ensure we have up-to-date analysis
        await self.refresh_context()
        
        if str(project_root) not in self._analysis_cache:
            return {"semantic_context_available": False}
        
        # Get the analysis results
        analysis = self._analysis_cache[str(project_root)]
        
        # Get the current file
        current_file = context_manager.current_file
        current_file_entities = None
        
        if current_file and str(current_file) in self._project_modules.get(str(project_root), {}):
            module = self._project_modules[str(project_root)][str(current_file)]
            
            # Extract information about entities in the current file
            current_file_entities = {
                "functions": list(module.functions.keys()),
                "classes": list(module.classes.keys()),
                "imports": list(module.imports.keys()),
                "docstring": module.docstring
            }
        
        # Build the enriched context
        return {
            "semantic_context_available": True,
            "project_semantic_info": {
                "analyzed_files": analysis["semantic_analysis"]["analyzed_files_count"],
                "entity_counts": analysis["semantic_analysis"]["entities"],
                "key_metrics": {
                    "total_lines": analysis["semantic_analysis"]["metrics"].get("total_lines", 0),
                    "function_count": analysis["semantic_analysis"]["metrics"].get("function_count", 0),
                    "class_count": analysis["semantic_analysis"]["metrics"].get("class_count", 0),
                    "average_function_complexity": analysis["semantic_analysis"]["metrics"].get("average_function_complexity", 0)
                }
            },
            "project_state": {
                "git": {
                    "current_branch": analysis["project_state"]["git_state"].get("current_branch"),
                    "has_changes": analysis["project_state"]["git_state"].get("has_changes", False),
                    "modified_files_count": len(analysis["project_state"]["git_state"].get("modified_files", [])),
                    "untracked_files_count": len(analysis["project_state"]["git_state"].get("untracked_files", []))
                },
                "tests": {
                    "framework": analysis["project_state"]["test_status"].get("framework"),
                    "test_files_count": analysis["project_state"]["test_status"].get("test_files_count", 0),
                    "coverage": analysis["project_state"]["test_status"].get("coverage", {}).get("percentage")
                },
                "dependencies": {
                    "count": analysis["project_state"]["dependencies"].get("dependencies_count", 0),
                    "outdated_count": len(analysis["project_state"]["dependencies"].get("outdated_packages", [])),
                    "package_manager": analysis["project_state"]["dependencies"].get("package_manager")
                },
                "code_quality": {
                    "linter": analysis["project_state"]["code_quality"].get("linter"),
                    "issues_count": analysis["project_state"]["code_quality"].get("issues_count", 0)
                },
                "todos_count": len(analysis["project_state"]["todo_items"])
            },
            "current_file_semantic": current_file_entities
        }
    
    async def track_entity_access(self, entity_name: str, file_path: Optional[Path] = None) -> None:
        """
        Track access to a code entity (function, class, etc.).
        
        Args:
            entity_name: Name of the entity being accessed
            file_path: Optional path to the file containing the entity
        """
        if not entity_name:
            return
        
        # If file_path is not provided, try to find it from the entity map
        if not file_path and entity_name in self._entity_map:
            file_path = Path(self._entity_map[entity_name])
        
        if not file_path:
            return
        
        # Add to recent entity usages
        timestamp = datetime.now().timestamp()
        self._recent_entity_usages.append({
            "entity_name": entity_name,
            "file_path": str(file_path),
            "timestamp": timestamp
        })
        
        # Keep only the most recent 100 usages
        if len(self._recent_entity_usages) > 100:
            self._recent_entity_usages = self._recent_entity_usages[-100:]
        
        # Also track file access at the file level
        file_activity_tracker.track_file_viewing(file_path, None, {
            "entity_name": entity_name,
            "entity_type": "code_entity",
            "timestamp": timestamp
        })
    
    async def get_entity_info(self, entity_name: str) -> Optional[Dict[str, Any]]:
        """
        Get detailed information about a code entity.
        
        Args:
            entity_name: Name of the entity to look up
            
        Returns:
            Dictionary with entity information or None if not found
        """
        project_root = context_manager.project_root
        if not project_root:
            return None
        
        # Ensure the context is refreshed
        await self.refresh_context()
        
        # Check if the entity exists in our map
        if entity_name not in self._entity_map:
            return None
        
        file_path = self._entity_map[entity_name]
        
        # Track this entity access
        await self.track_entity_access(entity_name, Path(file_path))
        
        # Get the module
        if str(project_root) not in self._project_modules or file_path not in self._project_modules[str(project_root)]:
            return None
        
        module = self._project_modules[str(project_root)][file_path]
        
        # Check if it's a function, class, or class method
        if "." in entity_name:
            # Class method
            class_name, method_name = entity_name.split(".", 1)
            
            if class_name in module.classes and method_name in module.classes[class_name].methods:
                method = module.classes[class_name].methods[method_name]
                return {
                    "type": "method",
                    "name": method_name,
                    "class_name": class_name,
                    "file_path": file_path,
                    "line_start": method.line_start,
                    "line_end": method.line_end,
                    "params": method.params,
                    "docstring": method.docstring,
                    "return_type": method.return_type,
                    "complexity": method.complexity
                }
        
        elif entity_name in module.functions:
            # Function
            function = module.functions[entity_name]
            return {
                "type": "function",
                "name": entity_name,
                "file_path": file_path,
                "line_start": function.line_start,
                "line_end": function.line_end,
                "params": function.params,
                "docstring": function.docstring,
                "return_type": function.return_type,
                "complexity": function.complexity,
                "called_functions": function.called_functions
            }
        
        elif entity_name in module.classes:
            # Class
            cls = module.classes[entity_name]
            return {
                "type": "class",
                "name": entity_name,
                "file_path": file_path,
                "line_start": cls.line_start,
                "line_end": cls.line_end,
                "docstring": cls.docstring,
                "base_classes": cls.base_classes,
                "methods": list(cls.methods.keys()),
                "attributes": list(cls.attributes.keys())
            }
        
        return None
    
    async def find_related_code(self, query: str, limit: int = 5) -> List[Dict[str, Any]]:
        """
        Find code entities related to a natural language query.
        
        Args:
            query: Natural language query describing code functionality
            limit: Maximum number of results to return
            
        Returns:
            List of entity information dictionaries
        """
        project_root = context_manager.project_root
        if not project_root:
            return []
        
        # Ensure the context is refreshed
        await self.refresh_context()
        
        if str(project_root) not in self._project_modules:
            return []
        
        # Simple keyword matching for now
        # In a real implementation, you might use embedding-based similarity
        keywords = query.lower().split()
        matches = []
        
        # Search through all modules
        for file_path, module in self._project_modules[str(project_root)].items():
            # Search functions
            for func_name, func in module.functions.items():
                score = self._calculate_match_score(func, keywords)
                if score > 0:
                    matches.append({
                        "entity_name": func_name,
                        "type": "function",
                        "file_path": file_path,
                        "score": score,
                        "preview": func.docstring[:100] + "..." if func.docstring and len(func.docstring) > 100 else func.docstring,
                        "line": func.line_start
                    })
            
            # Search classes
            for class_name, cls in module.classes.items():
                score = self._calculate_match_score(cls, keywords)
                if score > 0:
                    matches.append({
                        "entity_name": class_name,
                        "type": "class",
                        "file_path": file_path,
                        "score": score,
                        "preview": cls.docstring[:100] + "..." if cls.docstring and len(cls.docstring) > 100 else cls.docstring,
                        "line": cls.line_start
                    })
                
                # Search class methods
                for method_name, method in cls.methods.items():
                    score = self._calculate_match_score(method, keywords)
                    if score > 0:
                        matches.append({
                            "entity_name": f"{class_name}.{method_name}",
                            "type": "method",
                            "file_path": file_path,
                            "score": score,
                            "preview": method.docstring[:100] + "..." if method.docstring and len(method.docstring) > 100 else method.docstring,
                            "line": method.line_start
                        })
        
        # Sort by score
        matches.sort(key=lambda x: x["score"], reverse=True)
        
        # Return top results
        return matches[:limit]
    
    def _calculate_match_score(self, entity: Any, keywords: List[str]) -> float:
        """
        Calculate a match score between an entity and keywords.
        
        Args:
            entity: Code entity (function, class, etc.)
            keywords: List of keywords to match
            
        Returns:
            Score value where higher is better
        """
        score = 0.0
        
        # Check entity name
        name_words = entity.name.lower().split('_')
        for word in name_words:
            for keyword in keywords:
                if keyword in word:
                    score += 1.0 if keyword == word else 0.5
        
        # Check docstring
        if entity.docstring:
            for keyword in keywords:
                if keyword in entity.docstring.lower():
                    score += 0.3
        
        return score
    
    async def get_recent_entity_usages(self, limit: int = 10) -> List[Dict[str, Any]]:
        """
        Get the most recently used code entities.
        
        Args:
            limit: Maximum number of results to return
            
        Returns:
            List of entity usage information
        """
        # Sort by timestamp (newest first)
        sorted_usages = sorted(
            self._recent_entity_usages, 
            key=lambda x: x["timestamp"], 
            reverse=True
        )
        
        # Take only the most recent usage of each entity
        unique_entities = {}
        for usage in sorted_usages:
            entity_name = usage["entity_name"]
            if entity_name not in unique_entities:
                unique_entities[entity_name] = usage
                
                # Add entity information
                try:
                    entity_info = await self.get_entity_info(entity_name)
                    if entity_info:
                        unique_entities[entity_name]["info"] = entity_info
                except Exception:
                    pass
        
        # Convert to list and limit
        return list(unique_entities.values())[:limit]
    
    async def get_code_summary(self, file_path: Union[str, Path]) -> Dict[str, Any]:
        """
        Get a summary of the code in a file.
        
        Args:
            file_path: Path to the file
            
        Returns:
            Dictionary with code summary information
        """
        path_obj = Path(file_path)
        project_root = context_manager.project_root
        
        if not project_root:
            return {"error": "No project root detected"}
        
        # Ensure the context is refreshed
        await self.refresh_context()
        
        if str(project_root) not in self._project_modules:
            return {"error": "Project not analyzed"}
        
        # Get the module
        file_str = str(path_obj)
        if file_str not in self._project_modules[str(project_root)]:
            # Try to analyze the file now
            try:
                module = await semantic_analyzer.analyze_file(path_obj)
                if module:
                    self._project_modules[str(project_root)][file_str] = module
                else:
                    return {"error": "Failed to analyze file"}
            except Exception as e:
                return {"error": f"Error analyzing file: {str(e)}"}
        
        module = self._project_modules[str(project_root)][file_str]
        
        # Create a summary
        return {
            "file_path": file_str,
            "language": module.language,
            "docstring": module.docstring,
            "functions": [
                {
                    "name": name,
                    "params": func.params,
                    "docstring": func.docstring[:100] + "..." if func.docstring and len(func.docstring) > 100 else func.docstring,
                    "complexity": func.complexity
                }
                for name, func in module.functions.items()
            ],
            "classes": [
                {
                    "name": name,
                    "docstring": cls.docstring[:100] + "..." if cls.docstring and len(cls.docstring) > 100 else cls.docstring,
                    "methods_count": len(cls.methods),
                    "attributes_count": len(cls.attributes),
                    "base_classes": cls.base_classes
                }
                for name, cls in module.classes.items()
            ],
            "imports": len(module.imports),
            "metrics": module.code_metrics
        }
    
    async def get_project_summary(self) -> Dict[str, Any]:
        """
        Get a summary of the current project.
        
        Returns:
            Dictionary with project summary information
        """
        project_root = context_manager.project_root
        if not project_root:
            return {"error": "No project root detected"}
        
        # Ensure the context is refreshed
        await self.refresh_context()
        
        if str(project_root) not in self._analysis_cache:
            return {"error": "Project not analyzed"}
        
        # Get the analysis results
        analysis = self._analysis_cache[str(project_root)]
        
        # Build a detailed project summary
        return {
            "project_root": str(project_root),
            "project_type": analysis["project_state"].get("project_type", "unknown"),
            "git_info": {
                "current_branch": analysis["project_state"]["git_state"].get("current_branch"),
                "is_git_repo": analysis["project_state"]["git_state"].get("is_git_repo", False),
                "has_changes": analysis["project_state"]["git_state"].get("has_changes", False),
                "modified_files": analysis["project_state"]["git_state"].get("modified_files", []),
                "untracked_files": analysis["project_state"]["git_state"].get("untracked_files", []),
                "recent_commits": analysis["project_state"]["git_state"].get("recent_commits", [])
            },
            "test_info": {
                "framework": analysis["project_state"]["test_status"].get("framework"),
                "test_files_count": analysis["project_state"]["test_status"].get("test_files_count", 0),
                "coverage": analysis["project_state"]["test_status"].get("coverage", {}).get("percentage")
            },
            "build_info": {
                "system": analysis["project_state"]["build_status"].get("system"),
                "last_build": analysis["project_state"]["build_status"].get("last_build"),
                "artifacts_count": len(analysis["project_state"]["build_status"].get("artifacts", []))
            },
            "dependency_info": {
                "package_manager": analysis["project_state"]["dependencies"].get("package_manager"),
                "dependencies_count": analysis["project_state"]["dependencies"].get("dependencies_count", 0),
                "dev_dependencies_count": analysis["project_state"]["dependencies"].get("dev_dependencies_count", 0),
                "outdated_packages": analysis["project_state"]["dependencies"].get("outdated_packages", [])
            },
            "code_quality": {
                "linter": analysis["project_state"]["code_quality"].get("linter"),
                "formatter": analysis["project_state"]["code_quality"].get("formatter"),
                "issues_count": analysis["project_state"]["code_quality"].get("issues_count", 0)
            },
            "todo_items": analysis["project_state"]["todo_items"][:5],  # Include only the first 5 for brevity
            "semantic_stats": {
                "analyzed_files": analysis["semantic_analysis"]["analyzed_files_count"],
                "functions": analysis["semantic_analysis"]["entities"]["functions"],
                "classes": analysis["semantic_analysis"]["entities"]["classes"],
                "total_lines": analysis["semantic_analysis"]["metrics"].get("total_lines", 0),
                "avg_func_complexity": analysis["semantic_analysis"]["metrics"].get("average_function_complexity", 0)
            }
        }

# Global semantic context manager instance
semantic_context_manager = SemanticContextManager()
</file>

<file path="angela/context/session.py">
# angela/context/session.py

import json
import time
from typing import Dict, Any, Optional, List, Set
from datetime import datetime, timedelta
from dataclasses import dataclass, field, asdict

from angela.context.preferences import preferences_manager
from angela.utils.logging import get_logger

logger = get_logger(__name__)

@dataclass
class EntityReference:
    """A reference to an entity in the session context."""
    name: str  # Name or identifier of the entity
    type: str  # Type of entity (file, directory, command, result, etc.)
    value: str  # Actual value or path 
    created: datetime = field(default_factory=datetime.now)
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization."""
        return {
            "name": self.name,
            "type": self.type,
            "value": self.value,
            "created": self.created.isoformat()
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'EntityReference':
        """Create from dictionary."""
        return cls(
            name=data["name"],
            type=data["type"],
            value=data["value"],
            created=datetime.fromisoformat(data["created"])
        )


class SessionMemory:
    """Memory for a single conversation session."""
    
    def __init__(self):
        """Initialize session memory."""
        self.entities: Dict[str, EntityReference] = {}
        self.recent_commands: List[str] = []
        self.recent_results: List[str] = []
        self.created = datetime.now()
        self.last_accessed = datetime.now()
    
    def add_entity(self, name: str, entity_type: str, value: str) -> None:
        """
        Add an entity to the session memory.
        
        Args:
            name: The name or identifier of the entity
            entity_type: The type of entity
            value: The value or path of the entity
        """
        self.entities[name] = EntityReference(name, entity_type, value)
        self.last_accessed = datetime.now()
    
    def get_entity(self, name: str) -> Optional[EntityReference]:
        """
        Get an entity from the session memory.
        
        Args:
            name: The name or identifier of the entity
            
        Returns:
            The entity reference, or None if not found
        """
        self.last_accessed = datetime.now()
        return self.entities.get(name)
    
    def add_command(self, command: str) -> None:
        """
        Add a command to the recent commands list.
        
        Args:
            command: The command string
        """
        self.recent_commands.append(command)
        self.last_accessed = datetime.now()
        
        # Keep only the last 10 commands
        if len(self.recent_commands) > 10:
            self.recent_commands.pop(0)
    
    def add_result(self, result: str) -> None:
        """
        Add a result to the recent results list.
        
        Args:
            result: The result string
        """
        self.recent_results.append(result)
        self.last_accessed = datetime.now()
        
        # Keep only the last 5 results
        if len(self.recent_results) > 5:
            self.recent_results.pop(0)
    
    def get_context_dict(self) -> Dict[str, Any]:
        """
        Get the session memory as a dictionary.
        
        Returns:
            A dictionary representation of the session memory
        """
        return {
            "entities": {k: v.to_dict() for k, v in self.entities.items()},
            "recent_commands": self.recent_commands,
            "recent_results": self.recent_results,
            "created": self.created.isoformat(),
            "last_accessed": self.last_accessed.isoformat()
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'SessionMemory':
        """
        Create a session memory from a dictionary.
        
        Args:
            data: The dictionary representation
            
        Returns:
            A new SessionMemory instance
        """
        session = cls()
        session.entities = {
            k: EntityReference.from_dict(v) 
            for k, v in data.get("entities", {}).items()
        }
        session.recent_commands = data.get("recent_commands", [])
        session.recent_results = data.get("recent_results", [])
        session.created = datetime.fromisoformat(data["created"])
        session.last_accessed = datetime.fromisoformat(data["last_accessed"])
        return session


class SessionManager:
    """Manager for conversation session memories."""
    
    def __init__(self):
        """Initialize the session manager."""
        self._current_session = SessionMemory()
        self._logger = logger
    
    def refresh_session(self) -> None:
        """Refresh the current session or create a new one if expired."""
        # Check if session is enabled in preferences
        if not preferences_manager.preferences.context.remember_session_context:
            self._current_session = SessionMemory()
            return
        
        # Check if the session has expired (2 hours of inactivity)
        now = datetime.now()
        session_timeout = timedelta(hours=2)
        
        if now - self._current_session.last_accessed > session_timeout:
            self._logger.debug("Session expired, creating new session")
            self._current_session = SessionMemory()
    
    def add_entity(self, name: str, entity_type: str, value: str) -> None:
        """
        Add an entity to the current session.
        
        Args:
            name: The name or identifier of the entity
            entity_type: The type of entity
            value: The value or path of the entity
        """
        self.refresh_session()
        self._current_session.add_entity(name, entity_type, value)
    
    def get_entity(self, name: str) -> Optional[EntityReference]:
        """
        Get an entity from the current session.
        
        Args:
            name: The name or identifier of the entity
            
        Returns:
            The entity reference, or None if not found
        """
        self.refresh_session()
        return self._current_session.get_entity(name)
    
    def add_command(self, command: str) -> None:
        """
        Add a command to the current session.
        
        Args:
            command: The command string
        """
        self.refresh_session()
        self._current_session.add_command(command)
    
    def add_result(self, result: str) -> None:
        """
        Add a result to the current session.
        
        Args:
            result: The result string
        """
        self.refresh_session()
        self._current_session.add_result(result)
    
    def get_context(self) -> Dict[str, Any]:
        """
        Get the current session context as a dictionary.
        
        Returns:
            A dictionary representation of the current session context
        """
        self.refresh_session()
        return self._current_session.get_context_dict()
    
    def clear_session(self) -> None:
        """Clear the current session."""
        self._current_session = SessionMemory()

# Global session manager instance
session_manager = SessionManager()
</file>

<file path="angela/core/__init__.py">
# angela/core/__init__.py
"""Core components for Angela CLI."""
</file>

<file path="angela/core/events.py">
# angela/core/events.py
from typing import Dict, Any, Callable, List
import asyncio

class EventBus:
    """Central event bus for system-wide communication."""
    
    def __init__(self):
        self._handlers: Dict[str, List[Callable]] = {}
        self._logger = get_logger(__name__)
    
    def subscribe(self, event_type: str, handler: Callable) -> None:
        """Subscribe to an event type."""
        if event_type not in self._handlers:
            self._handlers[event_type] = []
        self._handlers[event_type].append(handler)
        self._logger.debug(f"Handler subscribed to {event_type}")
    
    def unsubscribe(self, event_type: str, handler: Callable) -> None:
        """Unsubscribe from an event type."""
        if event_type in self._handlers and handler in self._handlers[event_type]:
            self._handlers[event_type].remove(handler)
            self._logger.debug(f"Handler unsubscribed from {event_type}")
    
    async def publish(self, event_type: str, data: Dict[str, Any]) -> None:
        """Publish an event to all subscribers."""
        self._logger.debug(f"Publishing event: {event_type}")
        
        if event_type not in self._handlers:
            return
            
        # Call all handlers asynchronously
        tasks = []
        for handler in self._handlers[event_type]:
            if asyncio.iscoroutinefunction(handler):
                tasks.append(asyncio.create_task(handler(event_type, data)))
            else:
                handler(event_type, data)
        
        # Wait for all async handlers to complete
        if tasks:
            await asyncio.gather(*tasks, return_exceptions=True)

# Global event bus instance
event_bus = EventBus()
</file>

<file path="angela/core/registry.py">
# angela/core/registry.py
"""
Service registry for breaking circular dependencies.
"""
from typing import Dict, Any, Type, Optional
import logging

logger = logging.getLogger(__name__)

class ServiceRegistry:
    """
    A simple service locator that allows components to be registered and retrieved
    without direct imports, breaking circular dependencies.
    """
    
    _instance = None
    
    @classmethod
    def get_instance(cls) -> 'ServiceRegistry':
        """Get the singleton instance of the registry."""
        if cls._instance is None:
            cls._instance = ServiceRegistry()
        return cls._instance
    
    def __init__(self):
        """Initialize the registry."""
        self._services: Dict[str, Any] = {}
        logger.debug("Service registry initialized")
    
    def register(self, name: str, service: Any) -> None:
        """
        Register a service with the registry.
        
        Args:
            name: The name to register the service under
            service: The service instance
        """
        self._services[name] = service
        logger.debug(f"Service registered: {name}")
    
    def get(self, name: str) -> Optional[Any]:
        """
        Get a service from the registry.
        
        Args:
            name: The name of the service to retrieve
            
        Returns:
            The service instance or None if not found
        """
        service = self._services.get(name)
        if service is None:
            logger.warning(f"Service not found: {name}")
        return service
    
    def clear(self) -> None:
        """Clear all registered services."""
        self._services.clear()
        logger.debug("Service registry cleared")

# Global instance for convenience
registry = ServiceRegistry.get_instance()
</file>

<file path="angela/execution/__init__.py">
"""
Execution components for Angela CLI.
"""
</file>

<file path="angela/execution/adaptive_engine.py">
# angela/execution/adaptive_engine.py

import asyncio
import os
import sys
import signal
import time
from typing import Dict, Any, Optional, List, Tuple, Union
from pathlib import Path

from rich.console import Console
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TimeElapsedColumn

from angela.safety.classifier import classify_command_risk, analyze_command_impact
from angela.safety.adaptive_confirmation import get_adaptive_confirmation
from angela.execution.engine import execution_engine
from angela.context.history import history_manager
from angela.context.preferences import preferences_manager
from angela.context.session import session_manager
from angela.ai.analyzer import error_analyzer
from angela.utils.logging import get_logger

logger = get_logger(__name__)
console = Console()

class AdaptiveExecutionEngine:
    """
    Context-aware command execution engine.
    
    This engine adapts its behavior based on user history, preferences,
    and command characteristics.
    """
    
    def __init__(self):
        """Initialize the adaptive execution engine."""
        self._logger = logger
    
    async def execute_command(
        self, 
        command: str,
        natural_request: str,
        explanation: Optional[str] = None,
        dry_run: bool = False
    ) -> Dict[str, Any]:
        """
        Execute a command with adaptive behavior based on user context.
        
        Args:
            command: The command to execute
            natural_request: The original natural language request
            explanation: AI explanation of what the command does
            dry_run: Whether to simulate the command without execution
            
        Returns:
            Dictionary with execution results
        """
        self._logger.info(f"Preparing to execute command: {command}")
        
        # Analyze command risk and impact
        risk_level, risk_reason = classify_command_risk(command)
        impact = analyze_command_impact(command)
        
        # Add to session context
        session_manager.add_command(command)
        
        # Generate command preview if needed
        from angela.safety.preview import generate_preview
        preview = await generate_preview(command) if preferences_manager.preferences.ui.show_command_preview else None
        
        # Get adaptive confirmation based on risk level and user history
        confirmed = await get_adaptive_confirmation(
            command=command,
            risk_level=risk_level,
            risk_reason=risk_reason,
            impact=impact,
            preview=preview,
            explanation=explanation,
            natural_request=natural_request,
            dry_run=dry_run
        )
        
        if not confirmed and not dry_run:
            self._logger.info(f"Command execution cancelled by user: {command}")
            return {
                "command": command,
                "success": False,
                "cancelled": True,
                "stdout": "",
                "stderr": "Command execution cancelled by user",
                "return_code": 1,
                "dry_run": dry_run
            }
        
        # Execute the command
        result = await self._execute_with_feedback(command, dry_run)
        
        # Add to history
        history_manager.add_command(
            command=command,
            natural_request=natural_request,
            success=result["success"],
            output=result.get("stdout", ""),
            error=result.get("stderr", ""),
            risk_level=risk_level
        )
        
        # If execution failed, analyze error and suggest fixes
        if not result["success"] and result.get("stderr"):
            result["error_analysis"] = error_analyzer.analyze_error(command, result["stderr"])
            result["fix_suggestions"] = error_analyzer.generate_fix_suggestions(command, result["stderr"])
        
        # Offer to learn from successful executions
        if result["success"] and risk_level > 0:
            from angela.safety.adaptive_confirmation import offer_command_learning
            await offer_command_learning(command)
        
        return result
    
    async def _execute_with_feedback(self, command: str, dry_run: bool) -> Dict[str, Any]:
        """
        Execute a command with rich feedback.
        
        Args:
            command: The command to execute
            dry_run: Whether to simulate the command without execution
            
        Returns:
            Dictionary with execution results
        """
        use_spinners = preferences_manager.preferences.ui.use_spinners
        
        # For dry runs, return the preview directly
        if dry_run:
            # Execute in dry-run mode
            stdout, stderr, return_code = await execution_engine.dry_run_command(command)
            
            return {
                "command": command,
                "success": True,
                "stdout": stdout,
                "stderr": stderr,
                "return_code": return_code,
                "dry_run": True
            }
        
        # Show execution spinner if enabled
        if use_spinners:
            with Progress(
                SpinnerColumn(),
                TextColumn("[bold blue]Executing command...[/bold blue]"),
                TimeElapsedColumn(),
                console=console
            ) as progress:
                task = progress.add_task("Executing", total=None)
                
                # Execute the command
                stdout, stderr, return_code = await execution_engine.execute_command(
                    command,
                    check_safety=False  # We've already done safety checks
                )
                
                # Complete the progress
                progress.update(task, completed=True)
        else:
            # Execute without spinner
            console.print("[bold blue]Executing command...[/bold blue]")
            stdout, stderr, return_code = await execution_engine.execute_command(
                command,
                check_safety=False  # We've already done safety checks
            )
        
        # Store result in session for reference
        if stdout.strip():
            session_manager.add_result(stdout.strip())
        
        return {
            "command": command,
            "success": return_code == 0,
            "stdout": stdout,
            "stderr": stderr,
            "return_code": return_code,
            "dry_run": False
        }

# Global adaptive execution engine instance
adaptive_engine = AdaptiveExecutionEngine()
</file>

<file path="angela/execution/filesystem.py">
"""
File system operations for Angela CLI.

This module provides high-level file and directory operations with safety checks
and proper error handling.
"""
import os
import shutil
import tempfile
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional, List, Tuple, Union, BinaryIO, TextIO

from angela.utils.logging import get_logger
from angela.safety import check_operation_safety

logger = get_logger(__name__)

# Directory for storing backup files for rollback operations
BACKUP_DIR = Path(tempfile.gettempdir()) / "angela-backups"


class FileSystemError(Exception):
    """Exception raised for file system operation errors."""
    pass


# Ensure backup directory exists
def _ensure_backup_dir():
    """Create the backup directory if it doesn't exist."""
    BACKUP_DIR.mkdir(parents=True, exist_ok=True)


async def create_directory(
    path: Union[str, Path], 
    parents: bool = True,
    dry_run: bool = False
) -> bool:
    """
    Create a directory at the specified path.
    
    Args:
        path: The path where the directory should be created.
        parents: Whether to create parent directories if they don't exist.
        dry_run: Whether to simulate the operation without making changes.
        
    Returns:
        True if the operation was successful, False otherwise.
    """
    path_obj = Path(path)
    operation_params = {
        'path': str(path_obj),
        'parents': parents
    }
    
    try:
        # Check if the operation is safe
        if not await check_operation_safety('create_directory', operation_params, dry_run):
            return False
        
        # If this is a dry run, stop here
        if dry_run:
            logger.info(f"DRY RUN: Would create directory at {path_obj}")
            return True
        
        # Create the directory
        if parents:
            path_obj.mkdir(parents=True, exist_ok=True)
        else:
            path_obj.mkdir(exist_ok=False)
        
        logger.info(f"Created directory at {path_obj}")
        return True
    
    except Exception as e:
        logger.exception(f"Error creating directory at {path_obj}: {str(e)}")
        raise FileSystemError(f"Failed to create directory: {str(e)}")


async def delete_directory(
    path: Union[str, Path], 
    recursive: bool = False,
    force: bool = False,
    dry_run: bool = False
) -> bool:
    """
    Delete a directory at the specified path.
    
    Args:
        path: The path of the directory to delete.
        recursive: Whether to recursively delete contents (rmdir vs rm -r).
        force: Whether to ignore errors if the directory doesn't exist.
        dry_run: Whether to simulate the operation without making changes.
        
    Returns:
        True if the operation was successful, False otherwise.
    """
    path_obj = Path(path)
    operation_params = {
        'path': str(path_obj),
        'recursive': recursive,
        'force': force
    }
    
    try:
        # Check if the directory exists
        if not path_obj.exists():
            if force:
                logger.info(f"Directory does not exist, but force=True: {path_obj}")
                return True
            else:
                raise FileSystemError(f"Directory does not exist: {path_obj}")
        
        # Verify it's actually a directory
        if not path_obj.is_dir():
            raise FileSystemError(f"Path is not a directory: {path_obj}")
        
        # Check if the operation is safe
        if not await check_operation_safety('delete_directory', operation_params, dry_run):
            return False
        
        # Create a backup for rollback if needed
        if not dry_run and recursive:
            await _backup_directory(path_obj)
        
        # If this is a dry run, stop here
        if dry_run:
            logger.info(f"DRY RUN: Would delete directory at {path_obj}")
            return True
        
        # Delete the directory
        if recursive:
            shutil.rmtree(path_obj)
            logger.info(f"Recursively deleted directory at {path_obj}")
        else:
            path_obj.rmdir()
            logger.info(f"Deleted directory at {path_obj}")
        
        return True
    
    except Exception as e:
        logger.exception(f"Error deleting directory at {path_obj}: {str(e)}")
        raise FileSystemError(f"Failed to delete directory: {str(e)}")


async def create_file(
    path: Union[str, Path], 
    content: Optional[str] = None,
    dry_run: bool = False
) -> bool:
    """
    Create a file at the specified path with optional content.
    
    Args:
        path: The path where the file should be created.
        content: Optional content to write to the file (if None, like touch).
        dry_run: Whether to simulate the operation without making changes.
        
    Returns:
        True if the operation was successful, False otherwise.
    """
    path_obj = Path(path)
    operation_params = {
        'path': str(path_obj),
        'content': content is not None
    }
    
    try:
        # Check if the operation is safe
        if not await check_operation_safety('create_file', operation_params, dry_run):
            return False
        
        # If this is a dry run, stop here
        if dry_run:
            if content:
                logger.info(f"DRY RUN: Would create file with content at {path_obj}")
            else:
                logger.info(f"DRY RUN: Would touch file at {path_obj}")
            return True
        
        # Make sure parent directory exists
        if not path_obj.parent.exists():
            await create_directory(path_obj.parent, dry_run=False)
        
        # Handle backup if the file already exists
        if path_obj.exists():
            await _backup_file(path_obj)
        
        # Create/write the file
        if content is not None:
            with open(path_obj, 'w') as f:
                f.write(content)
            logger.info(f"Created file with content at {path_obj}")
        else:
            path_obj.touch()
            logger.info(f"Touched file at {path_obj}")
        
        return True
    
    except Exception as e:
        logger.exception(f"Error creating file at {path_obj}: {str(e)}")
        raise FileSystemError(f"Failed to create file: {str(e)}")


async def read_file(
    path: Union[str, Path], 
    binary: bool = False
) -> Union[str, bytes]:
    """
    Read the content of a file.
    
    Args:
        path: The path of the file to read.
        binary: Whether to read the file in binary mode.
        
    Returns:
        The content of the file as a string or bytes.
    """
    path_obj = Path(path)
    operation_params = {
        'path': str(path_obj),
        'binary': binary
    }
    
    try:
        # Check if the file exists
        if not path_obj.exists():
            raise FileSystemError(f"File does not exist: {path_obj}")
        
        # Verify it's actually a file
        if not path_obj.is_file():
            raise FileSystemError(f"Path is not a file: {path_obj}")
        
        # Check if the operation is safe
        if not await check_operation_safety('read_file', operation_params, False):
            raise FileSystemError("Operation not permitted due to safety constraints")
        
        # Read the file
        if binary:
            with open(path_obj, 'rb') as f:
                content = f.read()
        else:
            with open(path_obj, 'r', errors='replace') as f:
                content = f.read()
        
        logger.info(f"Read file at {path_obj}")
        return content
    
    except Exception as e:
        logger.exception(f"Error reading file at {path_obj}: {str(e)}")
        raise FileSystemError(f"Failed to read file: {str(e)}")


async def write_file(
    path: Union[str, Path], 
    content: Union[str, bytes],
    append: bool = False,
    dry_run: bool = False
) -> bool:
    """
    Write content to a file.
    
    Args:
        path: The path of the file to write.
        content: The content to write to the file.
        append: Whether to append to the file instead of overwriting.
        dry_run: Whether to simulate the operation without making changes.
        
    Returns:
        True if the operation was successful, False otherwise.
    """
    path_obj = Path(path)
    is_binary = isinstance(content, bytes)
    operation_params = {
        'path': str(path_obj),
        'append': append,
        'binary': is_binary
    }
    
    try:
        # Check if the operation is safe
        if not await check_operation_safety('write_file', operation_params, dry_run):
            return False
        
        # If this is a dry run, stop here
        if dry_run:
            mode = "append to" if append else "write to"
            logger.info(f"DRY RUN: Would {mode} file at {path_obj}")
            return True
        
        # Make sure parent directory exists
        if not path_obj.parent.exists():
            await create_directory(path_obj.parent, dry_run=False)
        
        # Handle backup if the file already exists
        if path_obj.exists():
            await _backup_file(path_obj)
        
        # Write the file
        mode = 'ab' if append and is_binary else 'wb' if is_binary else 'a' if append else 'w'
        with open(path_obj, mode) as f:
            f.write(content)
        
        action = "Appended to" if append else "Wrote to"
        logger.info(f"{action} file at {path_obj}")
        return True
    
    except Exception as e:
        logger.exception(f"Error writing to file at {path_obj}: {str(e)}")
        raise FileSystemError(f"Failed to write file: {str(e)}")


async def delete_file(
    path: Union[str, Path], 
    force: bool = False,
    dry_run: bool = False
) -> bool:
    """
    Delete a file at the specified path.
    
    Args:
        path: The path of the file to delete.
        force: Whether to ignore errors if the file doesn't exist.
        dry_run: Whether to simulate the operation without making changes.
        
    Returns:
        True if the operation was successful, False otherwise.
    """
    path_obj = Path(path)
    operation_params = {
        'path': str(path_obj),
        'force': force
    }
    
    try:
        # Check if the file exists
        if not path_obj.exists():
            if force:
                logger.info(f"File does not exist, but force=True: {path_obj}")
                return True
            else:
                raise FileSystemError(f"File does not exist: {path_obj}")
        
        # Verify it's actually a file
        if not path_obj.is_file():
            raise FileSystemError(f"Path is not a file: {path_obj}")
        
        # Check if the operation is safe
        if not await check_operation_safety('delete_file', operation_params, dry_run):
            return False
        
        # Create a backup for rollback if needed
        if not dry_run:
            await _backup_file(path_obj)
        
        # If this is a dry run, stop here
        if dry_run:
            logger.info(f"DRY RUN: Would delete file at {path_obj}")
            return True
        
        # Delete the file
        path_obj.unlink()
        logger.info(f"Deleted file at {path_obj}")
        
        return True
    
    except Exception as e:
        logger.exception(f"Error deleting file at {path_obj}: {str(e)}")
        raise FileSystemError(f"Failed to delete file: {str(e)}")


async def copy_file(
    source: Union[str, Path], 
    destination: Union[str, Path],
    overwrite: bool = False,
    dry_run: bool = False
) -> bool:
    """
    Copy a file from source to destination.
    
    Args:
        source: The path of the file to copy.
        destination: The destination path.
        overwrite: Whether to overwrite the destination if it exists.
        dry_run: Whether to simulate the operation without making changes.
        
    Returns:
        True if the operation was successful, False otherwise.
    """
    source_obj = Path(source)
    dest_obj = Path(destination)
    operation_params = {
        'source': str(source_obj),
        'destination': str(dest_obj),
        'overwrite': overwrite
    }
    
    try:
        # Check if the source file exists
        if not source_obj.exists():
            raise FileSystemError(f"Source file does not exist: {source_obj}")
        
        # Verify source is actually a file
        if not source_obj.is_file():
            raise FileSystemError(f"Source path is not a file: {source_obj}")
        
        # Check if the destination exists and handle overwrite
        if dest_obj.exists():
            if not overwrite:
                raise FileSystemError(f"Destination already exists: {dest_obj}")
            
            # Create a backup of the destination file
            if not dry_run:
                await _backup_file(dest_obj)
        
        # Check if the operation is safe
        if not await check_operation_safety('copy_file', operation_params, dry_run):
            return False
        
        # If this is a dry run, stop here
        if dry_run:
            logger.info(f"DRY RUN: Would copy {source_obj} to {dest_obj}")
            return True
        
        # Make sure parent directory exists
        if not dest_obj.parent.exists():
            await create_directory(dest_obj.parent, dry_run=False)
        
        # Copy the file
        shutil.copy2(source_obj, dest_obj)
        logger.info(f"Copied {source_obj} to {dest_obj}")
        
        return True
    
    except Exception as e:
        logger.exception(f"Error copying {source_obj} to {dest_obj}: {str(e)}")
        raise FileSystemError(f"Failed to copy file: {str(e)}")


async def move_file(
    source: Union[str, Path], 
    destination: Union[str, Path],
    overwrite: bool = False,
    dry_run: bool = False
) -> bool:
    """
    Move a file from source to destination.
    
    Args:
        source: The path of the file to move.
        destination: The destination path.
        overwrite: Whether to overwrite the destination if it exists.
        dry_run: Whether to simulate the operation without making changes.
        
    Returns:
        True if the operation was successful, False otherwise.
    """
    source_obj = Path(source)
    dest_obj = Path(destination)
    operation_params = {
        'source': str(source_obj),
        'destination': str(dest_obj),
        'overwrite': overwrite
    }
    
    try:
        # Check if the source file exists
        if not source_obj.exists():
            raise FileSystemError(f"Source file does not exist: {source_obj}")
        
        # Verify source is actually a file
        if not source_obj.is_file():
            raise FileSystemError(f"Source path is not a file: {source_obj}")
        
        # Check if the destination exists and handle overwrite
        if dest_obj.exists():
            if not overwrite:
                raise FileSystemError(f"Destination already exists: {dest_obj}")
            
            # Create a backup of the destination file
            if not dry_run:
                await _backup_file(dest_obj)
        
        # Check if the operation is safe
        if not await check_operation_safety('move_file', operation_params, dry_run):
            return False
        
        # Create a backup of the source file
        if not dry_run:
            await _backup_file(source_obj)
        
        # If this is a dry run, stop here
        if dry_run:
            logger.info(f"DRY RUN: Would move {source_obj} to {dest_obj}")
            return True
        
        # Make sure parent directory exists
        if not dest_obj.parent.exists():
            await create_directory(dest_obj.parent, dry_run=False)
        
        # Move the file
        shutil.move(str(source_obj), str(dest_obj))
        logger.info(f"Moved {source_obj} to {dest_obj}")
        
        return True
    
    except Exception as e:
        logger.exception(f"Error moving {source_obj} to {dest_obj}: {str(e)}")
        raise FileSystemError(f"Failed to move file: {str(e)}")


# --- Helper functions for backups and rollbacks ---

async def _backup_file(path: Path) -> Path:
    """
    Create a backup of a file for potential rollback.
    
    Args:
        path: The path of the file to back up.
        
    Returns:
        The path of the backup file.
    """
    try:
        _ensure_backup_dir()
        
        # Create a unique backup filename
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_name = f"{path.name}.{timestamp}.bak"
        backup_path = BACKUP_DIR / backup_name
        
        # Copy the file to the backup location
        shutil.copy2(path, backup_path)
        logger.debug(f"Created backup of {path} at {backup_path}")
        
        return backup_path
    
    except Exception as e:
        logger.warning(f"Failed to create backup of {path}: {str(e)}")
        # Not raising an exception here as this is a non-critical operation
        return None


async def _backup_directory(path: Path) -> Path:
    """
    Create a backup of a directory for potential rollback.
    
    Args:
        path: The path of the directory to back up.
        
    Returns:
        The path of the backup directory.
    """
    try:
        _ensure_backup_dir()
        
        # Create a unique backup directory name
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_name = f"{path.name}.{timestamp}.bak"
        backup_path = BACKUP_DIR / backup_name
        
        # Copy the directory to the backup location
        shutil.copytree(path, backup_path)
        logger.debug(f"Created backup of directory {path} at {backup_path}")
        
        return backup_path
    
    except Exception as e:
        logger.warning(f"Failed to create backup of directory {path}: {str(e)}")
        # Not raising an exception here as this is a non-critical operation
        return None
</file>

<file path="angela/execution/hooks.py">
"""
Execution hooks for file operations and command execution.

This module provides hooks for tracking file activities during execution
and enriching context in real-time.
"""
import os
import re
from pathlib import Path
from typing import Dict, Any, Optional, List, Tuple, Union

from angela.context.file_activity import file_activity_tracker, ActivityType
from angela.utils.logging import get_logger

logger = get_logger(__name__)

class ExecutionHooks:
    """
    Hooks for file operations and command execution.
    
    Provides hooks to track file activities during execution:
    1. Pre-execution hooks (before a command/operation is executed)
    2. Post-execution hooks (after a command/operation is executed)
    """
    
    def __init__(self):
        """Initialize the execution hooks."""
        self._logger = logger
    
    async def pre_execute_command(
        self, 
        command: str,
        context: Dict[str, Any]
    ) -> None:
        """
        Pre-execution hook for commands.
        
        Args:
            command: The command to be executed
            context: Context information
        """
        self._logger.debug(f"Pre-execute hook for command: {command}")
        
        # Extract potential file operations from the command
        await self._analyze_command_for_files(command, context)
    
    async def post_execute_command(
        self, 
        command: str,
        result: Dict[str, Any],
        context: Dict[str, Any]
    ) -> None:
        """
        Post-execution hook for commands.
        
        Args:
            command: The executed command
            result: The execution result
            context: Context information
        """
        self._logger.debug(f"Post-execute hook for command: {command}")
        
        # Check if the command succeeded
        if not result.get("success", False):
            return
        
        # Analyze command output for file information
        await self._analyze_command_output(command, result.get("stdout", ""), context)
        
        # Track file activities based on the command type
        base_command = command.split()[0] if command else ""
        
        # Handle common file operation commands
        if base_command in ["cat", "less", "more", "head", "tail"]:
            await self._track_file_viewing(command, context)
        elif base_command in ["touch", "echo", "tee"]:
            await self._track_file_creation(command, context)
        elif base_command in ["rm", "rmdir"]:
            await self._track_file_deletion(command, context)
        elif base_command in ["cp", "mv", "rsync"]:
            await self._track_file_copy_move(command, context)
        elif base_command in ["sed", "awk", "perl", "nano", "vim", "emacs"]:
            await self._track_file_modification(command, context)
    
    async def pre_execute_file_operation(
        self, 
        operation_type: str,
        parameters: Dict[str, Any],
        context: Dict[str, Any]
    ) -> None:
        """
        Pre-execution hook for file operations.
        
        Args:
            operation_type: The type of file operation
            parameters: The operation parameters
            context: Context information
        """
        self._logger.debug(f"Pre-execute hook for file operation: {operation_type}")
        
        # Nothing specific to do before file operations for now
        pass
    
    async def post_execute_file_operation(
        self, 
        operation_type: str,
        parameters: Dict[str, Any],
        result: Dict[str, Any],
        context: Dict[str, Any]
    ) -> None:
        """
        Post-execution hook for file operations.
        
        Args:
            operation_type: The type of file operation
            parameters: The operation parameters
            result: The operation result
            context: Context information
        """
        self._logger.debug(f"Post-execute hook for file operation: {operation_type}")
        
        # Check if the operation succeeded
        if not result.get("success", False):
            return
        
        # Track file activity based on operation type
        if operation_type == "create_file":
            file_path = parameters.get("path")
            if file_path:
                file_activity_tracker.track_file_creation(
                    Path(file_path),
                    None,  # No command
                    {"operation": operation_type}
                )
        elif operation_type == "write_file":
            file_path = parameters.get("path")
            if file_path:
                file_activity_tracker.track_file_modification(
                    Path(file_path),
                    None,  # No command
                    {"operation": operation_type, "append": parameters.get("append", False)}
                )
        elif operation_type == "delete_file":
            file_path = parameters.get("path")
            if file_path:
                file_activity_tracker.track_file_deletion(
                    Path(file_path),
                    None,  # No command
                    {"operation": operation_type}
                )
        elif operation_type == "read_file":
            file_path = parameters.get("path")
            if file_path:
                file_activity_tracker.track_file_viewing(
                    Path(file_path),
                    None,  # No command
                    {"operation": operation_type}
                )
        elif operation_type == "copy_file":
            source = parameters.get("source")
            destination = parameters.get("destination")
            if source and destination:
                # Track the source as read
                file_activity_tracker.track_file_viewing(
                    Path(source),
                    None,  # No command
                    {"operation": operation_type}
                )
                # Track the destination as created/modified
                file_activity_tracker.track_file_creation(
                    Path(destination),
                    None,  # No command
                    {"operation": operation_type, "source": source}
                )
        elif operation_type == "move_file":
            source = parameters.get("source")
            destination = parameters.get("destination")
            if source and destination:
                # Track the source as deleted
                file_activity_tracker.track_file_deletion(
                    Path(source),
                    None,  # No command
                    {"operation": operation_type}
                )
                # Track the destination as created
                file_activity_tracker.track_file_creation(
                    Path(destination),
                    None,  # No command
                    {"operation": operation_type, "source": source}
                )
    
    async def _analyze_command_for_files(
        self, 
        command: str,
        context: Dict[str, Any]
    ) -> None:
        """
        Analyze a command for potential file operations.
        
        Args:
            command: The command to analyze
            context: Context information
        """
        # Split command into tokens
        tokens = command.split()
        
        if not tokens:
            return
        
        base_command = tokens[0]
        
        # Check for file paths in tokens
        paths = []
        
        for token in tokens[1:]:
            # Skip options
            if token.startswith('-'):
                continue
            
            # Skip redirection operators
            if token in ['>', '<', '>>', '2>', '&>']:
                continue
            
            # Check if token looks like a path
            if '/' in token or '.' in token:
                # Resolve relative to CWD
                path = Path(context.get("cwd", ".")) / token
                if path.exists():
                    paths.append(path)
        
        # Track potential file accesses
        for path in paths:
            if path.is_file():
                file_activity_tracker.track_file_viewing(
                    path,
                    command,
                    {"pre_execution": True}
                )
    
    async def _analyze_command_output(
        self, 
        command: str,
        output: str,
        context: Dict[str, Any]
    ) -> None:
        """
        Analyze command output for file information.
        
        Args:
            command: The executed command
            output: The command output
            context: Context information
        """
        # Check for file paths in output
        paths = set()
        
        # Look for patterns that might be file paths
        path_patterns = [
            r'[\'"]([/\w\-\.]+\.\w+)[\'"]',  # Quoted paths with extension
            r'\b(/[/\w\-\.]+\.\w+)\b',       # Absolute paths with extension
            r'\b(\./[/\w\-\.]+\.\w+)\b',     # Relative paths with ./ prefix
        ]
        
        for pattern in path_patterns:
            for match in re.finditer(pattern, output):
                potential_path = match.group(1)
                
                # Resolve relative to CWD
                if not potential_path.startswith('/'):
                    potential_path = os.path.join(context.get("cwd", "."), potential_path)
                
                path = Path(potential_path)
                if path.exists() and path.is_file():
                    paths.add(path)
        
        # Track found files
        for path in paths:
            if path.is_file():
                file_activity_tracker.track_file_viewing(
                    path,
                    command,
                    {"from_output": True}
                )
    
    async def _track_file_viewing(
        self, 
        command: str,
        context: Dict[str, Any]
    ) -> None:
        """
        Track file viewing for commands like cat, less, more, etc.
        
        Args:
            command: The executed command
            context: Context information
        """
        tokens = command.split()
        
        if len(tokens) < 2:
            return
        
        # Find potential file paths
        for token in tokens[1:]:
            # Skip options
            if token.startswith('-'):
                continue
            
            # Skip if it looks like a pipe or redirection
            if token in ['|', '>', '<', '>>', '2>', '&>']:
                break
            
            # Resolve path
            path = Path(token)
            if not path.is_absolute():
                path = Path(context.get("cwd", ".")) / token
            
            if path.exists() and path.is_file():
                file_activity_tracker.track_file_viewing(
                    path,
                    command,
                    {}
                )
    
    async def _track_file_creation(
        self, 
        command: str,
        context: Dict[str, Any]
    ) -> None:
        """
        Track file creation for commands like touch, etc.
        
        Args:
            command: The executed command
            context: Context information
        """
        tokens = command.split()
        
        if len(tokens) < 2:
            return
        
        # Handle touch command
        if tokens[0] == 'touch':
            for token in tokens[1:]:
                # Skip options
                if token.startswith('-'):
                    continue
                
                # Resolve path
                path = Path(token)
                if not path.is_absolute():
                    path = Path(context.get("cwd", ".")) / token
                
                if path.exists() and path.is_file():
                    file_activity_tracker.track_file_creation(
                        path,
                        command,
                        {}
                    )
        
        # Handle echo/redirection
        elif tokens[0] == 'echo':
            # Look for redirection
            redirect_idx = -1
            for i, token in enumerate(tokens):
                if token in ['>', '>>']:
                    redirect_idx = i
                    break
            
            if redirect_idx > 0 and redirect_idx < len(tokens) - 1:
                file_path = tokens[redirect_idx + 1]
                
                # Resolve path
                path = Path(file_path)
                if not path.is_absolute():
                    path = Path(context.get("cwd", ".")) / file_path
                
                operation = ActivityType.CREATED
                if tokens[redirect_idx] == '>>':
                    operation = ActivityType.MODIFIED
                
                if path.exists() and path.is_file():
                    if operation == ActivityType.CREATED:
                        file_activity_tracker.track_file_creation(
                            path,
                            command,
                            {"redirect": tokens[redirect_idx]}
                        )
                    else:
                        file_activity_tracker.track_file_modification(
                            path,
                            command,
                            {"redirect": tokens[redirect_idx]}
                        )
    
    async def _track_file_deletion(
        self, 
        command: str,
        context: Dict[str, Any]
    ) -> None:
        """
        Track file deletion for commands like rm, etc.
        
        Args:
            command: The executed command
            context: Context information
        """
        tokens = command.split()
        
        if len(tokens) < 2:
            return
        
        # Skip arguments until we find a non-option
        for token in tokens[1:]:
            # Skip options
            if token.startswith('-'):
                continue
            
            # This is probably a path
            path = Path(token)
            if not path.is_absolute():
                path = Path(context.get("cwd", ".")) / token
            
            # We can't check if it exists since it was deleted
            file_activity_tracker.track_file_deletion(
                path,
                command,
                {}
            )
    
    async def _track_file_copy_move(
        self, 
        command: str,
        context: Dict[str, Any]
    ) -> None:
        """
        Track file copy/move for commands like cp, mv, etc.
        
        Args:
            command: The executed command
            context: Context information
        """
        tokens = command.split()
        
        if len(tokens) < 3:
            return
        
        base_command = tokens[0]
        
        # Find the source and destination
        source_tokens = []
        dest_token = tokens[-1]  # Last token is destination
        
        # Collect all tokens that aren't options as source tokens
        for token in tokens[1:-1]:
            if not token.startswith('-'):
                source_tokens.append(token)
        
        # Resolve destination path
        dest_path = Path(dest_token)
        if not dest_path.is_absolute():
            dest_path = Path(context.get("cwd", ".")) / dest_token
        
        # Track each source
        for source_token in source_tokens:
            source_path = Path(source_token)
            if not source_path.is_absolute():
                source_path = Path(context.get("cwd", ".")) / source_token
            
            if base_command == 'cp':
                # For cp, source is viewed and destination is created
                file_activity_tracker.track_file_viewing(
                    source_path,
                    command,
                    {"operation": "copy", "destination": str(dest_path)}
                )
                
                # If destination is a directory, the file goes inside it
                if dest_path.is_dir():
                    actual_dest = dest_path / source_path.name
                else:
                    actual_dest = dest_path
                
                file_activity_tracker.track_file_creation(
                    actual_dest,
                    command,
                    {"operation": "copy", "source": str(source_path)}
                )
            elif base_command == 'mv':
                # For mv, source is deleted and destination is created
                file_activity_tracker.track_file_deletion(
                    source_path,
                    command,
                    {"operation": "move", "destination": str(dest_path)}
                )
                
                # If destination is a directory, the file goes inside it
                if dest_path.is_dir():
                    actual_dest = dest_path / source_path.name
                else:
                    actual_dest = dest_path
                
                file_activity_tracker.track_file_creation(
                    actual_dest,
                    command,
                    {"operation": "move", "source": str(source_path)}
                )
    
    async def _track_file_modification(
        self, 
        command: str,
        context: Dict[str, Any]
    ) -> None:
        """
        Track file modification for commands like sed, etc.
        
        Args:
            command: The executed command
            context: Context information
        """
        tokens = command.split()
        
        if len(tokens) < 2:
            return
        
        base_command = tokens[0]
        
        # Handle sed command
        if base_command == 'sed':
            # Find the file token (usually the last one)
            file_token = None
            for i in range(len(tokens) - 1, 0, -1):
                if not tokens[i].startswith('-') and not tokens[i].startswith("'") and not tokens[i].startswith('"'):
                    file_token = tokens[i]
                    break
            
            if file_token:
                path = Path(file_token)
                if not path.is_absolute():
                    path = Path(context.get("cwd", ".")) / file_token
                
                if path.exists() and path.is_file():
                    file_activity_tracker.track_file_modification(
                        path,
                        command,
                        {}
                    )

# Global execution hooks instance
execution_hooks = ExecutionHooks()
</file>

<file path="angela/generation/__init__.py">
"""
Generation components for Angela CLI.
"""
</file>

<file path="angela/generation/architecture.py">
# angela/generation/architecture.py
"""
Architectural analysis and improvements for Angela CLI.

This module provides capabilities for analyzing project architecture,
detecting anti-patterns, and suggesting improvements.
"""
import os
import asyncio
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple, Union
import json
import re

from angela.ai.client import gemini_client, GeminiRequest
from angela.utils.logging import get_logger

logger = get_logger(__name__)

class ArchitecturalPattern:
    """Base class for architectural patterns."""
    
    def __init__(self, name: str, description: str):
        """
        Initialize the architectural pattern.
        
        Args:
            name: Pattern name
            description: Pattern description
        """
        self.name = name
        self.description = description
    
    async def detect(self, project_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """
        Detect if the pattern is present in the project.
        
        Args:
            project_analysis: Analysis of the project
            
        Returns:
            Dictionary with detection results
        """
        raise NotImplementedError("Subclasses must implement detect")
    
    def get_recommendations(self, detection_result: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Get recommendations based on detection results.
        
        Args:
            detection_result: Results from the detect method
            
        Returns:
            List of recommendation dictionaries
        """
        raise NotImplementedError("Subclasses must implement get_recommendations")

class AntiPattern:
    """Base class for architectural anti-patterns."""
    
    def __init__(self, name: str, description: str, severity: str):
        """
        Initialize the anti-pattern.
        
        Args:
            name: Anti-pattern name
            description: Anti-pattern description
            severity: Severity level (low, medium, high)
        """
        self.name = name
        self.description = description
        self.severity = severity
    
    async def detect(self, project_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """
        Detect if the anti-pattern is present in the project.
        
        Args:
            project_analysis: Analysis of the project
            
        Returns:
            Dictionary with detection results
        """
        raise NotImplementedError("Subclasses must implement detect")
    
    def get_recommendations(self, detection_result: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Get recommendations to fix the anti-pattern.
        
        Args:
            detection_result: Results from the detect method
            
        Returns:
            List of recommendation dictionaries
        """
        raise NotImplementedError("Subclasses must implement get_recommendations")

class MvcPattern(ArchitecturalPattern):
    """Model-View-Controller pattern detector."""
    
    def __init__(self):
        """Initialize the MVC pattern detector."""
        super().__init__(
            name="Model-View-Controller",
            description="Separates application logic into three components: Model (data), View (presentation), and Controller (logic)"
        )
    
    async def detect(self, project_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """
        Detect if MVC pattern is used in the project.
        
        Args:
            project_analysis: Analysis of the project
            
        Returns:
            Dictionary with detection results
        """
        logger.debug("Detecting MVC pattern")
        
        # Default result
        result = {
            "pattern": self.name,
            "present": False,
            "confidence": 0.0,
            "components": {
                "models": [],
                "views": [],
                "controllers": []
            }
        }
        
        # Check file structure for MVC pattern
        models = []
        views = []
        controllers = []
        
        for file_info in project_analysis.get("files", []):
            file_path = file_info.get("path", "").lower()
            file_content = file_info.get("content", "")
            
            # Check for models
            if "model" in file_path or "/models/" in file_path:
                models.append(file_path)
            elif file_content and re.search(r'class\s+\w*Model\b', file_content):
                models.append(file_path)
            
            # Check for views
            if "view" in file_path or "/views/" in file_path:
                views.append(file_path)
            elif file_path.endswith((".html", ".jsx", ".tsx", ".vue")) or "template" in file_path:
                views.append(file_path)
            elif file_content and re.search(r'class\s+\w*View\b', file_content):
                views.append(file_path)
            
            # Check for controllers
            if "controller" in file_path or "/controllers/" in file_path:
                controllers.append(file_path)
            elif file_content and re.search(r'class\s+\w*Controller\b', file_content):
                controllers.append(file_path)
        
        # Update result with components found
        result["components"]["models"] = models
        result["components"]["views"] = views
        result["components"]["controllers"] = controllers
        
        # Calculate confidence
        if models and views and controllers:
            result["present"] = True
            result["confidence"] = 0.9  # High confidence if all three components found
        elif (models and views) or (models and controllers) or (views and controllers):
            result["present"] = True
            result["confidence"] = 0.6  # Medium confidence if two components found
        elif models or views or controllers:
            result["present"] = False
            result["confidence"] = 0.3  # Low confidence if only one component found
        
        return result
    
    def get_recommendations(self, detection_result: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Get recommendations for improving MVC pattern usage.
        
        Args:
            detection_result: Results from the detect method
            
        Returns:
            List of recommendation dictionaries
        """
        recommendations = []
        
        if detection_result["present"]:
            # MVC pattern is present, check if all components are balanced
            models = detection_result["components"]["models"]
            views = detection_result["components"]["views"]
            controllers = detection_result["components"]["controllers"]
            
            if len(models) < len(controllers) / 2:
                recommendations.append({
                    "title": "Insufficient Model Separation",
                    "description": "There are significantly fewer Model files than Controllers, which may indicate business logic leaking into Controllers.",
                    "action": "Consider extracting data models from Controllers into separate Model classes.",
                    "priority": "medium"
                })
            
            if not controllers and models and views:
                recommendations.append({
                    "title": "Missing Controller Layer",
                    "description": "Models and Views are present, but no clear Controller layer was detected.",
                    "action": "Implement Controllers to handle the interaction between Models and Views.",
                    "priority": "high"
                })
        else:
            # MVC pattern is not present
            if detection_result["confidence"] > 0.0:
                # Some components found, but not all
                recommendations.append({
                    "title": "Incomplete MVC Implementation",
                    "description": "Some MVC components are present, but the pattern is not fully implemented.",
                    "action": "Consider fully adopting the MVC pattern by adding the missing components.",
                    "priority": "medium"
                })
            else:
                # No components found
                recommendations.append({
                    "title": "Consider MVC Pattern",
                    "description": "The project doesn't appear to use the MVC pattern, which can help with code organization and maintainability.",
                    "action": "Consider refactoring to separate concerns into Model, View, and Controller components.",
                    "priority": "low"
                })
        
        return recommendations

class SingleResponsibilityAntiPattern(AntiPattern):
    """Detects violations of the Single Responsibility Principle."""
    
    def __init__(self):
        """Initialize the single responsibility anti-pattern detector."""
        super().__init__(
            name="Single Responsibility Violation",
            description="Classes or modules that have more than one reason to change",
            severity="medium"
        )
    
    async def detect(self, project_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """
        Detect violations of the Single Responsibility Principle.
        
        Args:
            project_analysis: Analysis of the project
            
        Returns:
            Dictionary with detection results
        """
        logger.debug("Detecting Single Responsibility violations")
        
        # Default result
        result = {
            "anti_pattern": self.name,
            "detected": False,
            "instances": [],
            "severity": self.severity
        }
        
        # Check for large classes with many methods
        for file_info in project_analysis.get("files", []):
            if not file_info.get("content"):
                continue
            
            file_path = file_info.get("path", "")
            content = file_info.get("content", "")
            
            # Skip non-source files
            if file_info.get("type") != "source_code":
                continue
            
            language = file_info.get("language", "").lower()
            
            if language in ["python", "java", "javascript", "typescript"]:
                # Check for classes with too many methods
                classes = self._extract_classes(content, language)
                
                for class_info in classes:
                    # Check number of methods
                    if len(class_info["methods"]) > 10:  # Arbitrary threshold
                        # Check for different categories of methods
                        categories = self._categorize_methods(class_info["methods"], language)
                        
                        if len(categories) >= 3:  # If methods fall into 3+ categories, likely has multiple responsibilities
                            result["instances"].append({
                                "file": file_path,
                                "class": class_info["name"],
                                "method_count": len(class_info["methods"]),
                                "categories": categories,
                                "confidence": min(0.5 + (len(categories) - 3) * 0.1, 0.9)  # Higher confidence with more categories
                            })
        
        if result["instances"]:
            result["detected"] = True
        
        return result
    
    def _extract_classes(self, content: str, language: str) -> List[Dict[str, Any]]:
        """
        Extract classes and their methods from code.
        
        Args:
            content: Source code content
            language: Programming language
            
        Returns:
            List of dictionaries with class info
        """
        classes = []
        
        if language == "python":
            # Extract Python classes
            class_pattern = r'class\s+(\w+)(?:\(.*?\))?:'
            method_pattern = r'\s+def\s+(\w+)\s*\('
            
            class_matches = re.finditer(class_pattern, content)
            
            for class_match in class_matches:
                class_name = class_match.group(1)
                class_start = class_match.end()
                
                # Find the end of the class (indentation level)
                class_content = ""
                for line in content[class_start:].splitlines():
                    if line.strip() and not line.startswith(" ") and not line.startswith("\t"):
                        break
                    class_content += line + "\n"
                
                # Extract methods
                methods = []
                for method_match in re.finditer(method_pattern, class_content):
                    method_name = method_match.group(1)
                    if method_name != "__init__":  # Skip constructor
                        methods.append(method_name)
                
                classes.append({
                    "name": class_name,
                    "methods": methods
                })
        
        elif language in ["java", "javascript", "typescript"]:
            # Extract classes (simplified)
            class_pattern = r'class\s+(\w+)(?:\s+extends\s+\w+)?(?:\s+implements\s+[\w,\s]+)?\s*{'
            method_pattern = r'(?:public|private|protected)?\s+(?:static\s+)?(?:\w+\s+)?(\w+)\s*\([^)]*\)\s*{(?:[^{}]|{[^{}]*})*}'
            
            class_matches = re.finditer(class_pattern, content)
            
            for class_match in class_matches:
                class_name = class_match.group(1)
                class_start = class_match.start()
                
                # Find the class block by counting braces
                brace_count = 0
                class_end = class_start
                in_class = False
                
                for i, c in enumerate(content[class_start:]):
                    if c == '{':
                        if not in_class:
                            in_class = True
                        brace_count += 1
                    elif c == '}':
                        brace_count -= 1
                        if in_class and brace_count == 0:
                            class_end = class_start + i + 1
                            break
                
                class_content = content[class_start:class_end]
                
                # Extract methods
                methods = []
                for method_match in re.finditer(method_pattern, class_content):
                    method_name = method_match.group(1)
                    if method_name != "constructor" and not method_name.startswith("get") and not method_name.startswith("set"):
                        methods.append(method_name)
                
                classes.append({
                    "name": class_name,
                    "methods": methods
                })
        
        return classes
    
    def _categorize_methods(self, methods: List[str], language: str) -> Dict[str, List[str]]:
        """
        Categorize methods into different responsibilities.
        
        Args:
            methods: List of method names
            language: Programming language
            
        Returns:
            Dictionary mapping categories to method names
        """
        categories = {}
        
        # Common categories and their keywords
        categories_keywords = {
            "data_access": ["save", "load", "read", "write", "fetch", "store", "retrieve", "query", "find", "get", "set", "select", "insert", "update", "delete", "persist", "repository", "dao"],
            "business_logic": ["calculate", "compute", "process", "validate", "check", "verify", "evaluate", "analyze", "generate", "create", "build", "make", "service"],
            "presentation": ["display", "show", "render", "view", "draw", "paint", "print", "format", "transform", "convert", "ui", "gui", "interface"],
            "networking": ["connect", "disconnect", "send", "receive", "post", "get", "put", "delete", "request", "response", "url", "uri", "http", "api", "rest", "soap", "websocket"],
            "file_io": ["file", "stream", "open", "close", "read", "write", "input", "output", "io", "path", "directory", "folder"],
            "concurrency": ["thread", "async", "await", "parallel", "concurrent", "lock", "mutex", "semaphore", "synchronize", "task", "job", "worker", "pool"],
            "utility": ["util", "helper", "common", "shared", "factory", "builder", "converter", "mapper", "utils"]
        }
        
        # Categorize methods based on name
        for method in methods:
            method_lower = method.lower()
            categorized = False
            
            for category, keywords in categories_keywords.items():
                for keyword in keywords:
                    if keyword in method_lower:
                        if category not in categories:
                            categories[category] = []
                        categories[category].append(method)
                        categorized = True
                        break
                
                if categorized:
                    break
            
            # If method doesn't match any category, put it in "other"
            if not categorized:
                if "other" not in categories:
                    categories["other"] = []
                categories["other"].append(method)
        
        return categories
    
    def get_recommendations(self, detection_result: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Get recommendations for fixing Single Responsibility Principle violations.
        
        Args:
            detection_result: Results from the detect method
            
        Returns:
            List of recommendation dictionaries
        """
        recommendations = []
        
        if detection_result["detected"]:
            for instance in detection_result["instances"]:
                # Create a recommendation for each instance
                categories_str = ", ".join(instance["categories"].keys())
                
                recommendations.append({
                    "title": f"Refactor Class: {instance['class']}",
                    "description": f"This class has multiple responsibilities: {categories_str}",
                    "action": f"Consider splitting '{instance['class']}' into multiple classes, each with a single responsibility.",
                    "priority": "medium" if instance["confidence"] > 0.7 else "low"
                })
        
        return recommendations

class GodObjectAntiPattern(AntiPattern):
    """Detects God Objects - classes that know or do too much."""
    
    def __init__(self):
        """Initialize the God Object anti-pattern detector."""
        super().__init__(
            name="God Object",
            description="Classes that know or do too much, often with excessive size and responsibilities",
            severity="high"
        )
    
    async def detect(self, project_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """
        Detect God Objects in the project.
        
        Args:
            project_analysis: Analysis of the project
            
        Returns:
            Dictionary with detection results
        """
        logger.debug("Detecting God Objects")
        
        # Default result
        result = {
            "anti_pattern": self.name,
            "detected": False,
            "instances": [],
            "severity": self.severity
        }
        
        # Define thresholds for various metrics
        thresholds = {
            "lines": 500,  # Lines of code
            "methods": 20,  # Number of methods
            "fields": 15,   # Number of fields/properties
            "imports": 15,  # Number of imports
            "dependencies": 10  # Number of dependencies on other classes
        }
        
        # Check each file for potential God Objects
        for file_info in project_analysis.get("files", []):
            if not file_info.get("content"):
                continue
            
            file_path = file_info.get("path", "")
            content = file_info.get("content", "")
            
            # Skip non-source files
            if file_info.get("type") != "source_code":
                continue
            
            language = file_info.get("language", "").lower()
            
            if language in ["python", "java", "javascript", "typescript"]:
                # Extract classes
                classes = self._extract_classes_with_metrics(content, language)
                
                for class_info in classes:
                    # Check if any metric exceeds thresholds
                    violations = {}
                    for metric, value in class_info["metrics"].items():
                        if metric in thresholds and value > thresholds[metric]:
                            violations[metric] = value
                    
                    if violations:
                        # Calculate violation severity
                        violation_count = len(violations)
                        violation_ratio = sum(violations[m] / thresholds[m] for m in violations) / len(violations)
                        confidence = min(0.5 + (violation_count * 0.1) + (violation_ratio * 0.2), 0.95)
                        
                        result["instances"].append({
                            "file": file_path,
                            "class": class_info["name"],
                            "violations": violations,
                            "metrics": class_info["metrics"],
                            "confidence": confidence
                        })
        
        if result["instances"]:
            result["detected"] = True
        
        return result
    
    def _extract_classes_with_metrics(self, content: str, language: str) -> List[Dict[str, Any]]:
        """
        Extract classes and calculate metrics.
        
        Args:
            content: Source code content
            language: Programming language
            
        Returns:
            List of dictionaries with class info and metrics
        """
        classes = []
        
        if language == "python":
            # Extract Python classes
            class_pattern = r'class\s+(\w+)(?:\(.*?\))?:'
            method_pattern = r'\s+def\s+(\w+)\s*\('
            field_pattern = r'\s+self\.(\w+)\s*='
            import_pattern = r'(?:import|from)\s+[\w.]+'
            
            # Count imports
            imports = len(re.findall(import_pattern, content))
            
            class_matches = re.finditer(class_pattern, content)
            
            for class_match in class_matches:
                class_name = class_match.group(1)
                class_start = class_match.end()
                
                # Find the end of the class (indentation level)
                class_content = ""
                class_lines = 0
                for line in content[class_start:].splitlines():
                    if line.strip() and not line.startswith(" ") and not line.startswith("\t"):
                        break
                    class_content += line + "\n"
                    class_lines += 1
                
                # Extract methods
                methods = re.findall(method_pattern, class_content)
                
                # Extract fields
                fields = re.findall(field_pattern, class_content)
                
                # Calculate other dependencies (simplified)
                dependencies = set()
                for line in class_content.splitlines():
                    # Look for other class instantiations
                    instance_matches = re.findall(r'=\s*(\w+)\(', line)
                    for instance in instance_matches:
                        if instance != class_name and instance[0].isupper():  # Potential class
                            dependencies.add(instance)
                
                classes.append({
                    "name": class_name,
                    "content": class_content,
                    "metrics": {
                        "lines": class_lines,
                        "methods": len(methods),
                        "fields": len(fields),
                        "imports": imports,
                        "dependencies": len(dependencies)
                    }
                })
        
        elif language in ["java", "javascript", "typescript"]:
            # Extract classes (simplified)
            class_pattern = r'class\s+(\w+)(?:\s+extends\s+\w+)?(?:\s+implements\s+[\w,\s]+)?\s*{'
            method_pattern = r'(?:public|private|protected)?\s+(?:static\s+)?(?:\w+\s+)?(\w+)\s*\(['
            field_pattern = r'(?:public|private|protected)?\s+(?:static\s+)?(?:final\s+)?[\w<>[\],\s]+\s+(\w+)\s*[;=]'
            import_pattern = r'import\s+[\w.]+'
            
            # Count imports
            imports = len(re.findall(import_pattern, content))
            
            class_matches = re.finditer(class_pattern, content)
            
            for class_match in class_matches:
                class_name = class_match.group(1)
                class_start = class_match.start()
                
                # Find the class block by counting braces
                brace_count = 0
                class_end = class_start
                in_class = False
                
                for i, c in enumerate(content[class_start:]):
                    if c == '{':
                        if not in_class:
                            in_class = True
                        brace_count += 1
                    elif c == '}':
                        brace_count -= 1
                        if in_class and brace_count == 0:
                            class_end = class_start + i + 1
                            break
                
                class_content = content[class_start:class_end]
                class_lines = class_content.count('\n')
                
                # Extract methods
                methods = re.findall(method_pattern, class_content)
                
                # Extract fields
                fields = re.findall(field_pattern, class_content)
                
                # Calculate other dependencies (simplified)
                dependencies = set()
                for line in class_content.splitlines():
                    # Look for other class instantiations
                    instance_matches = re.findall(r'new\s+(\w+)\(', line)
                    for instance in instance_matches:
                        if instance != class_name:
                            dependencies.add(instance)
                
                classes.append({
                    "name": class_name,
                    "content": class_content,
                    "metrics": {
                        "lines": class_lines,
                        "methods": len(methods),
                        "fields": len(fields),
                        "imports": imports,
                        "dependencies": len(dependencies)
                    }
                })
        
        return classes
    
    def get_recommendations(self, detection_result: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Get recommendations for fixing God Objects.
        
        Args:
            detection_result: Results from the detect method
            
        Returns:
            List of recommendation dictionaries
        """
        recommendations = []
        
        if detection_result["detected"]:
            for instance in detection_result["instances"]:
                # Create specific recommendations based on violations
                violations_msg = []
                
                if "lines" in instance["violations"]:
                    violations_msg.append(f"excessive size ({instance['violations']['lines']} lines)")
                if "methods" in instance["violations"]:
                    violations_msg.append(f"too many methods ({instance['violations']['methods']})")
                if "fields" in instance["violations"]:
                    violations_msg.append(f"too many fields ({instance['violations']['fields']})")
                if "dependencies" in instance["violations"]:
                    violations_msg.append(f"too many dependencies ({instance['violations']['dependencies']})")
                
                violations_str = ", ".join(violations_msg)
                
                # Main recommendation
                recommendations.append({
                    "title": f"Refactor God Object: {instance['class']}",
                    "description": f"This class exhibits God Object symptoms: {violations_str}",
                    "action": f"Break '{instance['class']}' into smaller, more focused classes following the Single Responsibility Principle.",
                    "priority": "high" if instance["confidence"] > 0.8 else "medium"
                })
                
                # Add specific tactical recommendations
                if "methods" in instance["violations"] and instance["violations"]["methods"] > 25:
                    recommendations.append({
                        "title": f"Extract Classes from {instance['class']}",
                        "description": f"This class has an excessive number of methods ({instance['violations']['methods']}).",
                        "action": "Group related methods and extract them into new classes with clear responsibilities.",
                        "priority": "high"
                    })
                
                if "dependencies" in instance["violations"] and instance["violations"]["dependencies"] > 12:
                    recommendations.append({
                        "title": f"Reduce Dependencies in {instance['class']}",
                        "description": f"This class depends on too many other classes ({instance['violations']['dependencies']}).",
                        "action": "Use dependency injection or introduce service locators to reduce direct dependencies.",
                        "priority": "medium"
                    })
        
        return recommendations

class ArchitecturalAnalyzer:
    """
    Analyzer for project architecture, detecting patterns and anti-patterns.
    """
    
    def __init__(self):
        """Initialize the architectural analyzer."""
        self._logger = logger
        
        # Register patterns and anti-patterns
        self._patterns = [
            MvcPattern(),
            # Add more patterns here
        ]
        
        self._anti_patterns = [
            SingleResponsibilityAntiPattern(),
            GodObjectAntiPattern(),
            # Add more anti-patterns here
        ]
    
    async def analyze_architecture(
        self, 
        project_path: Union[str, Path],
        context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Analyze project architecture.
        
        Args:
            project_path: Path to the project
            context: Additional context information
            
        Returns:
            Dictionary with analysis results
        """
        self._logger.info(f"Analyzing architecture of project at {project_path}")
        
        # Analyze project structure
        project_analysis = await self._analyze_project_structure(project_path, context)
        
        # Detect patterns
        patterns_results = await self._detect_patterns(project_analysis)
        
        # Detect anti-patterns
        anti_patterns_results = await self._detect_anti_patterns(project_analysis)
        
        # Generate recommendations
        recommendations = await self._generate_recommendations(patterns_results, anti_patterns_results)
        
        return {
            "project_path": str(project_path),
            "patterns": patterns_results,
            "anti_patterns": anti_patterns_results,
            "recommendations": recommendations,
            "project_analysis": project_analysis
        }
    
    async def _analyze_project_structure(
        self, 
        project_path: Union[str, Path],
        context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Analyze project structure.
        
        Args:
            project_path: Path to the project
            context: Additional context information
            
        Returns:
            Dictionary with project analysis
        """
        self._logger.info(f"Analyzing project structure at {project_path}")
        
        # Convert to Path object
        project_path = Path(project_path)
        
        # Use context if available
        if context and "enhanced_project" in context:
            return {
                "project_type": context["enhanced_project"].get("type", "unknown"),
                "frameworks": context["enhanced_project"].get("frameworks", {}),
                "dependencies": context["enhanced_project"].get("dependencies", {}),
                "files": context.get("files", []),
                "path": str(project_path)
            }
        
        # Perform a simplified project analysis
        project_analysis = {
            "project_type": "unknown",
            "frameworks": {},
            "dependencies": {},
            "files": [],
            "path": str(project_path)
        }
        
        # Determine project type
        if (project_path / "requirements.txt").exists() or (project_path / "setup.py").exists() or (project_path / "pyproject.toml").exists():
            project_analysis["project_type"] = "python"
        elif (project_path / "package.json").exists():
            project_analysis["project_type"] = "node"
        elif (project_path / "pom.xml").exists() or (project_path / "build.gradle").exists():
            project_analysis["project_type"] = "java"
        
        # Collect file information
        for root, _, filenames in os.walk(project_path):
            for filename in filenames:
                # Skip common directories to ignore
                if any(ignored in root for ignored in [".git", "__pycache__", "node_modules", "venv", ".idea", ".vscode"]):
                    continue
                
                file_path = Path(root) / filename
                rel_path = file_path.relative_to(project_path)
                
                # Get basic file info
                file_info = {
                    "path": str(rel_path),
                    "full_path": str(file_path),
                    "type": None,
                    "language": None,
                    "content": None
                }
                
                # Try to determine file type and language
                try:
                    from angela.context.file_detector import detect_file_type
                    type_info = detect_file_type(file_path)
                    file_info["type"] = type_info.get("type")
                    file_info["language"] = type_info.get("language")
                    
                    # Read content for source code files (limit to prevent memory issues)
                    if type_info.get("type") == "source_code" and file_path.stat().st_size < 100000:
                        with open(file_path, 'r', encoding='utf-8', errors='replace') as f:
                            file_info["content"] = f.read()
                except Exception as e:
                    self._logger.debug(f"Error analyzing file {file_path}: {str(e)}")
                
                project_analysis["files"].append(file_info)
        
        return project_analysis
    
    async def _detect_patterns(self, project_analysis: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Detect architectural patterns in the project.
        
        Args:
            project_analysis: Analysis of the project
            
        Returns:
            List of pattern detection results
        """
        self._logger.info("Detecting architectural patterns")
        
        results = []
        
        # Run all pattern detectors
        for pattern in self._patterns:
            try:
                pattern_result = await pattern.detect(project_analysis)
                results.append(pattern_result)
                self._logger.debug(f"Pattern '{pattern.name}' detected: {pattern_result['present']}")
            except Exception as e:
                self._logger.error(f"Error detecting pattern '{pattern.name}': {str(e)}")
        
        return results
    
    async def _detect_anti_patterns(self, project_analysis: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Detect architectural anti-patterns in the project.
        
        Args:
            project_analysis: Analysis of the project
            
        Returns:
            List of anti-pattern detection results
        """
        self._logger.info("Detecting architectural anti-patterns")
        
        results = []
        
        # Run all anti-pattern detectors
        for anti_pattern in self._anti_patterns:
            try:
                anti_pattern_result = await anti_pattern.detect(project_analysis)
                results.append(anti_pattern_result)
                self._logger.debug(f"Anti-pattern '{anti_pattern.name}' detected: {anti_pattern_result['detected']}")
            except Exception as e:
                self._logger.error(f"Error detecting anti-pattern '{anti_pattern.name}': {str(e)}")
        
        return results
    
    async def _generate_recommendations(
        self, 
        patterns_results: List[Dict[str, Any]],
        anti_patterns_results: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        Generate recommendations based on detected patterns and anti-patterns.
        
        Args:
            patterns_results: Pattern detection results
            anti_patterns_results: Anti-pattern detection results
            
        Returns:
            List of recommendations
        """
        self._logger.info("Generating architecture recommendations")
        
        recommendations = []
        
        # Generate recommendations from patterns
        for pattern_result in patterns_results:
            pattern_name = pattern_result["pattern"]
            pattern = next((p for p in self._patterns if p.name == pattern_name), None)
            
            if pattern:
                pattern_recommendations = pattern.get_recommendations(pattern_result)
                recommendations.extend(pattern_recommendations)
        
        # Generate recommendations from anti-patterns
        for anti_pattern_result in anti_patterns_results:
            anti_pattern_name = anti_pattern_result["anti_pattern"]
            anti_pattern = next((ap for ap in self._anti_patterns if ap.name == anti_pattern_name), None)
            
            if anti_pattern and anti_pattern_result["detected"]:
                anti_pattern_recommendations = anti_pattern.get_recommendations(anti_pattern_result)
                recommendations.extend(anti_pattern_recommendations)
        
        # Generate general recommendations using AI for more complex analysis
        if patterns_results or anti_patterns_results:
            ai_recommendations = await self._generate_ai_recommendations(patterns_results, anti_patterns_results)
            recommendations.extend(ai_recommendations)
        
        return recommendations
    
    async def _generate_ai_recommendations(
        self, 
        patterns_results: List[Dict[str, Any]],
        anti_patterns_results: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        Generate additional recommendations using AI.
        
        Args:
            patterns_results: Pattern detection results
            anti_patterns_results: Anti-pattern detection results
            
        Returns:
            List of AI-generated recommendations
        """
        self._logger.debug("Generating AI recommendations")
        
        # Build prompt for AI
        prompt = """
You are an expert software architect tasked with providing architectural recommendations based on detected patterns and anti-patterns in a project.

Here are the detected architectural patterns:
"""
        
        # Add pattern information
        for pattern_result in patterns_results:
            prompt += f"\n- Pattern: {pattern_result['pattern']}"
            prompt += f"\n  Present: {pattern_result['present']}"
            prompt += f"\n  Confidence: {pattern_result['confidence']:.2f}"
            
            if "components" in pattern_result:
                prompt += "\n  Components:"
                for component_type, components in pattern_result["components"].items():
                    prompt += f"\n    - {component_type}: {len(components)} files"
        
        prompt += "\n\nHere are the detected architectural anti-patterns:"
        
        # Add anti-pattern information
        for anti_pattern_result in anti_patterns_results:
            prompt += f"\n- Anti-pattern: {anti_pattern_result['anti_pattern']}"
            prompt += f"\n  Detected: {anti_pattern_result['detected']}"
            prompt += f"\n  Severity: {anti_pattern_result['severity']}"
            
            if anti_pattern_result["detected"] and "instances" in anti_pattern_result:
                prompt += f"\n  Instances: {len(anti_pattern_result['instances'])}"
                
                # Add details for the first few instances
                for i, instance in enumerate(anti_pattern_result["instances"][:3]):
                    prompt += f"\n    {i+1}. Class: {instance.get('class', 'Unknown')}"
                    if "violations" in instance:
                        violations = ", ".join(f"{v}: {val}" for v, val in instance["violations"].items())
                        prompt += f"\n       Violations: {violations}"
        
        prompt += """

Based on the above information, provide 3-5 high-level architectural recommendations that would improve the project's design.
For each recommendation, include:
1. A title (concise description)
2. A detailed explanation
3. Concrete action steps
4. Priority (high, medium, low)

Format your response as a JSON array of recommendation objects, like this:
[
  {
    "title": "Clear recommendation title",
    "description": "Detailed explanation of the issue",
    "action": "Specific action steps to implement the recommendation",
    "priority": "high|medium|low"
  },
  ...
]
"""
        
        # Call AI service
        api_request = GeminiRequest(
            prompt=prompt,
            max_tokens=2000,
            temperature=0.3
        )
        
        try:
            response = await gemini_client.generate_text(api_request)
            
            # Parse the response
            recommendations = []
            
            # Extract JSON
            json_match = re.search(r'```(?:json)?\s*(.*?)\s*```', response.text, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
            else:
                # Try to find JSON without code blocks
                json_match = re.search(r'(\[.*\])', response.text, re.DOTALL)
                if json_match:
                    json_str = json_match.group(1)
                else:
                    # Assume the entire response is JSON
                    json_str = response.text
            
            try:
                recommendations = json.loads(json_str)
            except json.JSONDecodeError:
                self._logger.error("Failed to parse AI recommendations as JSON")
                recommendations = []
            
            # Add source information
            for rec in recommendations:
                rec["source"] = "ai"
            
            return recommendations
            
        except Exception as e:
            self._logger.error(f"Error generating AI recommendations: {str(e)}")
            return []

async def analyze_project_architecture(
    project_path: Union[str, Path],
    context: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    Analyze project architecture.
    
    Args:
        project_path: Path to the project
        context: Additional context information
        
    Returns:
        Dictionary with analysis results
    """
    analyzer = ArchitecturalAnalyzer()
    return await analyzer.analyze_architecture(project_path, context)

# Global architectural analyzer instance
architectural_analyzer = ArchitecturalAnalyzer()
</file>

<file path="angela/generation/planner.py">
# angela/generation/planner.py
"""
Project structure planning for Angela CLI.

This module is responsible for planning the structure of a new project,
identifying necessary files, their roles, and interdependencies.
"""
import os
import asyncio
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple, Union
import json
import re

from pydantic import BaseModel, Field

from angela.ai.client import gemini_client, GeminiRequest
from angela.context import context_manager
from angela.utils.logging import get_logger
from angela.generation.engine import CodeProject, CodeFile

logger = get_logger(__name__)

class ArchitectureComponent(BaseModel):
    """Model for a component in the project architecture."""
    name: str = Field(..., description="Name of the component")
    description: str = Field(..., description="Description of the component")
    responsibilities: List[str] = Field(..., description="Responsibilities of the component")
    files: List[str] = Field(default_factory=list, description="Files implementing this component")
    dependencies: List[str] = Field(default_factory=list, description="Components this depends on")

class ProjectArchitecture(BaseModel):
    """Model for a project's architecture."""
    components: List[ArchitectureComponent] = Field(..., description="Components in the architecture")
    layers: List[str] = Field(default_factory=list, description="Architectural layers")
    patterns: List[str] = Field(default_factory=list, description="Design patterns used")
    data_flow: List[str] = Field(default_factory=list, description="Data flow descriptions")

class ProjectPlanner:
    """
    Project planner for designing and organizing code projects.
    """
    
    def __init__(self):
        """Initialize the project planner."""
        self._logger = logger
    
    async def create_project_architecture(
        self, 
        description: str,
        project_type: str,
        context: Optional[Dict[str, Any]] = None
    ) -> ProjectArchitecture:
        """
        Create a high-level architecture for a project.
        
        Args:
            description: Natural language description of the project
            project_type: Type of project to generate
            context: Additional context information
            
        Returns:
            ProjectArchitecture object
        """
        self._logger.info(f"Creating project architecture for: {description}")
        
        # Get context if not provided
        if context is None:
            context = context_manager.get_context_dict()
        
        # Build prompt for architecture planning
        prompt = self._build_architecture_prompt(description, project_type, context)
        
        # Call AI service to generate architecture
        api_request = GeminiRequest(
            prompt=prompt,
            max_tokens=4000,
            temperature=0.2
        )
        
        self._logger.debug("Sending architecture planning request to AI service")
        response = await gemini_client.generate_text(api_request)
        
        # Parse the response to extract the architecture
        architecture = await self._parse_architecture(response.text)
        
        return architecture
    
    async def refine_project_plan(
        self, 
        project: CodeProject,
        architecture: ProjectArchitecture,
        context: Optional[Dict[str, Any]] = None
    ) -> CodeProject:
        """
        Refine a project plan based on architecture.
        
        Args:
            project: Initial CodeProject
            architecture: ProjectArchitecture to use for refinement
            context: Additional context information
            
        Returns:
            Refined CodeProject
        """
        self._logger.info(f"Refining project plan for: {project.name}")
        
        # Get context if not provided
        if context is None:
            context = context_manager.get_context_dict()
        
        # Build prompt for plan refinement
        prompt = self._build_plan_refinement_prompt(project, architecture, context)
        
        # Call AI service to refine plan
        api_request = GeminiRequest(
            prompt=prompt,
            max_tokens=4000,
            temperature=0.2
        )
        
        self._logger.debug("Sending plan refinement request to AI service")
        response = await gemini_client.generate_text(api_request)
        
        # Parse the response to extract the refined plan
        refined_plan = await self._parse_refined_plan(response.text, project)
        
        return refined_plan
    
    def _build_architecture_prompt(
        self, 
        description: str,
        project_type: str,
        context: Dict[str, Any]
    ) -> str:
        """
        Build a prompt for architecture planning.
        
        Args:
            description: Natural language description of the project
            project_type: Type of project to generate
            context: Additional context information
            
        Returns:
            Prompt string for the AI service
        """
        prompt = f"""
As an experienced software architect, design a high-level architecture for a {project_type} project based on this description:

"{description}"

Analyze the requirements and create a comprehensive architecture that is:
- Modular and maintainable
- Follows SOLID principles
- Anticipates future changes/extensions
- Accounts for scalability and performance

Your response should be a JSON object with this structure:

```json
{{
  "components": [
    {{
      "name": "component_name",
      "description": "what this component does",
      "responsibilities": ["resp1", "resp2", ...],
      "files": ["expected/path/to/file.ext", ...],
      "dependencies": ["other_component_names", ...]
    }},
    ...
  ],
  "layers": ["Layer1", "Layer2", ...],
  "patterns": ["Design patterns used in the architecture"],
  "data_flow": ["Descriptions of data flow between components"]
}}
Focus on a clean separation of concerns, appropriate design patterns for {project_type}, and efficient data flow.
"""
    return prompt

async def _parse_architecture(self, response: str) -> ProjectArchitecture:
    """
    Parse the AI response to extract the architecture.
    
    Args:
        response: AI response text
        
    Returns:
        ProjectArchitecture object
    """
    try:
        # Look for JSON block in the response
        json_match = re.search(r'```(?:json)?\s*(.*?)\s*```', response, re.DOTALL)
        if json_match:
            json_str = json_match.group(1)
        else:
            # Try to find JSON without code blocks
            json_match = re.search(r'({.*})', response, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
            else:
                # Assume the entire response is JSON
                json_str = response
        
        # Parse the JSON
        arch_data = json.loads(json_str)
        
        # Create ArchitectureComponent objects
        components = []
        for comp_data in arch_data.get("components", []):
            components.append(ArchitectureComponent(
                name=comp_data["name"],
                description=comp_data["description"],
                responsibilities=comp_data.get("responsibilities", []),
                files=comp_data.get("files", []),
                dependencies=comp_data.get("dependencies", [])
            ))
        
        # Create ProjectArchitecture object
        architecture = ProjectArchitecture(
            components=components,
            layers=arch_data.get("layers", []),
            patterns=arch_data.get("patterns", []),
            data_flow=arch_data.get("data_flow", [])
        )
        
        return architecture
        
    except Exception as e:
        self._logger.exception(f"Error parsing architecture: {str(e)}")
        
        # Create a minimal fallback architecture
        fallback_component = ArchitectureComponent(
            name="Core",
            description="Core application functionality",
            responsibilities=["Main application logic"],
            files=[],
            dependencies=[]
        )
        
        return ProjectArchitecture(
            components=[fallback_component],
            layers=["Presentation", "Business Logic", "Data Access"],
            patterns=["MVC"],
            data_flow=["User input -> Core processing -> Storage"]
        )

def _build_plan_refinement_prompt(
    self, 
    project: CodeProject,
    architecture: ProjectArchitecture,
    context: Dict[str, Any]
) -> str:
    """
    Build a prompt for plan refinement.
    
    Args:
        project: Initial CodeProject
        architecture: ProjectArchitecture to use for refinement
        context: Additional context information
        
    Returns:
        Prompt string for the AI service
    """
    # Extract architecture info
    arch_json = {}
    arch_json["components"] = [comp.dict() for comp in architecture.components]
    arch_json["layers"] = architecture.layers
    arch_json["patterns"] = architecture.patterns
    arch_json["data_flow"] = architecture.data_flow
    
    # Extract project info
    project_json = {}
    project_json["name"] = project.name
    project_json["description"] = project.description
    project_json["project_type"] = project.project_type
    project_json["dependencies"] = project.dependencies
    project_json["files"] = [
        {
            "path": file.path,
            "purpose": file.purpose,
            "dependencies": file.dependencies
        }
        for file in project.files
    ]
    
    prompt = f"""
You are refining a project plan based on a high-level architecture.
Here is the current project plan:
json{json.dumps(project_json, indent=2)}
And here is the architecture design:
json{json.dumps(arch_json, indent=2)}
Your task is to refine the project plan to better align with the architecture.
This may involve:

1. Adding missing files that would be needed for components in the architecture
2. Updating existing file purposes to match component responsibilities
3. Adjusting file dependencies to match component dependencies
4. Ensuring the project structure follows the architectural layers

Return a refined project plan in this JSON format:
json{{
  "name": "project_name",
  "description": "project description",
  "project_type": "{project.project_type}",
  "dependencies": {{
    "runtime": ["dep1", "dep2"],
    "development": ["dev_dep1", "dev_dep2"]
  }},
  "files": [
    {{
      "path": "path/to/file.ext",
      "purpose": "file purpose",
      "dependencies": ["other/file/paths"],
      "component": "associated_component_name"
    }}
  ],
  "structure_explanation": "explanation of the refined structure"
}}
Make sure the refined plan implements all components and follows all architectural patterns in the design.
"""
    return prompt

async def _parse_refined_plan(
    self, 
    response: str, 
    original_project: CodeProject
) -> CodeProject:
    """
    Parse the AI response to extract the refined plan.
    
    Args:
        response: AI response text
        original_project: The original project to refine
        
    Returns:
        Refined CodeProject
    """
    try:
        # Look for JSON block in the response
        json_match = re.search(r'```(?:json)?\s*(.*?)\s*```', response, re.DOTALL)
        if json_match:
            json_str = json_match.group(1)
        else:
            # Try to find JSON without code blocks
            json_match = re.search(r'({.*})', response, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
            else:
                # Assume the entire response is JSON
                json_str = response
        
        # Parse the JSON
        plan_data = json.loads(json_str)
        
        # Create CodeFile objects
        files = []
        for file_data in plan_data.get("files", []):
            # Check if this file existed in the original project
            original_file = next((f for f in original_project.files if f.path == file_data["path"]), None)
            
            files.append(CodeFile(
                path=file_data["path"],
                content=original_file.content if original_file else "",
                purpose=file_data["purpose"],
                dependencies=file_data.get("dependencies", []),
                language=original_file.language if original_file else None
            ))
        
        # Create CodeProject object
        project = CodeProject(
            name=plan_data.get("name", original_project.name),
            description=plan_data.get("description", original_project.description),
            root_dir=original_project.root_dir,
            files=files,
            dependencies=plan_data.get("dependencies", original_project.dependencies),
            project_type=original_project.project_type,
            structure_explanation=plan_data.get("structure_explanation", original_project.structure_explanation)
        )
        
        return project
        
    except Exception as e:
        self._logger.exception(f"Error parsing refined plan: {str(e)}")
        
        # Return the original project if parsing failed
        return original_project
        
        
project_planner = ProjectPlanner()
</file>

<file path="angela/generation/validators.py">
# angela/generation/validators.py
"""
Code validation for Angela CLI.

This module provides validators for different programming languages
to ensure generated code is syntactically correct and follows best practices.
"""
import os
import subprocess
import tempfile
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple, Union
import re

from angela.utils.logging import get_logger

logger = get_logger(__name__)

# Map file extensions to language validators
LANGUAGE_VALIDATORS = {
    ".py": "validate_python",
    ".js": "validate_javascript",
    ".jsx": "validate_javascript",
    ".ts": "validate_typescript",
    ".tsx": "validate_typescript",
    ".java": "validate_java",
    ".go": "validate_go",
    ".rb": "validate_ruby",
    ".rs": "validate_rust",
    ".html": "validate_html",
    ".css": "validate_css",
    ".php": "validate_php"
}

def validate_code(content: str, file_path: str) -> Tuple[bool, str]:
    """
    Validate code based on file extension.
    
    Args:
        content: Code content to validate
        file_path: Path of the file (used to determine language)
        
    Returns:
        Tuple of (is_valid, error_message)
    """
    logger.info(f"Validating code for: {file_path}")
    
    _, extension = os.path.splitext(file_path.lower())
    
    # Get the validator function for this extension
    validator_name = LANGUAGE_VALIDATORS.get(extension)
    
    if validator_name and validator_name in globals():
        validator_func = globals()[validator_name]
        return validator_func(content, file_path)
    
    # If no specific validator, do basic checks
    return validate_generic(content, file_path)

def validate_generic(content: str, file_path: str) -> Tuple[bool, str]:
    """
    Generic validator for any code file.
    
    Args:
        content: Code content to validate
        file_path: Path of the file
        
    Returns:
        Tuple of (is_valid, error_message)
    """
    # Check for basic issues like unmatched brackets
    bracket_pairs = [('(', ')'), ('[', ']'), ('{', '}')]
    
    for opening, closing in bracket_pairs:
        if content.count(opening) != content.count(closing):
            return False, f"Unmatched brackets: {opening}{closing}"
    
    return True, ""

def validate_python(content: str, file_path: str) -> Tuple[bool, str]:
    """
    Validate Python code.
    
    Args:
        content: Python code to validate
        file_path: Path of the file
        
    Returns:
        Tuple of (is_valid, error_message)
    """
    # Create a temporary file
    with tempfile.NamedTemporaryFile(suffix='.py', delete=False) as tmp:
        tmp_path = tmp.name
        tmp.write(content.encode('utf-8'))
    
    try:
        # Use Python's compile function to check syntax
        result = subprocess.run(
            ['python', '-m', 'py_compile', tmp_path],
            capture_output=True,
            text=True
        )
        
        if result.returncode != 0:
            # Parse the error message
            error_msg = result.stderr
            
            # Simplify the error message
            error_lines = error_msg.splitlines()
            for line in error_lines:
                if "File " in line and ", line " in line:
                    continue
                if line.strip():
                    error_msg = line.strip()
                    break
            
            return False, f"Python syntax error: {error_msg}"
        
        # Additional checks for common Python issues
        issues = []
        
        # Check for undefined or unused imports
        import_lines = []
        imported_modules = []
        
        for line in content.splitlines():
            if line.strip().startswith(('import ', 'from ')):
                import_lines.append(line)
                
                if line.strip().startswith('import '):
                    modules = line.strip()[7:].split(',')
                    for module in modules:
                        if ' as ' in module:
                            module = module.split(' as ')[1]
                        imported_modules.append(module.strip())
                elif line.strip().startswith('from '):
                    parts = line.strip().split(' import ')
                    if len(parts) == 2:
                        modules = parts[1].split(',')
                        for module in modules:
                            if ' as ' in module:
                                module = module.split(' as ')[1]
                            imported_modules.append(module.strip())
        
        # Check if imports are used
        for module in imported_modules:
            if module not in content.replace(f"import {module}", "").replace(f"from {module}", ""):
                issues.append(f"Potentially unused import: {module}")
        
        # If we found issues but not syntax errors, still consider it valid
        # but report the issues
        if issues:
            return True, f"Code is valid but has issues: {'; '.join(issues)}"
        
        return True, ""
    
    except Exception as e:
        logger.error(f"Error validating Python code: {str(e)}")
        return False, f"Error validating Python code: {str(e)}"
    
    finally:
        # Clean up the temporary file
        try:
            os.unlink(tmp_path)
        except Exception:
            pass

def validate_javascript(content: str, file_path: str) -> Tuple[bool, str]:
    """
    Validate JavaScript code.
    
    Args:
        content: JavaScript code to validate
        file_path: Path of the file
        
    Returns:
        Tuple of (is_valid, error_message)
    """
    # Check if node is available
    try:
        subprocess.run(['node', '--version'], capture_output=True, check=True)
    except (subprocess.SubprocessError, FileNotFoundError):
        logger.warning("Node.js not found, falling back to basic JS validation")
        return validate_javascript_basic(content, file_path)
    
    # Create a temporary file
    with tempfile.NamedTemporaryFile(suffix='.js', delete=False) as tmp:
        tmp_path = tmp.name
        tmp.write(content.encode('utf-8'))
    
    try:
        # Use Node.js to check syntax
        result = subprocess.run(
            ['node', '--check', tmp_path],
            capture_output=True,
            text=True
        )
        
        if result.returncode != 0:
            # Parse the error message
            error_msg = result.stderr
            return False, f"JavaScript syntax error: {error_msg.strip()}"
        
        return True, ""
    
    except Exception as e:
        logger.error(f"Error validating JavaScript code: {str(e)}")
        return False, f"Error validating JavaScript code: {str(e)}"
    
    finally:
        # Clean up the temporary file
        try:
            os.unlink(tmp_path)
        except Exception:
            pass

def validate_javascript_basic(content: str, file_path: str) -> Tuple[bool, str]:
    """
    Basic validation for JavaScript code without using Node.js.
    
    Args:
        content: JavaScript code to validate
        file_path: Path of the file
        
    Returns:
        Tuple of (is_valid, error_message)
    """
    # Check for basic syntax issues
    
    # Check for unmatched brackets
    bracket_pairs = [('(', ')'), ('[', ']'), ('{', '}')]
    
    for opening, closing in bracket_pairs:
        if content.count(opening) != content.count(closing):
            return False, f"Unmatched brackets: {opening}{closing}"
    
    # Check for missing semicolons (simplified)
    lines = content.splitlines()
    for i, line in enumerate(lines):
        line = line.strip()
        if line and not line.endswith(';') and not line.endswith('{') and not line.endswith('}') and \
           not line.endswith(':') and not line.startswith('//') and not line.startswith('/*') and \
           not line.endswith('*/') and not line.startswith('import ') and not line.startswith('export '):
            # This is a simplistic check and might have false positives
            logger.debug(f"Line {i+1} might be missing a semicolon: {line}")
    
    # Check for common React/JSX issues if it seems to be a React file
    if ".jsx" in file_path or "React" in content or "react" in content:
        # Check if JSX elements are closed
        jsx_tags = re.findall(r'<([a-zA-Z0-9]+)(?:\s+[^>]*)?>', content)
        for tag in jsx_tags:
            if tag[0].isupper() and f"</{tag}>" not in content and "/>" not in content:
                return False, f"Unclosed JSX element: <{tag}>"
    
    return True, ""

def validate_typescript(content: str, file_path: str) -> Tuple[bool, str]:
    """
    Validate TypeScript code.
    
    Args:
        content: TypeScript code to validate
        file_path: Path of the file
        
    Returns:
        Tuple of (is_valid, error_message)
    """
    # Check if tsc is available
    try:
        subprocess.run(['tsc', '--version'], capture_output=True, check=True)
    except (subprocess.SubprocessError, FileNotFoundError):
        logger.warning("TypeScript compiler not found, falling back to JavaScript validation")
        return validate_javascript(content, file_path)
    
    # Create a temporary file
    with tempfile.NamedTemporaryFile(suffix='.ts', delete=False) as tmp:
        tmp_path = tmp.name
        tmp.write(content.encode('utf-8'))
    
    try:
        # Use tsc to check syntax (without emitting JS files)
        result = subprocess.run(
            ['tsc', '--noEmit', tmp_path],
            capture_output=True,
            text=True
        )
        
        if result.returncode != 0:
            # Parse the error message
            error_msg = result.stderr or result.stdout
            return False, f"TypeScript error: {error_msg.strip()}"
        
        return True, ""
    
    except Exception as e:
        logger.error(f"Error validating TypeScript code: {str(e)}")
        return False, f"Error validating TypeScript code: {str(e)}"
    
    finally:
        # Clean up the temporary file
        try:
            os.unlink(tmp_path)
        except Exception:
            pass

def validate_java(content: str, file_path: str) -> Tuple[bool, str]:
    """
    Validate Java code.
    
    Args:
        content: Java code to validate
        file_path: Path of the file
        
    Returns:
        Tuple of (is_valid, error_message)
    """
    # Check if javac is available
    try:
        subprocess.run(['javac', '-version'], capture_output=True, check=True)
    except (subprocess.SubprocessError, FileNotFoundError):
        logger.warning("Java compiler not found, falling back to basic Java validation")
        return validate_java_basic(content, file_path)
    
    # Extract class name from the code
    class_name = None
    class_match = re.search(r'public\s+class\s+(\w+)', content)
    if class_match:
        class_name = class_match.group(1)
    else:
        # Try to get class name from file path
        base_name = os.path.basename(file_path)
        if base_name.endswith('.java'):
            class_name = base_name[:-5]
    
    if not class_name:
        return False, "Could not determine Java class name"
    
    # Update content to match class name from file if needed
    if class_match and class_match.group(1) != class_name:
        content = content.replace(f"class {class_match.group(1)}", f"class {class_name}")
    
    # Create a temporary file
    with tempfile.NamedTemporaryFile(suffix='.java', delete=False) as tmp:
        tmp_path = tmp.name
        tmp.write(content.encode('utf-8'))
    
    try:
        # Use javac to check syntax
        result = subprocess.run(
            ['javac', tmp_path],
            capture_output=True,
            text=True
        )
        
        if result.returncode != 0:
            # Parse the error message
            error_msg = result.stderr
            return False, f"Java syntax error: {error_msg.strip()}"
        
        return True, ""
    
    except Exception as e:
        logger.error(f"Error validating Java code: {str(e)}")
        return False, f"Error validating Java code: {str(e)}"
    
    finally:
        # Clean up the temporary file
        try:
            os.unlink(tmp_path)
        except Exception:
            pass

def validate_java_basic(content: str, file_path: str) -> Tuple[bool, str]:
    """
    Basic validation for Java code without using javac.
    
    Args:
        content: Java code to validate
        file_path: Path of the file
        
    Returns:
        Tuple of (is_valid, error_message)
    """
    # Check for basic syntax issues
    
    # Check for unmatched brackets
    bracket_pairs = [('(', ')'), ('[', ']'), ('{', '}')]
    
    for opening, closing in bracket_pairs:
        if content.count(opening) != content.count(closing):
            return False, f"Unmatched brackets: {opening}{closing}"
    
    # Check for missing semicolons (simplified)
    lines = content.splitlines()
    for i, line in enumerate(lines):
        line = line.strip()
        if line and not line.endswith(';') and not line.endswith('{') and not line.endswith('}') and \
           not line.endswith(':') and not line.startswith('//') and not line.startswith('/*') and \
           not line.endswith('*/'):
            if not any(keyword in line for keyword in ['class ', 'interface ', 'enum ', 'import ', 'package ']):
                # This is a simplistic check and might have false positives
                logger.debug(f"Line {i+1} might be missing a semicolon: {line}")
    
    # Check for class name matching file name
    class_match = re.search(r'public\s+class\s+(\w+)', content)
    if class_match:
        class_name = class_match.group(1)
        base_name = os.path.basename(file_path)
        if base_name.endswith('.java') and base_name[:-5] != class_name:
            return False, f"Class name '{class_name}' does not match file name '{base_name[:-5]}'"
    
    return True, ""

def validate_go(content: str, file_path: str) -> Tuple[bool, str]:
    """
    Validate Go code.
    
    Args:
        content: Go code to validate
        file_path: Path of the file
        
    Returns:
        Tuple of (is_valid, error_message)
    """
    # Check if go is available
    try:
        subprocess.run(['go', 'version'], capture_output=True, check=True)
    except (subprocess.SubprocessError, FileNotFoundError):
        logger.warning("Go compiler not found, falling back to basic Go validation")
        return validate_go_basic(content, file_path)
    
    # Create a temporary file
    with tempfile.NamedTemporaryFile(suffix='.go', delete=False) as tmp:
        tmp_path = tmp.name
        tmp.write(content.encode('utf-8'))
    
    try:
        # Use go vet to check syntax and common issues
        result = subprocess.run(
            ['go', 'vet', tmp_path],
            capture_output=True,
            text=True
        )
        
        if result.returncode != 0:
            # Parse the error message
            error_msg = result.stderr
            return False, f"Go error: {error_msg.strip()}"
        
        return True, ""
    
    except Exception as e:
        logger.error(f"Error validating Go code: {str(e)}")
        return False, f"Error validating Go code: {str(e)}"
    
    finally:
        # Clean up the temporary file
        try:
            os.unlink(tmp_path)
        except Exception:
            pass

def validate_go_basic(content: str, file_path: str) -> Tuple[bool, str]:
    """
    Basic validation for Go code without using go compiler.
    
    Args:
        content: Go code to validate
        file_path: Path of the file
        
    Returns:
        Tuple of (is_valid, error_message)
    """
    # Check for basic syntax issues
    
    # Check for unmatched brackets
    bracket_pairs = [('(', ')'), ('[', ']'), ('{', '}')]
    
    for opening, closing in bracket_pairs:
        if content.count(opening) != content.count(closing):
            return False, f"Unmatched brackets: {opening}{closing}"
    
    # Check for package declaration
    if not re.search(r'package\s+\w+', content):
        return False, "Missing package declaration"
    
    return True, ""

def validate_ruby(content: str, file_path: str) -> Tuple[bool, str]:
    """
    Validate Ruby code.
    
    Args:
        content: Ruby code to validate
        file_path: Path of the file
        
    Returns:
        Tuple of (is_valid, error_message)
    """
    # Check if ruby is available
    try:
        subprocess.run(['ruby', '--version'], capture_output=True, check=True)
    except (subprocess.SubprocessError, FileNotFoundError):
        logger.warning("Ruby interpreter not found, falling back to basic Ruby validation")
        return validate_ruby_basic(content, file_path)
    
    # Create a temporary file
    with tempfile.NamedTemporaryFile(suffix='.rb', delete=False) as tmp:
        tmp_path = tmp.name
        tmp.write(content.encode('utf-8'))
    
    try:
        # Use ruby -c to check syntax
        result = subprocess.run(
            ['ruby', '-c', tmp_path],
            capture_output=True,
            text=True
        )
        
        if result.returncode != 0:
            # Parse the error message
            error_msg = result.stderr
            return False, f"Ruby syntax error: {error_msg.strip()}"
        
        return True, ""
    
    except Exception as e:
        logger.error(f"Error validating Ruby code: {str(e)}")
        return False, f"Error validating Ruby code: {str(e)}"
    
    finally:
        # Clean up the temporary file
        try:
            os.unlink(tmp_path)
        except Exception:
            pass

def validate_ruby_basic(content: str, file_path: str) -> Tuple[bool, str]:
    """
    Basic validation for Ruby code without using ruby interpreter.
    
    Args:
        content: Ruby code to validate
        file_path: Path of the file
        
    Returns:
        Tuple of (is_valid, error_message)
    """
    # Check for basic syntax issues
    
    # Check for unmatched brackets
    bracket_pairs = [('(', ')'), ('[', ']'), ('{', '}')]
    
    for opening, closing in bracket_pairs:
        if content.count(opening) != content.count(closing):
            return False, f"Unmatched brackets: {opening}{closing}"
    
    # Check for unmatched 'do' blocks
    do_count = len(re.findall(r'\bdo\b(?:\s*\|.*?\|)?', content))
    end_count = len(re.findall(r'\bend\b', content))
    
    if do_count != end_count:
        return False, f"Unmatched 'do' and 'end' blocks: {do_count} 'do' vs {end_count} 'end'"
    
    return True, ""

def validate_rust(content: str, file_path: str) -> Tuple[bool, str]:
    """
    Validate Rust code.
    
    Args:
        content: Rust code to validate
        file_path: Path of the file
        
    Returns:
        Tuple of (is_valid, error_message)
    """
    # Check if rustc is available
    try:
        subprocess.run(['rustc', '--version'], capture_output=True, check=True)
    except (subprocess.SubprocessError, FileNotFoundError):
        logger.warning("Rust compiler not found, falling back to basic Rust validation")
        return validate_rust_basic(content, file_path)
    
    # Create a temporary file
    with tempfile.NamedTemporaryFile(suffix='.rs', delete=False) as tmp:
        tmp_path = tmp.name
        tmp.write(content.encode('utf-8'))
    
    try:
        # Use rustc to check syntax (with --emit=metadata to avoid producing binaries)
        result = subprocess.run(
            ['rustc', '--emit=metadata', tmp_path],
            capture_output=True,
            text=True
        )
        
        if result.returncode != 0:
            # Parse the error message
            error_msg = result.stderr
            return False, f"Rust syntax error: {error_msg.strip()}"
        
        return True, ""
    
    except Exception as e:
        logger.error(f"Error validating Rust code: {str(e)}")
        return False, f"Error validating Rust code: {str(e)}"
    
    finally:
        # Clean up the temporary files
        try:
            os.unlink(tmp_path)
            # Also try to remove any generated metadata files
            metadata_path = tmp_path.replace('.rs', '')
            if os.path.exists(metadata_path):
                os.unlink(metadata_path)
        except Exception:
            pass

def validate_rust_basic(content: str, file_path: str) -> Tuple[bool, str]:
    """
    Basic validation for Rust code without using rustc.
    
    Args:
        content: Rust code to validate
        file_path: Path of the file
        
    Returns:
        Tuple of (is_valid, error_message)
    """
    # Check for basic syntax issues
    
    # Check for unmatched brackets
    bracket_pairs = [('(', ')'), ('[', ']'), ('{', '}')]
    
    for opening, closing in bracket_pairs:
        if content.count(opening) != content.count(closing):
            return False, f"Unmatched brackets: {opening}{closing}"
    
    return True, ""

def validate_html(content: str, file_path: str) -> Tuple[bool, str]:
    """
    Validate HTML code.
    
    Args:
        content: HTML code to validate
        file_path: Path of the file
        
    Returns:
        Tuple of (is_valid, error_message)
    """
    # Basic HTML validation without external tools
    
    # Check for DOCTYPE declaration
    if not re.search(r'<!DOCTYPE\s+html>', content, re.IGNORECASE):
        logger.warning("HTML file missing DOCTYPE declaration")
    
    # Check for basic required elements
    if not re.search(r'<html', content, re.IGNORECASE):
        return False, "Missing <html> element"
    
    if not re.search(r'<head', content, re.IGNORECASE):
        return False, "Missing <head> element"
    
    if not re.search(r'<body', content, re.IGNORECASE):
        return False, "Missing <body> element"
    
    # Check for unmatched tags (simplified)
    html_tags = re.findall(r'<([a-zA-Z0-9]+)[^>]*>', content)
    void_elements = {'area', 'base', 'br', 'col', 'embed', 'hr', 'img', 'input', 
                     'link', 'meta', 'param', 'source', 'track', 'wbr'}
    
    tag_stack = []
    
    for tag in html_tags:
        tag_lower = tag.lower()
        if tag_lower not in void_elements:
            tag_stack.append(tag_lower)
    
    closing_tags = re.findall(r'</([a-zA-Z0-9]+)>', content)
    
    for tag in closing_tags:
        tag_lower = tag.lower()
        if tag_stack and tag_stack[-1] == tag_lower:
            tag_stack.pop()
        else:
            return False, f"Unmatched closing tag: </
            
            
def validate_css(content: str, file_path: str) -> Tuple[bool, str]:
    """
    Validate CSS code.
    
    Args:
        content: CSS code to validate
        file_path: Path of the file
        
    Returns:
        Tuple of (is_valid, error_message)
    """
    # Basic CSS validation without external tools
    
    # Check for unmatched brackets
    if content.count('{') != content.count('}'):
        return False, "Unmatched brackets in CSS"
    
    # Check for missing semicolons in property declarations
    lines = content.splitlines()
    in_rule_block = False
    
    for i, line in enumerate(lines):
        line = line.strip()
        
        if not line or line.startswith('/*') or line.endswith('*/'):
            continue
        
        if '{' in line:
            in_rule_block = True
            continue
            
        if '}' in line:
            in_rule_block = False
            continue
        
        if in_rule_block and ':' in line and not line.endswith(';') and not line.endswith('{'):
            # This might be a property without a semicolon
            # Check if it's not the last property in a block
            next_line_idx = i + 1
            while next_line_idx < len(lines) and not lines[next_line_idx].strip():
                next_line_idx += 1
                
            if next_line_idx < len(lines) and not lines[next_line_idx].strip().startswith('}'):
                return False, f"Missing semicolon at line {i+1}: {line}"
    
    return True, ""

def validate_php(content: str, file_path: str) -> Tuple[bool, str]:
    """
    Validate PHP code.
    
    Args:
        content: PHP code to validate
        file_path: Path of the file
        
    Returns:
        Tuple of (is_valid, error_message)
    """
    # Check if php is available
    try:
        subprocess.run(['php', '--version'], capture_output=True, check=True)
    except (subprocess.SubprocessError, FileNotFoundError):
        logger.warning("PHP interpreter not found, falling back to basic PHP validation")
        return validate_php_basic(content, file_path)
    
    # Create a temporary file
    with tempfile.NamedTemporaryFile(suffix='.php', delete=False) as tmp:
        tmp_path = tmp.name
        tmp.write(content.encode('utf-8'))
    
    try:
        # Use php -l to check syntax
        result = subprocess.run(
            ['php', '-l', tmp_path],
            capture_output=True,
            text=True
        )
        
        if result.returncode != 0:
            # Parse the error message
            error_msg = result.stderr or result.stdout
            return False, f"PHP syntax error: {error_msg.strip()}"
        
        return True, ""
    
    except Exception as e:
        logger.error(f"Error validating PHP code: {str(e)}")
        return False, f"Error validating PHP code: {str(e)}"
    
    finally:
        # Clean up the temporary file
        try:
            os.unlink(tmp_path)
        except Exception:
            pass

def validate_php_basic(content: str, file_path: str) -> Tuple[bool, str]:
    """
    Basic validation for PHP code without using php interpreter.
    
    Args:
        content: PHP code to validate
        file_path: Path of the file
        
    Returns:
        Tuple of (is_valid, error_message)
    """
    # Check for basic syntax issues
    
    # Check for PHP opening tag
    if not re.search(r'<\?php', content):
        return False, "Missing PHP opening tag (<?php)"
    
    # Check for unmatched brackets
    bracket_pairs = [('(', ')'), ('[', ']'), ('{', '}')]
    
    for opening, closing in bracket_pairs:
        if content.count(opening) != content.count(closing):
            return False, f"Unmatched brackets: {opening}{closing}"
    
    return True, ""
</file>

<file path="angela/integrations/__init__.py">
def init_application():
    """Initialize all application components."""
    # Import existing components
    from angela.execution.engine import execution_engine
    # ... other imports
    
    # Import the enhanced planner integration
    from angela.integrations.enhanced_planner import apply_enhanced_planner_integration
    
    # Register core services
    # ... existing registrations
</file>

<file path="angela/integrations/enhanced_planner_integration.py">
"""
Integration for the Enhanced Task Planner into Angela's Orchestration system.

This module extends the orchestrator to fully support advanced plan execution
with all step types (CODE, API, LOOP, etc.) and proper data flow.
"""
import os
import re
import json
import asyncio
from pathlib import Path
from typing import Dict, Any, List, Optional, Union, Set

from angela.orchestrator import Orchestrator, RequestType
from angela.intent.planner import (
    task_planner, TaskPlan, PlanStep, 
    AdvancedTaskPlan, AdvancedPlanStep, PlanStepType
)
from angela.utils.logging import get_logger
from angela.shell.formatter import terminal_formatter

logger = get_logger(__name__)

# Patch the Orchestrator._process_multi_step_request method to use the enhanced task planner
async def enhanced_process_multi_step_request(
    self, 
    request: str, 
    context: Dict[str, Any], 
    execute: bool, 
    dry_run: bool
) -> Dict[str, Any]:
    """
    Process a multi-step operation request with enhanced execution capabilities.
    
    Args:
        request: The user request
        context: Context information
        execute: Whether to execute the commands
        dry_run: Whether to simulate execution without making changes
        
    Returns:
        Dictionary with processing results
    """
    self._logger.info(f"Processing multi-step request with enhanced capabilities: {request}")
    
    # Determine complexity for planning
    complexity = await task_planner._determine_complexity(request)
    self._logger.debug(f"Determined plan complexity: {complexity}")
    
    # Start a transaction for this multi-step operation
    transaction_id = None
    if not dry_run:
        rollback_manager = self._get_rollback_manager()
        if rollback_manager:
            transaction_id = await rollback_manager.start_transaction(f"Multi-step plan: {request[:50]}...")
    
    try:
        # Create a plan based on complexity
        if complexity == "advanced":
            # Use the advanced planner for complex tasks
            plan = await task_planner.plan_task(request, context, complexity)
            
            # Record the plan in the transaction
            if transaction_id:
                await self._record_plan_in_transaction(plan, transaction_id)
            
            # Create result with the plan
            result = await self._handle_advanced_plan_execution(plan, request, context, execute, dry_run, transaction_id)
        else:
            # Use the basic planner for simple tasks
            plan = await task_planner.plan_task(request, context)
            result = await self._handle_basic_plan_execution(plan, request, context, execute, dry_run, transaction_id)
        
        return result
        
    except Exception as e:
        # Handle any exceptions and end the transaction
        if transaction_id:
            rollback_manager = self._get_rollback_manager()
            if rollback_manager:
                await rollback_manager.end_transaction(transaction_id, "failed")
        
        self._logger.exception(f"Error processing multi-step request: {str(e)}")
        raise
        
async def _handle_advanced_plan_execution(
    self,
    plan: AdvancedTaskPlan,
    request: str,
    context: Dict[str, Any],
    execute: bool,
    dry_run: bool,
    transaction_id: Optional[str] = None
) -> Dict[str, Any]:
    """
    Handle execution of an advanced plan.
    
    Args:
        plan: The advanced plan to execute
        request: The original request
        context: Context information
        execute: Whether to execute commands
        dry_run: Whether to simulate execution
        transaction_id: Transaction ID for rollback
        
    Returns:
        Dictionary with results
    """
    # Create result structure with the plan
    result = {
        "request": request,
        "type": "advanced_multi_step",
        "context": context,
        "plan": {
            "id": plan.id,
            "goal": plan.goal,
            "description": plan.description,
            "steps": [
                {
                    "id": step_id,
                    "type": step.type,
                    "description": step.description,
                    "command": getattr(step, "command", None),
                    "dependencies": step.dependencies,
                    "risk": step.estimated_risk
                }
                for step_id, step in plan.steps.items()
            ],
            "entry_points": plan.entry_points,
            "step_count": len(plan.steps)
        }
    }
    
    # Display the plan for the user
    await self._display_advanced_plan(plan)
    
    # Execute the plan if requested
    if execute or dry_run:
        # Get confirmation for plan execution
        confirmed = await self._confirm_advanced_plan_execution(plan, dry_run)
        
        if confirmed or dry_run:
            # Execute the plan with initial variables from context if needed
            initial_variables = self._extract_initial_variables(context)
            
            execution_results = await task_planner.execute_plan(
                plan, 
                dry_run=dry_run,
                transaction_id=transaction_id,
                initial_variables=initial_variables
            )
            
            result["execution_results"] = execution_results
            result["success"] = execution_results.get("success", False)
            
            # Update transaction status
            if transaction_id:
                rollback_manager = self._get_rollback_manager()
                if rollback_manager:
                    status = "completed" if result["success"] else "failed"
                    await rollback_manager.end_transaction(transaction_id, status)
                    
            # For failed steps, show error information
            if not result["success"]:
                failed_step = execution_results.get("failed_step")
                if failed_step and failed_step in execution_results.get("results", {}):
                    step_result = execution_results["results"][failed_step]
                    error_msg = step_result.get("error", "Unknown error")
                    self._logger.error(f"Step {failed_step} failed: {error_msg}")
                    
                    # Format error for display
                    await terminal_formatter.display_step_error(
                        failed_step,
                        error_msg,
                        step_result.get("type", "unknown"),
                        step_result.get("description", "")
                    )
        else:
            result["cancelled"] = True
            result["success"] = False
            
            # End the transaction as cancelled
            if transaction_id:
                rollback_manager = self._get_rollback_manager()
                if rollback_manager:
                    await rollback_manager.end_transaction(transaction_id, "cancelled")
    
    return result

async def _display_advanced_plan(
    self,
    plan: AdvancedTaskPlan
) -> None:
    """
    Display an advanced task plan to the user.
    
    Args:
        plan: The advanced plan to display
    """
    await terminal_formatter.display_advanced_plan(plan)

async def _confirm_advanced_plan_execution(
    self, 
    plan: AdvancedTaskPlan, 
    dry_run: bool
) -> bool:
    """
    Get confirmation for executing an advanced plan.
    
    Args:
        plan: The plan to execute
        dry_run: Whether this is a dry run
        
    Returns:
        True if confirmed, False otherwise
    """
    if dry_run:
        # No confirmation needed for dry run
        return True
    
    # Check if any steps are high risk
    has_high_risk = any(step.estimated_risk >= 3 for step in plan.steps.values())
    
    # Check for certain step types that might need extra caution
    has_complex_steps = any(step.type in [PlanStepType.CODE, PlanStepType.API, PlanStepType.LOOP] 
                           for step in plan.steps.values())
    
    # Import confirmation dialog
    from prompt_toolkit.shortcuts import yes_no_dialog
    
    # Build warning/information message
    message = f"Do you want to execute this advanced plan with {len(plan.steps)} steps?"
    
    if has_high_risk:
        message = f"⚠️  [WARNING] This plan includes HIGH RISK operations that could significantly change your system.\n\n{message}"
    
    if has_complex_steps:
        message += "\n\nThis plan includes advanced steps like code execution, API calls, or loops."
    
    # Get confirmation with appropriate styling
    return yes_no_dialog(
        title="Confirm Advanced Plan Execution",
        text=message
    ).run()

def _extract_initial_variables(self, context: Dict[str, Any]) -> Dict[str, Any]:
    """
    Extract variables from context to use as initial variables for plan execution.
    
    Args:
        context: Context information
        
    Returns:
        Dictionary of variables
    """
    initial_vars = {}
    
    # Extract relevant information from context
    if "cwd" in context:
        initial_vars["current_directory"] = context["cwd"]
    
    if "project_root" in context:
        initial_vars["project_root"] = context["project_root"]
    
    if "project_type" in context:
        initial_vars["project_type"] = context["project_type"]
    
    if "enhanced_project" in context:
        # Extract useful project information
        project_info = context["enhanced_project"]
        if "type" in project_info:
            initial_vars["project_type"] = project_info["type"]
        
        if "frameworks" in project_info:
            initial_vars["frameworks"] = project_info["frameworks"]
        
        if "dependencies" in project_info and "top_dependencies" in project_info["dependencies"]:
            initial_vars["dependencies"] = project_info["dependencies"]["top_dependencies"]
    
    if "resolved_files" in context:
        # Extract resolved file references
        files = {}
        for ref in context["resolved_files"]:
            ref_name = ref.get("reference", "").replace(" ", "_")
            if ref_name and "path" in ref:
                files[ref_name] = ref["path"]
        
        if files:
            initial_vars["files"] = files
    
    # Add session-specific information
    if "session" in context and "entities" in context["session"]:
        entities = {}
        for name, entity in context["session"].get("entities", {}).items():
            if "type" in entity and "value" in entity:
                entities[name] = {
                    "type": entity["type"],
                    "value": entity["value"]
                }
        
        if entities:
            initial_vars["entities"] = entities
    
    return initial_vars

def _get_rollback_manager(self):
    """Get the rollback manager from the registry."""
    from angela.core.registry import registry
    return registry.get("rollback_manager")

async def _record_plan_in_transaction(self, plan, transaction_id):
    """Record a plan in a transaction."""
    rollback_manager = self._get_rollback_manager()
    if rollback_manager:
        await rollback_manager.record_plan_execution(
            plan_id=plan.id,
            goal=plan.goal,
            plan_data=plan.dict(),
            transaction_id=transaction_id
        )

# Function to apply the patches to the Orchestrator class
def apply_enhanced_planner_integration():
    """Apply the enhanced task planner integration to the Orchestrator class."""
    # Patch the _process_multi_step_request method
    Orchestrator._process_multi_step_request = enhanced_process_multi_step_request
    
    # Add new methods to the Orchestrator class
    Orchestrator._handle_advanced_plan_execution = _handle_advanced_plan_execution
    Orchestrator._display_advanced_plan = _display_advanced_plan
    Orchestrator._confirm_advanced_plan_execution = _confirm_advanced_plan_execution
    Orchestrator._extract_initial_variables = _extract_initial_variables
    Orchestrator._get_rollback_manager = _get_rollback_manager
    Orchestrator._record_plan_in_transaction = _record_plan_in_transaction
    
    logger.info("Enhanced task planner integration applied to Orchestrator")

# Apply the patches when this module is imported
apply_enhanced_planner_integration()
</file>

<file path="angela/integrations/semantic_integration.py">
"""
Semantic integration module for Angela CLI.

This module ties together the various semantic analysis components and
integrates them into Angela's workflow, making semantic code understanding
available to all parts of the application.
"""
import asyncio
from typing import Dict, Any, List, Optional, Union, Set
from pathlib import Path

from angela.utils.logging import get_logger
from angela.context import context_manager
from angela.context.file_activity import file_activity_tracker
from angela.context.project_state_analyzer import project_state_analyzer
from angela.ai.semantic_analyzer import semantic_analyzer
from angela.context.enhancer import context_enhancer
from angela.context.session import session_manager

logger = get_logger(__name__)

class SemanticIntegration:
    """
    Integration hub for semantic understanding features.
    
    This class coordinates the different semantic analysis components
    and makes their functionality available to the rest of the application.
    It serves as the main entry point for requesting semantic information.
    """
    
    def __init__(self):
        """Initialize the semantic integration."""
        self._logger = logger
        self._semantic_context_cache = {}  # Cache for semantic context
        self._analysis_in_progress = set()  # Set of files/projects currently being analyzed
        self._analysis_tasks = {}  # Background analysis tasks by file/project path
    
    async def get_semantic_context(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """
        Enhance the context with semantic information.
        
        Args:
            context: The base context dictionary
            
        Returns:
            Enhanced context with semantic information
        """
        # Create a new context with semantic information
        semantic_context = dict(context)
        
        # Get project root if available
        project_root = context.get("project_root")
        if not project_root:
            return semantic_context
        
        # Check if we have a file in focus
        current_file = context.get("current_file", {}).get("path")
        
        try:
            # Add project state information
            semantic_context["project_state"] = await self._get_project_state(project_root)
            
            # Add semantic code information if a file is in focus
            if current_file:
                semantic_context["semantic_code"] = await self._get_semantic_code(current_file)
            
            # Add information about recently accessed files
            recent_files = context.get("recent_files", {}).get("accessed", [])
            if recent_files:
                semantic_context["semantic_recent"] = await self._get_semantic_recent(recent_files[:5])
            
            # Add semantic context for active project entities
            semantic_context["semantic_entities"] = await self._get_semantic_entities(project_root)
            
            # Add function/class relationships
            if current_file and semantic_context.get("semantic_code", {}).get("entity_name"):
                entity_name = semantic_context["semantic_code"]["entity_name"]
                semantic_context["semantic_relationships"] = await self._get_semantic_relationships(project_root, entity_name)
            
            return semantic_context
            
        except Exception as e:
            self._logger.error(f"Error getting semantic context: {str(e)}")
            return semantic_context
    
    async def _get_project_state(self, project_root: str) -> Dict[str, Any]:
        """
        Get project state information.
        
        Args:
            project_root: Path to the project root
            
        Returns:
            Project state information
        """
        # Start a background analysis task if not already in progress
        if project_root not in self._analysis_in_progress:
            self._schedule_background_analysis(project_root)
        
        # Get state information (cached or real-time)
        try:
            state_info = await project_state_analyzer.get_project_state(project_root)
            
            # Extract the most important information for the context
            summary = {
                "git": {
                    "branch": state_info.get("git_state", {}).get("current_branch"),
                    "has_changes": state_info.get("git_state", {}).get("has_changes", False),
                    "changed_files_count": len(state_info.get("git_state", {}).get("modified_files", [])) +
                                          len(state_info.get("git_state", {}).get("untracked_files", [])),
                },
                "tests": {
                    "framework": state_info.get("test_status", {}).get("framework"),
                    "count": state_info.get("test_status", {}).get("test_files_count", 0),
                    "coverage": state_info.get("test_status", {}).get("coverage", {}).get("percentage")
                },
                "dependencies": {
                    "package_manager": state_info.get("dependencies", {}).get("package_manager"),
                    "count": state_info.get("dependencies", {}).get("dependencies_count", 0),
                    "outdated_count": len(state_info.get("dependencies", {}).get("outdated_packages", []))
                },
                "build": {
                    "system": state_info.get("build_status", {}).get("system"),
                    "last_build": state_info.get("build_status", {}).get("last_build")
                },
                "code_quality": {
                    "linter": state_info.get("code_quality", {}).get("linter"),
                    "issues_count": state_info.get("code_quality", {}).get("issues_count", 0)
                },
                "todo_count": len(state_info.get("todo_items", []))
            }
            
            return summary
            
        except Exception as e:
            self._logger.error(f"Error getting project state: {str(e)}")
            return {}
    
    async def _get_semantic_code(self, file_path: str) -> Dict[str, Any]:
        """
        Get semantic information about a code file.
        
        Args:
            file_path: Path to the file
            
        Returns:
            Semantic code information
        """
        try:
            # Start a background analysis task if not already in progress
            if file_path not in self._analysis_in_progress:
                self._schedule_background_analysis(file_path, is_file=True)
            
            # Get the module information from semantic analyzer
            module = await semantic_analyzer.analyze_file(file_path)
            
            if not module:
                return {}
            
            # Extract important information for the context
            result = {
                "language": module.language,
                "docstring": module.docstring,
                "functions": list(module.functions.keys()),
                "classes": list(module.classes.keys()),
                "imports": list(module.imports.keys()),
                "code_metrics": module.code_metrics
            }
            
            # If current cursor position is known, try to determine the entity at cursor
            cursor_line = context_manager.get_context_dict().get("cursor_line")
            if cursor_line:
                entity = self._find_entity_at_line(module, cursor_line)
                if entity:
                    result["entity_name"] = entity.name
                    result["entity_type"] = entity.__class__.__name__.lower()
                    result["entity_line_start"] = entity.line_start
                    result["entity_line_end"] = entity.line_end
                    
                    # Add entity-specific information
                    if result["entity_type"] == "function":
                        result["function_params"] = entity.params
                        result["function_docstring"] = entity.docstring
                        result["function_return_type"] = entity.return_type
                        result["function_complexity"] = entity.complexity
                    elif result["entity_type"] == "class":
                        result["class_bases"] = entity.base_classes
                        result["class_methods"] = list(entity.methods.keys())
                        result["class_attributes"] = list(entity.attributes.keys())
            
            return result
            
        except Exception as e:
            self._logger.error(f"Error getting semantic code information: {str(e)}")
            return {}
    
    def _find_entity_at_line(self, module, line_number: int):
        """Find the entity at a specific line number."""
        # Check functions
        for func in module.functions.values():
            if func.line_start <= line_number <= func.line_end:
                return func
        
        # Check classes
        for cls in module.classes.values():
            if cls.line_start <= line_number <= cls.line_end:
                # Check if we're in a method of this class
                for method in cls.methods.values():
                    if method.line_start <= line_number <= method.line_end:
                        return method
                return cls
        
        # Check variables
        for var in module.variables.values():
            if var.line_start <= line_number <= var.line_end:
                return var
        
        return None
    
    async def _get_semantic_recent(self, recent_files: List[str]) -> Dict[str, Any]:
        """
        Get semantic information about recently accessed files.
        
        Args:
            recent_files: List of recently accessed file paths
            
        Returns:
            Semantic information about recent files
        """
        result = {}
        
        for file_path in recent_files:
            try:
                # Schedule background analysis if needed
                if file_path not in self._analysis_in_progress:
                    self._schedule_background_analysis(file_path, is_file=True)
                
                # Get module information
                module = await semantic_analyzer.analyze_file(file_path)
                
                if module:
                    # Get file summary
                    result[file_path] = module.get_summary()
            except Exception as e:
                self._logger.error(f"Error analyzing recent file {file_path}: {str(e)}")
        
        return result
    
    async def _get_semantic_entities(self, project_root: str) -> Dict[str, Any]:
        """
        Get semantic information about important entities in the project.
        
        Args:
            project_root: Path to the project root
            
        Returns:
            Semantic information about important project entities
        """
        # Extract entities from session
        entities = session_manager.get_context().get("entities", {})
        
        result = {
            "current_focus": [],
            "important_functions": [],
            "important_classes": []
        }
        
        # Find entities that the user has interacted with
        entity_names = set()
        for entity_name, entity_info in entities.items():
            if entity_info.get("type") == "function" or entity_info.get("type") == "class" or entity_info.get("type") == "method":
                entity_names.add(entity_info.get("value"))
        
        # Get recently viewed files
        recent_activities = file_activity_tracker.get_recent_activities(activity_types=["viewed"])
        recent_files = [activity.get("path") for activity in recent_activities]
        
        # Analyze recently viewed files to find important entities
        for file_path in recent_files[:5]:  # Limit to 5 most recent files
            try:
                module = await semantic_analyzer.analyze_file(file_path)
                
                if not module:
                    continue
                
                # Add functions and classes to the result
                for func_name, func in module.functions.items():
                    if func_name in entity_names:
                        result["current_focus"].append({
                            "name": func_name,
                            "type": "function",
                            "file": file_path,
                            "line": func.line_start
                        })
                    elif func.complexity and func.complexity > 5:  # Complex functions
                        result["important_functions"].append({
                            "name": func_name,
                            "file": file_path,
                            "complexity": func.complexity,
                            "line": func.line_start
                        })
                
                for class_name, cls in module.classes.items():
                    if class_name in entity_names:
                        result["current_focus"].append({
                            "name": class_name,
                            "type": "class",
                            "file": file_path,
                            "line": cls.line_start,
                            "method_count": len(cls.methods)
                        })
                    elif len(cls.methods) > 5:  # Classes with many methods
                        result["important_classes"].append({
                            "name": class_name,
                            "file": file_path,
                            "method_count": len(cls.methods),
                            "line": cls.line_start
                        })
            except Exception as e:
                self._logger.error(f"Error analyzing entities in {file_path}: {str(e)}")
        
        # Sort important entities by complexity/size
        result["important_functions"] = sorted(
            result["important_functions"], 
            key=lambda f: f.get("complexity", 0), 
            reverse=True
        )[:5]  # Limit to top 5
        
        result["important_classes"] = sorted(
            result["important_classes"], 
            key=lambda c: c.get("method_count", 0), 
            reverse=True
        )[:5]  # Limit to top 5
        
        return result
    
    async def _get_semantic_relationships(self, project_root: str, entity_name: str) -> Dict[str, Any]:
        """
        Get semantic relationship information for a specific entity.
        
        Args:
            project_root: Path to the project root
            entity_name: Name of the entity
            
        Returns:
            Semantic relationship information
        """
        try:
            # Get entity usage information
            usage_info = await semantic_analyzer.analyze_entity_usage(entity_name, project_root)
            
            if not usage_info.get("found", False):
                return {}
            
            # Extract relationship information
            result = {
                "type": usage_info.get("type"),
                "callers": [],
                "callees": [],
                "related_entities": []
            }
            
            # Process related entities
            related = usage_info.get("related_entities", [])
            
            for entity in related:
                rel_type = entity.get("relationship")
                
                if rel_type == "calls":
                    result["callers"].append({
                        "name": entity.get("name"),
                        "file": entity.get("filename"),
                        "line": entity.get("line")
                    })
                elif rel_type == "called_by":
                    result["callees"].append({
                        "name": entity.get("name"),
                        "file": entity.get("filename"),
                        "line": entity.get("line")
                    })
                else:
                    result["related_entities"].append({
                        "name": entity.get("name"),
                        "type": entity.get("type"),
                        "relationship": rel_type,
                        "file": entity.get("filename"),
                        "line": entity.get("line")
                    })
            
            return result
            
        except Exception as e:
            self._logger.error(f"Error getting relationships for {entity_name}: {str(e)}")
            return {}
    
    def _schedule_background_analysis(self, path: str, is_file: bool = False):
        """
        Schedule a background analysis task.
        
        Args:
            path: Path to the file or project
            is_file: Whether the path is a file or project
        """
        if path in self._analysis_in_progress:
            return
        
        self._analysis_in_progress.add(path)
        
        async def _run_analysis():
            try:
                if is_file:
                    await semantic_analyzer.analyze_file(path)
                else:
                    await project_state_analyzer.get_project_state(path)
            except Exception as e:
                self._logger.error(f"Error in background analysis for {path}: {str(e)}")
            finally:
                self._analysis_in_progress.remove(path)
        
        # Create and store the task
        task = asyncio.create_task(_run_analysis())
        self._analysis_tasks[path] = task
        
        # Remove the task when it's done
        def _clean_up(task):
            if path in self._analysis_tasks:
                del self._analysis_tasks[path]
        
        task.add_done_callback(_clean_up)
    
    async def get_entity_summary(self, entity_name: str, project_root: Optional[str] = None) -> str:
        """
        Get a natural language summary of a code entity.
        
        Args:
            entity_name: Name of the entity to summarize
            project_root: Path to the project root (optional)
            
        Returns:
            Natural language summary
        """
        if not project_root:
            project_root = context_manager.project_root
            
        if not project_root:
            return f"Cannot generate summary: No project root specified and none detected."
        
        return await semantic_analyzer.summarize_code_entity(entity_name, project_root)
    
    async def get_code_suggestions(self, file_path: str, line_number: Optional[int] = None) -> List[Dict[str, Any]]:
        """
        Get code improvement suggestions for a file.
        
        Args:
            file_path: Path to the file
            line_number: Optional line number to focus on
            
        Returns:
            List of improvement suggestions
        """
        try:
            # First, analyze the file
            module = await semantic_analyzer.analyze_file(file_path)
            
            if not module:
                return []
            
            # Find entity at line number if specified
            entity = None
            if line_number:
                entity = self._find_entity_at_line(module, line_number)
            
            # Get the file content
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Create suggestions based on analysis
            suggestions = []
            
            # Entity-specific suggestions
            if entity:
                if hasattr(entity, 'complexity') and entity.complexity > 10:
                    suggestions.append({
                        "type": "complexity",
                        "severity": "medium",
                        "message": f"Function '{entity.name}' has high complexity ({entity.complexity}). Consider refactoring.",
                        "line": entity.line_start,
                        "entity": entity.name
                    })
                
                if hasattr(entity, 'docstring') and not entity.docstring:
                    suggestions.append({
                        "type": "documentation",
                        "severity": "low",
                        "message": f"Add docstring to {entity.__class__.__name__.lower()} '{entity.name}'.",
                        "line": entity.line_start,
                        "entity": entity.name
                    })
                
                if hasattr(entity, 'params') and len(entity.params) > 5:
                    suggestions.append({
                        "type": "parameters",
                        "severity": "low",
                        "message": f"Function '{entity.name}' has many parameters ({len(entity.params)}). Consider grouping them.",
                        "line": entity.line_start,
                        "entity": entity.name
                    })
            
            # General file suggestions
            if len(module.functions) > 10:
                suggestions.append({
                    "type": "structure",
                    "severity": "low",
                    "message": f"File has {len(module.functions)} functions. Consider splitting into multiple modules.",
                    "line": 1,
                    "file": file_path
                })
            
            if module.code_metrics.get("blank_ratio", 0) < 0.1:
                suggestions.append({
                    "type": "readability",
                    "severity": "low",
                    "message": "Low blank line ratio. Add more whitespace to improve readability.",
                    "line": 1,
                    "file": file_path
                })
            
            if module.code_metrics.get("comment_ratio", 0) < 0.1:
                suggestions.append({
                    "type": "documentation",
                    "severity": "low",
                    "message": "Low comment ratio. Add more comments to improve maintainability.",
                    "line": 1,
                    "file": file_path
                })
            
            # Check for long lines
            lines = content.split('\n')
            long_lines = []
            for i, line in enumerate(lines, 1):
                if len(line) > 100:
                    long_lines.append(i)
            
            if long_lines:
                suggestions.append({
                    "type": "style",
                    "severity": "low",
                    "message": f"File contains {len(long_lines)} lines longer than 100 characters.",
                    "lines": long_lines[:5],  # List up to 5 problematic lines
                    "file": file_path
                })
            
            return suggestions
            
        except Exception as e:
            self._logger.error(f"Error getting code suggestions: {str(e)}")
            return []
    
    async def find_similar_code(self, code_snippet: str, project_root: Optional[str] = None) -> List[Dict[str, Any]]:
        """
        Find similar code in the project.
        
        Args:
            code_snippet: Code snippet to search for
            project_root: Path to the project root (optional)
            
        Returns:
            List of similar code snippets
        """
        if not project_root:
            project_root = context_manager.project_root
            
        if not project_root:
            return []
        
        # TODO: Implement semantic code similarity search
        # This would require more advanced techniques beyond the scope of this example
        # Could use embeddings, AST comparison, or other similarity metrics
        
        # For now, return a placeholder
        return [
            {
                "file": "placeholder.py",
                "similarity": 0.8,
                "code": "print('This is a placeholder')",
                "line": 1
            }
        ]

# Global instance of semantic integration
semantic_integration = SemanticIntegration()

# Add to context enhancer
async def enhance_context_with_semantics(context: Dict[str, Any]) -> Dict[str, Any]:
    """Context enhancer function for semantic information."""
    return await semantic_integration.get_semantic_context(context)

# Register with context_enhancer
context_enhancer.register_enhancer(enhance_context_with_semantics)
</file>

<file path="angela/intent/__init__.py">
"""
Intent components for Angela CLI.
"""
</file>

<file path="angela/intent/models.py">
# angela/intent/models.py
from enum import Enum
from typing import Dict, Any, Optional, List

from pydantic import BaseModel, Field

class IntentType(str, Enum):
    """Enumeration of possible intent types."""
    UNKNOWN = "unknown"
    FILE_SEARCH = "file_search"
    DIRECTORY_LIST = "directory_list"
    FILE_VIEW = "file_view"
    SYSTEM_INFO = "system_info"
    NETWORK_INFO = "network_info"
    FILE_EDIT = "file_edit"  # For future phases
    FILE_CREATE = "file_create"  # For future phases
    GIT_OPERATION = "git_operation"  # For future phases
    DOCKER_OPERATION = "docker_operation"  # For future phases

class Intent(BaseModel):
    """Model for user intent."""
    type: IntentType = Field(..., description="The type of intent")
    entities: Dict[str, Any] = Field(default_factory=dict, description="Entities extracted from the request")
    original_request: str = Field(..., description="The original user request")

class ActionPlan(BaseModel):
    """Model for an action plan derived from intent."""
    intent: Intent = Field(..., description="The intent that led to this plan")
    commands: List[str] = Field(..., description="List of commands to execute")
    explanations: List[str] = Field(..., description="Explanations for each command")
    risk_level: int = Field(0, description="Risk level of the plan (0-4)")
</file>

<file path="angela/intent/semantic_task_planner.py">
"""
Semantic task planning and intent decomposition for Angela CLI.

This module extends the enhanced task planner with semantic code understanding
and improved intent decomposition for handling complex, ambiguous, multi-stage goals.
"""
import re
import json
import uuid
import asyncio
from typing import Dict, Any, List, Tuple, Optional, Set, Union
from datetime import datetime
from pathlib import Path

from pydantic import BaseModel, Field, ValidationError

from angela.ai.client import gemini_client, GeminiRequest
from angela.ai.semantic_analyzer import semantic_analyzer
from angela.context import context_manager
from angela.context.project_state_analyzer import project_state_analyzer
from angela.intent.enhanced_task_planner import EnhancedTaskPlanner, AdvancedTaskPlan, PlanStepType
from angela.utils.logging import get_logger
from angela.core.registry import registry
from angela.shell.inline_feedback import inline_feedback

logger = get_logger(__name__)

class IntentClarification(BaseModel):
    """Model for intent clarification information."""
    
    original_request: str = Field(..., description="The original user request")
    ambiguity_type: str = Field(..., description="Type of ambiguity detected")
    ambiguity_details: str = Field(..., description="Details about the ambiguity")
    clarification_question: str = Field(..., description="Question to ask the user")
    options: List[str] = Field(default_factory=list, description="Possible options to present to the user")
    context: Dict[str, Any] = Field(default_factory=dict, description="Context for resolving the ambiguity")


class SemanticTaskPlanner:
    """
    Enhanced task planner with semantic code understanding and improved intent decomposition.
    
    This class extends the existing EnhancedTaskPlanner with:
    1. Integration with semantic code analysis
    2. Improved handling of ambiguous requests
    3. Multi-stage goal decomposition with sub-goals
    4. Interactive clarification for uncertain intents
    """
    
    def __init__(self):
        """Initialize the semantic task planner."""
        self._logger = logger
        self._enhanced_planner = EnhancedTaskPlanner()
        self._clarification_handlers = {
            "file_reference": self._clarify_file_reference,
            "entity_reference": self._clarify_entity_reference,
            "action_type": self._clarify_action_type,
            "operation_scope": self._clarify_operation_scope,
            "step_ordering": self._clarify_step_ordering,
            "parameter_value": self._clarify_parameter_value
        }
    
    async def plan_task(
        self, 
        request: str, 
        context: Dict[str, Any],
        enable_clarification: bool = True,
        semantic_context: bool = True
    ) -> Dict[str, Any]:
        """
        Plan a task with semantic understanding and potential user clarification.
        
        Args:
            request: User request
            context: Task context
            enable_clarification: Whether to enable interactive clarification
            semantic_context: Whether to include semantic code understanding
            
        Returns:
            Dictionary with planning results including a task plan
        """
        self._logger.info(f"Planning semantic task: {request}")
        
        # Enhance context with semantic information if requested
        if semantic_context:
            context = await self._enhance_context_with_semantics(context)
        
        # First, analyze the request for potential ambiguities
        intent_analysis = await self._analyze_intent(request, context)
        
        # Check if clarification is needed and enabled
        if intent_analysis.get("needs_clarification", False) and enable_clarification:
            clarification = await self._create_clarification(request, intent_analysis, context)
            
            if clarification:
                # Get user clarification
                clarified_request = await self._get_user_clarification(clarification)
                
                if clarified_request:
                    # Update the request and intent analysis
                    self._logger.info(f"Using clarified request: {clarified_request}")
                    request = clarified_request
                    intent_analysis = await self._analyze_intent(request, context)
        
        # Decompose the goal into sub-goals if complex
        goal_decomposition = await self._decompose_goal(request, intent_analysis, context)
        
        # Create an execution plan
        plan_result = await self._create_execution_plan(request, goal_decomposition, context)
        
        # Return the planning results
        return {
            "original_request": request,
            "intent_analysis": intent_analysis,
            "goal_decomposition": goal_decomposition,
            "execution_plan": plan_result.get("plan"),
            "plan_type": plan_result.get("plan_type", "simple"),
            "plan_id": plan_result.get("plan_id"),
            "estimated_steps": plan_result.get("estimated_steps", 0),
            "max_risk_level": plan_result.get("max_risk_level", 0),
            "clarification_needed": intent_analysis.get("needs_clarification", False),
            "clarification_performed": intent_analysis.get("needs_clarification", False) and enable_clarification
        }
    
    async def execute_plan(
        self, 
        plan_result: Dict[str, Any],
        context: Dict[str, Any],
        dry_run: bool = False,
        transaction_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Execute a task plan generated by the semantic planner.
        
        Args:
            plan_result: Planning results from plan_task
            context: Task context
            dry_run: Whether to perform a dry run without making changes
            transaction_id: Optional transaction ID for rollback
            
        Returns:
            Dictionary with execution results
        """
        self._logger.info(f"Executing semantic task plan: {plan_result.get('original_request')}")
        
        # Get the execution plan
        execution_plan = plan_result.get("execution_plan")
        
        if not execution_plan:
            return {
                "success": False,
                "error": "No execution plan available",
                "plan_result": plan_result
            }
        
        # Execute the plan using the enhanced task planner
        execution_result = await self._enhanced_planner.execute_plan(
            plan=execution_plan,
            dry_run=dry_run,
            transaction_id=transaction_id
        )
        
        # Return the execution results
        return {
            "success": execution_result.get("success", False),
            "execution_result": execution_result,
            "plan_result": plan_result,
            "dry_run": dry_run
        }
    
    async def _analyze_intent(self, request: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """
        Analyze user intent with semantic understanding.
        
        Args:
            request: User request
            context: Task context
            
        Returns:
            Dictionary with intent analysis
        """
        self._logger.debug(f"Analyzing intent for request: {request}")
        
        # Create a prompt for the AI to analyze the intent
        project_context = self._extract_project_context(context)
        
        prompt = f"""
You are an expert assistant analyzing a user's request to an AI terminal assistant that can perform tasks using shell commands and code.

USER REQUEST: "{request}"

CONTEXT:
{project_context}

Provide a detailed analysis of the user's intent, including:
1. The primary goal they're trying to achieve
2. Required sub-tasks or steps
3. Entities involved (files, directories, commands, APIs)
4. Any potential ambiguities that need clarification 
5. Level of complexity (simple/moderate/complex)

Return your analysis as a JSON object with this structure:
```json
{{
  "primary_goal": "Clear description of the main objective",
  "intent_type": "One of: file_operation, code_generation, system_command, project_setup, information_request, refactoring",
  "entities": [
    {{ "type": "file|directory|command|api|code_entity", "name": "entity_name", "confidence": 0.0-1.0 }}
  ],
  "sub_tasks": [
    "Description of sub-task 1",
    "Description of sub-task 2"
  ],
  "needs_clarification": true|false,
  "ambiguities": [
    {{
      "type": "file_reference|entity_reference|action_type|operation_scope|step_ordering|parameter_value",
      "description": "Description of the ambiguity",
      "possible_interpretations": ["interpretation1", "interpretation2"]
    }}
  ],
  "complexity": "simple|moderate|complex",
  "estimated_steps": 1-20,
  "potential_risk": 0-4,
  "confidence": 0.0-1.0
}}
```

Use the highest standards for identifying ambiguities that would benefit from clarification. If anything is unclear, set "needs_clarification" to true and document the ambiguity.
"""
        
        # Call AI to analyze the intent
        api_request = GeminiRequest(
            prompt=prompt,
            temperature=0.1,  # Lower temperature for more deterministic analysis
            max_tokens=3000
        )
        
        response = await gemini_client.generate_text(api_request)
        
        # Parse the response
        try:
            # Try to extract JSON from the response
            response_text = response.text
            
            # Look for JSON block
            json_match = re.search(r'```(?:json)?\s*(.*?)\s*```', response_text, re.DOTALL)
            if json_match:
                response_text = json_match.group(1)
            
            # Try to parse the JSON
            intent_analysis = json.loads(response_text)
            
            # Add some metadata to the analysis
            intent_analysis["original_request"] = request
            intent_analysis["analysis_time"] = datetime.now().isoformat()
            
            return intent_analysis
            
        except (json.JSONDecodeError, IndexError) as e:
            self._logger.error(f"Error parsing intent analysis response: {str(e)}")
            
            # Return a basic fallback analysis
            return {
                "primary_goal": request,
                "intent_type": "unknown",
                "entities": [],
                "sub_tasks": [request],
                "needs_clarification": False,
                "ambiguities": [],
                "complexity": "simple",
                "estimated_steps": 1,
                "potential_risk": 0,
                "confidence": 0.5,
                "original_request": request,
                "analysis_time": datetime.now().isoformat(),
                "analysis_error": str(e)
            }
    
    def _extract_project_context(self, context: Dict[str, Any]) -> str:
        """
        Extract relevant project context for intent analysis.
        
        Args:
            context: Task context
            
        Returns:
            String with formatted project context
        """
        lines = []
        
        # Add current working directory
        if "cwd" in context:
            lines.append(f"Current Directory: {context['cwd']}")
        
        # Add project type if available
        if "project_type" in context:
            lines.append(f"Project Type: {context['project_type']}")
        
        # Add project root if available
        if "project_root" in context:
            lines.append(f"Project Root: {context['project_root']}")
        
        # Add enhanced project information if available
        if "enhanced_project" in context:
            enhanced_project = context["enhanced_project"]
            
            if "type" in enhanced_project:
                lines.append(f"Project Type: {enhanced_project['type']}")
            
            if "frameworks" in enhanced_project:
                frameworks = enhanced_project["frameworks"]
                if frameworks:
                    lines.append(f"Frameworks: {', '.join(frameworks.keys())}")
            
            if "dependencies" in enhanced_project and "top_dependencies" in enhanced_project["dependencies"]:
                deps = enhanced_project["dependencies"]["top_dependencies"]
                if deps:
                    lines.append(f"Top Dependencies: {', '.join(deps[:5])}")
        
        # Add recent file context if available
        if "recent_files" in context and "accessed" in context["recent_files"]:
            recent_files = context["recent_files"]["accessed"]
            if recent_files:
                lines.append(f"Recently Accessed Files: {', '.join([Path(f).name for f in recent_files[:3]])}")
        
        # Add resolved file references if available
        if "resolved_files" in context:
            resolved_files = context["resolved_files"]
            if resolved_files:
                lines.append("Resolved File References:")
                for ref_info in resolved_files:
                    lines.append(f"- '{ref_info['reference']}' → {ref_info['path']}")
        
        # Add semantic code information if available
        if "semantic_code" in context:
            semantic_code = context["semantic_code"]
            
            if "modules" in semantic_code:
                module_count = len(semantic_code["modules"])
                lines.append(f"Analyzed Code Modules: {module_count}")
            
            if "key_entities" in semantic_code:
                key_entities = semantic_code["key_entities"]
                if key_entities:
                    lines.append("Key Code Entities:")
                    for entity in key_entities[:5]:
                        lines.append(f"- {entity['type']} '{entity['name']}' in {Path(entity['filename']).name}")
        
        # Add project state information if available
        if "project_state" in context:
            project_state = context["project_state"]
            
            if "git_state" in project_state and project_state["git_state"].get("is_git_repo", False):
                git_state = project_state["git_state"]
                branch = git_state.get("current_branch", "unknown")
                has_changes = git_state.get("has_changes", False)
                
                git_info = f"Git: on branch '{branch}'"
                if has_changes:
                    git_info += " with uncommitted changes"
                
                lines.append(git_info)
            
            if "todo_items" in project_state and project_state["todo_items"]:
                todo_count = len(project_state["todo_items"])
                lines.append(f"Project TODOs: {todo_count} items")
        
        return "\n".join(lines)
    
    async def _create_clarification(
        self, 
        request: str, 
        intent_analysis: Dict[str, Any], 
        context: Dict[str, Any]
    ) -> Optional[IntentClarification]:
        """
        Create a clarification request for ambiguous intent.
        
        Args:
            request: Original user request
            intent_analysis: Intent analysis results
            context: Task context
            
        Returns:
            IntentClarification object or None if no clarification needed
        """
        if not intent_analysis.get("needs_clarification", False):
            return None
        
        ambiguities = intent_analysis.get("ambiguities", [])
        if not ambiguities:
            return None
        
        # Select the most important ambiguity to clarify
        # (for simplicity, just take the first one)
        ambiguity = ambiguities[0]
        
        ambiguity_type = ambiguity.get("type", "unknown")
        description = ambiguity.get("description", "")
        interpretations = ambiguity.get("possible_interpretations", [])
        
        # Select a clarification handler based on ambiguity type
        if ambiguity_type in self._clarification_handlers:
            return await self._clarification_handlers[ambiguity_type](
                request, ambiguity, interpretations, context
            )
        
        # Default clarification
        return IntentClarification(
            original_request=request,
            ambiguity_type=ambiguity_type,
            ambiguity_details=description,
            clarification_question=f"I'm not sure about this part of your request: {description}. Could you clarify?",
            options=interpretations,
            context={"ambiguity": ambiguity}
        )
    
    async def _get_user_clarification(self, clarification: IntentClarification) -> Optional[str]:
        """
        Get clarification from the user.
        
        Args:
            clarification: Clarification object
            
        Returns:
            Clarified request or None if clarification was not provided
        """
        self._logger.info(f"Getting user clarification for: {clarification.ambiguity_type}")
        
        try:
            # Check if inline_feedback is available
            if inline_feedback:
                question = clarification.clarification_question
                options = clarification.options
                
                if options:
                    # Present options for selection
                    response = await inline_feedback.ask_question(
                        question, 
                        choices=options,
                        allow_free_text=True
                    )
                else:
                    # Free-form response
                    response = await inline_feedback.ask_question(question)
                
                if response:
                    # Check if we need to create a new request or use the response as is
                    if clarification.ambiguity_type in ["file_reference", "entity_reference", "parameter_value"]:
                        # Just use the clarified response to update the original request
                        return self._update_request_with_clarification(
                            clarification.original_request, 
                            response, 
                            clarification
                        )
                    else:
                        # For other types, assume the response is a complete revised request
                        return response
                
            else:
                self._logger.warning("inline_feedback not available for clarification")
            
            return None
                
        except Exception as e:
            self._logger.error(f"Error getting user clarification: {str(e)}")
            return None
    
    def _update_request_with_clarification(
        self, 
        original_request: str, 
        clarification: str, 
        intent_clarification: IntentClarification
    ) -> str:
        """
        Update the original request with the clarified information.
        
        Args:
            original_request: Original user request
            clarification: User's clarification response
            intent_clarification: Original clarification object
            
        Returns:
            Updated request
        """
        ambiguity_type = intent_clarification.ambiguity_type
        
        if ambiguity_type == "file_reference":
            # Replace the ambiguous file reference with the clarified one
            context = intent_clarification.context
            if "file_reference" in context:
                ambiguous_ref = context["file_reference"]
                # Simple replacement (in practice, you might want a more sophisticated approach)
                return original_request.replace(ambiguous_ref, clarification)
            
        elif ambiguity_type == "entity_reference":
            # Replace the ambiguous entity reference with the clarified one
            context = intent_clarification.context
            if "entity_reference" in context:
                ambiguous_ref = context["entity_reference"]
                return original_request.replace(ambiguous_ref, clarification)
        
        elif ambiguity_type == "parameter_value":
            # Add or update the parameter value
            context = intent_clarification.context
            if "parameter_name" in context:
                param_name = context["parameter_name"]
                # Check if parameter already exists in the request
                if param_name in original_request:
                    # Try to update the existing parameter
                    param_pattern = f"{param_name}\\s*[=:]?\\s*\\S+"
                    updated = re.sub(
                        param_pattern, 
                        f"{param_name}={clarification}", 
                        original_request
                    )
                    if updated != original_request:
                        return updated
                
                # If not found or update failed, append the parameter
                return f"{original_request} {param_name}={clarification}"
        
        # For other types, or if the specific handling failed,
        # just append the clarification to the original request
        return f"{original_request} ({clarification})"
    
    async def _clarify_file_reference(
        self, 
        request: str, 
        ambiguity: Dict[str, Any], 
        interpretations: List[str], 
        context: Dict[str, Any]
    ) -> IntentClarification:
        """
        Create a clarification for ambiguous file references.
        
        Args:
            request: Original user request
            ambiguity: Ambiguity information
            interpretations: Possible interpretations
            context: Task context
            
        Returns:
            IntentClarification object
        """
        description = ambiguity.get("description", "")
        
        # Extract the ambiguous file reference
        file_reference = None
        
        # Try to find the ambiguous reference in the request
        match = re.search(r'(?:file|directory|folder|path|docs?)\s+["\']?([^"\']+)["\']?', description)
        if match:
            file_reference = match.group(1)
        
        # If not found, use a generic approach
        if not file_reference:
            # Use file_resolver to get possible matches
            from angela.context.file_resolver import file_resolver
            
            project_root = context.get("project_root")
            if project_root:
                # Get files in the project
                possible_files = await file_resolver.find_files(project_root)
                
                # Filter to the most relevant files based on the request
                relevant_files = []
                
                for file_path in possible_files:
                    # Check if any part of the file path appears in the request
                    file_parts = Path(file_path).parts
                    for part in file_parts:
                        if part in request:
                            relevant_files.append(str(file_path))
                            break
                
                # Limit to 5 options
                interpretations = [Path(f).name for f in relevant_files[:5]]
        
        # Create the clarification
        question = "Which file are you referring to?"
        if file_reference:
            question = f"I'm not sure which file '{file_reference}' refers to. Which one did you mean?"
        
        return IntentClarification(
            original_request=request,
            ambiguity_type="file_reference",
            ambiguity_details=description,
            clarification_question=question,
            options=interpretations,
            context={"file_reference": file_reference}
        )
    
    async def _clarify_entity_reference(
        self, 
        request: str, 
        ambiguity: Dict[str, Any], 
        interpretations: List[str], 
        context: Dict[str, Any]
    ) -> IntentClarification:
        """
        Create a clarification for ambiguous code entity references.
        
        Args:
            request: Original user request
            ambiguity: Ambiguity information
            interpretations: Possible interpretations
            context: Task context
            
        Returns:
            IntentClarification object
        """
        description = ambiguity.get("description", "")
        
        # Extract the ambiguous entity reference
        entity_reference = None
        
        # Try to find the ambiguous reference in the request
        match = re.search(r'(?:function|class|method|variable|object|module|component)\s+["\']?([^"\']+)["\']?', description)
        if match:
            entity_reference = match.group(1)
        
        # If semantic code information is available, try to find similar entities
        if "semantic_code" in context and entity_reference:
            semantic_code = context["semantic_code"]
            
            if "modules" in semantic_code:
                # Get all entities from the modules
                all_entities = []
                
                for module_info in semantic_code["modules"]:
                    # Add functions
                    for func_name in module_info.get("functions", {}):
                        all_entities.append({
                            "name": func_name,
                            "type": "function",
                            "file": module_info.get("filename")
                        })
                    
                    # Add classes
                    for class_name in module_info.get("classes", {}):
                        all_entities.append({
                            "name": class_name,
                            "type": "class",
                            "file": module_info.get("filename")
                        })
                        
                        # Add methods from the class
                        class_info = module_info.get("classes", {}).get(class_name, {})
                        for method_name in class_info.get("methods", {}):
                            all_entities.append({
                                "name": f"{class_name}.{method_name}",
                                "type": "method",
                                "file": module_info.get("filename")
                            })
                
                # Filter to entities with similar names
                import difflib
                
                similar_entities = []
                for entity in all_entities:
                    similarity = difflib.SequenceMatcher(None, entity_reference, entity["name"]).ratio()
                    if similarity > 0.6:
                        similar_entities.append(entity)
                
                # Sort by similarity
                similar_entities.sort(
                    key=lambda e: difflib.SequenceMatcher(None, entity_reference, e["name"]).ratio(),
                    reverse=True
                )
                
                # Update interpretations with the similar entities
                interpretations = [
                    f"{e['name']} ({e['type']} in {Path(e['file']).name})"
                    for e in similar_entities[:5]
                ]
        
        # Create the clarification
        question = "Which code entity are you referring to?"
        if entity_reference:
            question = f"I'm not sure which code entity '{entity_reference}' refers to. Which one did you mean?"
        
        return IntentClarification(
            original_request=request,
            ambiguity_type="entity_reference",
            ambiguity_details=description,
            clarification_question=question,
            options=interpretations,
            context={"entity_reference": entity_reference}
        )
    
    async def _clarify_action_type(
        self, 
        request: str, 
        ambiguity: Dict[str, Any], 
        interpretations: List[str], 
        context: Dict[str, Any]
    ) -> IntentClarification:
        """
        Create a clarification for ambiguous action types.
        
        Args:
            request: Original user request
            ambiguity: Ambiguity information
            interpretations: Possible interpretations
            context: Task context
            
        Returns:
            IntentClarification object
        """
        description = ambiguity.get("description", "")
        
        # If interpretations are provided, use them
        if not interpretations:
            # Default interpretations for action type
            interpretations = [
                "Show/display the content",
                "Edit/modify the content",
                "Create a new file/content",
                "Delete the file/content",
                "Analyze/examine the content"
            ]
        
        # Create the clarification
        question = f"I'm not sure what action you want to perform: {description}. What would you like to do?"
        
        return IntentClarification(
            original_request=request,
            ambiguity_type="action_type",
            ambiguity_details=description,
            clarification_question=question,
            options=interpretations,
            context={}
        )
    
    async def _clarify_operation_scope(
        self, 
        request: str, 
        ambiguity: Dict[str, Any], 
        interpretations: List[str], 
        context: Dict[str, Any]
    ) -> IntentClarification:
        """
        Create a clarification for ambiguous operation scopes.
        
        Args:
            request: Original user request
            ambiguity: Ambiguity information
            interpretations: Possible interpretations
            context: Task context
            
        Returns:
            IntentClarification object
        """
        description = ambiguity.get("description", "")
        
        # If interpretations are provided, use them
        if not interpretations:
            # Default interpretations for operation scope
            interpretations = [
                "Only the current file",
                "The entire directory",
                "All files matching a pattern",
                "The specific files mentioned",
                "The entire project"
            ]
        
        # Create the clarification
        question = f"I'm not sure about the scope of this operation: {description}. What scope do you want to apply?"
        
        return IntentClarification(
            original_request=request,
            ambiguity_type="operation_scope",
            ambiguity_details=description,
            clarification_question=question,
            options=interpretations,
            context={}
        )
    
    async def _clarify_step_ordering(
        self, 
        request: str, 
        ambiguity: Dict[str, Any], 
        interpretations: List[str], 
        context: Dict[str, Any]
    ) -> IntentClarification:
        """
        Create a clarification for ambiguous step ordering.
        
        Args:
            request: Original user request
            ambiguity: Ambiguity information
            interpretations: Possible interpretations
            context: Task context
            
        Returns:
            IntentClarification object
        """
        description = ambiguity.get("description", "")
        
        # Extract the conflicting steps if possible
        step1 = None
        step2 = None
        
        match = re.search(r'([^\s,]+)\s+(?:before|after)\s+([^\s,]+)', description)
        if match:
            step1 = match.group(1)
            step2 = match.group(2)
        
        # Create interpretations if not provided
        if not interpretations and step1 and step2:
            interpretations = [
                f"Do {step1} first, then {step2}",
                f"Do {step2} first, then {step1}",
                f"Do {step1} and {step2} in parallel",
                f"Only do {step1}, skip {step2}",
                f"Only do {step2}, skip {step1}"
            ]
        elif not interpretations:
            # Generic interpretations
            interpretations = [
                "Follow the steps in the order listed",
                "Reverse the order of steps",
                "Only do the first step",
                "Only do the last step",
                "Skip steps that seem risky"
            ]
        
        # Create the clarification
        question = f"I'm not sure about the order of steps: {description}. How should I proceed?"
        
        return IntentClarification(
            original_request=request,
            ambiguity_type="step_ordering",
            ambiguity_details=description,
            clarification_question=question,
            options=interpretations,
            context={"step1": step1, "step2": step2}
        )
    
    async def _clarify_parameter_value(
        self, 
        request: str, 
        ambiguity: Dict[str, Any], 
        interpretations: List[str], 
        context: Dict[str, Any]
    ) -> IntentClarification:
        """
        Create a clarification for ambiguous parameter values.
        
        Args:
            request: Original user request
            ambiguity: Ambiguity information
            interpretations: Possible interpretations
            context: Task context
            
        Returns:
            IntentClarification object
        """
        description = ambiguity.get("description", "")
        
        # Extract the parameter name if available
        param_name = None
        
        match = re.search(r'parameter\s+["\']?([^"\']+)["\']?', description)
        if match:
            param_name = match.group(1)
        
        # If not found through "parameter", try "value"
        if not param_name:
            match = re.search(r'value\s+(?:for|of)\s+["\']?([^"\']+)["\']?', description)
            if match:
                param_name = match.group(1)
        
        # Create the clarification
        question = f"I need a value for the parameter: {param_name or description}. What should it be?"
        
        return IntentClarification(
            original_request=request,
            ambiguity_type="parameter_value",
            ambiguity_details=description,
            clarification_question=question,
            options=interpretations,
            context={"parameter_name": param_name}
        )
    
    async def _decompose_goal(
        self, 
        request: str, 
        intent_analysis: Dict[str, Any], 
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Decompose a complex goal into sub-goals.
        
        Args:
            request: User request
            intent_analysis: Intent analysis results
            context: Task context
            
        Returns:
            Dictionary with goal decomposition
        """
        # If the intent is already simple, no need to decompose
        if intent_analysis.get("complexity", "simple") == "simple":
            return {
                "main_goal": intent_analysis.get("primary_goal", request),
                "complexity": "simple",
                "sub_goals": [intent_analysis.get("primary_goal", request)],
                "sequential": True
            }
        
        # Start with the sub-tasks from the intent analysis
        sub_tasks = intent_analysis.get("sub_tasks", [])
        
        # For complex intentions, do a more detailed decomposition
        if intent_analysis.get("complexity", "simple") == "complex" or len(sub_tasks) < 2:
            # Create a prompt for the AI to decompose the goal
            prompt = f"""
You need to decompose a complex user request into clear, logical sub-goals that can be executed sequentially or in parallel.

USER REQUEST: "{request}"

ANALYZED INTENT:
- Primary Goal: {intent_analysis.get("primary_goal", request)}
- Intent Type: {intent_analysis.get("intent_type", "unknown")}
- Complexity: {intent_analysis.get("complexity", "complex")}

Break this request down into 2-7 clear, logical sub-goals that together will accomplish the main goal.
For each sub-goal, indicate:
1. A clear description of what needs to be done
2. Whether it depends on other sub-goals
3. The estimated complexity (simple, moderate, complex)

Return your decomposition as a JSON object with this structure:
```json
{{
  "main_goal": "Clear description of the main objective",
  "complexity": "complex|moderate",
  "sub_goals": [
    {{
      "id": "sg1",
      "description": "Sub-goal description",
      "dependencies": ["sg0"],
      "complexity": "simple|moderate|complex",
      "estimated_steps": 1-5
    }}
  ],
  "sequential": true|false,
  "explanation": "Brief explanation of the decomposition approach"
}}
```

If the goals must be executed in a specific order, set "sequential" to true and ensure the sub_goals are in the correct execution order.
If some goals can be executed in parallel, set "sequential" to false and use dependencies to indicate required ordering.
"""
            
            # Call AI to decompose the goal
            api_request = GeminiRequest(
                prompt=prompt,
                temperature=0.2,
                max_tokens=3000
            )
            
            response = await gemini_client.generate_text(api_request)
            
            # Parse the response
            try:
                # Try to extract JSON from the response
                response_text = response.text
                
                # Look for JSON block
                json_match = re.search(r'```(?:json)?\s*(.*?)\s*```', response_text, re.DOTALL)
                if json_match:
                    response_text = json_match.group(1)
                
                # Try to parse the JSON
                decomposition = json.loads(response_text)
                
                # Add some metadata to the decomposition
                decomposition["original_request"] = request
                decomposition["intent_type"] = intent_analysis.get("intent_type", "unknown")
                
                return decomposition
                
            except (json.JSONDecodeError, IndexError) as e:
                self._logger.error(f"Error parsing goal decomposition response: {str(e)}")
        
        # If we get here, use a simple decomposition based on the intent analysis
        return {
            "main_goal": intent_analysis.get("primary_goal", request),
            "complexity": intent_analysis.get("complexity", "moderate"),
            "sub_goals": [
                {
                    "id": f"sg{i}",
                    "description": sub_task,
                    "dependencies": [] if i == 0 else [f"sg{i-1}"],
                    "complexity": "simple",
                    "estimated_steps": 1
                }
                for i, sub_task in enumerate(sub_tasks)
            ],
            "sequential": True,
            "explanation": "Simple sequential decomposition based on intent analysis",
            "original_request": request,
            "intent_type": intent_analysis.get("intent_type", "unknown")
        }
    
    async def _create_execution_plan(
        self, 
        request: str, 
        goal_decomposition: Dict[str, Any], 
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Create an execution plan for the decomposed goal.
        
        Args:
            request: User request
            goal_decomposition: Goal decomposition
            context: Task context
            
        Returns:
            Dictionary with plan creation results
        """
        # For simple goals, use basic planning
        if goal_decomposition.get("complexity", "simple") == "simple":
            # Call the enhanced planner directly
            plan = await self._enhanced_planner.plan_task(
                request=request,
                context=context,
                complexity="auto"
            )
            
            return {
                "plan": plan,
                "plan_type": "simple",
                "plan_id": getattr(plan, "id", str(uuid.uuid4())),
                "estimated_steps": len(getattr(plan, "steps", [])),
                "max_risk_level": max(
                    [getattr(step, "estimated_risk", 0) for step in getattr(plan, "steps", {}).values()],
                    default=0
                ) if hasattr(plan, "steps") else 0
            }
        
        # For complex goals, create a more sophisticated plan
        # This is where we'd build a more complex execution plan
        # based on the goal decomposition
        
        # Extract the sub-goals
        sub_goals = goal_decomposition.get("sub_goals", [])
        sequential = goal_decomposition.get("sequential", True)
        
        if sequential:
            # For sequential execution, create a single plan with all steps
            combined_request = f"{request}\n\nExecute these steps in order:\n"
            for i, sub_goal in enumerate(sub_goals):
                combined_request += f"{i+1}. {sub_goal.get('description', '')}\n"
            
            plan = await self._enhanced_planner.plan_task(
                request=combined_request,
                context=context,
                complexity="advanced"
            )
            
            return {
                "plan": plan,
                "plan_type": "advanced_sequential",
                "plan_id": getattr(plan, "id", str(uuid.uuid4())),
                "estimated_steps": len(getattr(plan, "steps", [])),
                "max_risk_level": max(
                    [getattr(step, "estimated_risk", 0) for step in getattr(plan, "steps", {}).values()],
                    default=0
                ) if hasattr(plan, "steps") else 0
            }
            
        else:
            # For non-sequential execution, create a plan with dependencies
            # This requires a more sophisticated planning approach
            # that accounts for the dependencies between sub-goals
            
            # Generate a dependency-aware prompt
            dependency_prompt = f"{request}\n\nExecute these steps with the following dependencies:\n"
            for sub_goal in sub_goals:
                sg_id = sub_goal.get("id", "")
                description = sub_goal.get("description", "")
                dependencies = sub_goal.get("dependencies", [])
                
                if dependencies:
                    dependency_prompt += f"- {description} (depends on: {', '.join(dependencies)})\n"
                else:
                    dependency_prompt += f"- {description} (no dependencies)\n"
            
            plan = await self._enhanced_planner.plan_task(
                request=dependency_prompt,
                context=context,
                complexity="advanced"
            )
            
            return {
                "plan": plan,
                "plan_type": "advanced_dependency",
                "plan_id": getattr(plan, "id", str(uuid.uuid4())),
                "estimated_steps": len(getattr(plan, "steps", [])),
                "max_risk_level": max(
                    [getattr(step, "estimated_risk", 0) for step in getattr(plan, "steps", {}).values()],
                    default=0
                ) if hasattr(plan, "steps") else 0
            }
    
    async def _enhance_context_with_semantics(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """
        Enhance context with semantic code information.
        
        Args:
            context: Task context
            
        Returns:
            Enhanced context
        """
        enhanced_context = dict(context)
        
        # Check if project root is available
        project_root = context.get("project_root")
        if not project_root:
            return enhanced_context
        
        try:
            # Add semantic code information
            semantic_info = {
                "modules": [],
                "key_entities": []
            }
            
            # Get recently accessed files from context
            recent_files = []
            if "recent_files" in context and "accessed" in context["recent_files"]:
                recent_files = context["recent_files"]["accessed"]
            
            # Prioritize recently accessed files for semantic analysis
            for file_path in recent_files[:3]:  # Limit to 3 for performance
                module = await semantic_analyzer.analyze_file(file_path)
                if module:
                    semantic_info["modules"].append(module.get_summary())
                    
                    # Add key entities from this module
                    for func_name, func in module.functions.items():
                        semantic_info["key_entities"].append({
                            "name": func_name,
                            "type": "function",
                            "filename": func.filename,
                            "line_start": func.line_start,
                            "line_end": func.line_end
                        })
                    
                    for class_name, cls in module.classes.items():
                        semantic_info["key_entities"].append({
                            "name": class_name,
                            "type": "class",
                            "filename": cls.filename,
                            "line_start": cls.line_start,
                            "line_end": cls.line_end
                        })
            
            # Add project state information
            project_state = await project_state_analyzer.get_project_state(project_root)
            
            # Add the semantic information and project state to the context
            enhanced_context["semantic_code"] = semantic_info
            enhanced_context["project_state"] = project_state
            
            return enhanced_context
            
        except Exception as e:
            self._logger.error(f"Error enhancing context with semantics: {str(e)}")
            return enhanced_context

# Global semantic task planner instance
semantic_task_planner = SemanticTaskPlanner()
</file>

<file path="angela/interfaces/__init__.py">
# angela/interfaces/__init__.py
"""Interfaces for Angela CLI components."""
</file>

<file path="angela/interfaces/execution.py">
# angela/interfaces/execution.py
"""Interfaces for execution components."""
from abc import ABC, abstractmethod
from typing import Dict, Any, Optional, Tuple

class CommandExecutor(ABC):
    """Interface for command execution."""
    
    @abstractmethod
    async def execute_command(
        self,
        command: str,
        check_safety: bool = True,
        dry_run: bool = False
    ) -> Tuple[str, str, int]:
        """
        Execute a shell command and return its output.
        
        Args:
            command: The shell command to execute
            check_safety: Whether to perform safety checks
            dry_run: Whether to simulate execution
            
        Returns:
            Tuple of (stdout, stderr, return_code)
        """
        pass

class AdaptiveExecutor(ABC):
    """Interface for adaptive command execution."""
    
    @abstractmethod
    async def execute_command(
        self,
        command: str,
        natural_request: str,
        explanation: Optional[str] = None,
        dry_run: bool = False
    ) -> Dict[str, Any]:
        """
        Execute a command with adaptive behavior.
        
        Args:
            command: The command to execute
            natural_request: The original natural language request
            explanation: AI explanation of what the command does
            dry_run: Whether to simulate the command without execution
            
        Returns:
            Dictionary with execution results
        """
        pass
</file>

<file path="angela/interfaces/safety.py">
# angela/interfaces/safety.py
"""Interfaces for safety components."""
from abc import ABC, abstractmethod
from typing import Dict, Any, Tuple

class SafetyValidator(ABC):
    """Interface for safety validation."""
    
    @abstractmethod
    async def check_command_safety(self, command: str, dry_run: bool = False) -> bool:
        """
        Check if a command is safe to execute.
        
        Args:
            command: The shell command to check
            dry_run: Whether this is a dry run
            
        Returns:
            True if the command is safe and confirmed, False otherwise
        """
        pass

    @abstractmethod
    def validate_command_safety(self, command: str) -> Tuple[bool, str]:
        """
        Validate a command against safety rules.
        
        Args:
            command: The shell command to validate
            
        Returns:
            A tuple of (is_valid, error_message or None)
        """
        pass
</file>

<file path="angela/monitoring/__init__.py">
"""
Monitoring and proactive assistance for Angela CLI.

This package provides background monitoring capabilities that allow Angela
to offer proactive suggestions and assistance based on system state.
"""

from angela.monitoring.background import background_monitor
</file>

<file path="angela/monitoring/network_monitor.py">
# angela/monitoring/network_monitor.py

import asyncio
import time
import socket
import os
import re
import json
from pathlib import Path
from typing import Dict, Any, List, Set, Optional, Tuple
from datetime import datetime, timedelta

from angela.config import config_manager
from angela.utils.logging import get_logger
from angela.shell.formatter import terminal_formatter
from angela.context import context_manager

logger = get_logger(__name__)

class NetworkMonitor:
    """
    Network monitoring for services, dependencies, and connections.
    
    Monitors:
    1. Local service health (e.g., web servers, databases)
    2. External API status
    3. Network connectivity
    4. Dependency update availability
    """
    
    def __init__(self):
        """Initialize the network monitor."""
        self._logger = logger
        self._monitoring_tasks = set()
        self._monitoring_active = False
        self._suggestions = set()
        self._last_suggestion_time = datetime.now() - timedelta(hours=1)
        self._suggestion_cooldown = timedelta(minutes=15)
        
    def start_monitoring(self):
        """Start network monitoring tasks."""
        if self._monitoring_active:
            return
            
        self._monitoring_active = True
        
        # Create and start monitoring tasks
        self._create_monitoring_task(self._monitor_local_services(), "local_services")
        self._create_monitoring_task(self._monitor_dependency_updates(), "dependency_updates")
        self._create_monitoring_task(self._monitor_network_connectivity(), "network_connectivity")
        
        self._logger.info("Network monitoring started")
    
    def stop_monitoring(self):
        """Stop all network monitoring tasks."""
        if not self._monitoring_active:
            return
            
        self._monitoring_active = False
        
        # Cancel all running tasks
        for task in self._monitoring_tasks:
            if not task.done():
                task.cancel()
                
        self._monitoring_tasks.clear()
        self._logger.info("Network monitoring stopped")
    
    def _create_monitoring_task(self, coro, name):
        """Create and start a monitoring task."""
        task = asyncio.create_task(self._run_monitoring_task(coro, name))
        self._monitoring_tasks.add(task)
        task.add_done_callback(self._monitoring_tasks.discard)
    
    async def _run_monitoring_task(self, coro, name):
        """Run a monitoring task with error handling."""
        try:
            await coro
        except asyncio.CancelledError:
            self._logger.debug(f"Network monitoring task {name} cancelled")
        except Exception as e:
            self._logger.exception(f"Error in network monitoring task {name}: {str(e)}")
            
            # Restart the task after a delay
            await asyncio.sleep(60)
            if self._monitoring_active:
                self._logger.info(f"Restarting network monitoring task {name}")
                if name == "local_services":
                    self._create_monitoring_task(self._monitor_local_services(), name)
                elif name == "dependency_updates":
                    self._create_monitoring_task(self._monitor_dependency_updates(), name)
                elif name == "network_connectivity":
                    self._create_monitoring_task(self._monitor_network_connectivity(), name)
    
    async def _monitor_local_services(self):
        """Monitor local services like web servers and databases."""
        self._logger.debug("Starting local services monitoring")
        
        # Track service status to detect changes
        service_status = {}
        
        while self._monitoring_active:
            try:
                # Get current project context
                context = context_manager.get_context_dict()
                project_type = context.get("project_type")
                
                # Detect potential services based on project type
                services_to_check = self._detect_project_services(project_type)
                
                # Check each service
                for service_name, service_info in services_to_check.items():
                    status = await self._check_service_status(service_info)
                    
                    # Compare with previous status
                    prev_status = service_status.get(service_name, {}).get("status")
                    if prev_status is not None and prev_status != status["status"]:
                        # Status changed
                        if status["status"] == "down" and self._can_show_suggestion():
                            suggestion = f"Service '{service_name}' appears to be down. {status.get('message', '')}"
                            terminal_formatter.print_proactive_suggestion(suggestion, "Network Monitor")
                            self._last_suggestion_time = datetime.now()
                    
                    # Update status
                    service_status[service_name] = status
                
                # Wait before checking again
                await asyncio.sleep(60)
                
            except Exception as e:
                self._logger.exception(f"Error monitoring local services: {str(e)}")
                await asyncio.sleep(120)  # Wait before retrying
    
    async def _monitor_dependency_updates(self):
        """Monitor for available updates to project dependencies."""
        self._logger.debug("Starting dependency updates monitoring")
        
        # Track which dependencies we've already notified about
        notified_updates = set()
        
        while self._monitoring_active:
            try:
                # Get current project context
                context = context_manager.get_context_dict()
                project_root = context.get("project_root")
                project_type = context.get("project_type")
                
                if not project_root:
                    # No project detected, sleep and try again later
                    await asyncio.sleep(3600)  # Check every hour
                    continue
                
                # Check dependencies based on project type
                if project_type == "python":
                    updates = await self._check_python_dependencies(Path(project_root))
                elif project_type == "node":
                    updates = await self._check_node_dependencies(Path(project_root))
                else:
                    # Unknown project type, sleep and try again later
                    await asyncio.sleep(3600)
                    continue
                
                # Notify about new updates
                if updates and self._can_show_suggestion():
                    # Filter out already notified updates
                    new_updates = [u for u in updates if f"{u['name']}:{u['new_version']}" not in notified_updates]
                    
                    if new_updates:
                        count = len(new_updates)
                        pkg_list = ", ".join([f"{u['name']} ({u['current_version']} → {u['new_version']})" 
                                             for u in new_updates[:3]])
                        more = f" and {count - 3} more" if count > 3 else ""
                        
                        suggestion = f"Found {count} dependency updates available: {pkg_list}{more}"
                        terminal_formatter.print_proactive_suggestion(suggestion, "Dependency Monitor")
                        
                        # Mark as notified
                        for update in new_updates:
                            notified_updates.add(f"{update['name']}:{update['new_version']}")
                        
                        self._last_suggestion_time = datetime.now()
                
                # Wait before checking again (dependencies don't change often)
                await asyncio.sleep(86400)  # Check once per day
                
            except Exception as e:
                self._logger.exception(f"Error monitoring dependency updates: {str(e)}")
                await asyncio.sleep(3600)  # Wait before retrying
    
    async def _monitor_network_connectivity(self):
        """Monitor network connectivity to important services."""
        self._logger.debug("Starting network connectivity monitoring")
        
        # Track connectivity status to detect changes
        connectivity_status = {
            "internet": True,  # Assume connected initially
            "last_check": datetime.now()
        }
        
        while self._monitoring_active:
            try:
                # Check internet connectivity
                internet_status = await self._check_internet_connectivity()
                
                # Check if status changed
                if connectivity_status["internet"] != internet_status["connected"]:
                    if not internet_status["connected"] and self._can_show_suggestion():
                        suggestion = f"Internet connectivity appears to be down. {internet_status.get('message', '')}"
                        terminal_formatter.print_proactive_suggestion(suggestion, "Network Monitor")
                        self._last_suggestion_time = datetime.now()
                    elif internet_status["connected"] and not connectivity_status["internet"]:
                        # Internet connection restored
                        elapsed = datetime.now() - connectivity_status["last_check"]
                        if elapsed > timedelta(minutes=5) and self._can_show_suggestion():
                            suggestion = "Internet connectivity has been restored."
                            terminal_formatter.print_proactive_suggestion(suggestion, "Network Monitor")
                            self._last_suggestion_time = datetime.now()
                
                # Update status
                connectivity_status["internet"] = internet_status["connected"]
                connectivity_status["last_check"] = datetime.now()
                
                # Wait before checking again
                await asyncio.sleep(30)
                
            except Exception as e:
                self._logger.exception(f"Error monitoring network connectivity: {str(e)}")
                await asyncio.sleep(60)  # Wait before retrying
    
    def _detect_project_services(self, project_type: Optional[str]) -> Dict[str, Dict[str, Any]]:
        """
        Detect services to monitor based on project type.
        
        Args:
            project_type: The type of project
            
        Returns:
            Dictionary of service information
        """
        services = {}
        
        # Default services to check
        services["localhost:8000"] = {
            "host": "localhost",
            "port": 8000,
            "name": "Web Server (8000)",
            "type": "http"
        }
        
        # Add services based on project type
        if project_type == "node":
            services["localhost:3000"] = {
                "host": "localhost",
                "port": 3000,
                "name": "Node.js Server",
                "type": "http"
            }
        elif project_type == "python":
            services["localhost:5000"] = {
                "host": "localhost",
                "port": 5000,
                "name": "Flask Server",
                "type": "http"
            }
            services["localhost:8000"] = {
                "host": "localhost",
                "port": 8000,
                "name": "Django Server",
                "type": "http"
            }
        
        # Always check database ports
        services["localhost:5432"] = {
            "host": "localhost",
            "port": 5432,
            "name": "PostgreSQL",
            "type": "tcp"
        }
        services["localhost:3306"] = {
            "host": "localhost",
            "port": 3306,
            "name": "MySQL",
            "type": "tcp"
        }
        services["localhost:27017"] = {
            "host": "localhost",
            "port": 27017,
            "name": "MongoDB",
            "type": "tcp"
        }
        services["localhost:6379"] = {
            "host": "localhost",
            "port": 6379,
            "name": "Redis",
            "type": "tcp"
        }
        
        return services
    
    async def _check_service_status(self, service_info: Dict[str, Any]) -> Dict[str, Any]:
        """
        Check the status of a service.
        
        Args:
            service_info: Service information
            
        Returns:
            Status information
        """
        host = service_info.get("host", "localhost")
        port = service_info.get("port", 80)
        service_type = service_info.get("type", "tcp")
        
        # Basic port check
        try:
            # Create a socket
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(2.0)  # 2 second timeout
            
            # Try to connect
            result = sock.connect_ex((host, port))
            sock.close()
            
            if result == 0:
                # Port is open
                if service_type == "http":
                    # For HTTP services, try to get a response
                    try:
                        import aiohttp
                        async with aiohttp.ClientSession() as session:
                            async with session.get(f"http://{host}:{port}/", timeout=5) as response:
                                if response.status < 400:
                                    return {"status": "up", "message": f"HTTP status: {response.status}"}
                                else:
                                    return {"status": "error", "message": f"HTTP error: {response.status}"}
                    except Exception as e:
                        return {"status": "error", "message": f"HTTP error: {str(e)}"}
                else:
                    # TCP service is up
                    return {"status": "up", "message": "Port is open"}
            else:
                # Port is closed
                return {"status": "down", "message": "Port is closed"}
                
        except Exception as e:
            return {"status": "error", "message": f"Error checking service: {str(e)}"}
    
    async def _check_python_dependencies(self, project_root: Path) -> List[Dict[str, Any]]:
        """
        Check for updates to Python dependencies.
        
        Args:
            project_root: The project root directory
            
        Returns:
            List of available updates
        """
        requirements_path = project_root / "requirements.txt"
        
        if not requirements_path.exists():
            return []
        
        try:
            # Run pip list --outdated
            result = await self._run_command("pip list --outdated --format=json")
            
            if not result["success"]:
                return []
                
            # Parse the output
            outdated = json.loads(result["stdout"])
            
            # Format the updates
            updates = []
            for pkg in outdated:
                updates.append({
                    "name": pkg["name"],
                    "current_version": pkg["version"],
                    "new_version": pkg["latest_version"],
                    "type": "python"
                })
                
            return updates
            
        except Exception as e:
            self._logger.error(f"Error checking Python dependencies: {str(e)}")
            return []
    
    async def _check_node_dependencies(self, project_root: Path) -> List[Dict[str, Any]]:
        """
        Check for updates to Node.js dependencies.
        
        Args:
            project_root: The project root directory
            
        Returns:
            List of available updates
        """
        package_json_path = project_root / "package.json"
        
        if not package_json_path.exists():
            return []
        
        try:
            # Run npm outdated --json
            result = await self._run_command("npm outdated --json", cwd=str(project_root))
            
            if not result["success"] and not result["stdout"]:
                return []
                
            # Parse the output
            try:
                outdated = json.loads(result["stdout"])
            except json.JSONDecodeError:
                # npm outdated returns non-zero exit code when updates are available
                if not result["stdout"]:
                    return []
                outdated = {}
            
            # Format the updates
            updates = []
            for pkg_name, pkg_info in outdated.items():
                updates.append({
                    "name": pkg_name,
                    "current_version": pkg_info.get("current", "unknown"),
                    "new_version": pkg_info.get("latest", "unknown"),
                    "type": "npm"
                })
                
            return updates
            
        except Exception as e:
            self._logger.error(f"Error checking Node.js dependencies: {str(e)}")
            return []
    
    async def _check_internet_connectivity(self) -> Dict[str, Any]:
        """
        Check internet connectivity.
        
        Returns:
            Status information
        """
        # List of reliable domains to check
        check_domains = [
            "google.com",
            "cloudflare.com",
            "amazon.com",
            "microsoft.com"
        ]
        
        successes = 0
        failures = 0
        
        for domain in check_domains:
            try:
                # Try to resolve the domain
                await asyncio.get_event_loop().getaddrinfo(domain, 80)
                successes += 1
            except socket.gaierror:
                failures += 1
        
        # Consider internet connected if at least half of the checks succeeded
        connected = successes >= len(check_domains) / 2
        
        return {
            "connected": connected,
            "message": f"{successes}/{len(check_domains)} connectivity checks succeeded"
        }
    
    async def _run_command(self, command: str, cwd: Optional[str] = None) -> Dict[str, Any]:
        """
        Run a shell command and return its output.
        
        Args:
            command: The command to run
            cwd: Optional working directory
            
        Returns:
            Dictionary with command results
        """
        try:
            process = await asyncio.create_subprocess_shell(
                command,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
                cwd=cwd
            )
            
            stdout, stderr = await process.communicate()
            
            return {
                "command": command,
                "stdout": stdout.decode('utf-8', errors='replace'),
                "stderr": stderr.decode('utf-8', errors='replace'),
                "return_code": process.returncode,
                "success": process.returncode == 0
            }
        except Exception as e:
            self._logger.error(f"Error running command '{command}': {str(e)}")
            return {
                "command": command,
                "stdout": "",
                "stderr": str(e),
                "return_code": -1,
                "success": False
            }
    
    def _can_show_suggestion(self) -> bool:
        """
        Check if we can show a suggestion now (respecting cooldown period).
        
        Returns:
            True if a suggestion can be shown, False otherwise
        """
        now = datetime.now()
        return (now - self._last_suggestion_time) >= self._suggestion_cooldown

# Global network monitor instance
network_monitor = NetworkMonitor()
</file>

<file path="angela/review/diff_manager.py">
# angela/review/diff_manager.py
"""
Diff management for Angela CLI.

This module provides functionality for managing and presenting diffs
between original and modified code.
"""
import os
import difflib
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple, Union

from angela.utils.logging import get_logger

logger = get_logger(__name__)

class DiffManager:
    """
    Manager for generating and displaying code diffs.
    """
    
    def __init__(self):
        """Initialize the diff manager."""
        self._logger = logger
    
    def generate_diff(
        self, 
        original: str, 
        modified: str, 
        context_lines: int = 3
    ) -> str:
        """
        Generate a unified diff between original and modified content.
        
        Args:
            original: Original content
            modified: Modified content
            context_lines: Number of context lines to include
            
        Returns:
            Unified diff string
        """
        self._logger.debug("Generating diff")
        
        # Split content into lines
        original_lines = original.splitlines(keepends=True)
        modified_lines = modified.splitlines(keepends=True)
        
        # Generate unified diff
        diff = difflib.unified_diff(
            original_lines, 
            modified_lines,
            fromfile='original',
            tofile='modified',
            n=context_lines
        )
        
        return ''.join(diff)
    
    def generate_html_diff(
        self, 
        original: str, 
        modified: str, 
        context_lines: int = 3
    ) -> str:
        """
        Generate an HTML diff between original and modified content.
        
        Args:
            original: Original content
            modified: Modified content
            context_lines: Number of context lines to include
            
        Returns:
            HTML diff string
        """
        self._logger.debug("Generating HTML diff")
        
        # Split content into lines
        original_lines = original.splitlines()
        modified_lines = modified.splitlines()
        
        # Generate HTML diff
        diff = difflib.HtmlDiff().make_file(
            original_lines, 
            modified_lines,
            fromdesc='Original',
            todesc='Modified',
            context=True,
            numlines=context_lines
        )
        
        return diff
    
    def generate_file_diff(
        self, 
        original_file: Union[str, Path], 
        modified_file: Union[str, Path],
        context_lines: int = 3
    ) -> str:
        """
        Generate a unified diff between original and modified files.
        
        Args:
            original_file: Path to original file
            modified_file: Path to modified file
            context_lines: Number of context lines to include
            
        Returns:
            Unified diff string
        """
        self._logger.debug(f"Generating diff between {original_file} and {modified_file}")
        
        # Read file contents
        try:
            with open(original_file, 'r', encoding='utf-8', errors='replace') as f:
                original_content = f.read()
            
            with open(modified_file, 'r', encoding='utf-8', errors='replace') as f:
                modified_content = f.read()
            
            # Generate diff
            return self.generate_diff(
                original_content, 
                modified_content,
                context_lines
            )
        except Exception as e:
            self._logger.error(f"Error generating file diff: {str(e)}")
            return f"Error generating diff: {str(e)}"
    
    def generate_directory_diff(
        self, 
        original_dir: Union[str, Path], 
        modified_dir: Union[str, Path],
        context_lines: int = 3
    ) -> Dict[str, str]:
        """
        Generate diffs for all files in two directories.
        
        Args:
            original_dir: Path to original directory
            modified_dir: Path to modified directory
            context_lines: Number of context lines to include
            
        Returns:
            Dictionary mapping file paths to diffs
        """
        self._logger.debug(f"Generating diffs between {original_dir} and {modified_dir}")
        
        original_dir = Path(original_dir)
        modified_dir = Path(modified_dir)
        
        # Check if directories exist
        if not original_dir.exists() or not original_dir.is_dir():
            self._logger.error(f"Original directory does not exist: {original_dir}")
            return {}
        
        if not modified_dir.exists() or not modified_dir.is_dir():
            self._logger.error(f"Modified directory does not exist: {modified_dir}")
            return {}
        
        # Find all files in both directories
        original_files = set()
        modified_files = set()
        
        for root, _, files in os.walk(original_dir):
            for file in files:
                file_path = Path(root) / file
                rel_path = file_path.relative_to(original_dir)
                original_files.add(str(rel_path))
        
        for root, _, files in os.walk(modified_dir):
            for file in files:
                file_path = Path(root) / file
                rel_path = file_path.relative_to(modified_dir)
                modified_files.add(str(rel_path))
        
        # Generate diffs for all files
        diffs = {}
        
        # Files in both directories
        for rel_path in original_files.intersection(modified_files):
            original_file = original_dir / rel_path
            modified_file = modified_dir / rel_path
            
            try:
                diff = self.generate_file_diff(
                    original_file, 
                    modified_file,
                    context_lines
                )
                
                # Only include if there are differences
                if diff:
                    diffs[rel_path] = diff
            except Exception as e:
                self._logger.error(f"Error generating diff for {rel_path}: {str(e)}")
        
        # Files only in original directory (deleted)
        for rel_path in original_files - modified_files:
            original_file = original_dir / rel_path
            
            try:
                with open(original_file, 'r', encoding='utf-8', errors='replace') as f:
                    content = f.read()
                
                # Generate diff showing deletion
                diff = self.generate_diff(content, '')
                diffs[rel_path] = diff
            except Exception as e:
                self._logger.error(f"Error generating diff for {rel_path}: {str(e)}")
        
        # Files only in modified directory (added)
        for rel_path in modified_files - original_files:
            modified_file = modified_dir / rel_path
            
            try:
                with open(modified_file, 'r', encoding='utf-8', errors='replace') as f:
                    content = f.read()
                
                # Generate diff showing addition
                diff = self.generate_diff('', content)
                diffs[rel_path] = diff
            except Exception as e:
                self._logger.error(f"Error generating diff for {rel_path}: {str(e)}")
        
        return diffs
    
    def apply_diff(
        self, 
        original: str, 
        diff: str
    ) -> Tuple[str, bool]:
        """
        Apply a unified diff to original content.
        
        Args:
            original: Original content
            diff: Unified diff string
            
        Returns:
            Tuple of (modified_content, success)
        """
        self._logger.debug("Applying diff")
        
        try:
            # Parse the diff
            lines = diff.splitlines()
            
            # Skip header lines (starting with ---, +++, @@)
            i = 0
            while i < len(lines) and (lines[i].startswith('---') or lines[i].startswith('+++') or lines[i].startswith('@@')):
                i += 1
            
            # Apply changes
            result = []
            original_lines = original.splitlines()
            
            line_num = 0
            while line_num < len(original_lines):
                if i < len(lines):
                    if lines[i].startswith('-'):
                        # Line removed, skip in original
                        if not original_lines[line_num] == lines[i][1:]:
                            # Mismatch, can't apply diff
                            return original, False
                        
                        line_num += 1
                        i += 1
                    elif lines[i].startswith('+'):
                        # Line added
                        result.append(lines[i][1:])
                        i += 1
                    elif lines[i].startswith(' '):
                        # Context line
                        if not original_lines[line_num] == lines[i][1:]:
                            # Mismatch, can't apply diff
                            return original, False
                        
                        result.append(original_lines[line_num])
                        line_num += 1
                        i += 1
                    else:
                        # Unknown line in diff
                        return original, False
                else:
                    # No more diff lines, copy remaining original lines
                    result.extend(original_lines[line_num:])
                    break
            
            # Return the modified content
            return '\n'.join(result), True
        except Exception as e:
            self._logger.error(f"Error applying diff: {str(e)}")
            return original, False

# Global diff manager instance
diff_manager = DiffManager()
</file>

<file path="angela/review/feedback.py">
# angela/review/feedback.py
"""
Feedback processing for Angela CLI.

This module provides functionality for processing user feedback
on generated code and refining code based on feedback.
"""
import os
import re
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple, Union
import json

from angela.ai.client import gemini_client, GeminiRequest
from angela.review.diff_manager import diff_manager
from angela.utils.logging import get_logger

logger = get_logger(__name__)

class FeedbackManager:
    """
    Manager for processing user feedback and refining code.
    """
    
    def __init__(self):
        """Initialize the feedback manager."""
        self._logger = logger
    
    async def process_feedback(
        self, 
        feedback: str,
        original_code: str,
        file_path: Optional[str] = None,
        context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Process feedback on code and generate improved version.
        
        Args:
            feedback: User feedback
            original_code: Original code to improve
            file_path: Optional path to the file
            context: Optional additional context
            
        Returns:
            Dictionary with the improved code and other information
        """
        self._logger.info("Processing feedback for code improvement")
        
        # Extract file extension for language detection
        language = None
        if file_path:
            _, ext = os.path.splitext(file_path)
            language = self._get_language_from_extension(ext)
        
        # Build prompt for code improvement
        prompt = self._build_improvement_prompt(
            feedback, 
            original_code, 
            language,
            file_path,
            context
        )
        
        # Call AI service
        api_request = GeminiRequest(
            prompt=prompt,
            max_tokens=16000,  # Large token limit for code
            temperature=0.2
        )
        
        response = await gemini_client.generate_text(api_request)
        
        # Extract improved code and explanation
        improved_code, explanation = self._extract_improved_code(response.text, original_code)
        
        # Generate diff
        diff = diff_manager.generate_diff(original_code, improved_code)
        
        return {
            "original_code": original_code,
            "improved_code": improved_code,
            "explanation": explanation,
            "diff": diff,
            "file_path": file_path,
            "language": language,
            "feedback": feedback
        }
    
    async def refine_project(
        self, 
        project_dir: Union[str, Path],
        feedback: str,
        focus_files: Optional[List[str]] = None,
        context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Refine an entire project based on feedback.
        
        Args:
            project_dir: Path to the project directory
            feedback: User feedback
            focus_files: Optional list of files to focus on
            context: Optional additional context
            
        Returns:
            Dictionary with the refinement results
        """
        self._logger.info(f"Refining project in {project_dir} based on feedback")
        
        project_dir = Path(project_dir)
        
        # Check if directory exists
        if not project_dir.exists() or not project_dir.is_dir():
            return {
                "success": False,
                "error": f"Project directory does not exist: {project_dir}",
                "feedback": feedback
            }
        
        # Get list of files to refine
        files_to_refine = []
        
        if focus_files:
            # Refine specific files
            for file_pattern in focus_files:
                # Handle glob patterns
                if '*' in file_pattern or '?' in file_pattern:
                    matches = list(project_dir.glob(file_pattern))
                    for match in matches:
                        if match.is_file():
                            files_to_refine.append(match)
                else:
                    # Direct file path
                    file_path = project_dir / file_pattern
                    if file_path.is_file():
                        files_to_refine.append(file_path)
        else:
            # Auto-detect files to refine based on feedback
            files = self._find_relevant_files(project_dir, feedback)
            files_to_refine.extend(files)
        
        # Process each file
        results = []
        
        for file_path in files_to_refine:
            try:
                with open(file_path, 'r', encoding='utf-8', errors='replace') as f:
                    original_code = f.read()
                
                # Process feedback for this file
                file_result = await self.process_feedback(
                    feedback,
                    original_code,
                    str(file_path.relative_to(project_dir)),
                    context
                )
                
                results.append({
                    "file_path": str(file_path.relative_to(project_dir)),
                    "has_changes": original_code != file_result["improved_code"],
                    "diff": file_result["diff"],
                    "explanation": file_result["explanation"]
                })
            except Exception as e:
                self._logger.error(f"Error processing {file_path}: {str(e)}")
                results.append({
                    "file_path": str(file_path.relative_to(project_dir)),
                    "error": str(e)
                })
        
        return {
            "success": True,
            "project_dir": str(project_dir),
            "feedback": feedback,
            "results": results,
            "files_processed": len(results)
        }
    
    async def apply_refinements(
        self, 
        refinements: Dict[str, Any],
        backup: bool = True
    ) -> Dict[str, Any]:
        """
        Apply refinements to files.
        
        Args:
            refinements: Refinement results from refine_project
            backup: Whether to create backup files
            
        Returns:
            Dictionary with the application results
        """
        self._logger.info("Applying refinements to files")
        
        # Extract project directory and results
        project_dir = Path(refinements["project_dir"])
        results = refinements["results"]
        
        # Apply changes to each file
        applied_results = []
        
        for result in results:
            file_path = project_dir / result["file_path"]
            
            # Skip files with errors
            if "error" in result:
                applied_results.append({
                    "file_path": result["file_path"],
                    "applied": False,
                    "error": result["error"]
                })
                continue
            
            # Skip files without changes
            if not result.get("has_changes", False):
                applied_results.append({
                    "file_path": result["file_path"],
                    "applied": False,
                    "message": "No changes to apply"
                })
                continue
            
            try:
                # Read original content
                with open(file_path, 'r', encoding='utf-8', errors='replace') as f:
                    original_content = f.read()
                    
                    
                if backup:
                    backup_path = file_path.with_suffix(file_path.suffix + '.bak')
                    with open(backup_path, 'w', encoding='utf-8') as f:
                        f.write(original_content)
                
                # Apply diff
                new_content, success = diff_manager.apply_diff(original_content, result["diff"])
                
                if not success:
                    # If diff application fails, regenerate the improved code
                    new_content = self._regenerate_improved_code(original_content, result["diff"])
                
                # Write the improved content
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(new_content)
                
                applied_results.append({
                    "file_path": result["file_path"],
                    "applied": True,
                    "backup": str(backup_path) if backup else None,
                    "explanation": result.get("explanation", "")
                })
            except Exception as e:
                self._logger.error(f"Error applying changes to {file_path}: {str(e)}")
                applied_results.append({
                    "file_path": result["file_path"],
                    "applied": False,
                    "error": str(e)
                })
        
        return {
            "success": True,
            "project_dir": str(project_dir),
            "results": applied_results,
            "files_processed": len(applied_results),
            "files_changed": sum(1 for r in applied_results if r.get("applied", False))
        }
    
    def _get_language_from_extension(self, extension: str) -> Optional[str]:
        """
        Get programming language from file extension.
        
        Args:
            extension: File extension (with dot)
            
        Returns:
            Language name or None if unknown
        """
        # Map of extensions to languages
        extension_map = {
            '.py': 'Python',
            '.js': 'JavaScript',
            '.jsx': 'JavaScript (React)',
            '.ts': 'TypeScript',
            '.tsx': 'TypeScript (React)',
            '.html': 'HTML',
            '.css': 'CSS',
            '.java': 'Java',
            '.c': 'C',
            '.cpp': 'C++',
            '.h': 'C/C++ Header',
            '.rb': 'Ruby',
            '.go': 'Go',
            '.rs': 'Rust',
            '.php': 'PHP',
            '.swift': 'Swift',
            '.kt': 'Kotlin',
            '.md': 'Markdown',
            '.json': 'JSON',
            '.xml': 'XML',
            '.yaml': 'YAML',
            '.yml': 'YAML',
            '.toml': 'TOML',
            '.sh': 'Shell',
            '.bash': 'Bash',
            '.sql': 'SQL'
        }
        
        return extension_map.get(extension.lower())
    
    def _build_improvement_prompt(
        self, 
        feedback: str,
        original_code: str,
        language: Optional[str],
        file_path: Optional[str],
        context: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        Build a prompt for code improvement.
        
        Args:
            feedback: User feedback
            original_code: Original code to improve
            language: Programming language
            file_path: Path to the file
            context: Additional context
            
        Returns:
            Prompt for the AI service
        """
        # Add language context
        language_str = f"Language: {language}" if language else "Language: Unknown"
        
        # Add file path context
        file_context = f"File: {file_path}" if file_path else ""
        
        # Add additional context if provided
        context_str = ""
        if context:
            context_str = "Additional context:\n"
            for key, value in context.items():
                context_str += f"- {key}: {value}\n"
        
        # Build the prompt
        prompt = f"""
You are an expert software developer helping to improve code based on user feedback.

{language_str}
{file_context}
{context_str}

User feedback:
{feedback}

Your task is to refine the code according to the feedback while preserving the original functionality.
Provide both the improved code and an explanation of the changes you made.

Original code:
{original_code}

Provide your response in this format:
1. First, the full improved code block
2. Then, a detailed explanation of the changes you made

Improved code:
// Your improved code here

Explanation:
// Your explanation here
"""
        
        return prompt
    
    def _extract_improved_code(
        self, 
        response: str, 
        original_code: str
    ) -> Tuple[str, str]:
        """
        Extract improved code and explanation from AI response.
        
        Args:
            response: AI response
            original_code: Original code (fallback)
            
        Returns:
            Tuple of (improved_code, explanation)
        """
        # Try to extract code block
        code_match = re.search(r'```(?:\w*\n)?(.*?)```', response, re.DOTALL)
        
        if code_match:
            code = code_match.group(1).strip()
        else:
            # Fallback: look for "Improved code:" section
            code_section_match = re.search(r'Improved code:\s*(.*?)(?:\n\n|$)', response, re.DOTALL)
            if code_section_match:
                code = code_section_match.group(1).strip()
            else:
                # No clear code section, use original
                code = original_code
        
        # Try to extract explanation
        explanation_match = re.search(r'Explanation:\s*(.*?)(?:\n\n|$)', response, re.DOTALL)
        
        if explanation_match:
            explanation = explanation_match.group(1).strip()
        else:
            # Fallback: anything after the code block
            if code_match:
                parts = response.split('```', 2)
                if len(parts) > 2:
                    explanation = parts[2].strip()
                else:
                    explanation = "No explanation provided."
            else:
                explanation = "No explanation provided."
        
        return code, explanation
    
    def _find_relevant_files(
        self, 
        project_dir: Path, 
        feedback: str
    ) -> List[Path]:
        """
        Find files relevant to the user feedback.
        
        Args:
            project_dir: Project directory
            feedback: User feedback
            
        Returns:
            List of relevant file paths
        """
        relevant_files = []
        
        # Extract potential file references from feedback
        file_mentions = set()
        
        # Look for explicit file references
        file_patterns = [
            r'file[s]?\s+(?:"|\')?([^"\'\s]+)(?:"|\')?',
            r'in\s+(?:"|\')?([^"\'\s]+)(?:"|\')?',
            r'(?:"|\')?([^"\'\s]+\.(?:py|js|java|html|css|cpp|h|go|rb))(?:"|\')?'
        ]
        
        for pattern in file_patterns:
            for match in re.finditer(pattern, feedback, re.IGNORECASE):
                file_mentions.add(match.group(1))
        
        # Check if mentioned files exist
        for mention in file_mentions:
            # Check for exact path
            file_path = project_dir / mention
            if file_path.exists() and file_path.is_file():
                relevant_files.append(file_path)
                continue
            
            # Check for glob pattern
            if '*' in mention or '?' in mention:
                matches = list(project_dir.glob(mention))
                for match in matches:
                    if match.is_file():
                        relevant_files.append(match)
                continue
            
            # Check for just the filename (could be in any directory)
            for root, _, files in os.walk(project_dir):
                if mention in files:
                    relevant_files.append(Path(root) / mention)
        
        # If no specific files mentioned, return all source code files
        if not relevant_files:
            for root, _, files in os.walk(project_dir):
                for file in files:
                    # Skip common non-source files and directories
                    if any(excluded in root for excluded in ['.git', 'node_modules', '__pycache__', '.venv']):
                        continue
                    
                    # Check if it's a source file
                    _, ext = os.path.splitext(file)
                    if ext.lower() in ['.py', '.js', '.jsx', '.ts', '.tsx', '.java', '.c', '.cpp', '.h', '.go', '.rb', '.php', '.swift']:
                        relevant_files.append(Path(root) / file)
        
        return relevant_files
    
    def _regenerate_improved_code(
        self, 
        original_content: str, 
        diff: str
    ) -> str:
        """
        Regenerate improved code from original and diff when apply_diff fails.
        
        This is a fallback method when the diff can't be applied cleanly.
        It uses simple heuristics to apply changes.
        
        Args:
            original_content: Original content
            diff: Unified diff string
            
        Returns:
            Regenerated improved content
        """
        # Simple heuristic: if diff shows additions, add them at the end
        # if diff shows deletions, try to find and remove them
        
        lines = diff.splitlines()
        adds = []
        removes = []
        
        for line in lines:
            if line.startswith('+') and not line.startswith('+++'):
                adds.append(line[1:])
            elif line.startswith('-') and not line.startswith('---'):
                removes.append(line[1:])
        
        # Start with original content
        result = original_content
        
        # Try to remove lines
        for remove in removes:
            result = result.replace(remove + '\n', '')
            result = result.replace(remove, '')
        
        # Add new lines at the end
        if adds:
            if not result.endswith('\n'):
                result += '\n'
            result += '\n'.join(adds)
        
        return result

# Global feedback manager instance
feedback_manager = FeedbackManager()
</file>

<file path="angela/safety/adaptive_confirmation.py">
# angela/safety/adaptive_confirmation.py

import asyncio
from typing import Dict, Any, Optional, List, Tuple

from prompt_toolkit import PromptSession
from prompt_toolkit.shortcuts import input_dialog, message_dialog, yes_no_dialog
from prompt_toolkit.styles import Style
from rich.console import Console
from rich.panel import Panel
from rich.syntax import Syntax
from rich.text import Text
from rich.table import Table

from angela.constants import RISK_LEVELS
from angela.context.history import history_manager
from angela.context.preferences import preferences_manager
from angela.utils.logging import get_logger

logger = get_logger(__name__)

# Styles for different risk levels
CONFIRMATION_STYLES = Style.from_dict({
    'safe': '#2DA44E',        # Green
    'low': '#0969DA',         # Blue
    'medium': '#BF8700',      # Yellow/Orange
    'high': '#CF222E',        # Red
    'critical': '#820000',    # Dark Red
    'dialog': 'bg:#222222',
    'dialog.body': 'bg:#222222 #ffffff',
    'dialog.border': '#888888',
    'button': 'bg:#222222 #ffffff',
    'button.focused': 'bg:#0969DA #ffffff',
})

# Risk level names
RISK_LEVEL_NAMES = {v: k for k, v in RISK_LEVELS.items()}

# Console setup
console = Console()

async def get_adaptive_confirmation(
    command: str, 
    risk_level: int, 
    risk_reason: str,
    impact: Dict[str, Any],
    preview: Optional[str] = None,
    explanation: Optional[str] = None,
    natural_request: Optional[str] = None,
    dry_run: bool = False
) -> bool:
    """
    Get user confirmation for a command based on risk level and user history.
    
    Args:
        command: The command to be executed
        risk_level: The risk level of the command
        risk_reason: The reason for the risk classification
        impact: The impact analysis dictionary
        preview: Optional preview of command results
        explanation: AI explanation of the command
        natural_request: The original natural language request
        dry_run: Whether this is a dry run
        
    Returns:
        True if the user confirms, False otherwise
    """
    # If this is a dry run, skip confirmation
    if dry_run:
        await _show_dry_run_preview(command, risk_level, preview, explanation)
        return False
    
    # Check if auto-execution is enabled for this risk level and command
    if preferences_manager.should_auto_execute(risk_level, command):
        # Get command frequency and success rate
        frequency = history_manager.get_command_frequency(command)
        success_rate = history_manager.get_command_success_rate(command)
        
        # For frequently used commands with high success rate, auto-execute
        if frequency >= 5 and success_rate > 0.8:
            logger.info(f"Auto-executing command with high trust: {command}")
            await _show_auto_execution_notice(command, risk_level, preview)
            return True
    
    # For all other cases, get explicit confirmation
    risk_name = RISK_LEVEL_NAMES.get(risk_level, "UNKNOWN")
    risk_style = risk_name.lower() if risk_name.lower() in CONFIRMATION_STYLES.names else 'medium'
    
    # For high-risk operations, use a more detailed confirmation dialog
    if risk_level >= RISK_LEVELS["HIGH"]:
        return await _get_detailed_confirmation(command, risk_level, risk_reason, impact, preview, explanation)
    
    # For medium and lower risk operations, use a simpler confirmation
    return await _get_simple_confirmation(command, risk_level, risk_reason, preview, explanation)


async def _show_dry_run_preview(
    command: str, 
    risk_level: int, 
    preview: Optional[str],
    explanation: Optional[str]
) -> None:
    """Show a preview for dry run mode."""
    risk_name = RISK_LEVEL_NAMES.get(risk_level, "UNKNOWN")
    
    console.print("\n")
    console.print(Panel(
        Syntax(command, "bash", theme="monokai", word_wrap=True),
        title="[bold blue]DRY RUN PREVIEW[/bold blue]",
        subtitle=f"Risk Level: {risk_name}",
        border_style="blue",
        expand=False
    ))
    
    if explanation:
        console.print("[bold blue]Explanation:[/bold blue]")
        console.print(explanation)
    
    if preview:
        console.print(Panel(
            preview,
            title="Command Preview",
            border_style="blue",
            expand=False
        ))
    
    console.print("[blue]This is a dry run. No changes will be made.[/blue]")


async def _show_auto_execution_notice(
    command: str, 
    risk_level: int,
    preview: Optional[str]
) -> None:
    """Show a notice for auto-execution."""
    risk_name = RISK_LEVEL_NAMES.get(risk_level, "UNKNOWN")
    
    # Use a more subtle notification for auto-execution
    console.print("\n")
    console.print(Panel(
        Syntax(command, "bash", theme="monokai", word_wrap=True),
        title="Auto-Executing Command",
        border_style="green",
        expand=False
    ))
    
    # Only show preview if it's enabled in preferences
    if preview and preferences_manager.preferences.ui.show_command_preview:
        console.print(preview)
    
    # Brief pause to allow user to see what's happening
    await asyncio.sleep(0.5)


async def _get_simple_confirmation(
    command: str, 
    risk_level: int, 
    risk_reason: str,
    preview: Optional[str],
    explanation: Optional[str]
) -> bool:
    """Get a simple confirmation for medium/low risk operations."""
    risk_name = RISK_LEVEL_NAMES.get(risk_level, "UNKNOWN")
    risk_style = risk_name.lower() if risk_name.lower() in CONFIRMATION_STYLES.names else 'medium'
    
    # Display the command
    console.print("\n")
    console.print(Panel(
        Syntax(command, "bash", theme="monokai", word_wrap=True),
        title=f"Execute [{risk_name} Risk]",
        border_style=risk_style,
        expand=False
    ))
    
    # Display explanation if provided
    if explanation:
        console.print(explanation)
    
    # Display preview if available and enabled
    if preview and preferences_manager.preferences.ui.show_preview:
        console.print(Panel(
            preview,
            title="Preview",
            border_style=risk_style,
            expand=False
        ))
    
    # Use prompt_toolkit dialog for confirmation
    confirmed = yes_no_dialog(
        title=f'Execute {risk_name} Risk Command?',
        text=f'{command}\n\nReason: {risk_reason}',
        style=CONFIRMATION_STYLES
    ).run()
    
    return confirmed


async def _get_detailed_confirmation(
    command: str, 
    risk_level: int, 
    risk_reason: str,
    impact: Dict[str, Any],
    preview: Optional[str],
    explanation: Optional[str]
) -> bool:
    """Get a detailed confirmation for high/critical risk operations."""
    risk_name = RISK_LEVEL_NAMES.get(risk_level, "UNKNOWN")
    risk_style = risk_name.lower() if risk_name.lower() in CONFIRMATION_STYLES.names else 'high'
    
    # Format the command and impact information
    console.print("\n")
    console.print(Panel(
        Syntax(command, "bash", theme="monokai", word_wrap=True),
        title=f"[bold {risk_style}]HIGH RISK OPERATION[/bold {risk_style}]",
        border_style=risk_style,
        expand=False
    ))
    
    console.print(f"[bold {risk_style}]Risk Level:[/bold {risk_style}] {risk_name}")
    console.print(f"[bold {risk_style}]Reason:[/bold {risk_style}] {risk_reason}")
    
    # Display explanation if provided
    if explanation:
        console.print("[bold]Explanation:[/bold]")
        console.print(explanation)
    
    # Display impact analysis if enabled
    if preferences_manager.preferences.ui.show_impact_analysis:
        # Create a table for impact analysis
        table = Table(title="Impact Analysis", expand=True)
        table.add_column("Aspect", style="bold cyan")
        table.add_column("Details", style="white")
        
        # Add operations
        operations = ", ".join(impact.get("operations", ["unknown"]))
        table.add_row("Operations", operations)
        
        # Add warning for destructive operations
        if impact.get("destructive", False):
            table.add_row("⚠️ Warning", f"[bold {risk_style}]This operation may delete or overwrite files[/bold {risk_style}]")
        
        # Add affected files/directories
        affected_files = impact.get("affected_files", [])
        if affected_files:
            file_list = "\n".join(affected_files[:5])
            if len(affected_files) > 5:
                file_list += f"\n...and {len(affected_files) - 5} more"
            table.add_row("Affected Files", file_list)
        
        console.print(table)
    
    # Display preview if available and enabled
    if preview and preferences_manager.preferences.ui.show_command_preview:
        console.print(Panel(
            preview,
            title="Command Preview",
            border_style=risk_style,
            expand=False
        ))
    
    # For critical operations, use an even more prominent warning
    if risk_level == RISK_LEVELS["CRITICAL"]:
        console.print(Panel(
            "⚠️  [bold red]This is a CRITICAL risk operation[/bold red] ⚠️\n"
            "It may cause significant changes to your system or data loss.",
            border_style="red",
            expand=False
        ))
    
    # Use prompt_toolkit dialog for confirmation
    confirmed = yes_no_dialog(
        title=f'WARNING: Execute {risk_name} Risk Command?',
        text=f'{command}\n\nThis is a {risk_name} risk operation.\nReason: {risk_reason}\n\nAre you sure you want to proceed?',
        style=CONFIRMATION_STYLES
    ).run()
    
    # If confirmed for a high-risk operation, offer to add to trusted commands
    if confirmed and risk_level >= RISK_LEVELS["HIGH"]:
        add_to_trusted = yes_no_dialog(
            title='Add to Trusted Commands?',
            text=f'Would you like to auto-execute similar commands in the future?',
            style=CONFIRMATION_STYLES
        ).run()
        
        if add_to_trusted:
            preferences_manager.add_trusted_command(command)
    
    return confirmed


async def offer_command_learning(command: str) -> None:
    """
    After a successful execution, offer to add the command to trusted commands.
    
    Args:
        command: The command that was executed
    """
    # Check if the command should be offered for learning
    base_command = history_manager._extract_base_command(command)
    pattern = history_manager._patterns.get(base_command)
    
    # Only offer for commands used a few times but not yet trusted
    if pattern and 2 <= pattern.count <= 5 and command not in preferences_manager.preferences.trust.trusted_commands:
        add_to_trusted = yes_no_dialog(
            title='Add to Trusted Commands?',
            text=f'You\'ve used "{base_command}" {pattern.count} times. Would you like to auto-execute it in the future?',
            style=CONFIRMATION_STYLES
        ).run()
        
        if add_to_trusted:
            preferences_manager.add_trusted_command(command)
            console.print(f"Added [green]{base_command}[/green] to trusted commands.")
</file>

<file path="angela/safety/classifier.py">
"""
Command and operation risk classification system for Angela CLI.

This module is responsible for determining the risk level of commands 
and operations to ensure appropriate confirmation and safety measures.
"""
import re
import shlex
from typing import List, Dict, Tuple, Set, Optional

from angela.constants import RISK_LEVELS
from angela.utils.logging import get_logger

logger = get_logger(__name__)

# Define risk patterns for shell commands
RISK_PATTERNS = {
    # Critical risk - destructive operations
    RISK_LEVELS["CRITICAL"]: [
        # rm with recursive or force flags
        (r"^rm\s+.*((-r|-rf|--recursive|-f|--force)\b|--)", "File deletion with dangerous flags"),
        # Disk formatting
        (r"^(mkfs|fdisk|dd)\b", "Disk formatting/partitioning"), 
        # Systemwide configuration changes
        (r"^(sudo|pkexec|su)\s+", "Privileged operation"),
        # Direct writes to device files
        (r">\s*/dev/", "Direct write to device file"),
    ],
    
    # High risk - significant changes
    RISK_LEVELS["HIGH"]: [
        # Regular file deletion
        (r"^rm\s+", "File deletion"),
        # Moving files
        (r"^mv\s+", "File movement"),
        # Installing packages
        (r"^(apt(-get)?|yum|pacman|dnf|brew)\s+(install|remove|purge)\b", "Package management"),
        # Changing permissions
        (r"^chmod\s+", "Changing file permissions"),
        # Changing ownership
        (r"^chown\s+", "Changing file ownership"),
    ],
    
    # Medium risk - file modifications
    RISK_LEVELS["MEDIUM"]: [
        # Writing to files
        (r"(>|>>)\s*[\w\./-]+", "Writing to files"),
        # Editing files
        (r"^(nano|vim|vi|emacs|sed)\s+", "File editing"),
        # Creating symbolic links
        (r"^ln\s+(-s|--symbolic)\s+", "Creating symbolic links"),
        # Transferring files remotely
        (r"^(scp|rsync)\s+", "File transfer"),
    ],
    
    # Low risk - creating files/dirs without overwriting
    RISK_LEVELS["LOW"]: [
        # Making directories
        (r"^mkdir\s+", "Creating directory"),
        # Touching files
        (r"^touch\s+", "Creating/updating file timestamp"),
        # Copying files
        (r"^cp\s+", "Copying files"),
    ],
    
    # Safe - read-only operations
    RISK_LEVELS["SAFE"]: [
        # Listing files
        (r"^ls\s+", "Listing files"),
        # Reading files
        (r"^(cat|less|more|head|tail)\s+", "Reading file content"),
        # Finding files
        (r"^find\s+", "Finding files"),
        # Viewing disk usage
        (r"^du\s+", "Checking disk usage"),
        # Getting working directory
        (r"^pwd\s*$", "Printing working directory"),
        # Checking file status
        (r"^(stat|file)\s+", "Checking file information"),
    ],
}

# Special case patterns that override normal classification
OVERRIDE_PATTERNS = {
    # Force certain grep operations to be safe
    "SAFE": [
        r"^grep\s+(-r|--recursive)?\s+[\w\s]+\s+[\w\s\./-]+$",  # Basic grep with fixed strings
        r"^find\s+[\w\s\./-]+\s+-name\s+[\w\s\*\./-]+$",  # Basic find by name
    ],
    # Operations that should always be considered critical regardless of base command
    "CRITICAL": [
        r"[\s;|`]+rm\s+(-r|-f|--recursive|--force)\s+[~/]",  # rm commands affecting home or root
        r"[\s;|`]+dd\s+",  # dd embedded in a command chain
        r">/dev/null\s+2>&1",  # Redirecting errors (often hiding destructive operations)
    ],
}

def classify_command_risk(command: str) -> Tuple[int, str]:
    """
    Classify the risk level of a shell command.
    
    Args:
        command: The shell command to classify.
        
    Returns:
        A tuple of (risk_level, reason), where risk_level is an integer
        from the RISK_LEVELS constants and reason is a string explaining
        the classification.
    """
    if not command.strip():
        return RISK_LEVELS["SAFE"], "Empty command"
    
    # First check override patterns that would force a specific risk level
    for level_name, patterns in OVERRIDE_PATTERNS.items():
        for pattern in patterns:
            if re.search(pattern, command):
                level = RISK_LEVELS[level_name]
                return level, f"Matched override pattern for {level_name} risk"
    
    # Check standard risk patterns from highest to lowest risk
    for level, patterns in sorted(RISK_PATTERNS.items(), key=lambda x: x[0], reverse=True):
        for pattern, reason in patterns:
            if re.search(pattern, command.strip()):
                return level, reason
    
    # Default to medium risk if no pattern matches
    # It's safer to require confirmation for unknown commands
    return RISK_LEVELS["MEDIUM"], "Unrecognized command type"


def analyze_command_impact(command: str) -> Dict[str, any]:
    """
    Analyze the potential impact of a command.
    
    Args:
        command: The shell command to analyze.
        
    Returns:
        A dictionary containing impact analysis information, such as
        affected files, operations, etc.
    """
    impact = {
        "affected_files": set(),
        "affected_dirs": set(),
        "operations": [],
        "destructive": False,
        "creates_files": False,
        "modifies_files": False,
    }
    
    try:
        # Simple lexical analysis of the command
        tokens = shlex.split(command)
        if not tokens:
            return impact
        
        base_cmd = tokens[0]
        args = tokens[1:]
        
        # Extract potentially affected files and directories
        for arg in args:
            # Skip arguments that start with a dash (options)
            if arg.startswith('-'):
                continue
            
            # Skip redirection operators
            if arg in ['>', '>>', '<', '|']:
                continue
                
            # Assume it might be a file or directory path
            if '/' in arg or '.' in arg or not arg.startswith('-'):
                if base_cmd in ['rm', 'mv', 'rmdir']:
                    impact["destructive"] = True
                
                if base_cmd in ['mkdir']:
                    impact["affected_dirs"].add(arg)
                    impact["creates_files"] = True
                else:
                    impact["affected_files"].add(arg)
                
                if base_cmd in ['cp', 'mv', 'touch', 'mkdir', 'ln']:
                    impact["creates_files"] = True
                
                if base_cmd in ['vim', 'nano', 'sed', 'cp', 'mv']:
                    impact["modifies_files"] = True
        
        # Record the type of operation
        if base_cmd in ['ls', 'find', 'grep', 'cat', 'less', 'more', 'tail', 'head']:
            impact["operations"].append("read")
        elif base_cmd in ['rm', 'rmdir']:
            impact["operations"].append("delete")
        elif base_cmd in ['mv']:
            impact["operations"].append("move")
        elif base_cmd in ['cp']:
            impact["operations"].append("copy")
        elif base_cmd in ['touch', 'mkdir']:
            impact["operations"].append("create")
        elif base_cmd in ['chmod', 'chown']:
            impact["operations"].append("change_attributes")
        else:
            impact["operations"].append("unknown")
    
    except Exception as e:
        logger.exception(f"Error analyzing command impact for '{command}': {str(e)}")
    
    # Convert sets to lists for easier serialization
    impact["affected_files"] = list(impact["affected_files"])
    impact["affected_dirs"] = list(impact["affected_dirs"])
    
    return impact
</file>

<file path="angela/shell/__init__.py">
# In angela/shell/__init__.py
from .formatter import terminal_formatter
from . import advanced_formatter  # This loads the extensions
</file>

<file path="angela/shell/advanced_formatter.py">
"""
Terminal formatter extensions for displaying advanced task plans.

This module extends the terminal_formatter to properly display advanced
task plans with all step types, data flow, and execution results.
"""
import os
from pathlib import Path
from typing import Dict, Any, List, Optional, Union
from datetime import datetime

from rich.console import Console
from rich.panel import Panel
from rich.table import Table
from rich.syntax import Syntax
from rich.tree import Tree
from rich.markdown import Markdown
from rich.text import Text
from rich import box

from angela.shell.formatter import terminal_formatter, OutputType
from angela.intent.planner import AdvancedTaskPlan, PlanStepType
from angela.utils.logging import get_logger

logger = get_logger(__name__)

console = Console()

async def display_advanced_plan(plan: AdvancedTaskPlan) -> None:
    """
    Display an advanced task plan with rich formatting.
    
    Args:
        plan: The advanced task plan to display
    """
    logger.debug(f"Displaying advanced plan: {plan.id}")
    
    # Create a header panel
    header = Panel(
        f"[bold]{plan.description}[/bold]\n\n{plan.goal}",
        title=f"Advanced Plan: {plan.id}",
        border_style="blue"
    )
    console.print(header)
    
    # Create a table for the steps
    table = Table(
        title="Execution Steps",
        box=box.ROUNDED,
        header_style="bold cyan",
        expand=True
    )
    
    # Add columns
    table.add_column("ID", style="cyan")
    table.add_column("Type", style="magenta")
    table.add_column("Description", style="green")
    table.add_column("Details", style="yellow")
    table.add_column("Risk", style="red")
    table.add_column("Dependencies", style="blue")
    
    # Add rows for each step
    for step_id, step in plan.steps.items():
        # Format risk level
        risk_colors = ["green", "green", "yellow", "red", "red bold"]
        risk_level = min(step.estimated_risk, 4)  # Cap at 4
        risk_text = f"[{risk_colors[risk_level]}]{risk_level}[/{risk_colors[risk_level]}]"
        
        # Format details based on step type
        details = ""
        if step.type == PlanStepType.COMMAND:
            if step.command:
                details = f"Command: {step.command}"
        elif step.type == PlanStepType.CODE:
            details = f"Code: {len(step.code)} chars"
        elif step.type == PlanStepType.FILE:
            if step.file_path:
                operation = getattr(step, "operation", "read/write")
                details = f"{operation.capitalize()}: {step.file_path}"
        elif step.type == PlanStepType.DECISION:
            if step.condition:
                details = f"Condition: {step.condition}"
        elif step.type == PlanStepType.API:
            if step.api_url:
                details = f"{step.api_method} {step.api_url}"
        elif step.type == PlanStepType.LOOP:
            if step.loop_items:
                details = f"Items: {step.loop_items}"
        
        # Format dependencies
        deps = ", ".join(step.dependencies) if step.dependencies else "None"
        
        # Add row
        table.add_row(
            step_id,
            str(step.type.value),
            step.description,
            details,
            risk_text,
            deps
        )
    
    console.print(table)
    
    # Show execution flow with entry points
    flow_panel = Panel(
        f"Entry Points: [bold cyan]{', '.join(plan.entry_points)}[/bold cyan]",
        title="Execution Flow",
        border_style="green"
    )
    console.print(flow_panel)
    
    # Show dependencies as a tree for visualization
    console.print("\n[bold]Dependency Tree:[/bold]")
    
    # Build dependency tree
    tree = Tree("🔄 [bold]Execution Plan[/bold]")
    
    # Add entry points
    entry_node = tree.add("🚀 [bold cyan]Entry Points[/bold cyan]")
    for entry in plan.entry_points:
        entry_branch = entry_node.add(f"[cyan]{entry}[/cyan]")
        _build_dependency_tree(entry_branch, entry, plan)
    
    console.print(tree)

def _build_dependency_tree(node, step_id, plan):
    """
    Recursively build a dependency tree for visualization.
    
    Args:
        node: The current tree node
        step_id: Current step ID
        plan: The advanced task plan
    """
    # Find steps that depend on this step
    for next_id, next_step in plan.steps.items():
        if step_id in next_step.dependencies:
            step_node = node.add(f"[yellow]{next_id}[/yellow]: {next_step.description}")
            # Recursively build the tree
            _build_dependency_tree(step_node, next_id, plan)
    
    # Special handling for decision steps (branches)
    if step_id in plan.steps and plan.steps[step_id].type == PlanStepType.DECISION:
        step = plan.steps[step_id]
        
        if step.true_branch:
            true_node = node.add("[green]True Branch[/green]")
            for branch_step in step.true_branch:
                branch_text = f"[green]{branch_step}[/green]"
                if branch_step in plan.steps:
                    branch_text += f": {plan.steps[branch_step].description}"
                true_node.add(branch_text)
        
        if step.false_branch:
            false_node = node.add("[red]False Branch[/red]")
            for branch_step in step.false_branch:
                branch_text = f"[red]{branch_step}[/red]"
                if branch_step in plan.steps:
                    branch_text += f": {plan.steps[branch_step].description}"
                false_node.add(branch_text)
    
    # Special handling for loop steps
    if step_id in plan.steps and plan.steps[step_id].type == PlanStepType.LOOP:
        step = plan.steps[step_id]
        
        if step.loop_body:
            loop_node = node.add("[blue]Loop Body[/blue]")
            for body_step in step.loop_body:
                body_text = f"[blue]{body_step}[/blue]"
                if body_step in plan.steps:
                    body_text += f": {plan.steps[body_step].description}"
                loop_node.add(body_text)

async def display_execution_results(
    plan: AdvancedTaskPlan, 
    results: Dict[str, Any]
) -> None:
    """
    Display execution results for an advanced task plan.
    
    Args:
        plan: The executed advanced task plan
        results: The execution results
    """
    logger.debug(f"Displaying execution results for plan: {plan.id}")
    
    # Create a header
    success = results.get("success", False)
    success_text = "[bold green]SUCCESS[/bold green]" if success else "[bold red]FAILED[/bold red]"
    
    header = Panel(
        f"Plan execution {success_text}\n\n"
        f"Steps completed: [bold]{results.get('steps_completed', 0)}[/bold] / {results.get('steps_total', len(plan.steps))}\n"
        f"Execution time: [bold]{results.get('execution_time', 0):.2f}[/bold] seconds",
        title=f"Execution Results: {plan.id}",
        border_style="green" if success else "red"
    )
    console.print(header)
    
    # Display execution path
    if "execution_path" in results:
        path_text = " → ".join(results["execution_path"])
        path_panel = Panel(
            path_text,
            title="Execution Path",
            border_style="blue"
        )
        console.print(path_panel)
    
    # Display step results in a table
    if "results" in results:
        step_results = results["results"]
        
        # Create table
        table = Table(
            title="Step Results",
            box=box.ROUNDED,
            header_style="bold cyan",
            expand=True
        )
        
        # Add columns
        table.add_column("Step", style="cyan")
        table.add_column("Type", style="magenta")
        table.add_column("Status", style="green")
        table.add_column("Output", style="yellow")
        table.add_column("Time (s)", style="blue")
        
        # Add rows for each step in execution order
        execution_order = results.get("execution_path", list(step_results.keys()))
        
        for step_id in execution_order:
            if step_id not in step_results:
                continue
                
            result = step_results[step_id]
            
            # Format status
            status = "[green]Success[/green]" if result.get("success", False) else "[red]Failed[/red]"
            
            # Handle retry/recovery
            if result.get("retried", False):
                status += " [yellow](Retried)[/yellow]"
            if result.get("recovery_applied", False):
                status += " [blue](Recovered)[/blue]"
            
            # Format output based on step type
            output = ""
            step_type = result.get("type", "")
            
            if step_type == PlanStepType.COMMAND:
                # Get first few lines of stdout
                stdout = result.get("stdout", "").strip()
                if stdout:
                    lines = stdout.split("\n")
                    output = lines[0]
                    if len(lines) > 1:
                        output += f"... (+{len(lines)-1} lines)"
            elif step_type == PlanStepType.CODE:
                # Show execution result or console output
                if "result" in result:
                    output = f"Result: {result['result']}"
                elif "stdout" in result and result["stdout"]:
                    lines = result["stdout"].strip().split("\n")
                    output = lines[0]
                    if len(lines) > 1:
                        output += f"... (+{len(lines)-1} lines)"
            elif step_type == PlanStepType.FILE:
                # Show operation result
                output = result.get("message", "")
            elif step_type == PlanStepType.DECISION:
                # Show condition result
                condition_result = result.get("condition_result", False)
                output = f"Condition: [green]True[/green]" if condition_result else "Condition: [red]False[/red]"
                output += f" → {result.get('next_branch', '')}"
            elif step_type == PlanStepType.API:
                # Show status code and response summary
                status_code = result.get("status_code", 0)
                output = f"Status: {status_code}"
                
                # Add response summary
                if "json" in result:
                    output += f" (JSON response)"
                elif "text" in result:
                    text = result["text"]
                    if len(text) > 30:
                        text = text[:30] + "..."
                    output += f" Response: {text}"
            elif step_type == PlanStepType.LOOP:
                # Show loop iteration count
                iterations = result.get("iterations", 0)
                output = f"Iterations: {iterations}"
            
            # Format execution time
            exec_time = result.get("execution_time", 0)
            time_text = f"{exec_time:.2f}"
            
            # Add row
            table.add_row(
                step_id,
                str(step_type.value) if isinstance(step_type, PlanStepType) else str(step_type),
                status,
                output,
                time_text
            )
        
        console.print(table)
    
    # Display detailed outputs for steps of interest
    if "results" in results:
        step_results = results["results"]
        
        # First show any failed step in detail
        failed_step = results.get("failed_step")
        if failed_step and failed_step in step_results:
            console.print(f"\n[bold red]Failed Step: {failed_step}[/bold red]")
            await display_step_details(failed_step, step_results[failed_step], plan)
        
        # Show details for specific step types that typically have interesting output
        for step_id, result in step_results.items():
            if step_id == failed_step:
                continue  # Already displayed
                
            step_type = result.get("type", "")
            
            # Show all API responses, loop results, and code outputs with results
            if step_type == PlanStepType.API or step_type == PlanStepType.LOOP or (
                step_type == PlanStepType.CODE and ("result" in result or "output" in result)):
                console.print(f"\n[bold cyan]Step Details: {step_id}[/bold cyan]")
                await display_step_details(step_id, result, plan)
    
    # Show variables at the end of execution if available
    if "variables" in results:
        console.print("\n[bold]Final Variables:[/bold]")
        var_table = Table(title="Data Flow Variables", box=box.ROUNDED)
        var_table.add_column("Name", style="cyan")
        var_table.add_column("Value", style="green")
        var_table.add_column("Source", style="blue")
        
        for var_name, var_info in results["variables"].items():
            # Format value based on type
            value = var_info.get("value", "")
            if isinstance(value, dict) or isinstance(value, list):
                import json
                value_str = json.dumps(value, indent=2)
                if len(value_str) > 50:
                    value_str = value_str[:50] + "..."
            else:
                value_str = str(value)
                if len(value_str) > 50:
                    value_str = value_str[:50] + "..."
            
            var_table.add_row(
                var_name,
                value_str,
                var_info.get("source_step", "initial")
            )
        
        console.print(var_table)

async def display_step_details(
    step_id: str, 
    result: Dict[str, Any],
    plan: Optional[AdvancedTaskPlan] = None
) -> None:
    """
    Display detailed results for a specific step.
    
    Args:
        step_id: ID of the step
        result: The step's execution result
        plan: Optional plan for context
    """
    step_type = result.get("type", "")
    
    # Get step description from plan if available
    description = ""
    if plan and step_id in plan.steps:
        description = plan.steps[step_id].description
    
    # Format output based on step type
    if step_type == PlanStepType.COMMAND:
        # Show command and output
        console.print(f"[bold]Command:[/bold] {result.get('command', '')}")
        
        if result.get("stdout", "").strip():
            syntax = Syntax(
                result["stdout"],
                "bash-session",
                theme="monokai",
                line_numbers=True,
                word_wrap=True
            )
            console.print(Panel(syntax, title="Standard Output", border_style="green"))
        
        if result.get("stderr", "").strip():
            syntax = Syntax(
                result["stderr"],
                "bash-session",
                theme="monokai",
                line_numbers=True,
                word_wrap=True
            )
            console.print(Panel(syntax, title="Error Output", border_style="red"))
    
    elif step_type == PlanStepType.CODE:
        # Show code and output
        if "code" in result:
            lang = "python"  # Default to Python
            if plan and step_id in plan.steps:
                lang = getattr(plan.steps[step_id], "language", "python")
            
            syntax = Syntax(
                result["code"],
                lang,
                theme="monokai",
                line_numbers=True,
                word_wrap=True
            )
            console.print(Panel(syntax, title="Code", border_style="blue"))
        
        if "stdout" in result and result["stdout"].strip():
            console.print(Panel(result["stdout"], title="Standard Output", border_style="green"))
        
        if "result" in result:
            import json
            if isinstance(result["result"], (dict, list)):
                result_str = json.dumps(result["result"], indent=2)
            else:
                result_str = str(result["result"])
            
            console.print(Panel(result_str, title="Result", border_style="cyan"))
        
        if "error" in result:
            console.print(Panel(result["error"], title="Error", border_style="red"))
            if "traceback" in result:
                console.print(Panel(result["traceback"], title="Traceback", border_style="red"))
    
    elif step_type == PlanStepType.FILE:
        # Show file operation details
        console.print(f"[bold]File Path:[/bold] {result.get('file_path', '')}")
        console.print(f"[bold]Operation:[/bold] {getattr(plan.steps[step_id], 'operation', 'read/write') if plan and step_id in plan.steps else 'read/write'}")
        
        if "content" in result:
            # For read operations
            content = result["content"]
            if len(content) > 500:
                content = content[:500] + "...\n(truncated)"
            
            syntax = Syntax(
                content,
                "text",
                theme="monokai",
                line_numbers=True,
                word_wrap=True
            )
            console.print(Panel(syntax, title="File Content", border_style="green"))
        
        if "message" in result:
            console.print(f"[bold]Result:[/bold] {result['message']}")
    
    elif step_type == PlanStepType.DECISION:
        # Show decision details
        console.print(f"[bold]Condition:[/bold] {result.get('condition', '')}")
        condition_result = result.get("condition_result", False)
        console.print(f"[bold]Evaluated:[/bold] {'[green]True[/green]' if condition_result else '[red]False[/red]'}")
        
        if plan and step_id in plan.steps:
            step = plan.steps[step_id]
            if condition_result and step.true_branch:
                console.print(f"[bold]True Branch:[/bold] {', '.join(step.true_branch)}")
            elif not condition_result and step.false_branch:
                console.print(f"[bold]False Branch:[/bold] {', '.join(step.false_branch)}")
    
    elif step_type == PlanStepType.API:
        # Show API call details
        console.print(f"[bold]URL:[/bold] {result.get('url', '')}")
        console.print(f"[bold]Method:[/bold] {result.get('method', 'GET')}")
        console.print(f"[bold]Status Code:[/bold] {result.get('status_code', 0)}")
        
        # Show headers
        if "headers" in result:
            header_table = Table(title="Response Headers", box=box.SIMPLE)
            header_table.add_column("Header", style="cyan")
            header_table.add_column("Value", style="green")
            
            for header, value in result["headers"].items():
                header_table.add_row(header, str(value))
            
            console.print(header_table)
        
        # Show JSON response if available
        if "json" in result:
            import json
            json_str = json.dumps(result["json"], indent=2)
            
            syntax = Syntax(
                json_str,
                "json",
                theme="monokai",
                line_numbers=True,
                word_wrap=True
            )
            console.print(Panel(syntax, title="JSON Response", border_style="green"))
        elif "text" in result:
            # Show text response
            text = result["text"]
            
            # Try to detect content type
            is_json = text.strip().startswith('{') and text.strip().endswith('}')
            is_xml = text.strip().startswith('<') and text.strip().endswith('>')
            is_html = '<html' in text.lower() and '</html>' in text.lower()
            
            syntax_type = "json" if is_json else "xml" if is_xml or is_html else "text"
            
            syntax = Syntax(
                text,
                syntax_type,
                theme="monokai",
                line_numbers=True,
                word_wrap=True
            )
            console.print(Panel(syntax, title="Response Body", border_style="green"))
    
    elif step_type == PlanStepType.LOOP:
        # Show loop details
        console.print(f"[bold]Loop Items:[/bold] {getattr(plan.steps[step_id], 'loop_items', '') if plan and step_id in plan.steps else ''}")
        console.print(f"[bold]Iterations:[/bold] {result.get('iterations', 0)}")
        
        if "loop_results" in result:
            loop_results = result["loop_results"]
            
            # Create a table for iteration results
            loop_table = Table(title="Loop Iterations", box=box.SIMPLE)
            loop_table.add_column("Index", style="cyan")
            loop_table.add_column("Item", style="green")
            loop_table.add_column("Status", style="yellow")
            
            for iteration in loop_results:
                # Format item based on type
                item = iteration.get("item", "")
                if isinstance(item, (dict, list)):
                    import json
                    item_str = json.dumps(item)
                    if len(item_str) > 30:
                        item_str = item_str[:30] + "..."
                else:
                    item_str = str(item)
                    if len(item_str) > 30:
                        item_str = item_str[:30] + "..."
                
                # Format status
                status = "[green]Success[/green]" if iteration.get("success", False) else "[red]Failed[/red]"
                
                loop_table.add_row(
                    str(iteration.get("index", 0)),
                    item_str,
                    status
                )
            
            console.print(loop_table)

async def display_step_error(
    step_id: str,
    error: str,
    step_type: str,
    description: str
) -> None:
    """
    Display an error that occurred during step execution.
    
    Args:
        step_id: ID of the failed step
        error: Error message
        step_type: Type of the step
        description: Step description
    """
    error_panel = Panel(
        f"[bold]{description}[/bold]\n\n"
        f"Step Type: {step_type}\n"
        f"Error: {error}",
        title=f"Step Error: {step_id}",
        border_style="red"
    )
    console.print(error_panel)

# Add the new methods to terminal_formatter
terminal_formatter.display_advanced_plan = display_advanced_plan
terminal_formatter.display_execution_results = display_execution_results
terminal_formatter.display_step_details = display_step_details
terminal_formatter.display_step_error = display_step_error

logger.info("Extended terminal formatter with advanced task plan display capabilities")
</file>

<file path="angela/shell/angela_enhanced.bash">
#!/bin/bash
# Angela CLI Enhanced Bash Integration

# Global variables for tracking
ANGELA_LAST_COMMAND=""
ANGELA_LAST_COMMAND_RESULT=$?
ANGELA_LAST_PWD="$PWD"
ANGELA_COMMAND_START_TIME=0

# Pre-command execution hook
angela_pre_exec() {
    # Capture the command
    ANGELA_LAST_COMMAND="$BASH_COMMAND"
    ANGELA_COMMAND_START_TIME=$(date +%s)
    
    # Send notification to Angela's monitoring system
    if [[ ! "$ANGELA_LAST_COMMAND" =~ ^angela ]]; then
        # Only track non-angela commands to avoid recursion
        (angela --notify pre_exec "$ANGELA_LAST_COMMAND" &>/dev/null &)
    fi
}

# Post-command execution hook
angela_post_exec() {
    local exit_code=$?
    ANGELA_LAST_COMMAND_RESULT=$exit_code
    local duration=$(($(date +%s) - ANGELA_COMMAND_START_TIME))
    
    # Check for directory change
    if [[ "$PWD" != "$ANGELA_LAST_PWD" ]]; then
        # Directory changed, update context
        ANGELA_LAST_PWD="$PWD"
        (angela --notify dir_change "$PWD" &>/dev/null &)
    fi
    
    # Send post-execution notification for non-angela commands
    if [[ ! "$ANGELA_LAST_COMMAND" =~ ^angela ]]; then
        # Pass execution result to Angela
        (angela --notify post_exec "$ANGELA_LAST_COMMAND" $exit_code $duration &>/dev/null &)
        
        # Check if we should offer assistance based on exit code and command pattern
        if [[ $exit_code -ne 0 ]]; then
            angela_check_command_suggestion "$ANGELA_LAST_COMMAND" $exit_code
        fi
    fi
}

# Function to check if Angela should offer command suggestions
angela_check_command_suggestion() {
    local command="$1"
    local exit_code=$2
    
    # Check for common error patterns
    case "$command" in
        git*)
            # For git commands with errors, offer assistance
            if [[ $exit_code -ne 0 ]]; then
                echo -e "\033[33m[Angela] I noticed your git command failed. Need help? Try: angela fix-git\033[0m"
            fi
            ;;
        python*|pip*)
            # For Python-related errors
            if [[ $exit_code -ne 0 ]]; then
                echo -e "\033[33m[Angela] Python command failed. For assistance, try: angela fix-python\033[0m"
            fi
            ;;
    esac
    
    # Match other patterns that might benefit from Angela's assistance
    if [[ "$command" =~ "commit -m" ]]; then
        # Offer to enhance commit messages
        echo -e "\033[33m[Angela] I can help with more descriptive commit messages. Try: angela enhance-commit\033[0m"
    fi
}

# Install hooks
trap angela_pre_exec DEBUG
PROMPT_COMMAND="angela_post_exec${PROMPT_COMMAND:+;$PROMPT_COMMAND}"

# Main Angela function
angela() {
    # Check if no arguments or help requested
    if [ $# -eq 0 ] || [ "$1" = "--help" ] || [ "$1" = "-h" ]; then
        python -m angela --help
        return
    fi

    # Handle notify subcommand (used by hooks)
    if [ "$1" = "--notify" ]; then
        # This is a notification from the hooks, handle silently
        python -m angela --notify "${@:2}" &>/dev/null &
        return
    fi

    # Handle version flag
    if [ "$1" = "--version" ] || [ "$1" = "-v" ]; then
        python -m angela --version
        return
    fi

    # Handle debug flag
    if [ "$1" = "--debug" ] || [ "$1" = "-d" ]; then
        DEBUG_FLAG="--debug"
        shift  # Remove the debug flag from arguments
    else
        DEBUG_FLAG=""
    fi

    # Handle natural language commands (implicit invocation)
    if [ "$1" = "fix" ] || [ "$1" = "explain" ] || [ "$1" = "help-with" ]; then
        # These are common natural language commands
        python -m angela $DEBUG_FLAG request "$@"
        return
    fi

    # Handle specific command (init, etc.)
    if [ "$1" = "init" ]; then
        python -m angela $DEBUG_FLAG init
        return
    fi

    # Process as a request for anything else
    python -m angela $DEBUG_FLAG request "$@"
}

# Register completion for angela
_angela_completion() {
    local cur prev opts
    COMPREPLY=()
    cur="${COMP_WORDS[COMP_CWORD]}"
    prev="${COMP_WORDS[COMP_CWORD-1]}"
    
    # Get dynamic completions from Angela
    local completions=$(angela --completions "${COMP_WORDS[@]:1}" 2>/dev/null)
    
    # If completions were returned, use them
    if [ -n "$completions" ]; then
        COMPREPLY=( $(compgen -W "$completions" -- "$cur") )
        return 0
    fi
    
    # Fallback static completions
    opts="init status shell files workflows generate rollback fix explain help-with"
    
    # Complete based on the current argument
    if [[ ${prev} == "angela" ]]; then
        COMPREPLY=( $(compgen -W "${opts}" -- ${cur}) )
        return 0
    fi
}
complete -F _angela_completion angela
</file>

<file path="angela/shell/angela_enhanced.zsh">
#!/bin/zsh
# Angela CLI Enhanced Zsh Integration

# Global variables for tracking
ANGELA_LAST_COMMAND=""
ANGELA_LAST_COMMAND_RESULT=0
ANGELA_LAST_PWD="$PWD"
ANGELA_COMMAND_START_TIME=0

# Pre-command execution hook (before command runs)
angela_preexec() {
    # Capture the command
    ANGELA_LAST_COMMAND="$1"
    ANGELA_COMMAND_START_TIME=$(date +%s)
    
    # Send notification to Angela's monitoring system
    if [[ ! "$ANGELA_LAST_COMMAND" =~ ^angela ]]; then
        # Only track non-angela commands to avoid recursion
        (angela --notify pre_exec "$ANGELA_LAST_COMMAND" &>/dev/null &)
    fi
}

# Pre-prompt hook (after command runs, before showing next prompt)
angela_precmd() {
    local exit_code=$?
    ANGELA_LAST_COMMAND_RESULT=$exit_code
    local duration=$(($(date +%s) - ANGELA_COMMAND_START_TIME))
    
    # Check for directory change
    if [[ "$PWD" != "$ANGELA_LAST_PWD" ]]; then
        # Directory changed, update context
        ANGELA_LAST_PWD="$PWD"
        (angela --notify dir_change "$PWD" &>/dev/null &)
    fi
    
    # Send post-execution notification for non-angela commands
    if [[ ! "$ANGELA_LAST_COMMAND" =~ ^angela ]]; then
        # Pass execution result to Angela
        (angela --notify post_exec "$ANGELA_LAST_COMMAND" $exit_code $duration &>/dev/null &)
        
        # Check if we should offer assistance based on exit code and command pattern
        if [[ $exit_code -ne 0 ]]; then
            angela_check_command_suggestion "$ANGELA_LAST_COMMAND" $exit_code
        fi
    fi
}

# Function to check if Angela should offer command suggestions
angela_check_command_suggestion() {
    local command="$1"
    local exit_code=$2
    
    # Check for common error patterns
    case "$command" in
        git*)
            # For git commands with errors, offer assistance
            if [[ $exit_code -ne 0 ]]; then
                echo -e "\033[33m[Angela] I noticed your git command failed. Need help? Try: angela fix-git\033[0m"
            fi
            ;;
        python*|pip*)
            # For Python-related errors
            if [[ $exit_code -ne 0 ]]; then
                echo -e "\033[33m[Angela] Python command failed. For assistance, try: angela fix-python\033[0m"
            fi
            ;;
    esac
    
    # Match other patterns that might benefit from Angela's assistance
    if [[ "$command" =~ "commit -m" ]]; then
        # Offer to enhance commit messages
        echo -e "\033[33m[Angela] I can help with more descriptive commit messages. Try: angela enhance-commit\033[0m"
    fi
}

# Register the hooks with Zsh
autoload -Uz add-zsh-hook
add-zsh-hook preexec angela_preexec
add-zsh-hook precmd angela_precmd

# Main Angela function
angela() {
    # Check if no arguments or help requested
    if [[ $# -eq 0 || "$1" = "--help" || "$1" = "-h" ]]; then
        python -m angela --help
        return
    fi

    # Handle notify subcommand (used by hooks)
    if [[ "$1" = "--notify" ]]; then
        # This is a notification from the hooks, handle silently
        python -m angela --notify "${@:2}" &>/dev/null &
        return
    fi

    # Handle version flag
    if [[ "$1" = "--version" || "$1" = "-v" ]]; then
        python -m angela --version
        return
    fi

    # Handle debug flag
    if [[ "$1" = "--debug" || "$1" = "-d" ]]; then
        DEBUG_FLAG="--debug"
        shift  # Remove the debug flag from arguments
    else
        DEBUG_FLAG=""
    fi

    # Handle natural language commands (implicit invocation)
    if [[ "$1" = "fix" || "$1" = "explain" || "$1" = "help-with" ]]; then
        # These are common natural language commands
        python -m angela $DEBUG_FLAG request "$@"
        return
    fi

    # Handle specific command (init, etc.)
    if [[ "$1" = "init" ]]; then
        python -m angela $DEBUG_FLAG init
        return
    fi

    # Process as a request for anything else
    python -m angela $DEBUG_FLAG request "$@"
}

# ZSH completion function for angela
_angela_completion() {
    local curcontext="$curcontext" state line
    typeset -A opt_args
    
    # Get dynamic completions from Angela
    local completions=$(angela --completions "${words[@]:1}" 2>/dev/null)
    
    # If completions were returned, use them
    if [[ -n "$completions" ]]; then
        _arguments '*: :(('"$completions"'))'
        return
    fi
    
    # Fallback static completions
    _arguments \
        '1: :(init status shell files workflows generate rollback fix explain help-with)' \
        '*::arg:->args'
}
compdef _angela_completion angela
</file>

<file path="angela/shell/angela.tmux">
#!/bin/bash
# Angela CLI Tmux Integration

# Define Angela status indicator for Tmux status bar
angela_tmux_status() {
    # Check if Angela is enabled
    if [ -f "$HOME/.config/angela/enabled" ]; then
        echo "#[fg=green]◉ Angela#[fg=default]"
    else
        echo "#[fg=red]◯ Angela#[fg=default]"
    fi
}

# Register Angela key bindings
angela_tmux_bindings() {
    # Bind Alt+A to activate Angela
    tmux bind-key -n M-a run-shell "angela status"
    
    # Bind Alt+C to send current pane command to Angela
    tmux bind-key -n M-c run-shell "tmux capture-pane -p | tail -n 1 | sed 's/^[^#]*#//' | angela request"
    
    # Bind Alt+H for Angela help
    tmux bind-key -n M-h run-shell "angela --help"
}

# Setup Angela integration in Tmux
angela_tmux_setup() {
    # Add Angela status to right status bar
    tmux set-option -g status-right "#{?window_zoomed_flag,#[fg=yellow]Z#[fg=default] ,}#[fg=blue]#(angela_tmux_status) | %H:%M %d-%b-%y"
    
    # Register key bindings
    angela_tmux_bindings
    
    # Set the status update interval to update Angela status
    tmux set-option -g status-interval 5
}

# Main function
main() {
    # Check if we're running inside tmux
    if [ -n "$TMUX" ]; then
        angela_tmux_setup
        echo "Angela Tmux integration enabled"
    else
        echo "Error: Not running inside tmux session"
        exit 1
    fi
}

# Run main function
main "$@"
</file>

<file path="angela/toolchain/ci_cd.py">
# angela/toolchain/ci_cd.py
"""
CI/CD configuration generation for Angela CLI.

This module provides functionality for generating CI/CD configurations
for common CI platforms.
"""
import os
from pathlib import Path
from typing import Dict, Any, List, Optional, Union
import yaml
import json

from angela.utils.logging import get_logger
from angela.context import context_manager

logger = get_logger(__name__)

class CiCdIntegration:
    """
    Integration for CI/CD platforms.
    """
    
    def __init__(self):
        """Initialize the CI/CD integration."""
        self._logger = logger
        
        # Supported CI/CD platforms
        self._supported_platforms = [
            "github_actions",
            "gitlab_ci",
            "jenkins",
            "travis",
            "circle_ci"
        ]
    
    async def detect_project_type(
        self, 
        path: Union[str, Path]
    ) -> Dict[str, Any]:
        """
        Detect the project type for CI/CD configuration.
        
        Args:
            path: Path to the project
            
        Returns:
            Dictionary with the detected project info
        """
        self._logger.info(f"Detecting project type in {path}")
        
        path_obj = Path(path)
        
        # Check if path exists
        if not path_obj.exists() or not path_obj.is_dir():
            return {
                "detected": False,
                "error": f"Path does not exist or is not a directory: {path}",
                "project_type": None
            }
        
        # Check for project type indicators
        project_type = None
        
        # Python indicators
        if (path_obj / "requirements.txt").exists() or (path_obj / "setup.py").exists() or (path_obj / "pyproject.toml").exists():
            project_type = "python"
        # Node.js indicators
        elif (path_obj / "package.json").exists():
            project_type = "node"
        # Go indicators
        elif (path_obj / "go.mod").exists():
            project_type = "go"
        # Rust indicators
        elif (path_obj / "Cargo.toml").exists():
            project_type = "rust"
        # Java indicators
        elif (path_obj / "pom.xml").exists():
            project_type = "java"
        elif (path_obj / "build.gradle").exists() or (path_obj / "build.gradle.kts").exists():
            project_type = "java"
        # Ruby indicators
        elif (path_obj / "Gemfile").exists():
            project_type = "ruby"
        
        if project_type:
            return {
                "detected": True,
                "project_type": project_type,
                "project_path": str(path_obj)
            }
        
        # Try from context
        context = context_manager.get_context_dict()
        if context.get("project_type"):
            return {
                "detected": True,
                "project_type": context["project_type"],
                "project_path": str(path_obj),
                "from_context": True
            }
        
        return {
            "detected": False,
            "error": "Could not detect project type",
            "project_type": None
        }
    
    async def generate_ci_configuration(
        self, 
        path: Union[str, Path],
        platform: str,
        project_type: Optional[str] = None,
        custom_settings: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Generate a CI/CD configuration file.
        
        Args:
            path: Path to the project
            platform: CI/CD platform to generate for
            project_type: Optional project type
            custom_settings: Optional custom settings
            
        Returns:
            Dictionary with the generation result
        """
        self._logger.info(f"Generating CI configuration for {platform}")
        
        path_obj = Path(path)
        
        # Check if platform is supported
        if platform not in self._supported_platforms:
            return {
                "success": False,
                "error": f"Unsupported CI/CD platform: {platform}",
                "platform": platform
            }
        
        # Detect project type if not provided
        if project_type is None:
            detection_result = await self.detect_project_type(path_obj)
            project_type = detection_result.get("project_type")
            
            if not project_type:
                return {
                    "success": False,
                    "error": f"Could not detect project type: {detection_result.get('error', 'Unknown error')}",
                    "platform": platform
                }
        
        # Generate configuration based on platform
        if platform == "github_actions":
            return await self._generate_github_actions(path_obj, project_type, custom_settings)
        elif platform == "gitlab_ci":
            return await self._generate_gitlab_ci(path_obj, project_type, custom_settings)
        elif platform == "jenkins":
            return await self._generate_jenkins(path_obj, project_type, custom_settings)
        elif platform == "travis":
            return await self._generate_travis(path_obj, project_type, custom_settings)
        elif platform == "circle_ci":
            return await self._generate_circle_ci(path_obj, project_type, custom_settings)
        
        return {
            "success": False,
            "error": f"Unsupported CI/CD platform: {platform}",
            "platform": platform
        }
    
    async def _generate_github_actions(
        self, 
        path: Path,
        project_type: str,
        custom_settings: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Generate GitHub Actions configuration.
        
        Args:
            path: Path to the project
            project_type: Project type
            custom_settings: Optional custom settings
            
        Returns:
            Dictionary with the generation result
        """
        self._logger.info(f"Generating GitHub Actions configuration for {project_type}")
        
        # Create .github/workflows directory
        workflows_dir = path / ".github" / "workflows"
        if not workflows_dir.exists():
            os.makedirs(workflows_dir, exist_ok=True)
        
        # Get configuration settings
        settings = {}
        if custom_settings:
            settings.update(custom_settings)
        
        # Set default settings based on project type
        if project_type == "python":
            workflow = {
                "name": "Python CI",
                "on": {
                    "push": {
                        "branches": ["main", "master"]
                    },
                    "pull_request": {
                        "branches": ["main", "master"]
                    }
                },
                "jobs": {
                    "build": {
                        "runs-on": "ubuntu-latest",
                        "strategy": {
                            "matrix": {
                                "python-version": ["3.8", "3.9", "3.10"]
                            }
                        },
                        "steps": [
                            {
                                "name": "Checkout code",
                                "uses": "actions/checkout@v3"
                            },
                            {
                                "name": "Set up Python ${{ matrix.python-version }}",
                                "uses": "actions/setup-python@v4",
                                "with": {
                                    "python-version": "${{ matrix.python-version }}"
                                }
                            },
                            {
                                "name": "Install dependencies",
                                "run": "python -m pip install --upgrade pip\npip install -r requirements.txt\npip install pytest pytest-cov flake8"
                            },
                            {
                                "name": "Lint with flake8",
                                "run": "flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics"
                            },
                            {
                                "name": "Test with pytest",
                                "run": "pytest --cov=. --cov-report=xml"
                            },
                            {
                                "name": "Upload coverage to Codecov",
                                "uses": "codecov/codecov-action@v3",
                                "with": {
                                    "file": "./coverage.xml",
                                    "fail_ci_if_error": "false"
                                }
                            }
                        ]
                    }
                }
            }
        elif project_type == "node":
            workflow = {
                "name": "Node.js CI",
                "on": {
                    "push": {
                        "branches": ["main", "master"]
                    },
                    "pull_request": {
                        "branches": ["main", "master"]
                    }
                },
                "jobs": {
                    "build": {
                        "runs-on": "ubuntu-latest",
                        "strategy": {
                            "matrix": {
                                "node-version": ["14.x", "16.x", "18.x"]
                            }
                        },
                        "steps": [
                            {
                                "name": "Checkout code",
                                "uses": "actions/checkout@v3"
                            },
                            {
                                "name": "Use Node.js ${{ matrix.node-version }}",
                                "uses": "actions/setup-node@v3",
                                "with": {
                                    "node-version": "${{ matrix.node-version }}",
                                    "cache": "npm"
                                }
                            },
                            {
                                "name": "Install dependencies",
                                "run": "npm ci"
                            },
                            {
                                "name": "Run linting",
                                "run": "npm run lint --if-present"
                            },
                            {
                                "name": "Build",
                                "run": "npm run build --if-present"
                            },
                            {
                                "name": "Test",
                                "run": "npm test"
                            }
                        ]
                    }
                }
            }
        elif project_type == "go":
            workflow = {
                "name": "Go CI",
                "on": {
                    "push": {
                        "branches": ["main", "master"]
                    },
                    "pull_request": {
                        "branches": ["main", "master"]
                    }
                },
                "jobs": {
                    "build": {
                        "runs-on": "ubuntu-latest",
                        "steps": [
                            {
                                "name": "Checkout code",
                                "uses": "actions/checkout@v3"
                            },
                            {
                                "name": "Set up Go",
                                "uses": "actions/setup-go@v3",
                                "with": {
                                    "go-version": "1.18"
                                }
                            },
                            {
                                "name": "Build",
                                "run": "go build -v ./..."
                            },
                            {
                                "name": "Test",
                                "run": "go test -v ./..."
                            }
                        ]
                    }
                }
            }
        # Add other project types as needed
        
        # Update with custom settings
        if settings:
            # Use recursive update function (not shown) or libraries
            # This is a simplified approach
            if "jobs" in settings and "build" in settings["jobs"] and "steps" in settings["jobs"]["build"]:
                # Append custom steps
                workflow["jobs"]["build"]["steps"].extend(settings["jobs"]["build"]["steps"])
        
        # Write the workflow file
        workflow_file = workflows_dir / f"{project_type}-ci.yml"
        try:
            with open(workflow_file, 'w') as f:
                yaml.dump(workflow, f, default_flow_style=False, sort_keys=False)
            
            return {
                "success": True,
                "platform": "github_actions",
                "project_type": project_type,
                "config_file": str(workflow_file)
            }
        except Exception as e:
            return {
                "success": False,
                "error": f"Failed to write GitHub Actions workflow: {str(e)}",
                "platform": "github_actions",
                "project_type": project_type
            }
    
    async def _generate_gitlab_ci(
        self, 
        path: Path,
        project_type: str,
        custom_settings: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Generate GitLab CI configuration.
        
        Args:
            path: Path to the project
            project_type: Project type
            custom_settings: Optional custom settings
            
        Returns:
            Dictionary with the generation result
        """
        self._logger.info(f"Generating GitLab CI configuration for {project_type}")
        
        # Get configuration settings
        settings = {}
        if custom_settings:
            settings.update(custom_settings)
        
        # Set default settings based on project type
        if project_type == "python":
            config = {
                "image": "python:3.9",
                "stages": ["test", "build", "deploy"],
                "before_script": [
                    "python -V",
                    "pip install -r requirements.txt"
                ],
                "test": {
                    "stage": "test",
                    "script": [
                        "pip install pytest pytest-cov",
                        "pytest --cov=. --cov-report=xml",
                    ],
                    "artifacts": {
                        "reports": {
                            "coverage_report": {
                                "coverage_format": "cobertura",
                                "path": "coverage.xml"
                            }
                        }
                    }
                },
                "lint": {
                    "stage": "test",
                    "script": [
                        "pip install flake8",
                        "flake8 ."
                    ]
                },
                "build": {
                    "stage": "build",
                    "script": [
                        "echo 'Building package'",
                        "pip install build",
                        "python -m build"
                    ],
                    "artifacts": {
                        "paths": ["dist/"]
                    }
                }
            }
        elif project_type == "node":
            config = {
                "image": "node:16",
                "stages": ["test", "build", "deploy"],
                "cache": {
                    "paths": ["node_modules/"]
                },
                "install_dependencies": {
                    "stage": "test",
                    "script": ["npm ci"]
                },
                "test": {
                    "stage": "test",
                    "script": ["npm test"]
                },
                "lint": {
                    "stage": "test",
                    "script": ["npm run lint"]
                },
                "build": {
                    "stage": "build",
                    "script": ["npm run build"],
                    "artifacts": {
                        "paths": ["dist/", "build/"]
                    }
                }
            }
        # Add other project types as needed
        
        # Update with custom settings
        if settings:
            # Use recursive update function or libraries
            # This is a simplified approach
            for key, value in settings.items():
                if isinstance(value, dict) and key in config and isinstance(config[key], dict):
                    config[key].update(value)
                else:
                    config[key] = value
        
        # Write the config file
        config_file = path / ".gitlab-ci.yml"
        try:
            with open(config_file, 'w') as f:
                yaml.dump(config, f, default_flow_style=False, sort_keys=False)
            
            return {
                "success": True,
                "platform": "gitlab_ci",
                "project_type": project_type,
                "config_file": str(config_file)
            }
        except Exception as e:
            return {
                "success": False,
                "error": f"Failed to write GitLab CI config: {str(e)}",
                "platform": "gitlab_ci",
                "project_type": project_type
            }
    
    async def _generate_jenkins(
        self, 
        path: Path,
        project_type: str,
        custom_settings: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Generate Jenkins configuration (Jenkinsfile).
        
        Args:
            path: Path to the project
            project_type: Project type
            custom_settings: Optional custom settings
            
        Returns:
            Dictionary with the generation result
        """
        self._logger.info(f"Generating Jenkins configuration for {project_type}")
        
        # Set Jenkinsfile content based on project type
        if project_type == "python":
            content = """
pipeline {
    agent {
        docker {
            image 'python:3.9'
        }
    }
    stages {
        stage('Build') {
            steps {
                sh 'python -m pip install --upgrade pip'
                sh 'pip install -r requirements.txt'
            }
        }
        stage('Test') {
            steps {
                sh 'pip install pytest pytest-cov'
                sh 'pytest --cov=. --cov-report=xml'
            }
            post {
                always {
                    junit 'pytest-results.xml'
                    cobertura coberturaReportFile: 'coverage.xml'
                }
            }
        }
        stage('Lint') {
            steps {
                sh 'pip install flake8'
                sh 'flake8 .'
            }
        }
        stage('Deploy') {
            when {
                branch 'main'
            }
            steps {
                echo 'Deploying to production...'
                // Add deployment steps here
            }
        }
    }
}
"""
        elif project_type == "node":
            content = """
pipeline {
    agent {
        docker {
            image 'node:16'
        }
    }
    stages {
        stage('Build') {
            steps {
                sh 'npm ci'
                sh 'npm run build --if-present'
            }
        }
        stage('Test') {
            steps {
                sh 'npm test'
            }
        }
        stage('Lint') {
            steps {
                sh 'npm run lint --if-present'
            }
        }
        stage('Deploy') {
            when {
                branch 'main'
            }
            steps {
                echo 'Deploying to production...'
                // Add deployment steps here
            }
        }
    }
}
"""
        # Add other project types as needed
        
        # Update with custom settings
        # For Jenkins, we'd need more sophisticated templating to properly merge
        # custom settings into the Jenkinsfile
        
        # Write the Jenkinsfile
        jenkinsfile_path = path / "Jenkinsfile"
        try:
            with open(jenkinsfile_path, 'w') as f:
                f.write(content.strip())
            
            return {
                "success": True,
                "platform": "jenkins",
                "project_type": project_type,
                "config_file": str(jenkinsfile_path)
            }
        except Exception as e:
            return {
                "success": False,
                "error": f"Failed to write Jenkinsfile: {str(e)}",
                "platform": "jenkins",
                "project_type": project_type
            }
    
    async def _generate_travis(
        self, 
        path: Path,
        project_type: str,
        custom_settings: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Generate Travis CI configuration.
        
        Args:
            path: Path to the project
            project_type: Project type
            custom_settings: Optional custom settings
            
        Returns:
            Dictionary with the generation result
        """
        self._logger.info(f"Generating Travis CI configuration for {project_type}")
        
        # Get configuration settings
        settings = {}
        if custom_settings:
            settings.update(custom_settings)
        
        # Set default settings based on project type
        if project_type == "python":
            config = {
                "language": "python",
                "python": ["3.8", "3.9", "3.10"],
                "install": [
                    "pip install -r requirements.txt",
                    "pip install pytest pytest-cov flake8"
                ],
                "script": [
                    "flake8 .",
                    "pytest --cov=."
                ],
                "after_success": [
                    "bash <(curl -s https://codecov.io/bash)"
                ]
            }
        elif project_type == "node":
            config = {
                "language": "node_js",
                "node_js": ["14", "16", "18"],
                "cache": "npm",
                "install": [
                    "npm ci"
                ],
                "script": [
                    "npm run lint --if-present",
                    "npm run build --if-present",
                    "npm test"
                ]
            }
        # Add other project types as needed
        
        # Update with custom settings
        if settings:
            for key, value in settings.items():
                if isinstance(value, list) and key in config and isinstance(config[key], list):
                    config[key].extend(value)
                else:
                    config[key] = value
        
        # Write the config file
        config_file = path / ".travis.yml"
        try:
            with open(config_file, 'w') as f:
                yaml.dump(config, f, default_flow_style=False, sort_keys=False)
            
            return {
                "success": True,
                "platform": "travis",
                "project_type": project_type,
                "config_file": str(config_file)
            }
        except Exception as e:
            return {
                "success": False,
                "error": f"Failed to write Travis CI config: {str(e)}",
                "platform": "travis",
                "project_type": project_type
            }
    
    async def _generate_circle_ci(
        self, 
        path: Path,
        project_type: str,
        custom_settings: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Generate CircleCI configuration.
        
        Args:
            path: Path to the project
            project_type: Project type
            custom_settings: Optional custom settings
            
        Returns:
            Dictionary with the generation result
        """
        self._logger.info(f"Generating CircleCI configuration for {project_type}")
        
        # Create .circleci directory
        circleci_dir = path / ".circleci"
        if not circleci_dir.exists():
            os.makedirs(circleci_dir, exist_ok=True)
        
        # Get configuration settings
        settings = {}
        if custom_settings:
            settings.update(custom_settings)
        
        # Set default settings based on project type
        if project_type == "python":
            config = {
                "version": 2.1,
                "orbs": {
                    "python": "circleci/python@1.5"
                },
                "jobs": {
                    "build-and-test": {
                        "docker": [
                            {"image": "cimg/python:3.9"}
                        ],
                        "steps": [
                            "checkout",
                            {
                                "python/install-packages": {
                                    "pkg-manager": "pip",
                                    "packages": [
                                        "pytest",
                                        "pytest-cov"
                                    ]
                                }
                            },
                            {
                                "run": {
                                    "name": "Install dependencies",
                                    "command": "pip install -r requirements.txt"
                                }
                            },
                            {
                                "run": {
                                    "name": "Run tests",
                                    "command": "pytest --cov=. --cov-report=xml"
                                }
                            },
                            {
                                "store_artifacts": {
                                    "path": "coverage.xml"
                                }
                            }
                        ]
                    }
                },
                "workflows": {
                    "main": {
                        "jobs": [
                            "build-and-test"
                        ]
                    }
                }
            }
        elif project_type == "node":
            config = {
                "version": 2.1,
                "orbs": {
                    "node": "circleci/node@5.0.0"
                },
                "jobs": {
                    "build-and-test": {
                        "docker": [
                            {"image": "cimg/node:16.14"}
                        ],
                        "steps": [
                            "checkout",
                            {
                                "node/install-packages": {
                                    "pkg-manager": "npm"
                                }
                            },
                            {
                                "run": {
                                    "name": "Run tests",
                                    "command": "npm test"
                                }
                            },
                            {
                                "run": {
                                    "name": "Run lint",
                                    "command": "npm run lint --if-present"
                                }
                            },
                            {
                                "run": {
                                    "name": "Build",
                                    "command": "npm run build --if-present"
                                }
                            }
                        ]
                    }
                },
                "workflows": {
                    "main": {
                        "jobs": [
                            "build-and-test"
                        ]
                    }
                }
            }
        # Add other project types as needed
        
        # Update with custom settings
        if settings:
            # This is a simplified approach; in a real implementation, 
            # we'd need more sophisticated merging
            if "jobs" in settings and "build-and-test" in settings["jobs"] and "steps" in settings["jobs"]["build-and-test"]:
                config["jobs"]["build-and-test"]["steps"].extend(settings["jobs"]["build-and-test"]["steps"])
        
        # Write the config file
        config_file = circleci_dir / "config.yml"
        try:
            with open(config_file, 'w') as f:
                yaml.dump(config, f, default_flow_style=False, sort_keys=False)
            
            return {
                "success": True,
                "platform": "circle_ci",
                "project_type": project_type,
                "config_file": str(config_file)
            }
        except Exception as e:
            return {
                "success": False,
                "error": f"Failed to write CircleCI config: {str(e)}",
                "platform": "circle_ci",
                "project_type": project_type
            }

# Global CI/CD integration instance
ci_cd_integration = CiCdIntegration()
</file>

<file path="angela/toolchain/docker.py">
"""
Docker toolchain integration for Angela CLI.

This module provides functionality for interacting with Docker and Docker Compose,
including container management, image operations, and Dockerfile generation.
"""
import asyncio
import json
import os
import re
import shutil
import yaml
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple, Union, Set

from angela.utils.logging import get_logger
from angela.execution.engine import execution_engine
from angela.context import context_manager
from angela.safety.classifier import classify_command_risk

logger = get_logger(__name__)

# Constants for Docker file templates
DOCKERFILE_TEMPLATES = {
    "python": """FROM python:{python_version}-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

{expose_port}

CMD ["python", "{entry_point}"]
""",
    "node": """FROM node:{node_version}-alpine

WORKDIR /app

COPY package.json {package_lock} ./
RUN npm install {production_flag}

COPY . .

{expose_port}

CMD ["npm", "start"]
""",
    "golang": """FROM golang:{go_version}-alpine AS builder

WORKDIR /app

COPY go.mod go.sum ./
RUN go mod download

COPY . .
RUN go build -o main {main_file}

FROM alpine:latest

WORKDIR /app
COPY --from=builder /app/main .

{expose_port}

CMD ["./main"]
""",
    "java": """FROM maven:{maven_version}-jdk-{java_version} AS builder

WORKDIR /app
COPY pom.xml .
RUN mvn dependency:go-offline

COPY src ./src
RUN mvn package -DskipTests

FROM openjdk:{java_version}-jre-slim

WORKDIR /app
COPY --from=builder /app/target/{jar_file} app.jar

{expose_port}

CMD ["java", "-jar", "app.jar"]
""",
    "ruby": """FROM ruby:{ruby_version}-alpine

WORKDIR /app

COPY Gemfile Gemfile.lock ./
RUN bundle install --jobs 4 --retry 3

COPY . .

{expose_port}

CMD ["ruby", "{entry_point}"]
"""
}

DOCKER_COMPOSE_TEMPLATE = """version: '3'

services:
{services}
{networks}
{volumes}
"""

SERVICE_TEMPLATE = """  {service_name}:
    image: {image}
    build:
      context: {context}
      dockerfile: {dockerfile}
    {ports}
    {environment}
    {volumes}
    {depends_on}
    {networks}
"""

class DockerIntegration:
    """
    Integration with Docker and Docker Compose.
    
    Provides methods for interacting with Docker and Docker Compose,
    including command execution, file generation, and status checking.
    """
    
    def __init__(self):
        """Initialize Docker integration."""
        self._logger = logger
    
    async def is_docker_available(self) -> bool:
        """
        Check if Docker is available on the system.
        
        Returns:
            True if Docker is available, False otherwise
        """
        try:
            stdout, stderr, exit_code = await execution_engine.execute_command(
                "docker --version",
                check_safety=True
            )
            return exit_code == 0
        except Exception as e:
            self._logger.error(f"Error checking Docker availability: {str(e)}")
            return False
    
    async def is_docker_compose_available(self) -> bool:
        """
        Check if Docker Compose is available on the system.
        
        Returns:
            True if Docker Compose is available, False otherwise
        """
        try:
            # Try docker compose (v2) command first
            stdout, stderr, exit_code = await execution_engine.execute_command(
                "docker compose version",
                check_safety=True
            )
            if exit_code == 0:
                return True
            
            # Fall back to docker-compose (v1) command
            stdout, stderr, exit_code = await execution_engine.execute_command(
                "docker-compose --version",
                check_safety=True
            )
            return exit_code == 0
        except Exception as e:
            self._logger.error(f"Error checking Docker Compose availability: {str(e)}")
            return False
    
    async def get_docker_compose_command(self) -> str:
        """
        Get the appropriate Docker Compose command (v1 or v2).
        
        Returns:
            String with the appropriate command
        """
        try:
            # Check if docker compose (v2) is available
            stdout, stderr, exit_code = await execution_engine.execute_command(
                "docker compose version",
                check_safety=True
            )
            if exit_code == 0:
                return "docker compose"
            
            # Fall back to docker-compose (v1)
            return "docker-compose"
        except Exception as e:
            self._logger.error(f"Error determining Docker Compose command: {str(e)}")
            return "docker compose"  # Default to v2 compose
    
    #
    # Container Management
    #
    
    async def list_containers(self, all_containers: bool = False) -> Dict[str, Any]:
        """
        List Docker containers.
        
        Args:
            all_containers: Whether to list all containers (including stopped)
            
        Returns:
            Dictionary with container list and status information
        """
        self._logger.info(f"Listing {'all' if all_containers else 'running'} Docker containers")
        
        try:
            # Build command
            command = "docker ps --format json"
            if all_containers:
                command += " --all"
            
            # Execute command
            stdout, stderr, exit_code = await execution_engine.execute_command(
                command,
                check_safety=True
            )
            
            if exit_code != 0:
                return {
                    "success": False,
                    "error": f"Error listing containers: {stderr}",
                    "containers": []
                }
            
            # Parse container information
            containers = []
            
            # Handle older Docker versions that don't support --format json
            if not stdout.strip().startswith('['):
                # Fall back to regular format parsing
                fallback_command = f"docker ps{' --all' if all_containers else ''}"
                stdout, stderr, exit_code = await execution_engine.execute_command(
                    fallback_command,
                    check_safety=True
                )
                
                if exit_code != 0:
                    return {
                        "success": False,
                        "error": f"Error listing containers: {stderr}",
                        "containers": []
                    }
                
                # Parse tabular output
                lines = stdout.strip().split('\n')
                if len(lines) <= 1:  # Only header, no containers
                    return {
                        "success": True,
                        "containers": [],
                        "count": 0
                    }
                
                # Skip header
                lines = lines[1:]
                
                # Parse container lines
                for line in lines:
                    parts = re.split(r'\s{2,}', line.strip())
                    if len(parts) >= 7:
                        container = {
                            "id": parts[0],
                            "image": parts[1],
                            "command": parts[2],
                            "created": parts[3],
                            "status": parts[4],
                            "ports": parts[5] if len(parts) > 5 else "",
                            "names": parts[6] if len(parts) > 6 else ""
                        }
                        containers.append(container)
            else:
                # Parse JSON output for newer Docker versions
                for line in stdout.strip().split('\n'):
                    if line.strip():
                        try:
                            container = json.loads(line)
                            containers.append(container)
                        except json.JSONDecodeError as e:
                            self._logger.error(f"Error parsing container JSON: {str(e)}")
            
            return {
                "success": True,
                "containers": containers,
                "count": len(containers)
            }
        except Exception as e:
            self._logger.exception(f"Error listing containers: {str(e)}")
            return {
                "success": False,
                "error": f"Error listing containers: {str(e)}",
                "containers": []
            }
    
    async def get_container_details(self, container_id_or_name: str) -> Dict[str, Any]:
        """
        Get detailed information about a specific container.
        
        Args:
            container_id_or_name: Container ID or name
            
        Returns:
            Dictionary with container details
        """
        self._logger.info(f"Getting details for container: {container_id_or_name}")
        
        try:
            # Execute command
            stdout, stderr, exit_code = await execution_engine.execute_command(
                f"docker inspect {container_id_or_name}",
                check_safety=True
            )
            
            if exit_code != 0:
                return {
                    "success": False,
                    "error": f"Error inspecting container: {stderr}"
                }
            
            # Parse container details
            try:
                details = json.loads(stdout)
                if not details or not isinstance(details, list):
                    return {
                        "success": False,
                        "error": "Invalid container details format"
                    }
                
                # Get first item (there should be only one)
                container_info = details[0]
                
                # Extract useful information
                result = {
                    "success": True,
                    "id": container_info.get("Id", ""),
                    "name": container_info.get("Name", "").lstrip('/'),
                    "image": container_info.get("Config", {}).get("Image", ""),
                    "state": container_info.get("State", {}),
                    "network_settings": container_info.get("NetworkSettings", {}),
                    "mounts": container_info.get("Mounts", []),
                    "config": container_info.get("Config", {}),
                    "created": container_info.get("Created", ""),
                    "full_details": container_info
                }
                
                return result
            except json.JSONDecodeError as e:
                return {
                    "success": False,
                    "error": f"Error parsing container details: {str(e)}"
                }
        except Exception as e:
            self._logger.exception(f"Error getting container details: {str(e)}")
            return {
                "success": False,
                "error": f"Error getting container details: {str(e)}"
            }
    
    async def start_container(self, container_id_or_name: str) -> Dict[str, Any]:
        """
        Start a Docker container.
        
        Args:
            container_id_or_name: Container ID or name
            
        Returns:
            Dictionary with operation status
        """
        self._logger.info(f"Starting container: {container_id_or_name}")
        
        try:
            # Execute command
            stdout, stderr, exit_code = await execution_engine.execute_command(
                f"docker start {container_id_or_name}",
                check_safety=True
            )
            
            if exit_code != 0:
                return {
                    "success": False,
                    "error": f"Error starting container: {stderr}"
                }
            
            return {
                "success": True,
                "message": f"Container {container_id_or_name} started successfully",
                "output": stdout.strip()
            }
        except Exception as e:
            self._logger.exception(f"Error starting container: {str(e)}")
            return {
                "success": False,
                "error": f"Error starting container: {str(e)}"
            }
    
    async def stop_container(self, container_id_or_name: str, timeout: Optional[int] = None) -> Dict[str, Any]:
        """
        Stop a Docker container.
        
        Args:
            container_id_or_name: Container ID or name
            timeout: Optional timeout in seconds
            
        Returns:
            Dictionary with operation status
        """
        self._logger.info(f"Stopping container: {container_id_or_name}")
        
        try:
            # Build command
            command = f"docker stop {container_id_or_name}"
            if timeout is not None:
                command += f" --time {timeout}"
            
            # Execute command
            stdout, stderr, exit_code = await execution_engine.execute_command(
                command,
                check_safety=True
            )
            
            if exit_code != 0:
                return {
                    "success": False,
                    "error": f"Error stopping container: {stderr}"
                }
            
            return {
                "success": True,
                "message": f"Container {container_id_or_name} stopped successfully",
                "output": stdout.strip()
            }
        except Exception as e:
            self._logger.exception(f"Error stopping container: {str(e)}")
            return {
                "success": False,
                "error": f"Error stopping container: {str(e)}"
            }
    
    async def restart_container(self, container_id_or_name: str, timeout: Optional[int] = None) -> Dict[str, Any]:
        """
        Restart a Docker container.
        
        Args:
            container_id_or_name: Container ID or name
            timeout: Optional timeout in seconds
            
        Returns:
            Dictionary with operation status
        """
        self._logger.info(f"Restarting container: {container_id_or_name}")
        
        try:
            # Build command
            command = f"docker restart {container_id_or_name}"
            if timeout is not None:
                command += f" --time {timeout}"
            
            # Execute command
            stdout, stderr, exit_code = await execution_engine.execute_command(
                command,
                check_safety=True
            )
            
            if exit_code != 0:
                return {
                    "success": False,
                    "error": f"Error restarting container: {stderr}"
                }
            
            return {
                "success": True,
                "message": f"Container {container_id_or_name} restarted successfully",
                "output": stdout.strip()
            }
        except Exception as e:
            self._logger.exception(f"Error restarting container: {str(e)}")
            return {
                "success": False,
                "error": f"Error restarting container: {str(e)}"
            }
    
    async def remove_container(
        self, 
        container_id_or_name: str, 
        force: bool = False,
        remove_volumes: bool = False
    ) -> Dict[str, Any]:
        """
        Remove a Docker container.
        
        Args:
            container_id_or_name: Container ID or name
            force: Force removal of running container
            remove_volumes: Remove anonymous volumes
            
        Returns:
            Dictionary with operation status
        """
        self._logger.info(f"Removing container: {container_id_or_name}")
        
        try:
            # Build command
            command = f"docker rm {container_id_or_name}"
            if force:
                command += " --force"
            if remove_volumes:
                command += " --volumes"
            
            # Execute command
            stdout, stderr, exit_code = await execution_engine.execute_command(
                command,
                check_safety=True
            )
            
            if exit_code != 0:
                return {
                    "success": False,
                    "error": f"Error removing container: {stderr}"
                }
            
            return {
                "success": True,
                "message": f"Container {container_id_or_name} removed successfully",
                "output": stdout.strip()
            }
        except Exception as e:
            self._logger.exception(f"Error removing container: {str(e)}")
            return {
                "success": False,
                "error": f"Error removing container: {str(e)}"
            }
    
    async def get_container_logs(
        self, 
        container_id_or_name: str, 
        tail: Optional[int] = None,
        follow: bool = False,
        timestamps: bool = False,
        since: Optional[str] = None,
        until: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Get logs from a Docker container.
        
        Args:
            container_id_or_name: Container ID or name
            tail: Number of lines to show from the end
            follow: Follow log output
            timestamps: Show timestamps
            since: Show logs since timestamp
            until: Show logs until timestamp
            
        Returns:
            Dictionary with container logs
        """
        self._logger.info(f"Getting logs for container: {container_id_or_name}")
        
        # Build command
        command = f"docker logs {container_id_or_name}"
        if tail is not None:
            command += f" --tail {tail}"
        if timestamps:
            command += " --timestamps"
        if since:
            command += f" --since {since}"
        if until:
            command += f" --until {until}"
        
        try:
            if follow:
                # For follow mode, we need to stream the output
                # This is a simplified implementation - a more complex one would use
                # a proper streaming mechanism with callbacks
                command += " --follow"
                
                # Limit to 30 seconds maximum for safety
                process = await asyncio.create_subprocess_shell(
                    command,
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE
                )
                
                try:
                    # Wait for up to 30 seconds
                    stdout, stderr = await asyncio.wait_for(
                        process.communicate(), 
                        timeout=30
                    )
                    stdout_str = stdout.decode('utf-8', errors='replace')
                    stderr_str = stderr.decode('utf-8', errors='replace')
                    
                    return {
                        "success": process.returncode == 0,
                        "logs": stdout_str,
                        "error": stderr_str if process.returncode != 0 else None,
                        "followed": True,
                        "truncated": False
                    }
                except asyncio.TimeoutError:
                    # Kill the process after timeout
                    process.kill()
                    return {
                        "success": True,
                        "logs": "Log streaming timeout after 30 seconds",
                        "followed": True,
                        "truncated": True
                    }
            else:
                # For non-follow mode, just execute the command
                stdout, stderr, exit_code = await execution_engine.execute_command(
                    command,
                    check_safety=True
                )
                
                if exit_code != 0:
                    return {
                        "success": False,
                        "error": f"Error getting container logs: {stderr}"
                    }
                
                return {
                    "success": True,
                    "logs": stdout,
                    "followed": False
                }
        except Exception as e:
            self._logger.exception(f"Error getting container logs: {str(e)}")
            return {
                "success": False,
                "error": f"Error getting container logs: {str(e)}"
            }
    
    async def run_container(
        self,
        image: str,
        command: Optional[str] = None,
        name: Optional[str] = None,
        ports: Optional[List[str]] = None,
        volumes: Optional[List[str]] = None,
        environment: Optional[Dict[str, str]] = None,
        detach: bool = True,
        remove: bool = False,
        network: Optional[str] = None,
        interactive: bool = False
    ) -> Dict[str, Any]:
        """
        Run a Docker container.
        
        Args:
            image: Docker image to run
            command: Command to run in the container
            name: Name for the container
            ports: Port mappings (host:container)
            volumes: Volume mappings (host:container)
            environment: Environment variables
            detach: Run container in background
            remove: Remove container when it exits
            network: Connect to network
            interactive: Run container with interactive mode
            
        Returns:
            Dictionary with operation status
        """
        self._logger.info(f"Running container from image: {image}")
        
        # Build command
        docker_command = "docker run"
        
        if detach:
            docker_command += " --detach"
        if remove:
            docker_command += " --rm"
        if interactive:
            docker_command += " --interactive --tty"
        
        # Add name if provided
        if name:
            docker_command += f" --name {name}"
        
        # Add network if provided
        if network:
            docker_command += f" --network {network}"
        
        # Add port mappings
        if ports:
            for port_mapping in ports:
                docker_command += f" --publish {port_mapping}"
        
        # Add volume mappings
        if volumes:
            for volume_mapping in volumes:
                docker_command += f" --volume {volume_mapping}"
        
        # Add environment variables
        if environment:
            for key, value in environment.items():
                docker_command += f" --env {key}={value}"
        
        # Add image
        docker_command += f" {image}"
        
        # Add command if provided
        if command:
            docker_command += f" {command}"
        
        try:
            # Execute command
            stdout, stderr, exit_code = await execution_engine.execute_command(
                docker_command,
                check_safety=True
            )
            
            if exit_code != 0:
                return {
                    "success": False,
                    "error": f"Error running container: {stderr}",
                    "command": docker_command
                }
            
            container_id = stdout.strip()
            
            return {
                "success": True,
                "message": f"Container started successfully{'in detached mode' if detach else ''}",
                "container_id": container_id,
                "command": docker_command
            }
        except Exception as e:
            self._logger.exception(f"Error running container: {str(e)}")
            return {
                "success": False,
                "error": f"Error running container: {str(e)}",
                "command": docker_command
            }
    
    async def exec_in_container(
        self,
        container_id_or_name: str,
        command: str,
        interactive: bool = False
    ) -> Dict[str, Any]:
        """
        Execute a command in a running container.
        
        Args:
            container_id_or_name: Container ID or name
            command: Command to execute
            interactive: Run in interactive mode
            
        Returns:
            Dictionary with execution result
        """
        self._logger.info(f"Executing command in container {container_id_or_name}: {command}")
        
        # Build docker exec command
        docker_command = f"docker exec"
        if interactive:
            docker_command += " --interactive --tty"
        
        docker_command += f" {container_id_or_name} {command}"
        
        try:
            # Execute command
            stdout, stderr, exit_code = await execution_engine.execute_command(
                docker_command,
                check_safety=True
            )
            
            if exit_code != 0:
                return {
                    "success": False,
                    "error": f"Error executing command in container: {stderr}",
                    "command": docker_command
                }
            
            return {
                "success": True,
                "output": stdout,
                "command": docker_command
            }
        except Exception as e:
            self._logger.exception(f"Error executing command in container: {str(e)}")
            return {
                "success": False,
                "error": f"Error executing command in container: {str(e)}",
                "command": docker_command
            }
    
    #
    # Image Management
    #
    
    async def list_images(self, show_all: bool = False) -> Dict[str, Any]:
        """
        List Docker images.
        
        Args:
            show_all: Whether to show all images (including intermediate)
            
        Returns:
            Dictionary with image list
        """
        self._logger.info("Listing Docker images")
        
        try:
            # Build command
            command = "docker images --format json"
            if show_all:
                command += " --all"
            
            # Execute command
            stdout, stderr, exit_code = await execution_engine.execute_command(
                command,
                check_safety=True
            )
            
            if exit_code != 0:
                return {
                    "success": False,
                    "error": f"Error listing images: {stderr}",
                    "images": []
                }
            
            # Parse image information
            images = []
            
            # Handle older Docker versions that don't support --format json
            if not stdout.strip().startswith('[') and not stdout.strip().startswith('{'):
                # Fall back to regular format parsing
                fallback_command = f"docker images{' --all' if show_all else ''}"
                stdout, stderr, exit_code = await execution_engine.execute_command(
                    fallback_command,
                    check_safety=True
                )
                
                if exit_code != 0:
                    return {
                        "success": False,
                        "error": f"Error listing images: {stderr}",
                        "images": []
                    }
                
                # Parse tabular output
                lines = stdout.strip().split('\n')
                if len(lines) <= 1:  # Only header, no images
                    return {
                        "success": True,
                        "images": [],
                        "count": 0
                    }
                
                # Skip header
                lines = lines[1:]
                
                # Parse image lines
                for line in lines:
                    parts = re.split(r'\s{2,}', line.strip())
                    if len(parts) >= 5:
                        image = {
                            "repository": parts[0],
                            "tag": parts[1],
                            "id": parts[2],
                            "created": parts[3],
                            "size": parts[4]
                        }
                        images.append(image)
            else:
                # Parse JSON output for newer Docker versions
                for line in stdout.strip().split('\n'):
                    if line.strip():
                        try:
                            image = json.loads(line)
                            images.append(image)
                        except json.JSONDecodeError as e:
                            self._logger.error(f"Error parsing image JSON: {str(e)}")
            
            return {
                "success": True,
                "images": images,
                "count": len(images)
            }
        except Exception as e:
            self._logger.exception(f"Error listing images: {str(e)}")
            return {
                "success": False,
                "error": f"Error listing images: {str(e)}",
                "images": []
            }
    
    async def build_image(
        self,
        context_path: Union[str, Path],
        tag: Optional[str] = None,
        dockerfile: Optional[str] = None,
        build_args: Optional[Dict[str, str]] = None,
        no_cache: bool = False
    ) -> Dict[str, Any]:
        """
        Build a Docker image.
        
        Args:
            context_path: Path to build context
            tag: Tag for the built image
            dockerfile: Path to Dockerfile (relative to context_path)
            build_args: Build arguments
            no_cache: Do not use cache when building
            
        Returns:
            Dictionary with build result
        """
        self._logger.info(f"Building Docker image from context: {context_path}")
        
        # Ensure context path exists
        context_path_obj = Path(context_path)
        if not context_path_obj.exists() or not context_path_obj.is_dir():
            return {
                "success": False,
                "error": f"Build context does not exist or is not a directory: {context_path}"
            }
        
        # Build command
        command = f"docker build {context_path_obj}"
        
        if tag:
            command += f" --tag {tag}"
        
        if dockerfile:
            command += f" --file {dockerfile}"
        
        if build_args:
            for key, value in build_args.items():
                command += f" --build-arg {key}={value}"
        
        if no_cache:
            command += " --no-cache"
        
        try:
            # Execute command
            stdout, stderr, exit_code = await execution_engine.execute_command(
                command,
                check_safety=True
            )
            
            if exit_code != 0:
                return {
                    "success": False,
                    "error": f"Error building image: {stderr}",
                    "command": command
                }
            
            # Parse image ID from output
            image_id = None
            for line in stdout.splitlines():
                if line.strip().startswith("Successfully built "):
                    image_id = line.strip().split(" ")[-1]
                    break
            
            return {
                "success": True,
                "message": "Image built successfully",
                "image_id": image_id,
                "tag": tag,
                "output": stdout,
                "command": command
            }
        except Exception as e:
            self._logger.exception(f"Error building image: {str(e)}")
            return {
                "success": False,
                "error": f"Error building image: {str(e)}",
                "command": command
            }
    
    async def remove_image(
        self,
        image_id_or_name: str,
        force: bool = False
    ) -> Dict[str, Any]:
        """
        Remove a Docker image.
        
        Args:
            image_id_or_name: Image ID or name
            force: Force removal
            
        Returns:
            Dictionary with removal result
        """
        self._logger.info(f"Removing Docker image: {image_id_or_name}")
        
        # Build command
        command = f"docker rmi {image_id_or_name}"
        if force:
            command += " --force"
        
        try:
            # Execute command
            stdout, stderr, exit_code = await execution_engine.execute_command(
                command,
                check_safety=True
            )
            
            if exit_code != 0:
                return {
                    "success": False,
                    "error": f"Error removing image: {stderr}",
                    "command": command
                }
            
            return {
                "success": True,
                "message": f"Image {image_id_or_name} removed successfully",
                "output": stdout.strip(),
                "command": command
            }
        except Exception as e:
            self._logger.exception(f"Error removing image: {str(e)}")
            return {
                "success": False,
                "error": f"Error removing image: {str(e)}",
                "command": command
            }
    
    async def pull_image(self, image_name: str) -> Dict[str, Any]:
        """
        Pull a Docker image from a registry.
        
        Args:
            image_name: Image name to pull
            
        Returns:
            Dictionary with pull result
        """
        self._logger.info(f"Pulling Docker image: {image_name}")
        
        try:
            # Execute command
            stdout, stderr, exit_code = await execution_engine.execute_command(
                f"docker pull {image_name}",
                check_safety=True
            )
            
            if exit_code != 0:
                return {
                    "success": False,
                    "error": f"Error pulling image: {stderr}"
                }
            
            return {
                "success": True,
                "message": f"Image {image_name} pulled successfully",
                "output": stdout.strip()
            }
        except Exception as e:
            self._logger.exception(f"Error pulling image: {str(e)}")
            return {
                "success": False,
                "error": f"Error pulling image: {str(e)}"
            }
    
    #
    # Docker Compose
    #
    
    async def compose_up(
        self,
        compose_file: Optional[Union[str, Path]] = None,
        project_directory: Optional[Union[str, Path]] = None,
        detach: bool = True,
        build: bool = False,
        no_recreate: bool = False,
        force_recreate: bool = False,
        services: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """
        Start containers using Docker Compose.
        
        Args:
            compose_file: Path to docker-compose.yml (default: docker-compose.yml in project_directory)
            project_directory: Project directory (default: current directory)
            detach: Run in background
            build: Build images before starting
            no_recreate: Don't recreate containers
            force_recreate: Force recreate containers
            services: List of services to start (default: all)
            
        Returns:
            Dictionary with operation result
        """
        self._logger.info(f"Starting services with Docker Compose")
        
        # Get appropriate Docker Compose command
        compose_command = await self.get_docker_compose_command()
        
        # Determine project directory
        if project_directory is None:
            project_directory = context_manager.cwd
        else:
            project_directory = Path(project_directory)
        
        # Build command
        command = f"{compose_command}"
        
        if compose_file:
            command += f" -f {compose_file}"
        
        command += " up"
        
        if detach:
            command += " -d"
        
        if build:
            command += " --build"
        
        if no_recreate:
            command += " --no-recreate"
        
        if force_recreate:
            command += " --force-recreate"
        
        # Add services if specified
        if services:
            command += " " + " ".join(services)
        
        try:
            # Execute command
            stdout, stderr, exit_code = await execution_engine.execute_command(
                command,
                check_safety=True,
                working_dir=str(project_directory)
            )
            
            if exit_code != 0:
                return {
                    "success": False,
                    "error": f"Error starting Docker Compose services: {stderr}",
                    "command": command,
                    "working_dir": str(project_directory)
                }
            
            return {
                "success": True,
                "message": "Docker Compose services started successfully",
                "output": stdout,
                "command": command,
                "working_dir": str(project_directory)
            }
        except Exception as e:
            self._logger.exception(f"Error starting Docker Compose services: {str(e)}")
            return {
                "success": False,
                "error": f"Error starting Docker Compose services: {str(e)}",
                "command": command,
                "working_dir": str(project_directory)
            }
    
    async def compose_down(
        self,
        compose_file: Optional[Union[str, Path]] = None,
        project_directory: Optional[Union[str, Path]] = None,
        remove_images: bool = False,
        remove_volumes: bool = False,
        remove_orphans: bool = False
    ) -> Dict[str, Any]:
        """
        Stop and remove containers, networks, volumes, and images created by compose up.
        
        Args:
            compose_file: Path to docker-compose.yml (default: docker-compose.yml in project_directory)
            project_directory: Project directory (default: current directory)
            remove_images: Remove images
            remove_volumes: Remove volumes
            remove_orphans: Remove containers for services not defined in the Compose file
            
        Returns:
            Dictionary with operation result
        """
        self._logger.info(f"Stopping services with Docker Compose")
        
        # Get appropriate Docker Compose command
        compose_command = await self.get_docker_compose_command()
        
        # Determine project directory
        if project_directory is None:
            project_directory = context_manager.cwd
        else:
            project_directory = Path(project_directory)
        
        # Build command
        command = f"{compose_command}"
        
        if compose_file:
            command += f" -f {compose_file}"
        
        command += " down"
        
        if remove_images:
            command += " --rmi all"
        
        if remove_volumes:
            command += " --volumes"
        
        if remove_orphans:
            command += " --remove-orphans"
        
        try:
            # Execute command
            stdout, stderr, exit_code = await execution_engine.execute_command(
                command,
                check_safety=True,
                working_dir=str(project_directory)
            )
            
            if exit_code != 0:
                return {
                    "success": False,
                    "error": f"Error stopping Docker Compose services: {stderr}",
                    "command": command,
                    "working_dir": str(project_directory)
                }
            
            return {
                "success": True,
                "message": "Docker Compose services stopped successfully",
                "output": stdout,
                "command": command,
                "working_dir": str(project_directory)
            }
        except Exception as e:
            self._logger.exception(f"Error stopping Docker Compose services: {str(e)}")
            return {
                "success": False,
                "error": f"Error stopping Docker Compose services: {str(e)}",
                "command": command,
                "working_dir": str(project_directory)
            }
    
    async def compose_logs(
        self,
        compose_file: Optional[Union[str, Path]] = None,
        project_directory: Optional[Union[str, Path]] = None,
        services: Optional[List[str]] = None,
        follow: bool = False,
        tail: Optional[int] = None,
        timestamps: bool = False
    ) -> Dict[str, Any]:
        """
        View logs from Docker Compose services.
        
        Args:
            compose_file: Path to docker-compose.yml (default: docker-compose.yml in project_directory)
            project_directory: Project directory (default: current directory)
            services: List of services to show logs for (default: all)
            follow: Follow log output
            tail: Number of lines to show from the end
            timestamps: Show timestamps
            
        Returns:
            Dictionary with logs
        """
        self._logger.info(f"Getting logs from Docker Compose services")
        
        # Get appropriate Docker Compose command
        compose_command = await self.get_docker_compose_command()
        
        # Determine project directory
        if project_directory is None:
            project_directory = context_manager.cwd
        else:
            project_directory = Path(project_directory)
        
        # Build command
        command = f"{compose_command}"
        
        if compose_file:
            command += f" -f {compose_file}"
        
        command += " logs"
        
        if follow:
            command += " --follow"
        
        if tail is not None:
            command += f" --tail={tail}"
        
        if timestamps:
            command += " --timestamps"
        
        # Add services if specified
        if services:
            command += " " + " ".join(services)
        
        try:
            if follow:
                # For follow mode, we need to stream the output
                # This is a simplified implementation
                
                # Limit to 30 seconds maximum for safety
                process = await asyncio.create_subprocess_shell(
                    command,
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE,
                    cwd=str(project_directory)
                )
                
                try:
                    # Wait for up to 30 seconds
                    stdout, stderr = await asyncio.wait_for(
                        process.communicate(), 
                        timeout=30
                    )
                    stdout_str = stdout.decode('utf-8', errors='replace')
                    stderr_str = stderr.decode('utf-8', errors='replace')
                    
                    return {
                        "success": process.returncode == 0,
                        "logs": stdout_str,
                        "error": stderr_str if process.returncode != 0 else None,
                        "followed": True,
                        "truncated": False,
                        "command": command,
                        "working_dir": str(project_directory)
                    }
                except asyncio.TimeoutError:
                    # Kill the process after timeout
                    process.kill()
                    return {
                        "success": True,
                        "logs": "Log streaming timeout after 30 seconds",
                        "followed": True,
                        "truncated": True,
                        "command": command,
                        "working_dir": str(project_directory)
                    }
            else:
                # Execute command
                stdout, stderr, exit_code = await execution_engine.execute_command(
                    command,
                    check_safety=True,
                    working_dir=str(project_directory)
                )
                
                if exit_code != 0:
                    return {
                        "success": False,
                        "error": f"Error getting Docker Compose logs: {stderr}",
                        "command": command,
                        "working_dir": str(project_directory)
                    }
                
                return {
                    "success": True,
                    "logs": stdout,
                    "command": command,
                    "working_dir": str(project_directory)
                }
        except Exception as e:
            self._logger.exception(f"Error getting Docker Compose logs: {str(e)}")
            return {
                "success": False,
                "error": f"Error getting Docker Compose logs: {str(e)}",
                "command": command,
                "working_dir": str(project_directory)
            }
    
    async def compose_ps(
        self,
        compose_file: Optional[Union[str, Path]] = None,
        project_directory: Optional[Union[str, Path]] = None,
        services: Optional[List[str]] = None,
        all_services: bool = False
    ) -> Dict[str, Any]:
        """
        List Docker Compose services.
        
        Args:
            compose_file: Path to docker-compose.yml (default: docker-compose.yml in project_directory)
            project_directory: Project directory (default: current directory)
            services: List of services to show (default: all)
            all_services: Show stopped services
            
        Returns:
            Dictionary with services list
        """
        self._logger.info(f"Listing Docker Compose services")
        
        # Get appropriate Docker Compose command
        compose_command = await self.get_docker_compose_command()
        
        # Determine project directory
        if project_directory is None:
            project_directory = context_manager.cwd
        else:
            project_directory = Path(project_directory)
        
        # Build command
        command = f"{compose_command}"
        
        if compose_file:
            command += f" -f {compose_file}"
        
        command += " ps"
        
        if all_services:
            command += " --all"
        
        # Add services if specified
        if services:
            command += " " + " ".join(services)
        
        try:
            # Execute command
            stdout, stderr, exit_code = await execution_engine.execute_command(
                command,
                check_safety=True,
                working_dir=str(project_directory)
            )
            
            if exit_code != 0:
                return {
                    "success": False,
                    "error": f"Error listing Docker Compose services: {stderr}",
                    "command": command,
                    "working_dir": str(project_directory)
                }
            
            # Parse service information
            services_info = []
            
            # Skip empty output
            if not stdout.strip():
                return {
                    "success": True,
                    "services": [],
                    "count": 0,
                    "command": command,
                    "working_dir": str(project_directory)
                }
            
            # Parse table output (format varies between compose versions)
            lines = stdout.strip().split('\n')
            if len(lines) <= 1:  # Only header, no services
                return {
                    "success": True,
                    "services": [],
                    "count": 0,
                    "command": command,
                    "working_dir": str(project_directory)
                }
            
            # Try to parse as a table with header
            header = lines[0]
            data_lines = lines[1:]
            
            for line in data_lines:
                # Different compose versions have different formats
                # Try to extract at least name and state
                parts = re.split(r'\s{2,}', line.strip())
                if len(parts) >= 2:
                    service = {"name": parts[0]}
                    
                    # Detect format
                    if "Up" in line or "Exit" in line:
                        # Search for status like "Up 2 hours" or "Exit (1) 5 minutes ago"
                        status_match = re.search(r'(Up|Exit \(\d+\))[^,]*', line)
                        if status_match:
                            service["status"] = status_match.group(0)
                    
                    # Add all parts with labels if we can identify them
                    if len(header.split()) >= len(parts):
                        header_parts = re.split(r'\s{2,}', header.strip())
                        for i, value in enumerate(parts):
                            if i < len(header_parts):
                                key = header_parts[i].lower().replace(' ', '_')
                                service[key] = value
                    
                    services_info.append(service)
            
            return {
                "success": True,
                "services": services_info,
                "count": len(services_info),
                "raw_output": stdout,
                "command": command,
                "working_dir": str(project_directory)
            }
        except Exception as e:
            self._logger.exception(f"Error listing Docker Compose services: {str(e)}")
            return {
                "success": False,
                "error": f"Error listing Docker Compose services: {str(e)}",
                "command": command,
                "working_dir": str(project_directory)
            }
    
    #
    # Dockerfile Generation
    #
    
    async def detect_project_type(
        self, 
        project_directory: Union[str, Path]
    ) -> Dict[str, Any]:
        """
        Detect the type of project in a directory.
        
        Args:
            project_directory: Path to the project directory
            
        Returns:
            Dictionary with project type and details
        """
        self._logger.info(f"Detecting project type in: {project_directory}")
        
        project_dir = Path(project_directory)
        if not project_dir.exists() or not project_dir.is_dir():
            return {
                "success": False,
                "error": f"Project directory does not exist or is not a directory: {project_directory}"
            }
        
        # Look for common project markers
        markers = {
            "python": ["requirements.txt", "setup.py", "pyproject.toml", "Pipfile"],
            "node": ["package.json", "yarn.lock", "package-lock.json"],
            "golang": ["go.mod", "go.sum"],
            "java": ["pom.xml", "build.gradle", "build.gradle.kts"],
            "ruby": ["Gemfile", "Gemfile.lock"],
            "php": ["composer.json", "composer.lock"],
            "dotnet": ["*.csproj", "*.fsproj", "*.vbproj"]
        }
        
        # Check for each marker
        detected_types = {}
        
        for project_type, files in markers.items():
            for file_pattern in files:
                # Handle glob patterns
                if "*" in file_pattern:
                    matching_files = list(project_dir.glob(file_pattern))
                    if matching_files:
                        detected_types[project_type] = {
                            "marker_file": str(matching_files[0].relative_to(project_dir)),
                            "confidence": 0.9
                        }
                        break
                else:
                    file_path = project_dir / file_pattern
                    if file_path.exists():
                        detected_types[project_type] = {
                            "marker_file": file_pattern,
                            "confidence": 0.9
                        }
                        break
        
        # If nothing detected, try to infer from file extensions
        if not detected_types:
            extensions = {}
            
            # Count file extensions
            for file_path in project_dir.glob("**/*"):
                if file_path.is_file():
                    ext = file_path.suffix.lower()
                    if ext:
                        extensions[ext] = extensions.get(ext, 0) + 1
            
            # Map extensions to project types
            extension_types = {
                ".py": "python",
                ".js": "node",
                ".ts": "node",
                ".jsx": "node",
                ".tsx": "node",
                ".go": "golang",
                ".java": "java",
                ".rb": "ruby",
                ".php": "php",
                ".cs": "dotnet",
                ".fs": "dotnet",
                ".vb": "dotnet"
            }
            
            # Count by project type
            type_counts = {}
            for ext, count in extensions.items():
                if ext in extension_types:
                    project_type = extension_types[ext]
                    type_counts[project_type] = type_counts.get(project_type, 0) + count
            
            # Sort by count
            if type_counts:
                most_common = max(type_counts.items(), key=lambda x: x[1])
                detected_types[most_common[0]] = {
                    "inferred_from_extensions": True,
                    "file_count": most_common[1],
                    "confidence": 0.7
                }
        
        # Detect versions for the project
        version_info = {}
        for project_type in detected_types.keys():
            if project_type == "python":
                version_info["python_version"] = await self._detect_python_version(project_dir)
            elif project_type == "node":
                version_info["node_version"] = await self._detect_node_version(project_dir)
            elif project_type == "golang":
                version_info["go_version"] = await self._detect_go_version(project_dir)
            elif project_type == "java":
                java_info = await self._detect_java_version(project_dir)
                version_info.update(java_info)
            elif project_type == "ruby":
                version_info["ruby_version"] = await self._detect_ruby_version(project_dir)
        
        # Determine the most likely project type
        result = {
            "success": True,
            "detected_types": detected_types,
            "version_info": version_info
        }
        
        if detected_types:
            # Find the type with highest confidence
            best_type = max(detected_types.items(), key=lambda x: x[1]["confidence"])
            result["primary_type"] = best_type[0]
            result["details"] = best_type[1]
        else:
            result["primary_type"] = "unknown"
        
        return result
    
    async def _detect_python_version(self, project_dir: Path) -> str:
        """
        Detect Python version used in a project.
        
        Args:
            project_dir: Path to the project directory
            
        Returns:
            Python version string
        """
        # Check for explicit version in pyproject.toml
        pyproject_path = project_dir / "pyproject.toml"
        if pyproject_path.exists():
            try:
                with open(pyproject_path, 'r') as f:
                    content = f.read()
                    # Look for requires-python or python_requires
                    requires_match = re.search(r'(requires-python|python_requires)\s*=\s*["\']([^"\']+)["\']', content)
                    if requires_match:
                        version_req = requires_match.group(2)
                        # Extract a simple version number from the requirement
                        version_match = re.search(r'(\d+\.\d+)', version_req)
                        if version_match:
                            return version_match.group(1)
            except Exception as e:
                self._logger.error(f"Error reading pyproject.toml: {str(e)}")
        
        # Check .python-version file
        python_version_file = project_dir / ".python-version"
        if python_version_file.exists():
            try:
                with open(python_version_file, 'r') as f:
                    version = f.read().strip()
                    if version:
                        return version
            except Exception as e:
                self._logger.error(f"Error reading .python-version: {str(e)}")
        
        # Default to 3.10 if no specific version found
        return "3.10"
    
    async def _detect_node_version(self, project_dir: Path) -> str:
        """
        Detect Node.js version used in a project.
        
        Args:
            project_dir: Path to the project directory
            
        Returns:
            Node.js version string
        """
        # Check package.json for engines field
        package_json_path = project_dir / "package.json"
        if package_json_path.exists():
            try:
                with open(package_json_path, 'r') as f:
                    data = json.load(f)
                    if "engines" in data and "node" in data["engines"]:
                        # Extract a simple version number from the requirement
                        version_req = data["engines"]["node"]
                        version_match = re.search(r'(\d+\.\d+)', version_req)
                        if version_match:
                            return version_match.group(1)
            except Exception as e:
                self._logger.error(f"Error reading package.json: {str(e)}")
        
        # Check .nvmrc file
        nvmrc_file = project_dir / ".nvmrc"
        if nvmrc_file.exists():
            try:
                with open(nvmrc_file, 'r') as f:
                    version = f.read().strip()
                    if version:
                        # Clean up version string
                        version = version.lstrip('v')
                        version_match = re.search(r'(\d+\.\d+)', version)
                        if version_match:
                            return version_match.group(1)
            except Exception as e:
                self._logger.error(f"Error reading .nvmrc: {str(e)}")
        
        # Default to 18 if no specific version found
        return "18"
    
    async def _detect_go_version(self, project_dir: Path) -> str:
        """
        Detect Go version used in a project.
        
        Args:
            project_dir: Path to the project directory
            
        Returns:
            Go version string
        """
        # Check go.mod file
        go_mod_path = project_dir / "go.mod"
        if go_mod_path.exists():
            try:
                with open(go_mod_path, 'r') as f:
                    content = f.read()
                    # Look for go directive
                    go_match = re.search(r'go\s+(\d+\.\d+)', content)
                    if go_match:
                        return go_match.group(1)
            except Exception as e:
                self._logger.error(f"Error reading go.mod: {str(e)}")
        
        # Default to 1.19 if no specific version found
        return "1.19"
    
    async def _detect_java_version(self, project_dir: Path) -> Dict[str, str]:
        """
        Detect Java version and build tool used in a project.
        
        Args:
            project_dir: Path to the project directory
            
        Returns:
            Dictionary with java_version and build tool info
        """
        result = {
            "java_version": "17",  # Default
            "maven_version": "3.8"  # Default
        }
        
        # Check for Maven pom.xml
        pom_path = project_dir / "pom.xml"
        if pom_path.exists():
            result["build_tool"] = "maven"
            try:
                with open(pom_path, 'r') as f:
                    content = f.read()
                    # Look for Java version
                    java_match = re.search(r'<java.version>(\d+)</java.version>', content)
                    if java_match:
                        result["java_version"] = java_match.group(1)
                    
                    # Look for Maven compiler source
                    compiler_match = re.search(r'<maven.compiler.source>(\d+)</maven.compiler.source>', content)
                    if compiler_match:
                        result["java_version"] = compiler_match.group(1)
                    
                    # Try to find jar file name
                    artifact_match = re.search(r'<artifactId>([^<]+)</artifactId>', content)
                    if artifact_match:
                        result["jar_file"] = f"{artifact_match.group(1)}.jar"
            except Exception as e:
                self._logger.error(f"Error reading pom.xml: {str(e)}")
        
        # Check for Gradle build file
        gradle_path = project_dir / "build.gradle"
        if gradle_path.exists():
            result["build_tool"] = "gradle"
            try:
                with open(gradle_path, 'r') as f:
                    content = f.read()
                    # Look for Java version
                    java_match = re.search(r'sourceCompatibility\s*=\s*[\'"](\d+)[\'"]', content)
                    if java_match:
                        result["java_version"] = java_match.group(1)
            except Exception as e:
                self._logger.error(f"Error reading build.gradle: {str(e)}")
        
        return result
    
    async def _detect_ruby_version(self, project_dir: Path) -> str:
        """
        Detect Ruby version used in a project.
        
        Args:
            project_dir: Path to the project directory
            
        Returns:
            Ruby version string
        """
        # Check .ruby-version file
        ruby_version_file = project_dir / ".ruby-version"
        if ruby_version_file.exists():
            try:
                with open(ruby_version_file, 'r') as f:
                    version = f.read().strip()
                    if version:
                        return version
            except Exception as e:
                self._logger.error(f"Error reading .ruby-version: {str(e)}")
        
        # Check Gemfile
        gemfile_path = project_dir / "Gemfile"
        if gemfile_path.exists():
            try:
                with open(gemfile_path, 'r') as f:
                    content = f.read()
                    # Look for ruby directive
                    ruby_match = re.search(r'ruby\s+[\'"](\d+\.\d+\.\d+)[\'"]', content)
                    if ruby_match:
                        return ruby_match.group(1)
            except Exception as e:
                self._logger.error(f"Error reading Gemfile: {str(e)}")
        
        # Default to 3.1 if no specific version found
        return "3.1"
    
    async def detect_services(self, project_directory: Union[str, Path]) -> Dict[str, Any]:
        """
        Detect potential services in a project.
        
        Args:
            project_directory: Path to the project directory
            
        Returns:
            Dictionary with detected services
        """
        self._logger.info(f"Detecting services in project: {project_directory}")
        
        project_dir = Path(project_directory)
        if not project_dir.exists() or not project_dir.is_dir():
            return {
                "success": False,
                "error": f"Project directory does not exist or is not a directory: {project_directory}"
            }
        
        # Get project type
        project_type_info = await self.detect_project_type(project_dir)
        if not project_type_info["success"]:
            return project_type_info
        
        primary_type = project_type_info["primary_type"]
        version_info = project_type_info["version_info"]
        
        # Detect entry points based on project type
        entry_points = await self._detect_entry_points(project_dir, primary_type)
        
        # Detect ports used by the application
        ports = await self._detect_ports(project_dir, primary_type)
        
        # Detect dependencies that might indicate additional services
        dependencies = await self._detect_dependencies(project_dir, primary_type)
        
        # Detect databases
        databases = await self._detect_databases(project_dir, primary_type, dependencies)
        
        # Build services map
        services = {}
        
        # Main service for the project
        services["app"] = {
            "type": primary_type,
            "entry_point": entry_points.get("main"),
            "ports": ports.get("app", []),
            "build": {
                "context": ".",
                "dockerfile": "Dockerfile"
            }
        }
        
        # Add additional services based on dependencies
        for db_name, db_info in databases.items():
            services[db_name] = {
                "type": "database",
                "image": db_info["image"],
                "ports": db_info["ports"],
                "volumes": db_info["volumes"],
                "environment": db_info["environment"]
            }
        
        # Detect other services based on dockerfiles or compose files
        for docker_dir in project_dir.glob("**/[Dd]ocker"):
            if docker_dir.is_dir():
                for service_dir in docker_dir.glob("*"):
                    if service_dir.is_dir() and service_dir.name not in services:
                        dockerfile = service_dir / "Dockerfile"
                        if dockerfile.exists():
                            services[service_dir.name] = {
                                "type": "custom",
                                "build": {
                                    "context": str(service_dir.relative_to(project_dir)),
                                    "dockerfile": "Dockerfile"
                                }
                            }
        
        return {
            "success": True,
            "primary_type": primary_type,
            "version_info": version_info,
            "entry_points": entry_points,
            "ports": ports,
            "dependencies": dependencies,
            "databases": databases,
            "services": services
        }
    
    async def _detect_entry_points(
        self, 
        project_dir: Path, 
        project_type: str
    ) -> Dict[str, str]:
        """
        Detect entry points for a project.
        
        Args:
            project_dir: Path to the project directory
            project_type: Type of the project
            
        Returns:
            Dictionary with entry points
        """
        entry_points = {"main": None}
        
        if project_type == "python":
            # Check for common Python entry points
            candidates = [
                "app.py", "main.py", "run.py", "server.py", "api.py",
                "src/app.py", "src/main.py", "src/server.py"
            ]
            
            for candidate in candidates:
                candidate_path = project_dir / candidate
                if candidate_path.exists():
                    entry_points["main"] = candidate
                    break
            
            # Check for Flask or Django apps
            if (project_dir / "wsgi.py").exists():
                entry_points["main"] = "wsgi.py"
            elif (project_dir / "manage.py").exists():
                entry_points["main"] = "manage.py"
        
        elif project_type == "node":
            # Check package.json for main or scripts.start
            package_json_path = project_dir / "package.json"
            if package_json_path.exists():
                try:
                    with open(package_json_path, 'r') as f:
                        data = json.load(f)
                        if "main" in data:
                            entry_points["main"] = data["main"]
                        elif "scripts" in data and "start" in data["scripts"]:
                            # Use the start script
                            entry_points["main"] = "npm start"
                except Exception as e:
                    self._logger.error(f"Error reading package.json: {str(e)}")
            
            # Check common Node.js entry points
            if not entry_points["main"]:
                candidates = [
                    "index.js", "server.js", "app.js", "main.js",
                    "src/index.js", "src/server.js", "src/app.js"
                ]
                
                for candidate in candidates:
                    candidate_path = project_dir / candidate
                    if candidate_path.exists():
                        entry_points["main"] = candidate
                        break
        
        elif project_type == "golang":
            # Check for main.go
            candidates = [
                "main.go", "cmd/main.go", "cmd/app/main.go", "cmd/server/main.go"
            ]
            
            for candidate in candidates:
                candidate_path = project_dir / candidate
                if candidate_path.exists():
                    entry_points["main"] = candidate
                    break
        
        elif project_type == "ruby":
            # Check for common Ruby entry points
            candidates = [
                "app.rb", "main.rb", "server.rb", "config.ru"
            ]
            
            for candidate in candidates:
                candidate_path = project_dir / candidate
                if candidate_path.exists():
                    entry_points["main"] = candidate
                    break
        
        # If no entry point found, use a reasonable default
        if not entry_points["main"]:
            if project_type == "python":
                entry_points["main"] = "app.py"
            elif project_type == "node":
                entry_points["main"] = "index.js"
            elif project_type == "golang":
                entry_points["main"] = "main.go"
            elif project_type == "java":
                entry_points["main"] = "src/main/java/Main.java"
            elif project_type == "ruby":
                entry_points["main"] = "app.rb"
        
        return entry_points
    
    async def _detect_ports(
        self, 
        project_dir: Path, 
        project_type: str
    ) -> Dict[str, List[int]]:
        """
        Detect ports used by the application.
        
        Args:
            project_dir: Path to the project directory
            project_type: Type of the project
            
        Returns:
            Dictionary with ports information
        """
        ports = {
            "app": []
        }
        
        # Common default ports
        default_ports = {
            "http": 8080,
            "https": 8443,
            "django": 8000,
            "flask": 5000,
            "express": 3000,
            "react": 3000,
            "vue": 8080,
            "angular": 4200,
            "mongodb": 27017,
            "mysql": 3306,
            "postgresql": 5432,
            "redis": 6379
        }
        
        # Add default port based on project type
        if project_type == "python":
            # Look for common Python web frameworks
            try:
                # Read requirements.txt to check dependencies
                req_file = project_dir / "requirements.txt"
                if req_file.exists():
                    with open(req_file, 'r') as f:
                        requirements = f.read()
                        if "django" in requirements.lower():
                            ports["app"].append(default_ports["django"])
                        elif "flask" in requirements.lower():
                            ports["app"].append(default_ports["flask"])
                        elif "fastapi" in requirements.lower():
                            ports["app"].append(default_ports["http"])
            except Exception as e:
                self._logger.error(f"Error analyzing requirements: {str(e)}")
        
        elif project_type == "node":
            # Default to Express port
            ports["app"].append(default_ports["express"])
            
            # Check package.json for dependencies
            package_json_path = project_dir / "package.json"
            if package_json_path.exists():
                try:
                    with open(package_json_path, 'r') as f:
                        data = json.load(f)
                        dependencies = data.get("dependencies", {})
                        
                        if "react" in dependencies:
                            if "express" not in dependencies:
                                ports["app"] = [default_ports["react"]]
                        elif "vue" in dependencies:
                            ports["app"] = [default_ports["vue"]]
                        elif "angular" in dependencies:
                            ports["app"] = [default_ports["angular"]]
                except Exception as e:
                    self._logger.error(f"Error reading package.json: {str(e)}")
        
        # Look for port references in code files
        detected_ports = await self._scan_for_ports(project_dir)
        if detected_ports:
            # Add detected ports to app ports
            for port in detected_ports:
                if port not in ports["app"]:
                    ports["app"].append(port)
        
        # If no ports detected, use a sensible default
        if not ports["app"]:
            ports["app"].append(default_ports["http"])
        
        return ports
    
    async def _scan_for_ports(self, project_dir: Path) -> List[int]:
        """
        Scan project files for port specifications.
        
        Args:
            project_dir: Path to the project directory
            
        Returns:
            List of detected ports
        """
        detected_ports = set()
        
        # Pattern for common port assignments
        port_patterns = [
            r'(?:PORT|port)\s*=\s*(\d+)',
            r'\.listen\(\s*(\d+)',
            r'port\s*:\s*(\d+)',
            r'port=(\d+)',
            r'"port":\s*(\d+)',
            r"'port':\s*(\d+)",
            r'EXPOSE\s+(\d+)'
        ]
        
        # Limit scanning to common config and source files to avoid binary files
        # and reduce processing time
        file_patterns = [
            "*.py", "*.js", "*.ts", "*.jsx", "*.tsx", "*.go", "*.rb", "*.java",
            "*.yml", "*.yaml", "*.json", "*.env", "*.toml", "*.ini", "Dockerfile"
        ]
        
        for pattern in file_patterns:
            for file_path in project_dir.glob(f"**/{pattern}"):
                if file_path.is_file() and file_path.stat().st_size < 1000000:  # Skip large files
                    try:
                        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                            content = f.read()
                            for port_pattern in port_patterns:
                                matches = re.findall(port_pattern, content)
                                for match in matches:
                                    try:
                                        port = int(match)
                                        if 1 <= port <= 65535:  # Valid port range
                                            detected_ports.add(port)
                                    except ValueError:
                                        pass
                    except Exception as e:
                        # Skip files with encoding or access issues
                        pass
        
        return list(sorted(detected_ports))
    
    async def _detect_dependencies(
        self, 
        project_dir: Path, 
        project_type: str
    ) -> Dict[str, List[str]]:
        """
        Detect dependencies for a project.
        
        Args:
            project_dir: Path to the project directory
            project_type: Type of the project
            
        Returns:
            Dictionary with dependencies
        """
        dependencies = {
            "databases": [],
            "messaging": [],
            "cache": []
        }
        
        # Database keywords to look for
        database_keywords = {
            "mongodb": ["mongodb", "mongoose", "pymongo"],
            "mysql": ["mysql", "sequelize", "mysql-connector"],
            "postgresql": ["postgresql", "postgres", "pg", "psycopg2", "sqlalchemy"],
            "sqlite": ["sqlite", "sqlite3"],
            "redis": ["redis"],
            "elasticsearch": ["elasticsearch", "elastic"],
            "cassandra": ["cassandra"]
        }
        
        # Messaging systems
        messaging_keywords = {
            "rabbitmq": ["rabbitmq", "amqp"],
            "kafka": ["kafka"],
            "activemq": ["activemq"],
            "sqs": ["sqs", "aws-sdk"]
        }
        
        # Cache systems
        cache_keywords = {
            "redis": ["redis"],
            "memcached": ["memcached", "memcache"]
        }
        
        if project_type == "python":
            # Check requirements.txt
            req_file = project_dir / "requirements.txt"
            if req_file.exists():
                try:
                    with open(req_file, 'r') as f:
                        requirements = f.read().lower()
                        
                        # Check for database dependencies
                        for db, keywords in database_keywords.items():
                            if any(keyword in requirements for keyword in keywords):
                                dependencies["databases"].append(db)
                        
                        # Check for messaging dependencies
                        for msg, keywords in messaging_keywords.items():
                            if any(keyword in requirements for keyword in keywords):
                                dependencies["messaging"].append(msg)
                        
                        # Check for cache dependencies
                        for cache, keywords in cache_keywords.items():
                            if any(keyword in requirements for keyword in keywords):
                                dependencies["cache"].append(cache)
                except Exception as e:
                    self._logger.error(f"Error analyzing requirements: {str(e)}")
        
        elif project_type == "node":
            # Check package.json
            package_json_path = project_dir / "package.json"
            if package_json_path.exists():
                try:
                    with open(package_json_path, 'r') as f:
                        data = json.load(f)
                        deps = {**data.get("dependencies", {}), **data.get("devDependencies", {})}
                        deps_str = " ".join(deps.keys()).lower()
                        
                        # Check for database dependencies
                        for db, keywords in database_keywords.items():
                            if any(keyword in deps_str for keyword in keywords):
                                dependencies["databases"].append(db)
                        
                        # Check for messaging dependencies
                        for msg, keywords in messaging_keywords.items():
                            if any(keyword in deps_str for keyword in keywords):
                                dependencies["messaging"].append(msg)
                        
                        # Check for cache dependencies
                        for cache, keywords in cache_keywords.items():
                            if any(keyword in deps_str for keyword in keywords):
                                dependencies["cache"].append(cache)
                except Exception as e:
                    self._logger.error(f"Error reading package.json: {str(e)}")
        
        # Remove duplicates (e.g. redis can be both database and cache)
        for category in dependencies:
            dependencies[category] = list(set(dependencies[category]))
        
        return dependencies
    
    async def _detect_databases(
        self, 
        project_dir: Path, 
        project_type: str,
        dependencies: Dict[str, List[str]]
    ) -> Dict[str, Dict[str, Any]]:
        """
        Detect databases used by the project.
        
        Args:
            project_dir: Path to the project directory
            project_type: Type of the project
            dependencies: Detected dependencies
            
        Returns:
            Dictionary with database configurations
        """
        databases = {}
        
        # Map database names to configurations
        db_configs = {
            "mongodb": {
                "image": "mongo:6",
                "ports": ["27017:27017"],
                "volumes": ["mongodb_data:/data/db"],
                "environment": {
                    "MONGO_INITDB_ROOT_USERNAME": "root",
                    "MONGO_INITDB_ROOT_PASSWORD": "example"
                }
            },
            "mysql": {
                "image": "mysql:8",
                "ports": ["3306:3306"],
                "volumes": ["mysql_data:/var/lib/mysql"],
                "environment": {
                    "MYSQL_ROOT_PASSWORD": "example",
                    "MYSQL_DATABASE": "app"
                }
            },
            "postgresql": {
                "image": "postgres:14",
                "ports": ["5432:5432"],
                "volumes": ["postgres_data:/var/lib/postgresql/data"],
                "environment": {
                    "POSTGRES_PASSWORD": "example",
                    "POSTGRES_USER": "postgres",
                    "POSTGRES_DB": "app"
                }
            },
            "redis": {
                "image": "redis:7",
                "ports": ["6379:6379"],
                "volumes": ["redis_data:/data"],
                "command": "redis-server --appendonly yes"
            },
            "elasticsearch": {
                "image": "elasticsearch:8.6.0",
                "ports": ["9200:9200", "9300:9300"],
                "volumes": ["elasticsearch_data:/usr/share/elasticsearch/data"],
                "environment": {
                    "discovery.type": "single-node",
                    "ES_JAVA_OPTS": "-Xms512m -Xmx512m"
                }
            }
        }
        
        # Add detected databases
        for db in dependencies.get("databases", []):
            if db in db_configs:
                databases[db] = db_configs[db]
        
        # Add Redis if it's used as a cache
        if "redis" in dependencies.get("cache", []) and "redis" not in databases:
            databases["redis"] = db_configs["redis"]
        
        return databases
    
    async def generate_dockerfile(
        self,
        project_directory: Union[str, Path],
        output_file: Optional[Union[str, Path]] = None,
        overwrite: bool = False
    ) -> Dict[str, Any]:
        """
        Generate a Dockerfile for a project.
        
        Args:
            project_directory: Path to the project directory
            output_file: Path to output Dockerfile (default: <project_directory>/Dockerfile)
            overwrite: Whether to overwrite existing Dockerfile
            
        Returns:
            Dictionary with result information
        """
        self._logger.info(f"Generating Dockerfile for project: {project_directory}")
        
        project_dir = Path(project_directory)
        if not project_dir.exists() or not project_dir.is_dir():
            return {
                "success": False,
                "error": f"Project directory does not exist or is not a directory: {project_directory}"
            }
        
        # Determine output file
        if output_file is None:
            output_file = project_dir / "Dockerfile"
        else:
            output_file = Path(output_file)
        
        # Check if file already exists
        if output_file.exists() and not overwrite:
            return {
                "success": False,
                "error": f"Dockerfile already exists at {output_file}. Use overwrite=True to replace it."
            }
        
        # Detect project type
        project_info = await self.detect_project_type(project_dir)
        if not project_info["success"]:
            return project_info
        
        project_type = project_info["primary_type"]
        version_info = project_info["version_info"]
        
        # Detect entry points
        entry_points = await self._detect_entry_points(project_dir, project_type)
        
        # Detect ports
        ports_info = await self._detect_ports(project_dir, project_type)
        app_ports = ports_info.get("app", [8080])  # Default to 8080 if no ports detected
        
        # Generate Dockerfile content based on project type
        dockerfile_content = ""
        
        if project_type == "python":
            # Get Python version
            python_version = version_info.get("python_version", "3.10")
            
            # Format EXPOSE statement
            expose_port = ""
            if app_ports:
                expose_port = f"EXPOSE {app_ports[0]}"
            
            # Get entry point file
            entry_point = entry_points.get("main", "app.py")
            
            # Generate Dockerfile
            dockerfile_content = DOCKERFILE_TEMPLATES["python"].format(
                python_version=python_version,
                entry_point=entry_point,
                expose_port=expose_port
            )
        
        elif project_type == "node":
            # Get Node.js version
            node_version = version_info.get("node_version", "18")
            
            # Format EXPOSE statement
            expose_port = ""
            if app_ports:
                expose_port = f"EXPOSE {app_ports[0]}"
            
            # Check for package lock file
            package_lock = ""
            if (project_dir / "package-lock.json").exists():
                package_lock = "package-lock.json"
            elif (project_dir / "yarn.lock").exists():
                package_lock = "yarn.lock"
            
            # Determine if it's a production build
            production_flag = "--production"
            
            # Generate Dockerfile
            dockerfile_content = DOCKERFILE_TEMPLATES["node"].format(
                node_version=node_version,
                package_lock=package_lock,
                expose_port=expose_port,
                production_flag=production_flag
            )
        
        elif project_type == "golang":
            # Get Go version
            go_version = version_info.get("go_version", "1.19")
            
            # Format EXPOSE statement
            expose_port = ""
            if app_ports:
                expose_port = f"EXPOSE {app_ports[0]}"
            
            # Get main file
            main_file = entry_points.get("main", "main.go")
            
            # Generate Dockerfile
            dockerfile_content = DOCKERFILE_TEMPLATES["golang"].format(
                go_version=go_version,
                main_file=main_file,
                expose_port=expose_port
            )
        
        elif project_type == "java":
            # Get Java version
            java_version = version_info.get("java_version", "17")
            maven_version = version_info.get("maven_version", "3.8")
            jar_file = version_info.get("jar_file", "app.jar")
            
            # Format EXPOSE statement
            expose_port = ""
            if app_ports:
                expose_port = f"EXPOSE {app_ports[0]}"
            
            # Generate Dockerfile
            dockerfile_content = DOCKERFILE_TEMPLATES["java"].format(
                java_version=java_version,
                maven_version=maven_version,
                jar_file=jar_file,
                expose_port=expose_port
            )
        
        elif project_type == "ruby":
            # Get Ruby version
            ruby_version = version_info.get("ruby_version", "3.1")
            
            # Format EXPOSE statement
            expose_port = ""
            if app_ports:
                expose_port = f"EXPOSE {app_ports[0]}"
            
            # Get entry point file
            entry_point = entry_points.get("main", "app.rb")
            
            # Generate Dockerfile
            dockerfile_content = DOCKERFILE_TEMPLATES["ruby"].format(
                ruby_version=ruby_version,
                entry_point=entry_point,
                expose_port=expose_port
            )
        
        else:
            return {
                "success": False,
                "error": f"Unsupported project type: {project_type}",
                "suggestion": "Try specifying a different project type or creating a custom Dockerfile."
            }
        
        # Write Dockerfile
        try:
            with open(output_file, 'w') as f:
                f.write(dockerfile_content)
            
            return {
                "success": True,
                "message": f"Dockerfile generated successfully at {output_file}",
                "dockerfile_path": str(output_file),
                "project_type": project_type,
                "entry_point": entry_points.get("main"),
                "ports": app_ports,
                "content": dockerfile_content
            }
        except Exception as e:
            self._logger.exception(f"Error writing Dockerfile: {str(e)}")
            return {
                "success": False,
                "error": f"Error writing Dockerfile: {str(e)}"
            }
    
    async def generate_docker_compose(
        self,
        project_directory: Union[str, Path],
        output_file: Optional[Union[str, Path]] = None,
        overwrite: bool = False,
        include_databases: bool = True
    ) -> Dict[str, Any]:
        """
        Generate a docker-compose.yml file for a project.
        
        Args:
            project_directory: Path to the project directory
            output_file: Path to output file (default: <project_directory>/docker-compose.yml)
            overwrite: Whether to overwrite existing file
            include_databases: Whether to include detected database services
            
        Returns:
            Dictionary with result information
        """
        self._logger.info(f"Generating docker-compose.yml for project: {project_directory}")
        
        project_dir = Path(project_directory)
        if not project_dir.exists() or not project_dir.is_dir():
            return {
                "success": False,
                "error": f"Project directory does not exist or is not a directory: {project_directory}"
            }
        
        # Determine output file
        if output_file is None:
            output_file = project_dir / "docker-compose.yml"
        else:
            output_file = Path(output_file)
        
        # Check if file already exists
        if output_file.exists() and not overwrite:
            return {
                "success": False,
                "error": f"docker-compose.yml already exists at {output_file}. Use overwrite=True to replace it."
            }
        
        # Detect services
        services_info = await self.detect_services(project_dir)
        if not services_info["success"]:
            return services_info
        
        services = services_info["services"]
        
        # Generate docker-compose.yml content
        services_content = ""
        networks_content = "networks:\n  app-network:\n    driver: bridge\n"
        volumes_content = "volumes:\n"
        
        # Check if Dockerfile exists
        dockerfile_exists = (project_dir / "Dockerfile").exists()
        
        # Generate app service
        app_service = services.get("app", {})
        app_ports = app_service.get("ports", [8080])
        
        ports_str = ""
        if app_ports:
            ports_str = "    ports:\n"
            for port in app_ports:
                ports_str += f"      - '{port}:{port}'\n"
        
        # Environment variables
        environment_str = ""
        
        # Volumes
        volumes_str = ""
        
        # Networks
        networks_str = "    networks:\n      - app-network\n"
        
        # Depends on (empty for app service)
        depends_on_str = ""
        
        # App service
        if dockerfile_exists:
            services_content += SERVICE_TEMPLATE.format(
                service_name="app",
                image="app:latest",
                context=".",
                dockerfile="Dockerfile",
                ports=ports_str,
                environment=environment_str,
                volumes=volumes_str,
                depends_on=depends_on_str,
                networks=networks_str
            )
        
        # Generate database services
        if include_databases:
            databases = services_info.get("databases", {})
            depends_on_list = []
            
            for db_name, db_info in databases.items():
                # Add volume for database
                volumes_content += f"  {db_name}_data:\n"
                
                # Add database service
                db_ports = ""
                if db_info.get("ports"):
                    db_ports = "    ports:\n"
                    for port in db_info["ports"]:
                        db_ports += f"      - '{port}'\n"
                
                db_volumes = ""
                if db_info.get("volumes"):
                    db_volumes = "    volumes:\n"
                    for volume in db_info["volumes"]:
                        db_volumes += f"      - {volume}\n"
                
                db_environment = ""
                if db_info.get("environment"):
                    db_environment = "    environment:\n"
                    for key, value in db_info["environment"].items():
                        db_environment += f"      - {key}={value}\n"
                
                db_networks = "    networks:\n      - app-network\n"
                
                services_content += SERVICE_TEMPLATE.format(
                    service_name=db_name,
                    image=db_info["image"],
                    context=".",
                    dockerfile="Dockerfile",
                    ports=db_ports,
                    environment=db_environment,
                    volumes=db_volumes,
                    depends_on="",
                    networks=db_networks
                )
                
                # Add to depends_on list for app service
                depends_on_list.append(db_name)
            
            # Update app service with depends_on if needed
            if depends_on_list and dockerfile_exists:
                depends_on_str = "    depends_on:\n"
                for dep in depends_on_list:
                    depends_on_str += f"      - {dep}\n"
                
                # Replace app service with updated version
                services_content = services_content.replace(
                    "app:\n    image: app:latest",
                    f"app:\n    image: app:latest\n{depends_on_str}"
                )
        
        # Combine all sections
        compose_content = DOCKER_COMPOSE_TEMPLATE.format(
            services=services_content,
            networks=networks_content,
            volumes=volumes_content
        )
        
        # Write docker-compose.yml
        try:
            with open(output_file, 'w') as f:
                f.write(compose_content)
            
            return {
                "success": True,
                "message": f"docker-compose.yml generated successfully at {output_file}",
                "compose_file_path": str(output_file),
                "services_included": list(services.keys()),
                "content": compose_content
            }
        except Exception as e:
            self._logger.exception(f"Error writing docker-compose.yml: {str(e)}")
            return {
                "success": False,
                "error": f"Error writing docker-compose.yml: {str(e)}"
            }

    async def generate_dockerignore(
        self,
        project_directory: Union[str, Path],
        output_file: Optional[Union[str, Path]] = None,
        overwrite: bool = False
    ) -> Dict[str, Any]:
        """
        Generate a .dockerignore file for a project.
        
        Args:
            project_directory: Path to the project directory
            output_file: Path to output file (default: <project_directory>/.dockerignore)
            overwrite: Whether to overwrite existing file
            
        Returns:
            Dictionary with result information
        """
        self._logger.info(f"Generating .dockerignore for project: {project_directory}")
        
        project_dir = Path(project_directory)
        if not project_dir.exists() or not project_dir.is_dir():
            return {
                "success": False,
                "error": f"Project directory does not exist or is not a directory: {project_directory}"
            }
        
        # Determine output file
        if output_file is None:
            output_file = project_dir / ".dockerignore"
        else:
            output_file = Path(output_file)
        
        # Check if file already exists
        if output_file.exists() and not overwrite:
            return {
                "success": False,
                "error": f".dockerignore already exists at {output_file}. Use overwrite=True to replace it."
            }
        
        # Detect project type
        project_info = await self.detect_project_type(project_dir)
        project_type = project_info["primary_type"]
        
        # Common files to ignore
        common_ignores = [
            "**/.git",
            "**/.gitignore",
            "**/.vscode",
            "**/.idea",
            "**/__pycache__",
            "**/node_modules",
            "**/dist",
            "**/build",
            "**/.env",
            "**/.DS_Store",
            "**/*.log",
            "**/*.swp",
            "**/*.swo",
            "Dockerfile",
            "docker-compose.yml",
            "README.md",
            ".dockerignore"
        ]
        
        # Type-specific ignores
        type_specific_ignores = {
            "python": [
                "**/*.pyc",
                "**/*.pyo",
                "**/*.pyd",
                "**/.Python",
                "**/env/",
                "**/venv/",
                "**/.venv/",
                "**/.pytest_cache/",
                "**/.coverage",
                "**/htmlcov/",
                "**/pytestdebug.log"
            ],
            "node": [
                "**/npm-debug.log",
                "**/yarn-debug.log",
                "**/yarn-error.log",
                "**/.pnpm-debug.log",
                "**/coverage/",
                "**/.next/",
                "**/out/",
                "**/docs/",
                "**/.eslintcache"
            ],
            "golang": [
                "**/vendor/",
                "**/*.test",
                "**/coverage.txt",
                "**/coverage.html"
            ],
            "java": [
                "**/target/",
                "**/.gradle/",
                "**/gradle-app.setting",
                "**/.gradletasknamecache",
                "**/bin/",
                "**/out/",
                "**/*.class",
                "**/*.jar"
            ],
            "ruby": [
                "**/.bundle/",
                "**/vendor/bundle",
                "**/lib/bundler/man/",
                "**/.rubocop-*",
                "**/*.gem",
                "**/coverage/"
            ]
        }
        
        # Combine common and type-specific ignores
        ignores = common_ignores.copy()
        if project_type in type_specific_ignores:
            ignores.extend(type_specific_ignores[project_type])
        
        # Sort and remove duplicates
        ignores = sorted(set(ignores))
        
        # Generate .dockerignore content
        content = "\n".join(ignores) + "\n"
        
        # Write .dockerignore
        try:
            with open(output_file, 'w') as f:
                f.write(content)
            
            return {
                "success": True,
                "message": f".dockerignore generated successfully at {output_file}",
                "path": str(output_file),
                "content": content
            }
        except Exception as e:
            self._logger.exception(f"Error writing .dockerignore: {str(e)}")
            return {
                "success": False,
                "error": f"Error writing .dockerignore: {str(e)}"
            }

    async def setup_docker_project(
        self,
        project_directory: Union[str, Path],
        generate_dockerfile: bool = True,
        generate_compose: bool = True,
        generate_dockerignore: bool = True,
        overwrite: bool = False,
        include_databases: bool = True,
        build_image: bool = False
    ) -> Dict[str, Any]:
        """
        Set up a complete Docker environment for a project.
        
        Args:
            project_directory: Path to the project directory
            generate_dockerfile: Whether to generate a Dockerfile
            generate_compose: Whether to generate a docker-compose.yml
            generate_dockerignore: Whether to generate a .dockerignore
            overwrite: Whether to overwrite existing files
            include_databases: Whether to include detected database services
            build_image: Whether to build the Docker image after setup
            
        Returns:
            Dictionary with setup results
        """
        self._logger.info(f"Setting up Docker environment for project: {project_directory}")
        
        project_dir = Path(project_directory)
        if not project_dir.exists() or not project_dir.is_dir():
            return {
                "success": False,
                "error": f"Project directory does not exist or is not a directory: {project_directory}"
            }
        
        results = {
            "success": True,
            "project_directory": str(project_dir),
            "files_generated": []
        }
        
        # Generate Dockerfile if requested
        if generate_dockerfile:
            dockerfile_result = await self.generate_dockerfile(
                project_dir,
                overwrite=overwrite
            )
            results["dockerfile"] = dockerfile_result
            
            if dockerfile_result["success"]:
                results["files_generated"].append(dockerfile_result["dockerfile_path"])
            else:
                # Non-fatal error if file exists and overwrite is False
                if "already exists" in dockerfile_result.get("error", ""):
                    results["dockerfile"]["skipped"] = True
                else:
                    # Fatal error for other issues
                    results["success"] = False
        
        # Generate docker-compose.yml if requested
        if generate_compose:
            compose_result = await self.generate_docker_compose(
                project_dir,
                overwrite=overwrite,
                include_databases=include_databases
            )
            results["docker_compose"] = compose_result
            
            if compose_result["success"]:
                results["files_generated"].append(compose_result["compose_file_path"])
            else:
                # Non-fatal error if file exists and overwrite is False
                if "already exists" in compose_result.get("error", ""):
                    results["docker_compose"]["skipped"] = True
                else:
                    # Fatal error for other issues
                    results["success"] = False
        
        # Generate .dockerignore if requested
        if generate_dockerignore:
            dockerignore_result = await self.generate_dockerignore(
                project_dir,
                overwrite=overwrite
            )
            results["dockerignore"] = dockerignore_result
            
            if dockerignore_result["success"]:
                results["files_generated"].append(dockerignore_result["path"])
            else:
                # Non-fatal error if file exists and overwrite is False
                if "already exists" in dockerignore_result.get("error", ""):
                    results["dockerignore"]["skipped"] = True
                else:
                    # Fatal error for other issues
                    results["success"] = False
        
        # Build Docker image if requested and Dockerfile was generated
        if build_image and results["success"] and results.get("dockerfile", {}).get("success", False):
            build_result = await self.build_image(
                context_path=project_dir,
                tag="app:latest"
            )
            results["build_image"] = build_result
            
            if not build_result["success"]:
                # Non-fatal error
                results["build_warnings"] = build_result.get("error", "Unknown build error")
        
        return results

# Global Docker integration instance
docker_integration = DockerIntegration()
</file>

<file path="angela/toolchain/git.py">
# angela/toolchain/git.py
"""
Enhanced Git integration for Angela CLI.

This module provides advanced Git functionality for the code generation lifecycle,
such as automatic repository initialization, commit management, and feature branch creation.
"""
import os
import asyncio
import subprocess
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple, Union
import re

from angela.utils.logging import get_logger
from angela.execution.engine import execution_engine

logger = get_logger(__name__)

class GitIntegration:
    """
    Enhanced Git integration for the code generation lifecycle.
    """
    
    def __init__(self):
        """Initialize the Git integration."""
        self._logger = logger
    
    async def init_repository(
        self, 
        path: Union[str, Path], 
        initial_branch: str = "main",
        gitignore_template: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Initialize a Git repository.
        
        Args:
            path: Path to initialize the repository in
            initial_branch: Name of the initial branch
            gitignore_template: Optional template for .gitignore (e.g., 'python', 'node')
            
        Returns:
            Dictionary with the operation result
        """
        self._logger.info(f"Initializing Git repository in {path}")
        
        path_obj = Path(path)
        
        # Check if path exists
        if not path_obj.exists():
            return {
                "success": False,
                "error": f"Path does not exist: {path}",
                "command": None,
                "stdout": "",
                "stderr": f"Path does not exist: {path}"
            }
        
        # Check if already a Git repository
        if (path_obj / ".git").exists():
            return {
                "success": True,
                "message": "Repository already initialized",
                "command": None,
                "stdout": "Repository already initialized",
                "stderr": ""
            }
        
        # Initialize the repository
        init_command = f"git init -b {initial_branch}"
        
        # Execute the command
        stdout, stderr, return_code = await execution_engine.execute_command(
            init_command,
            check_safety=True,
            working_dir=str(path_obj)
        )
        
        if return_code != 0:
            return {
                "success": False,
                "error": f"Failed to initialize repository: {stderr}",
                "command": init_command,
                "stdout": stdout,
                "stderr": stderr
            }
        
        # Create .gitignore if requested
        if gitignore_template:
            gitignore_result = await self._create_gitignore(path_obj, gitignore_template)
            if not gitignore_result["success"]:
                # Continue even if gitignore creation fails
                self._logger.warning(f"Failed to create .gitignore: {gitignore_result['error']}")
        
        return {
            "success": True,
            "message": "Repository initialized successfully",
            "command": init_command,
            "stdout": stdout,
            "stderr": stderr
        }
    
    async def stage_files(
        self, 
        path: Union[str, Path], 
        files: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """
        Stage files for a Git commit.
        
        Args:
            path: Path to the Git repository
            files: List of files to stage (all files if None)
            
        Returns:
            Dictionary with the operation result
        """
        self._logger.info(f"Staging files in {path}")
        
        path_obj = Path(path)
        
        # Check if path is a Git repository
        if not (path_obj / ".git").exists():
            return {
                "success": False,
                "error": f"Not a Git repository: {path}",
                "command": None,
                "stdout": "",
                "stderr": f"Not a Git repository: {path}"
            }
        
        # Build the git add command
        if files:
            # Quote file paths to handle spaces
            quoted_files = [f'"{f}"' for f in files]
            add_command = f"git add {' '.join(quoted_files)}"
        else:
            add_command = "git add ."
        
        # Execute the command
        stdout, stderr, return_code = await execution_engine.execute_command(
            add_command,
            check_safety=True,
            working_dir=str(path_obj)
        )
        
        if return_code != 0:
            return {
                "success": False,
                "error": f"Failed to stage files: {stderr}",
                "command": add_command,
                "stdout": stdout,
                "stderr": stderr
            }
        
        return {
            "success": True,
            "message": "Files staged successfully",
            "command": add_command,
            "stdout": stdout,
            "stderr": stderr
        }
    
    async def commit_changes(
        self, 
        path: Union[str, Path], 
        message: str,
        files: Optional[List[str]] = None,
        auto_stage: bool = True
    ) -> Dict[str, Any]:
        """
        Commit changes to a Git repository.
        
        Args:
            path: Path to the Git repository
            message: Commit message
            files: Optional list of files to commit (all staged files if None)
            auto_stage: Whether to automatically stage files before committing
            
        Returns:
            Dictionary with the operation result
        """
        self._logger.info(f"Committing changes in {path}")
        
        path_obj = Path(path)
        
        # Check if path is a Git repository
        if not (path_obj / ".git").exists():
            return {
                "success": False,
                "error": f"Not a Git repository: {path}",
                "command": None,
                "stdout": "",
                "stderr": f"Not a Git repository: {path}"
            }
        
        # Stage files if requested
        if auto_stage:
            stage_result = await self.stage_files(path_obj, files)
            if not stage_result["success"]:
                return stage_result
        
        # Build the git commit command
        commit_command = f'git commit -m "{message}"'
        
        # Add specific files if provided and not auto-staging
        if files and not auto_stage:
            # Quote file paths to handle spaces
            quoted_files = [f'"{f}"' for f in files]
            commit_command += f" {' '.join(quoted_files)}"
        
        # Execute the command
        stdout, stderr, return_code = await execution_engine.execute_command(
            commit_command,
            check_safety=True,
            working_dir=str(path_obj)
        )
        
        if return_code != 0:
            return {
                "success": False,
                "error": f"Failed to commit changes: {stderr}",
                "command": commit_command,
                "stdout": stdout,
                "stderr": stderr
            }
        
        return {
            "success": True,
            "message": "Changes committed successfully",
            "command": commit_command,
            "stdout": stdout,
            "stderr": stderr
        }
    
    async def create_branch(
        self, 
        path: Union[str, Path], 
        branch_name: str,
        checkout: bool = True,
        start_point: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Create a new Git branch.
        
        Args:
            path: Path to the Git repository
            branch_name: Name of the branch to create
            checkout: Whether to check out the new branch
            start_point: Optional starting point for the branch
            
        Returns:
            Dictionary with the operation result
        """
        self._logger.info(f"Creating branch {branch_name} in {path}")
        
        path_obj = Path(path)
        
        # Check if path is a Git repository
        if not (path_obj / ".git").exists():
            return {
                "success": False,
                "error": f"Not a Git repository: {path}",
                "command": None,
                "stdout": "",
                "stderr": f"Not a Git repository: {path}"
            }
        
        # Build the git branch command
        if checkout:
            branch_command = f"git checkout -b {branch_name}"
        else:
            branch_command = f"git branch {branch_name}"
        
        # Add start point if provided
        if start_point:
            branch_command += f" {start_point}"
        
        # Execute the command
        stdout, stderr, return_code = await execution_engine.execute_command(
            branch_command,
            check_safety=True,
            working_dir=str(path_obj)
        )
        
        if return_code != 0:
            return {
                "success": False,
                "error": f"Failed to create branch: {stderr}",
                "command": branch_command,
                "stdout": stdout,
                "stderr": stderr
            }
        
        return {
            "success": True,
            "message": f"Branch {branch_name} created successfully",
            "command": branch_command,
            "stdout": stdout,
            "stderr": stderr
        }
    
    async def get_repository_status(
        self, 
        path: Union[str, Path]
    ) -> Dict[str, Any]:
        """
        Get the status of a Git repository.
        
        Args:
            path: Path to the Git repository
            
        Returns:
            Dictionary with the repository status
        """
        path_obj = Path(path)
        
        # Check if path is a Git repository
        if not (path_obj / ".git").exists():
            return {
                "is_repo": False,
                "error": f"Not a Git repository: {path}",
                "command": None,
                "stdout": "",
                "stderr": f"Not a Git repository: {path}"
            }
        
        # Get current branch
        branch_command = "git branch --show-current"
        branch_stdout, branch_stderr, branch_code = await execution_engine.execute_command(
            branch_command,
            check_safety=True,
            working_dir=str(path_obj)
        )
        
        current_branch = branch_stdout.strip() if branch_code == 0 else "unknown"
        
        # Get status
        status_command = "git status --porcelain"
        status_stdout, status_stderr, status_code = await execution_engine.execute_command(
            status_command,
            check_safety=True,
            working_dir=str(path_obj)
        )
        
        if status_code != 0:
            return {
                "is_repo": True,
                "current_branch": current_branch,
                "error": f"Failed to get status: {status_stderr}",
                "command": status_command,
                "stdout": status_stdout,
                "stderr": status_stderr
            }
        
        # Parse status output
        status_lines = status_stdout.strip().split('\n') if status_stdout.strip() else []
        
        modified_files = []
        untracked_files = []
        staged_files = []
        
        for line in status_lines:
            if not line:
                continue
                
            status_code = line[:2]
            file_path = line[3:]
            
            if status_code.startswith('??'):
                untracked_files.append(file_path)
            elif status_code.startswith('M'):
                modified_files.append(file_path)
            elif status_code.startswith('A'):
                staged_files.append(file_path)
        
        return {
            "is_repo": True,
            "current_branch": current_branch,
            "modified_files": modified_files,
            "untracked_files": untracked_files,
            "staged_files": staged_files,
            "clean": len(status_lines) == 0,
            "command": status_command,
            "stdout": status_stdout,
            "stderr": status_stderr
        }
    
    async def _create_gitignore(
        self, 
        path: Union[str, Path], 
        template: str
    ) -> Dict[str, Any]:
        """
        Create a .gitignore file from a template.
        
        Args:
            path: Path to the Git repository
            template: Template to use (e.g., 'python', 'node')
            
        Returns:
            Dictionary with the operation result
        """
        self._logger.info(f"Creating .gitignore with template {template} in {path}")
        
        path_obj = Path(path)
        
        # Check if .gitignore already exists
        gitignore_path = path_obj / ".gitignore"
        if gitignore_path.exists():
            return {
                "success": True,
                "message": ".gitignore already exists",
                "path": str(gitignore_path),
                "modified": False
            }
        
        # Get template content
        if template == "python":
            content = """
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# Distribution / packaging
dist/
build/
*.egg-info/

# Virtual environments
venv/
env/
.env/
.venv/

# Unit test / coverage reports
htmlcov/
.tox/
.coverage
.coverage.*
.cache
coverage.xml
*.cover

# Local development settings
.env
.env.local

# IDE specific files
.idea/
.vscode/
*.swp
*.swo
"""
        elif template == "node":
            content = """
# Logs
logs
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# Dependency directories
node_modules/
jspm_packages/

# Build output
dist/
build/

# Environment variables
.env
.env.local
.env.development
.env.test
.env.production

# IDE specific files
.idea/
.vscode/
*.swp
*.swo

# OS specific files
.DS_Store
Thumbs.db
"""
        else:
            # Generic gitignore
            content = """
# IDE specific files
.idea/
.vscode/
*.swp
*.swo

# OS specific files
.DS_Store
Thumbs.db

# Local development settings
.env
.env.local

# Logs
*.log
"""
        
        # Write the .gitignore file
        try:
            with open(gitignore_path, 'w') as f:
                f.write(content.strip())
            
            return {
                "success": True,
                "message": ".gitignore created successfully",
                "path": str(gitignore_path),
                "modified": True
            }
        except Exception as e:
            return {
                "success": False,
                "error": f"Failed to create .gitignore: {str(e)}",
                "path": str(gitignore_path),
                "modified": False
            }

# Global Git integration instance
git_integration = GitIntegration()
</file>

<file path="angela/toolchain/package_managers.py">
# angela/toolchain/package_managers.py
"""
Package manager integration for Angela CLI.

This module provides functionality for interacting with package managers
to install dependencies required by generated code.
"""
import os
import json
import asyncio
import subprocess
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple, Union
import re

from angela.utils.logging import get_logger
from angela.execution.engine import execution_engine
from angela.context import context_manager

logger = get_logger(__name__)

class PackageManagerIntegration:
    """
    Integration with package managers for dependency management.
    """
    
    def __init__(self):
        """Initialize the package manager integration."""
        self._logger = logger
        
        # Map of project types to package managers
        self._package_managers = {
            "python": ["pip", "pipenv", "poetry"],
            "node": ["npm", "yarn", "pnpm"],
            "ruby": ["gem", "bundler"],
            "php": ["composer"],
            "go": ["go"],
            "rust": ["cargo"],
            "java": ["maven", "gradle"]
        }
    
    async def detect_package_manager(
        self, 
        path: Union[str, Path],
        project_type: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Detect the package manager used in a project.
        
        Args:
            path: Path to the project
            project_type: Optional type of project
            
        Returns:
            Dictionary with the detected package manager info
        """
        self._logger.info(f"Detecting package manager in {path}")
        
        path_obj = Path(path)
        
        # Check if path exists
        if not path_obj.exists() or not path_obj.is_dir():
            return {
                "detected": False,
                "error": f"Path does not exist or is not a directory: {path}",
                "package_manager": None,
                "project_type": project_type
            }
        
        # Determine project type if not provided
        if project_type is None:
            # Try to detect from context
            context = context_manager.get_context_dict()
            if context.get("project_type"):
                project_type = context["project_type"]
            else:
                # Try to infer from files
                project_type = await self._infer_project_type(path_obj)
        
        # Files that indicate package managers
        package_manager_files = {
            "python": {
                "requirements.txt": "pip",
                "Pipfile": "pipenv",
                "pyproject.toml": "poetry"  # Could also be other tools
            },
            "node": {
                "package.json": "npm",  # Could also be yarn or pnpm
                "yarn.lock": "yarn",
                "pnpm-lock.yaml": "pnpm"
            },
            "ruby": {
                "Gemfile": "bundler"
            },
            "php": {
                "composer.json": "composer"
            },
            "go": {
                "go.mod": "go"
            },
            "rust": {
                "Cargo.toml": "cargo"
            },
            "java": {
                "pom.xml": "maven",
                "build.gradle": "gradle",
                "build.gradle.kts": "gradle"
            }
        }
        
        # Check for package manager files based on project type
        if project_type in package_manager_files:
            for file_name, manager in package_manager_files[project_type].items():
                if (path_obj / file_name).exists():
                    # For Python, check if poetry is actually used in pyproject.toml
                    if file_name == "pyproject.toml" and manager == "poetry":
                        # Check if [tool.poetry] section exists
                        try:
                            with open(path_obj / file_name, 'r') as f:
                                content = f.read()
                                if "[tool.poetry]" not in content:
                                    # Might be another tool, default to pip
                                    manager = "pip"
                        except Exception:
                            manager = "pip"
                    
                    # For Node.js, check if yarn or pnpm is used
                    if file_name == "package.json" and manager == "npm":
                        # If yarn.lock or pnpm-lock.yaml exists, use that instead
                        if (path_obj / "yarn.lock").exists():
                            manager = "yarn"
                        elif (path_obj / "pnpm-lock.yaml").exists():
                            manager = "pnpm"
                    
                    return {
                        "detected": True,
                        "package_manager": manager,
                        "project_type": project_type,
                        "indicator_file": file_name
                    }
        
        # If no specific package manager detected, use default for project type
        if project_type in self._package_managers:
            default_manager = self._package_managers[project_type][0]
            return {
                "detected": False,
                "package_manager": default_manager,
                "project_type": project_type,
                "indicator_file": None,
                "message": f"No package manager detected, defaulting to {default_manager}"
            }
        
        return {
            "detected": False,
            "error": f"Unable to detect package manager for project type: {project_type}",
            "package_manager": None,
            "project_type": project_type
        }
    
    async def install_dependencies(
        self, 
        path: Union[str, Path],
        dependencies: List[str],
        dev_dependencies: Optional[List[str]] = None,
        package_manager: Optional[str] = None,
        project_type: Optional[str] = None,
        update_dependency_file: bool = True,
        virtual_env: bool = False
    ) -> Dict[str, Any]:
        """
        Install dependencies using the appropriate package manager.
        
        Args:
            path: Path to the project
            dependencies: List of dependencies to install
            dev_dependencies: Optional list of development dependencies
            package_manager: Optional package manager to use
            project_type: Optional project type
            update_dependency_file: Whether to update dependency file
            virtual_env: Whether to use a virtual environment for Python
            
        Returns:
            Dictionary with the installation result
        """
        self._logger.info(f"Installing dependencies in {path}")
        
        path_obj = Path(path)
        
        # Check if path exists
        if not path_obj.exists() or not path_obj.is_dir():
            return {
                "success": False,
                "error": f"Path does not exist or is not a directory: {path}",
                "package_manager": package_manager,
                "project_type": project_type
            }
        
        # Detect package manager if not provided
        if package_manager is None or project_type is None:
            detection_result = await self.detect_package_manager(path_obj, project_type)
            package_manager = detection_result.get("package_manager")
            project_type = detection_result.get("project_type")
            
            if not package_manager:
                return {
                    "success": False,
                    "error": f"Unable to detect package manager: {detection_result.get('error', 'Unknown error')}",
                    "package_manager": None,
                    "project_type": project_type
                }
        
        # Install dependencies based on package manager
        if package_manager == "pip":
            return await self._install_pip_dependencies(
                path_obj, dependencies, dev_dependencies, update_dependency_file, virtual_env
            )
        elif package_manager == "npm":
            return await self._install_npm_dependencies(
                path_obj, dependencies, dev_dependencies, update_dependency_file
            )
        elif package_manager == "yarn":
            return await self._install_yarn_dependencies(
                path_obj, dependencies, dev_dependencies, update_dependency_file
            )
        elif package_manager == "poetry":
            return await self._install_poetry_dependencies(
                path_obj, dependencies, dev_dependencies, update_dependency_file
            )
        elif package_manager == "cargo":
            return await self._install_cargo_dependencies(
                path_obj, dependencies, dev_dependencies, update_dependency_file
            )
        # Add other package managers as needed
        
        return {
            "success": False,
            "error": f"Unsupported package manager: {package_manager}",
            "package_manager": package_manager,
            "project_type": project_type
        }
    
    async def _install_pip_dependencies(
        self, 
        path: Path,
        dependencies: List[str],
        dev_dependencies: Optional[List[str]] = None,
        update_dependency_file: bool = True,
        virtual_env: bool = False
    ) -> Dict[str, Any]:
        """
        Install Python dependencies using pip.
        
        Args:
            path: Path to the project
            dependencies: List of dependencies to install
            dev_dependencies: Optional list of development dependencies
            update_dependency_file: Whether to update requirements.txt
            virtual_env: Whether to use a virtual environment
            
        Returns:
            Dictionary with the installation result
        """
        self._logger.info(f"Installing Python dependencies with pip in {path}")
        
        results = {
            "success": True,
            "package_manager": "pip",
            "project_type": "python",
            "commands": [],
            "outputs": [],
            "errors": []
        }
        
        # Create virtual environment if requested
        if virtual_env and not (path / "venv").exists():
            venv_command = "python -m venv venv"
            venv_stdout, venv_stderr, venv_code = await execution_engine.execute_command(
                venv_command,
                check_safety=True,
                working_dir=str(path)
            )
            
            results["commands"].append(venv_command)
            results["outputs"].append(venv_stdout)
            
            if venv_code != 0:
                results["success"] = False
                results["errors"].append(f"Failed to create virtual environment: {venv_stderr}")
                return results
        
        # Determine pip command
        pip_cmd = "venv/bin/pip" if virtual_env and (path / "venv").exists() else "pip"
        
        # Install dependencies
        if dependencies:
            deps_str = " ".join(dependencies)
            install_command = f"{pip_cmd} install {deps_str}"
            
            install_stdout, install_stderr, install_code = await execution_engine.execute_command(
                install_command,
                check_safety=True,
                working_dir=str(path)
            )
            
            results["commands"].append(install_command)
            results["outputs"].append(install_stdout)
            
            if install_code != 0:
                results["success"] = False
                results["errors"].append(f"Failed to install dependencies: {install_stderr}")
                return results
        
        # Install dev dependencies
        if dev_dependencies:
            dev_deps_str = " ".join(dev_dependencies)
            dev_install_command = f"{pip_cmd} install {dev_deps_str}"
            
            dev_stdout, dev_stderr, dev_code = await execution_engine.execute_command(
                dev_install_command,
                check_safety=True,
                working_dir=str(path)
            )
            
            results["commands"].append(dev_install_command)
            results["outputs"].append(dev_stdout)
            
            if dev_code != 0:
                results["success"] = False
                results["errors"].append(f"Failed to install dev dependencies: {dev_stderr}")
                return results
        
        # Update requirements.txt if requested
        if update_dependency_file:
            # Check if requirements.txt already exists
            req_file = path / "requirements.txt"
            existing_deps = []
            
            if req_file.exists():
                try:
                    with open(req_file, 'r') as f:
                        existing_deps = [line.strip() for line in f if line.strip() and not line.strip().startswith('#')]
                except Exception as e:
                    results["errors"].append(f"Failed to read requirements.txt: {str(e)}")
            
            # Combine existing and new dependencies
            all_deps = list(set(existing_deps + dependencies))
            
            # Write back to requirements.txt
            try:
                with open(req_file, 'w') as f:
                    for dep in sorted(all_deps):
                        f.write(f"{dep}\n")
                
                results["updated_files"] = [str(req_file)]
            except Exception as e:
                results["errors"].append(f"Failed to update requirements.txt: {str(e)}")
        
        return results
    
    async def _install_npm_dependencies(
        self, 
        path: Path,
        dependencies: List[str],
        dev_dependencies: Optional[List[str]] = None,
        update_dependency_file: bool = True
    ) -> Dict[str, Any]:
        """
        Install Node.js dependencies using npm.
        
        Args:
            path: Path to the project
            dependencies: List of dependencies to install
            dev_dependencies: Optional list of development dependencies
            update_dependency_file: Whether to update package.json
            
        Returns:
            Dictionary with the installation result
        """
        self._logger.info(f"Installing Node.js dependencies with npm in {path}")
        
        results = {
            "success": True,
            "package_manager": "npm",
            "project_type": "node",
            "commands": [],
            "outputs": [],
            "errors": []
        }
        
        # Initialize npm project if package.json doesn't exist
        package_json = path / "package.json"
        if not package_json.exists() and update_dependency_file:
            init_command = "npm init -y"
            init_stdout, init_stderr, init_code = await execution_engine.execute_command(
                init_command,
                check_safety=True,
                working_dir=str(path)
            )
            
            results["commands"].append(init_command)
            results["outputs"].append(init_stdout)
            
            if init_code != 0:
                results["success"] = False
                results["errors"].append(f"Failed to initialize npm project: {init_stderr}")
                return results
        
        # Install dependencies
        if dependencies:
            deps_str = " ".join(dependencies)
            install_command = f"npm install --save {deps_str}"
            
            install_stdout, install_stderr, install_code = await execution_engine.execute_command(
                install_command,
                check_safety=True,
                working_dir=str(path)
            )
            
            results["commands"].append(install_command)
            results["outputs"].append(install_stdout)
            
            if install_code != 0:
                results["success"] = False
                results["errors"].append(f"Failed to install dependencies: {install_stderr}")
                return results
        
        # Install dev dependencies
        if dev_dependencies:
            dev_deps_str = " ".join(dev_dependencies)
            dev_install_command = f"npm install --save-dev {dev_deps_str}"
            
            dev_stdout, dev_stderr, dev_code = await execution_engine.execute_command(
                dev_install_command,
                check_safety=True,
                working_dir=str(path)
            )
            
            results["commands"].append(dev_install_command)
            results["outputs"].append(dev_stdout)
            
            if dev_code != 0:
                results["success"] = False
                results["errors"].append(f"Failed to install dev dependencies: {dev_stderr}")
                return results
        
        # Update package.json directly if using npm doesn't work
        if update_dependency_file and package_json.exists() and (dependencies or dev_dependencies):
            try:
                with open(package_json, 'r') as f:
                    package_data = json.load(f)
                
                # Make sure dependencies sections exist
                if dependencies and "dependencies" not in package_data:
                    package_data["dependencies"] = {}
                
                if dev_dependencies and "devDependencies" not in package_data:
                    package_data["devDependencies"] = {}
                
                # Update package.json
                with open(package_json, 'w') as f:
                    json.dump(package_data, f, indent=2)
                
                results["updated_files"] = [str(package_json)]
            except Exception as e:
                results["errors"].append(f"Failed to update package.json: {str(e)}")
        
        return results
    
    async def _install_yarn_dependencies(
        self, 
        path: Path,
        dependencies: List[str],
        dev_dependencies: Optional[List[str]] = None,
        update_dependency_file: bool = True
    ) -> Dict[str, Any]:
        """
        Install Node.js dependencies using yarn.
        
        Args:
            path: Path to the project
            dependencies: List of dependencies to install
            dev_dependencies: Optional list of development dependencies
            update_dependency_file: Whether to update package.json
            
        Returns:
            Dictionary with the installation result
        """
        self._logger.info(f"Installing Node.js dependencies with yarn in {path}")
        
        results = {
            "success": True,
            "package_manager": "yarn",
            "project_type": "node",
            "commands": [],
            "outputs": [],
            "errors": []
        }
        
        # Initialize yarn project if package.json doesn't exist
        package_json = path / "package.json"
        if not package_json.exists() and update_dependency_file:
            init_command = "yarn init -y"
            init_stdout, init_stderr, init_code = await execution_engine.execute_command(
                init_command,
                check_safety=True,
                working_dir=str(path)
            )
            
            results["commands"].append(init_command)
            results["outputs"].append(init_stdout)
            
            if init_code != 0:
                results["success"] = False
                results["errors"].append(f"Failed to initialize yarn project: {init_stderr}")
                return results
        
        # Install dependencies
        if dependencies:
            deps_str = " ".join(dependencies)
            install_command = f"yarn add {deps_str}"
            
            install_stdout, install_stderr, install_code = await execution_engine.execute_command(
                install_command,
                check_safety=True,
                working_dir=str(path)
            )
            
            results["commands"].append(install_command)
            results["outputs"].append(install_stdout)
            
            if install_code != 0:
                results["success"] 
                
                
            if install_code != 0:
                results["success"] = False
                results["errors"].append(f"Failed to install dependencies: {install_stderr}")
                return results
        
        # Install dev dependencies
        if dev_dependencies:
            dev_deps_str = " ".join(dev_dependencies)
            dev_install_command = f"yarn add --dev {dev_deps_str}"
            
            dev_stdout, dev_stderr, dev_code = await execution_engine.execute_command(
                dev_install_command,
                check_safety=True,
                working_dir=str(path)
            )
            
            results["commands"].append(dev_install_command)
            results["outputs"].append(dev_stdout)
            
            if dev_code != 0:
                results["success"] = False
                results["errors"].append(f"Failed to install dev dependencies: {dev_stderr}")
                return results
        
        return results
    
    async def _install_poetry_dependencies(
        self, 
        path: Path,
        dependencies: List[str],
        dev_dependencies: Optional[List[str]] = None,
        update_dependency_file: bool = True
    ) -> Dict[str, Any]:
        """
        Install Python dependencies using Poetry.
        
        Args:
            path: Path to the project
            dependencies: List of dependencies to install
            dev_dependencies: Optional list of development dependencies
            update_dependency_file: Whether to update pyproject.toml
            
        Returns:
            Dictionary with the installation result
        """
        self._logger.info(f"Installing Python dependencies with Poetry in {path}")
        
        results = {
            "success": True,
            "package_manager": "poetry",
            "project_type": "python",
            "commands": [],
            "outputs": [],
            "errors": []
        }
        
        # Initialize poetry project if pyproject.toml doesn't exist
        pyproject_toml = path / "pyproject.toml"
        if not pyproject_toml.exists() and update_dependency_file:
            init_command = "poetry init --no-interaction"
            init_stdout, init_stderr, init_code = await execution_engine.execute_command(
                init_command,
                check_safety=True,
                working_dir=str(path)
            )
            
            results["commands"].append(init_command)
            results["outputs"].append(init_stdout)
            
            if init_code != 0:
                results["success"] = False
                results["errors"].append(f"Failed to initialize Poetry project: {init_stderr}")
                return results
        
        # Install dependencies
        if dependencies:
            for dep in dependencies:
                install_command = f"poetry add {dep}"
                
                install_stdout, install_stderr, install_code = await execution_engine.execute_command(
                    install_command,
                    check_safety=True,
                    working_dir=str(path)
                )
                
                results["commands"].append(install_command)
                results["outputs"].append(install_stdout)
                
                if install_code != 0:
                    results["success"] = False
                    results["errors"].append(f"Failed to install dependency {dep}: {install_stderr}")
                    return results
        
        # Install dev dependencies
        if dev_dependencies:
            for dev_dep in dev_dependencies:
                dev_install_command = f"poetry add --dev {dev_dep}"
                
                dev_stdout, dev_stderr, dev_code = await execution_engine.execute_command(
                    dev_install_command,
                    check_safety=True,
                    working_dir=str(path)
                )
                
                results["commands"].append(dev_install_command)
                results["outputs"].append(dev_stdout)
                
                if dev_code != 0:
                    results["success"] = False
                    results["errors"].append(f"Failed to install dev dependency {dev_dep}: {dev_stderr}")
                    return results
        
        return results
    
    async def _install_cargo_dependencies(
        self, 
        path: Path,
        dependencies: List[str],
        dev_dependencies: Optional[List[str]] = None,
        update_dependency_file: bool = True
    ) -> Dict[str, Any]:
        """
        Install Rust dependencies using Cargo.
        
        Args:
            path: Path to the project
            dependencies: List of dependencies to install
            dev_dependencies: Optional list of development dependencies
            update_dependency_file: Whether to update Cargo.toml
            
        Returns:
            Dictionary with the installation result
        """
        self._logger.info(f"Installing Rust dependencies with Cargo in {path}")
        
        results = {
            "success": True,
            "package_manager": "cargo",
            "project_type": "rust",
            "commands": [],
            "outputs": [],
            "errors": []
        }
        
        # Check if this is a Cargo project
        cargo_toml = path / "Cargo.toml"
        if not cargo_toml.exists():
            if update_dependency_file:
                # Initialize a new Cargo project
                project_name = path.name.replace("-", "_").lower()
                init_command = f"cargo init --name {project_name}"
                
                init_stdout, init_stderr, init_code = await execution_engine.execute_command(
                    init_command,
                    check_safety=True,
                    working_dir=str(path)
                )
                
                results["commands"].append(init_command)
                results["outputs"].append(init_stdout)
                
                if init_code != 0:
                    results["success"] = False
                    results["errors"].append(f"Failed to initialize Cargo project: {init_stderr}")
                    return results
            else:
                results["success"] = False
                results["errors"].append("Not a Cargo project and update_dependency_file is False")
                return results
        
        # Add dependencies to Cargo.toml
        if (dependencies or dev_dependencies) and update_dependency_file:
            try:
                with open(cargo_toml, 'r') as f:
                    cargo_content = f.read()
                
                # Add [dependencies] section if it doesn't exist
                if dependencies and "[dependencies]" not in cargo_content:
                    cargo_content += "\n[dependencies]\n"
                
                # Add dependencies
                if dependencies:
                    for dep in dependencies:
                        # Check if dependency is already in the file
                        if dep not in cargo_content:
                            # Parse dependency name and version (if provided)
                            if "=" in dep:
                                dep_name, dep_version = dep.split("=", 1)
                                cargo_content += f'{dep_name.strip()} = {dep_version.strip()}\n'
                            else:
                                cargo_content += f'{dep.strip()} = "*"\n'
                
                # Add [dev-dependencies] section if it doesn't exist
                if dev_dependencies and "[dev-dependencies]" not in cargo_content:
                    cargo_content += "\n[dev-dependencies]\n"
                
                # Add dev dependencies
                if dev_dependencies:
                    for dep in dev_dependencies:
                        # Check if dependency is already in the file
                        if dep not in cargo_content:
                            # Parse dependency name and version (if provided)
                            if "=" in dep:
                                dep_name, dep_version = dep.split("=", 1)
                                cargo_content += f'{dep_name.strip()} = {dep_version.strip()}\n'
                            else:
                                cargo_content += f'{dep.strip()} = "*"\n'
                
                # Write back to Cargo.toml
                with open(cargo_toml, 'w') as f:
                    f.write(cargo_content)
                
                results["updated_files"] = [str(cargo_toml)]
            except Exception as e:
                results["errors"].append(f"Failed to update Cargo.toml: {str(e)}")
        
        # Run cargo build to install dependencies
        build_command = "cargo build"
        build_stdout, build_stderr, build_code = await execution_engine.execute_command(
            build_command,
            check_safety=True,
            working_dir=str(path)
        )
        
        results["commands"].append(build_command)
        results["outputs"].append(build_stdout)
        
        if build_code != 0:
            results["success"] = False
            results["errors"].append(f"Failed to build project: {build_stderr}")
            return results
        
        return results
    
    async def _infer_project_type(self, path: Path) -> Optional[str]:
        """
        Infer the project type from the files in the directory.
        
        Args:
            path: Path to the project
            
        Returns:
            Inferred project type, or None if unable to infer
        """
        # Check for key files that indicate project type
        if (path / "requirements.txt").exists() or (path / "setup.py").exists() or (path / "pyproject.toml").exists():
            return "python"
        elif (path / "package.json").exists():
            return "node"
        elif (path / "Gemfile").exists() or (path / "Gemfile.lock").exists():
            return "ruby"
        elif (path / "composer.json").exists():
            return "php"
        elif (path / "go.mod").exists():
            return "go"
        elif (path / "Cargo.toml").exists():
            return "rust"
        elif (path / "pom.xml").exists() or (path / "build.gradle").exists() or (path / "build.gradle.kts").exists():
            return "java"
        
        # Count file extensions to guess project type
        extensions = {}
        for file_path in path.glob("**/*"):
            if file_path.is_file():
                ext = file_path.suffix.lower()
                if ext:
                    extensions[ext] = extensions.get(ext, 0) + 1
        
        # Determine project type based on most common extension
        if extensions:
            py_exts = extensions.get(".py", 0)
            js_exts = extensions.get(".js", 0) + extensions.get(".jsx", 0) + extensions.get(".ts", 0) + extensions.get(".tsx", 0)
            rb_exts = extensions.get(".rb", 0)
            php_exts = extensions.get(".php", 0)
            go_exts = extensions.get(".go", 0)
            rs_exts = extensions.get(".rs", 0)
            java_exts = extensions.get(".java", 0)
            
            max_ext = max([
                ("python", py_exts),
                ("node", js_exts),
                ("ruby", rb_exts),
                ("php", php_exts),
                ("go", go_exts),
                ("rust", rs_exts),
                ("java", java_exts)
            ], key=lambda x: x[1])
            
            if max_ext[1] > 0:
                return max_ext[0]
        
        return None

# Global package manager integration instance
package_manager_integration = PackageManagerIntegration()
</file>

<file path="angela/utils/__init__.py">
"""
Utility functions for Angela CLI.
"""

from angela.utils.logging import setup_logging, get_logger
</file>

<file path="angela/workflows/__init__.py">
"""
Workflow management for Angela CLI.

This package handles creating, managing, and executing user-defined
workflows - reusable sequences of commands that can be invoked by name.
"""

from angela.workflows.manager import workflow_manager
</file>

<file path="angela/workflows/manager.py">
"""
Workflow management for Angela CLI.

This module handles user-defined workflows - reusable sequences
of commands that can be invoked by name.
"""
import os
import json
import shlex
from pathlib import Path
from typing import Dict, Any, List, Tuple, Optional
from datetime import datetime
from dataclasses import dataclass, field, asdict

from pydantic import BaseModel, Field

from angela.config import config_manager
from angela.intent.planner import TaskPlan, PlanStep
from angela.utils.logging import get_logger

logger = get_logger(__name__)

# File for storing workflows
WORKFLOWS_FILE = config_manager.CONFIG_DIR / "workflows.json"

class WorkflowStep(BaseModel):
    """Model for a step in a workflow."""
    command: str = Field(..., description="The command to execute")
    explanation: str = Field(..., description="Explanation of what the command does")
    optional: bool = Field(False, description="Whether this step is optional")
    requires_confirmation: bool = Field(False, description="Whether this step requires explicit confirmation")


class Workflow(BaseModel):
    """Model for a user-defined workflow."""
    name: str = Field(..., description="Unique name for the workflow")
    description: str = Field(..., description="Human-readable description")
    steps: List[WorkflowStep] = Field(..., description="Steps in the workflow")
    variables: Dict[str, str] = Field(default_factory=dict, description="Variable placeholders")
    created: datetime = Field(default_factory=datetime.now, description="When the workflow was created")
    modified: datetime = Field(default_factory=datetime.now, description="When the workflow was last modified")
    tags: List[str] = Field(default_factory=list, description="Tags for categorizing workflows")
    author: Optional[str] = Field(None, description="Author of the workflow")


class WorkflowManager:
    """
    Manager for user-defined workflows.
    
    This class handles:
    1. Defining new workflows from natural language descriptions
    2. Storing and retrieving workflows
    3. Executing workflows with parameter substitution
    4. Listing and searching available workflows
    """
    
    def __init__(self):
        """Initialize the workflow manager."""
        self._workflows: Dict[str, Workflow] = {}
        self._workflow_file = WORKFLOWS_FILE
        self._logger = logger
        self._load_workflows()
    
    def _load_workflows(self) -> None:
        """Load workflows from the storage file."""
        try:
            if self._workflow_file.exists():
                with open(self._workflow_file, "r") as f:
                    data = json.load(f)
                    
                for workflow_data in data:
                    try:
                        # Handle datetime serialization
                        if "created" in workflow_data:
                            workflow_data["created"] = datetime.fromisoformat(workflow_data["created"])
                        if "modified" in workflow_data:
                            workflow_data["modified"] = datetime.fromisoformat(workflow_data["modified"])
                            
                        workflow = Workflow(**workflow_data)
                        self._workflows[workflow.name] = workflow
                    except Exception as e:
                        self._logger.error(f"Error loading workflow: {str(e)}")
                
                self._logger.info(f"Loaded {len(self._workflows)} workflows")
            else:
                self._logger.info("No workflows file found, starting with empty workflows")
                self._save_workflows()  # Create the file
        except Exception as e:
            self._logger.error(f"Error loading workflows: {str(e)}")
    
    def _save_workflows(self) -> None:
        """Save workflows to the storage file."""
        try:
            # Ensure the directory exists
            self._workflow_file.parent.mkdir(parents=True, exist_ok=True)
            
            # Convert workflows to serializable dict
            data = []
            for workflow in self._workflows.values():
                workflow_dict = workflow.dict()
                # Handle datetime serialization
                workflow_dict["created"] = workflow_dict["created"].isoformat()
                workflow_dict["modified"] = workflow_dict["modified"].isoformat()
                data.append(workflow_dict)
            
            # Write to file
            with open(self._workflow_file, "w") as f:
                json.dump(data, f, indent=2)
                
            self._logger.info(f"Saved {len(self._workflows)} workflows")
        except Exception as e:
            self._logger.error(f"Error saving workflows: {str(e)}")
    
    async def define_workflow(
        self, 
        name: str, 
        description: str, 
        steps: List[Dict[str, Any]],
        variables: Optional[Dict[str, str]] = None,
        tags: Optional[List[str]] = None,
        author: Optional[str] = None
    ) -> Workflow:
        """
        Define a new workflow or update an existing one.
        
        Args:
            name: Unique name for the workflow
            description: Human-readable description
            steps: List of step dictionaries with commands and explanations
            variables: Optional variable placeholders
            tags: Optional tags for categorization
            author: Optional author name
            
        Returns:
            The created or updated Workflow
        """
        # Convert steps to WorkflowStep objects
        workflow_steps = []
        for step_data in steps:
            workflow_step = WorkflowStep(
                command=step_data["command"],
                explanation=step_data.get("explanation", ""),
                optional=step_data.get("optional", False),
                requires_confirmation=step_data.get("requires_confirmation", False)
            )
            workflow_steps.append(workflow_step)
        
        # Check if workflow already exists
        if name in self._workflows:
            # Update existing workflow
            workflow = self._workflows[name]
            workflow.description = description
            workflow.steps = workflow_steps
            workflow.variables = variables or {}
            workflow.modified = datetime.now()
            if tags:
                workflow.tags = tags
            if author:
                workflow.author = author
                
            self._logger.info(f"Updated workflow: {name}")
        else:
            # Create new workflow
            workflow = Workflow(
                name=name,
                description=description,
                steps=workflow_steps,
                variables=variables or {},
                tags=tags or [],
                author=author
            )
            self._workflows[name] = workflow
            self._logger.info(f"Created new workflow: {name}")
        
        # Save updated workflows
        self._save_workflows()
        
        return workflow
    
    async def define_workflow_from_natural_language(
        self, 
        name: str, 
        description: str, 
        natural_language: str,
        context: Dict[str, Any]
    ) -> Workflow:
        """
        Define a workflow from a natural language description.
        
        Args:
            name: Unique name for the workflow
            description: Human-readable description
            natural_language: Natural language description of the workflow steps
            context: Context information
            
        Returns:
            The created Workflow
        """
        # Import here to avoid circular imports
        from angela.intent.planner import task_planner
        from angela.ai.client import gemini_client, GeminiRequest
        
        self._logger.info(f"Creating workflow from natural language: {name}")
        
        # Generate a plan using the task planner
        try:
            plan = await task_planner.plan_task(natural_language, context)
            
            # Convert plan steps to workflow steps
            steps = []
            for plan_step in plan.steps:
                step = {
                    "command": plan_step.command,
                    "explanation": plan_step.explanation,
                    "optional": False,
                    "requires_confirmation": plan_step.estimated_risk >= 3  # High or Critical risk
                }
                steps.append(step)
                
            # Identify potential variables
            variables = await self._identify_variables(steps, natural_language)
            
            # Create the workflow
            workflow = await self.define_workflow(
                name=name,
                description=description,
                steps=steps,
                variables=variables,
                tags=["user-defined"]
            )
            
            return workflow
            
        except Exception as e:
            self._logger.exception(f"Error creating workflow from natural language: {str(e)}")
            # Create a placeholder workflow
            placeholder_workflow = await self.define_workflow(
                name=name,
                description=description,
                steps=[{
                    "command": f"echo 'Error creating workflow: {str(e)}'",
                    "explanation": "This is a placeholder for a workflow that could not be created",
                    "optional": False,
                    "requires_confirmation": False
                }],
                tags=["error", "placeholder"]
            )
            return placeholder_workflow
    
    async def _identify_variables(
        self, 
        steps: List[Dict[str, Any]], 
        natural_language: str
    ) -> Dict[str, str]:
        """
        Identify potential variables in workflow steps.
        
        Args:
            steps: The workflow steps
            natural_language: Original natural language description
            
        Returns:
            Dictionary of variable names and descriptions
        """
        # Extract all commands
        commands = [step["command"] for step in steps]
        
        # Build prompt for variable identification
        prompt = f"""
Identify potential variables in the following workflow commands:

Commands:
{json.dumps(commands, indent=2)}

Original description:
{natural_language}

Identify parameters or values that might change each time the workflow is run.
For each variable, provide:
1. A variable name (use format like $NAME or {{NAME}})
2. A description of what the variable represents

Format your response as JSON:
{{
  "variables": {{
    "$VARIABLE1": "Description of variable 1",
    "$VARIABLE2": "Description of variable 2",
    ...
  }}
}}
"""
        
        # Call AI service
        from angela.ai.client import gemini_client, GeminiRequest
        
        api_request = GeminiRequest(prompt=prompt, max_tokens=2000)
        response = await gemini_client.generate_text(api_request)
        
        # Parse the response
        try:
            # Extract JSON from the response
            import re
            json_match = re.search(r'```(?:json)?\s*(.*?)\s*```', response.text, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
            else:
                # Fallback to entire response
                json_str = response.text
                
            # Parse JSON
            result = json.loads(json_str)
            variables = result.get("variables", {})
            
            self._logger.info(f"Identified {len(variables)} variables")
            return variables
            
        except Exception as e:
            self._logger.error(f"Error identifying variables: {str(e)}")
            return {}
    
    def get_workflow(self, name: str) -> Optional[Workflow]:
        """
        Get a workflow by name.
        
        Args:
            name: Name of the workflow to retrieve
            
        Returns:
            The Workflow if found, None otherwise
        """
        return self._workflows.get(name)
    
    def list_workflows(self, tag: Optional[str] = None) -> List[Workflow]:
        """
        List all workflows, optionally filtered by tag.
        
        Args:
            tag: Optional tag to filter workflows
            
        Returns:
            List of matching Workflows
        """
        if tag:
            return [w for w in self._workflows.values() if tag in w.tags]
        else:
            return list(self._workflows.values())
    
    def search_workflows(self, query: str) -> List[Workflow]:
        """
        Search for workflows by name or description.
        
        Args:
            query: Search query
            
        Returns:
            List of matching Workflows
        """
        query_lower = query.lower()
        results = []
        
        for workflow in self._workflows.values():
            # Check name, description, and tags
            if (query_lower in workflow.name.lower() or 
                query_lower in workflow.description.lower() or
                any(query_lower in tag.lower() for tag in workflow.tags)):
                results.append(workflow)
                
        return results
    
    def delete_workflow(self, name: str) -> bool:
        """
        Delete a workflow by name.
        
        Args:
            name: Name of the workflow to delete
            
        Returns:
            True if deleted, False if not found
        """
        if name in self._workflows:
            del self._workflows[name]
            self._save_workflows()
            self._logger.info(f"Deleted workflow: {name}")
            return True
        
        return False
    
    async def execute_workflow(
        self, 
        workflow_name: str, 
        variables: Dict[str, Any],
        context: Dict[str, Any],
        dry_run: bool = False
    ) -> Dict[str, Any]:
        """
        Execute a workflow with variable substitution.
        
        Args:
            workflow_name: Name of the workflow to execute
            variables: Variable values for substitution
            context: Context information
            dry_run: Whether to simulate execution without making changes
            
        Returns:
            Dictionary with execution results
        """
        workflow = self.get_workflow(workflow_name)
        if not workflow:
            return {
                "success": False,
                "error": f"Workflow not found: {workflow_name}"
            }
        
        # Import here to avoid circular imports
        from angela.intent.planner import TaskPlan, PlanStep, task_planner
        
        # Convert workflow to a task plan
        plan_steps = []
        for i, step in enumerate(workflow.steps):
            # Apply variable substitution
            command = self._substitute_variables(step.command, variables)
            
            plan_step = PlanStep(
                command=command,
                explanation=step.explanation,
                dependencies=[i-1] if i > 0 else [],  # Simple linear dependencies
                estimated_risk=3 if step.requires_confirmation else 1  # Default risk levels
            )
            plan_steps.append(plan_step)
            
        plan = TaskPlan(
            goal=f"Execute workflow: {workflow.name}",
            steps=plan_steps,
            context=context
        )
        
        # Execute the plan
        results = await task_planner.execute_plan(plan, dry_run=dry_run)
        
        return {
            "workflow": workflow.name,
            "description": workflow.description,
            "steps": len(workflow.steps),
            "results": results,
            "success": all(result.get("success", False) for result in results),
            "dry_run": dry_run
        }
    
    def _substitute_variables(self, command: str, variables: Dict[str, Any]) -> str:
        """
        Substitute variables in a command.
        
        Args:
            command: The command template
            variables: Variable values for substitution
            
        Returns:
            Command with variables substituted
        """
        result = command
        
        # Handle ${VAR} and $VAR syntax
        for var_name, var_value in variables.items():
            # Remove leading $ if present
            clean_name = var_name[1:] if var_name.startswith('$') else var_name
            
            # Substitute ${VAR} syntax
            result = result.replace(f"${{{clean_name}}}", str(var_value))
            
            # Substitute $VAR syntax
            result = result.replace(f"${clean_name}", str(var_value))
        
        return result


# Global workflow manager instance
workflow_manager = WorkflowManager()
</file>

<file path="angela/workflows/sharing.py">
Let's also create an implementation plan for the workflow sharing and importing:

```python
# angela/workflows/sharing.py

import os
import sys
import json
import tempfile
import shutil
import zipfile
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple, Union
from datetime import datetime
import uuid
import hashlib

from pydantic import BaseModel, Field

from angela.workflows.manager import Workflow, WorkflowManager, workflow_manager
from angela.config import config_manager
from angela.utils.logging import get_logger

logger = get_logger(__name__)

# Constants
WORKFLOW_EXPORT_DIR = config_manager.CONFIG_DIR / "exported_workflows"
WORKFLOW_IMPORT_DIR = config_manager.CONFIG_DIR / "imported_workflows"

class WorkflowExportMetadata(BaseModel):
    """Metadata for an exported workflow package."""
    id: str = Field(..., description="Unique identifier for this workflow package")
    name: str = Field(..., description="Name of the workflow")
    version: str = Field("1.0.0", description="Version of the workflow")
    description: str = Field(..., description="Description of the workflow")
    author: Optional[str] = Field(None, description="Author of the workflow")
    created: str = Field(..., description="Creation timestamp")
    exported: str = Field(..., description="Export timestamp")
    checksum: str = Field(..., description="SHA-256 checksum of the workflow data")
    tags: List[str] = Field(default_factory=list, description="Tags for the workflow")
    dependencies: Dict[str, str] = Field(default_factory=dict, description="External dependencies")

class WorkflowSharingManager:
    """Manager for workflow sharing, importing, and exporting."""
    
    def __init__(self, workflow_manager: WorkflowManager):
        """
        Initialize the workflow sharing manager.
        
        Args:
            workflow_manager: The workflow manager instance
        """
        self._workflow_manager = workflow_manager
        self._logger = logger
        
        # Ensure directories exist
        WORKFLOW_EXPORT_DIR.mkdir(parents=True, exist_ok=True)
        WORKFLOW_IMPORT_DIR.mkdir(parents=True, exist_ok=True)
    
    async def export_workflow(
        self, 
        workflow_name: str,
        output_path: Optional[Path] = None,
        include_dependencies: bool = True
    ) -> Dict[str, Any]:
        """
        Export a workflow to a shareable package.
        
        Args:
            workflow_name: Name of the workflow to export
            output_path: Optional custom output path
            include_dependencies: Whether to include external dependencies
            
        Returns:
            Dictionary with export results
        """
        # Get the workflow
        workflow = self._workflow_manager.get_workflow(workflow_name)
        if not workflow:
            return {
                "success": False,
                "error": f"Workflow not found: {workflow_name}"
            }
        
        try:
            # Create a temporary directory for packaging
            with tempfile.TemporaryDirectory() as temp_dir:
                temp_path = Path(temp_dir)
                
                # Convert workflow to serializable dict
                workflow_dict = workflow.dict()
                # Handle datetime serialization
                workflow_dict["created"] = workflow_dict["created"].isoformat()
                workflow_dict["modified"] = workflow_dict["modified"].isoformat()
                
                # Create workflow data file
                workflow_data_path = temp_path / "workflow.json"
                with open(workflow_data_path, "w") as f:
                    json.dump(workflow_dict, f, indent=2)
                
                # Generate checksum
                checksum = self._generate_checksum(workflow_data_path)
                
                # Create metadata
                metadata = WorkflowExportMetadata(
                    id=str(uuid.uuid4()),
                    name=workflow.name,
                    description=workflow.description,
                    author=workflow.author,
                    created=workflow.created.isoformat(),
                    exported=datetime.now().isoformat(),
                    checksum=checksum,
                    tags=workflow.tags
                )
                
                # Detect dependencies if requested
                if include_dependencies:
                    dependencies = await self._detect_dependencies(workflow)
                    metadata.dependencies = dependencies
                
                # Write metadata
                metadata_path = temp_path / "metadata.json"
                with open(metadata_path, "w") as f:
                    json.dump(metadata.dict(), f, indent=2)
                
                # Create README with information
                readme_path = temp_path / "README.md"
                with open(readme_path, "w") as f:
                    f.write(f"# {workflow.name}\n\n")
                    f.write(f"{workflow.description}\n\n")
                    if workflow.author:
                        f.write(f"Author: {workflow.author}\n\n")
                    f.write(f"Created: {workflow.created.isoformat()}\n")
                    f.write(f"Exported: {datetime.now().isoformat()}\n\n")
                    f.write("## Steps\n\n")
                    for i, step in enumerate(workflow.steps, 1):
                        f.write(f"### Step {i}: {step.command}\n")
                        f.write(f"{step.explanation}\n\n")
                
                # Determine output path
                if not output_path:
                    safe_name = workflow.name.replace(" ", "_").lower()
                    output_path = WORKFLOW_EXPORT_DIR / f"{safe_name}.angela-workflow"
                
                # Create zip archive
                with zipfile.ZipFile(output_path, "w") as zip_file:
                    for file_path in [workflow_data_path, metadata_path, readme_path]:
                        zip_file.write(file_path, arcname=file_path.name)
                
                return {
                    "success": True,
                    "workflow": workflow.name,
                    "output_path": str(output_path),
                    "metadata": metadata.dict()
                }
                
        except Exception as e:
            self._logger.exception(f"Error exporting workflow {workflow_name}: {str(e)}")
            return {
                "success": False,
                "error": f"Export failed: {str(e)}"
            }
    
    async def import_workflow(
        self, 
        workflow_path: Union[str, Path],
        rename: Optional[str] = None,
        replace_existing: bool = False
    ) -> Dict[str, Any]:
        """
        Import a workflow from a package.
        
        Args:
            workflow_path: Path to the workflow package
            rename: Optional new name for the workflow
            replace_existing: Whether to replace existing workflow with same name
            
        Returns:
            Dictionary with import results
        """
        path_obj = Path(workflow_path)
        
        # Check if file exists
        if not path_obj.exists():
            return {
                "success": False,
                "error": f"File not found: {path_obj}"
            }
        
        try:
            # Create a temporary directory for extraction
            with tempfile.TemporaryDirectory() as temp_dir:
                temp_path = Path(temp_dir)
                
                # Extract the zip archive
                with zipfile.ZipFile(path_obj, "r") as zip_file:
                    zip_file.extractall(temp_path)
                
                # Check metadata
                metadata_path = temp_path / "metadata.json"
                if not metadata_path.exists():
                    return {
                        "success": False,
                        "error": "Invalid workflow package: missing metadata.json"
                    }
                
                # Load metadata
                with open(metadata_path, "r") as f:
                    metadata = WorkflowExportMetadata(**json.load(f))
                
                # Check workflow data
                workflow_data_path = temp_path / "workflow.json"
                if not workflow_data_path.exists():
                    return {
                        "success": False,
                        "error": "Invalid workflow package: missing workflow.json"
                    }
                
                # Verify checksum
                computed_checksum = self._generate_checksum(workflow_data_path)
                if computed_checksum != metadata.checksum:
                    return {
                        "success": False,
                        "error": "Checksum verification failed. The workflow package may be corrupted."
                    }
                
                # Load workflow data
                with open(workflow_data_path, "r") as f:
                    workflow_data = json.load(f)
                
                # Apply rename if provided
                if rename:
                    workflow_data["name"] = rename
                
                # Check if workflow already exists
                existing_workflow = self._workflow_manager.get_workflow(workflow_data["name"])
                if existing_workflow and not replace_existing:
                    return {
                        "success": False,
                        "error": f"Workflow '{workflow_data['name']}' already exists. Use replace_existing=True to replace it."
                    }
                
                # Import the workflow
                workflow = await self._workflow_manager.define_workflow_from_data(
                    workflow_data,
                    source=f"Imported from {path_obj.name}"
                )
                
                return {
                    "success": True,
                    "workflow": workflow.name,
                    "metadata": metadata.dict()
                }
                
        except Exception as e:
            self._logger.exception(f"Error importing workflow from {workflow_path}: {str(e)}")
            return {
                "success": False,
                "error": f"Import failed: {str(e)}"
            }
    
    def _generate_checksum(self, file_path: Path) -> str:
        """
        Generate SHA-256 checksum of a file.
        
        Args:
            file_path: Path to the file
            
        Returns:
            Hex digest of the checksum
        """
        sha256 = hashlib.sha256()
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                sha256.update(chunk)
        return sha256.hexdigest()
    
    async def _detect_dependencies(self, workflow: Workflow) -> Dict[str, str]:
        """
        Detect external dependencies of a workflow.
        
        Args:
            workflow: The workflow to analyze
            
        Returns:
            Dictionary of dependencies
        """
        dependencies = {}
        
        # Check for tool dependencies in commands
        for step in workflow.steps:
            command = step.command.split()[0] if step.command else ""
            
            # Common tools to check
            if command in ["python", "python3"]:
                # Check Python version
                result = await self._run_command("python --version")
                if result["success"]:
                    dependencies["python"] = result["stdout"].strip().replace("Python ", "")
            elif command in ["node", "npm"]:
                # Check Node.js/npm version
                result = await self._run_command("node --version")
                if result["success"]:
                    dependencies["node"] = result["stdout"].strip().replace("v", "")
            elif command == "docker":
                # Check Docker version
                result = await self._run_command("docker --version")
                if result["success"]:
                    dependencies["docker"] = result["stdout"].strip()
            # Add more tool checks as needed
        
        return dependencies
    
    async def _run_command(self, command: str) -> Dict[str, Any]:
        """
        Run a shell command and return its output.
        
        Args:
            command: The command to run
            
        Returns:
            Dictionary with command results
        """
        import asyncio
        
        try:
            process = await asyncio.create_subprocess_shell(
                command,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            stdout, stderr = await process.communicate()
            
            return {
                "command": command,
                "stdout": stdout.decode('utf-8', errors='replace').strip(),
                "stderr": stderr.decode('utf-8', errors='replace').strip(),
                "return_code": process.returncode,
                "success": process.returncode == 0
            }
        except Exception as e:
            self._logger.error(f"Error running command '{command}': {str(e)}")
            return {
                "command": command,
                "stdout": "",
                "stderr": str(e),
                "return_code": -1,
                "success": False
            }

# Global workflow sharing manager instance
workflow_sharing_manager = WorkflowSharingManager(workflow_manager)
</file>

<file path="MD/ImplemenationsMD/Phase_5_implementation.md">
# angela/integrations.py

import asyncio
from typing import Dict, Any, List, Optional, Set
from pathlib import Path

from angela.utils.logging import get_logger
from angela.context import context_manager
from angela.context.project_inference import project_inference
from angela.intent.advanced_planner import advanced_task_planner
from angela.ai.content_analyzer import content_analyzer
from angela.monitoring.network_monitor import network_monitor
from angela.workflows.sharing import workflow_sharing_manager
from angela.execution.error_recovery import ErrorRecoveryManager

logger = get_logger(__name__)

class PhaseIntegration:
    """
    Integration module for Phase 5.5 features.
    
    This class provides:
    1. Initialization and setup of Phase 5.5 features
    2. Integration between different components
    3. Helper methods for the orchestrator
    4. Status reporting
    """
    
    def __init__(self):
        """Initialize the integration module."""
        self._logger = logger
        self._error_recovery = ErrorRecoveryManager()
        self._features_enabled = {}
    
    async def initialize(self, config: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        Initialize Phase 5.5 features.
        
        Args:
            config: Optional configuration dictionary
            
        Returns:
            Status of initialization
        """
        config = config or {}
        results = {}
        
        # Initialize project inference
        if config.get("enable_project_inference", True):
            try:
                project_root = context_manager.project_root
                if project_root:
                    project_info = await project_inference.infer_project_info(project_root)
                    results["project_inference"] = {
                        "status": "initialized",
                        "project_type": project_info.get("project_type", "unknown")
                    }
                    self._features_enabled["project_inference"] = True
                else:
                    results["project_inference"] = {
                        "status": "disabled",
                        "reason": "No project root detected"
                    }
            except Exception as e:
                self._logger.error(f"Error initializing project inference: {str(e)}")
                results["project_inference"] = {
                    "status": "error",
                    "error": str(e)
                }
        
        # Initialize network monitoring
        if config.get("enable_network_monitoring", False):
            try:
                network_monitor.start_monitoring()
                results["network_monitoring"] = {
                    "status": "started"
                }
                self._features_enabled["network_monitoring"] = True
            except Exception as e:
                self._logger.error(f"Error starting network monitoring: {str(e)}")
                results["network_monitoring"] = {
                    "status": "error",
                    "error": str(e)
                }
        
        # Log the initialization results
        self._logger.info(f"Phase 5.5 features initialized: {', '.join(k for k, v in self._features_enabled.items() if v)}")
        
        return results
    
    async def get_enhanced_context(self) -> Dict[str, Any]:
        """
        Get enhanced context information for AI prompts.
        
        Returns:
            Enhanced context dictionary
        """
        context = {}
        
        # Add project inference data if available
        if self._features_enabled.get("project_inference"):
            project_root = context_manager.project_root
            if project_root:
                try:
                    project_info = await project_inference.infer_project_info(project_root)
                    context["project_info"] = project_info
                except Exception as e:
                    self._logger.error(f"Error getting project information: {str(e)}")
        
        # Add network status if available
        if self._features_enabled.get("network_monitoring"):
            try:
                # This is a placeholder - in a real implementation, you would
                # get the actual network status from the network monitor
                context["network_status"] = {
                    "internet_connected": True,
                    "local_services": {}
                }
            except Exception as e:
                self._logger.error(f"Error getting network status: {str(e)}")
        
        return context
    
    async def handle_execution_error(
        self, 
        step: Any, 
        error_result: Dict[str, Any], 
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Handle execution errors with recovery.
        
        Args:
            step: The step that failed
            error_result: The execution result with error information
            context: Context information
            
        Returns:
            Updated execution result
        """
        return await self._error_recovery.handle_error(step, error_result, context)
    
    async def analyze_content(
        self, 
        file_path: Path, 
        request: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Analyze file content with enhanced capabilities.
        
        Args:
            file_path: Path to the file to analyze
            request: Optional specific analysis request
            
        Returns:
            Analysis results
        """
        # Get project context for better analysis
        enhanced_context = {}
        if self._features_enabled.get("project_inference"):
            project_root = context_manager.project_root
            if project_root:
                try:
                    project_info = await project_inference.infer_project_info(project_root)
                    enhanced_context["project_type"] = project_info.get("project_type", "unknown")
                    enhanced_context["frameworks"] = project_info.get("detected_frameworks", {})
                except Exception as e:
                    self._logger.error(f"Error getting project information: {str(e)}")
        
        # Use the enhanced content analyzer
        from angela.ai.content_analyzer_extensions import enhanced_content_analyzer
        return await enhanced_content_analyzer.analyze_content(file_path, request)
    
    async def status(self) -> Dict[str, Any]:
        """
        Get status of Phase 5.5 features.
        
        Returns:
            Status dictionary
        """
        status = {
            "enabled_features": {k: v for k, v in self._features_enabled.items() if v},
            "phase": "5.5",
            "description": "Autonomous Task Orchestration & Proactive Assistance"
        }
        
        # Add project information if available
        if self._features_enabled.get("project_inference"):
            project_root = context_manager.project_root
            if project_root:
                try:
                    project_info = await project_inference.infer_project_info(project_root)
                    status["project"] = {
                        "type": project_info.get("project_type", "unknown"),
                        "frameworks": list(project_info.get("detected_frameworks", {}).keys()),
                        "dependencies_count": len(project_info.get("dependencies", []))
                    }
                except Exception as e:
                    self._logger.error(f"Error getting project status: {str(e)}")
        
        # Add network status if available
        if self._features_enabled.get("network_monitoring"):
            try:
                # This is a placeholder - in a real implementation, you would
                # get actual network monitor statistics
                status["network_monitoring"] = {
                    "status": "active",
                    "services_monitored": 0,
                    "dependency_updates": 0
                }
            except Exception as e:
                self._logger.error(f"Error getting network status: {str(e)}")
        
        return status

# Global integration instance
phase_integration = PhaseIntegration()
</file>

<file path="MD/ImplemenationsMD/Phase_6_implementation.md">
"""
Phase 6 Integration for Enhanced Project Context.

This file provides the necessary integration points for all Phase 6 components.
It should be used to update the existing code in the Angela CLI project.
"""

# Import statements to add to the beginning of orchestrator.py
IMPORT_STATEMENTS = """
from angela.context.enhancer import context_enhancer
from angela.context.file_resolver import file_resolver
from angela.context.file_activity import file_activity_tracker, ActivityType
from angela.execution.hooks import execution_hooks
"""

# Updated process_request method for Orchestrator class
PROCESS_REQUEST_METHOD = """
async def process_request(
    self, 
    request: str, 
    execute: bool = True,
    dry_run: bool = False
) -> Dict[str, Any]:
    '''
    Process a request from the user with enhanced context.
    
    Args:
        request: The user request
        execute: Whether to execute commands
        dry_run: Whether to simulate execution without making changes
        
    Returns:
        Dictionary with processing results
    '''
    # Refresh context to ensure we have the latest information
    context_manager.refresh_context()
    context = context_manager.get_context_dict()
    
    # Add session context for continuity across requests
    session_context = session_manager.get_context()
    context["session"] = session_context
    
    # Enhance context with project information, dependencies, and recent activity
    context = await context_enhancer.enrich_context(context)
    
    self._logger.info(f"Processing request: {request}")
    self._logger.debug(f"Enhanced context with {len(context)} keys")
    
    # Extract and resolve file references
    file_references = await file_resolver.extract_references(request, context)
    if file_references:
        # Add resolved file references to context
        context["resolved_files"] = [
            {"reference": ref, "path": str(path) if path else None}
            for ref, path in file_references
        ]
        self._logger.debug(f"Resolved {len(file_references)} file references")
    
    try:
        # Analyze the request to determine its type
        request_type = await self._determine_request_type(request, context)
        self._logger.info(f"Determined request type: {request_type.value}")
        
        # Process the request based on its type
        if request_type == RequestType.COMMAND:
            # Handle single command request
            return await self._process_command_request(request, context, execute, dry_run)
            
        elif request_type == RequestType.MULTI_STEP:
            # Handle multi-step operation
            return await self._process_multi_step_request(request, context, execute, dry_run)
            
        elif request_type == RequestType.FILE_CONTENT:
            # Handle file content analysis/manipulation
            return await self._process_file_content_request(request, context, execute, dry_run)
            
        elif request_type == RequestType.WORKFLOW_DEFINITION:
            # Handle workflow definition
            return await self._process_workflow_definition(request, context)
            
        elif request_type == RequestType.WORKFLOW_EXECUTION:
            # Handle workflow execution
            return await self._process_workflow_execution(request, context, execute, dry_run)
            
        elif request_type == RequestType.CLARIFICATION:
            # Handle request for clarification
            return await self._process_clarification_request(request, context)
            
        else:
            # Handle unknown request type
            return await self._process_unknown_request(request, context)
        
    except Exception as e:
        self._logger.exception(f"Error processing request: {str(e)}")
        # Fallback behavior
        return {
            "request": request,
            "response": f"An error occurred while processing your request: {str(e)}",
            "error": str(e),
            "context": context,
        }
"""

# Updated _extract_file_path method for Orchestrator class
EXTRACT_FILE_PATH_METHOD = """
async def _extract_file_path(
    self, 
    request: str, 
    context: Dict[str, Any]
) -> Optional[Path]:
    '''
    Extract a file path from a request using file_resolver.
    
    Args:
        request: The user request
        context: Context information
        
    Returns:
        Path object if found, None otherwise
    '''
    self._logger.debug(f"Extracting file path from: {request}")
    
    # Try to extract file references
    file_references = await file_resolver.extract_references(request, context)
    
    # If we found any resolved references, return the first one
    for reference, path in file_references:
        if path:
            # Track as viewed file
            file_activity_tracker.track_file_viewing(path, None, {
                "request": request,
                "reference": reference
            })
            return path
    
    # If we found references but couldn't resolve them, use AI extraction as fallback
    if file_references:
        for reference, _ in file_references:
            # Try to resolve with a broader scope
            path = await file_resolver.resolve_reference(
                reference, 
                context,
                search_scope="project"
            )
            if path:
                # Track as viewed file
                file_activity_tracker.track_file_viewing(path, None, {
                    "request": request,
                    "reference": reference
                })
                return path
    
    # If all else fails, fall back to the original AI method
    prompt = f'''
Extract the most likely file path from this user request:
"{request}"

Current working directory: {context["cwd"]}
Project root (if any): {context.get("project_root", "None")}

Return the most likely file path as just a single word, with no additional explanation or context.
'''
    
    api_request = GeminiRequest(prompt=prompt, max_tokens=100)
    response = await gemini_client.generate_text(api_request)
    
    file_name = response.text.strip()
    
    # Remove quotes if present
    if file_name.startswith('"') and file_name.endswith('"'):
        file_name = file_name[1:-1]
    if file_name.startswith("'") and file_name.endswith("'"):
        file_name = file_name[1:-1]
    
    # Check if this is a valid path
    path = Path(file_name)
    if not path.is_absolute():
        # Check in current directory
        cwd_path = Path(context["cwd"]) / path
        if cwd_path.exists():
            return cwd_path
        
        # Check in project root if available
        if context.get("project_root"):
            proj_path = Path(context["project_root"]) / path
            if proj_path.exists():
                return proj_path
    else:
        # Absolute path
        if path.exists():
            return path
    
    # No valid path found
    return None
"""

# Updates to execution methods to add hooks
EXECUTE_COMMAND_METHOD = """
async def execute_command(
    self, 
    command: str,
    natural_request: str,
    explanation: Optional[str] = None,
    dry_run: bool = False
) -> Dict[str, Any]:
    '''
    Execute a command with adaptive behavior based on user context.
    
    Args:
        command: The command to execute
        natural_request: The original natural language request
        explanation: AI explanation of what the command does
        dry_run: Whether to simulate the command without execution
        
    Returns:
        Dictionary with execution results
    '''
    self._logger.info(f"Preparing to execute command: {command}")
    
    # Get current context for hooks
    context = context_manager.get_context_dict()
    
    # Call pre-execution hook
    await execution_hooks.pre_execute_command(command, context)
    
    # Analyze command risk and impact
    risk_level, risk_reason = classify_command_risk(command)
    impact = analyze_command_impact(command)
    
    # Add to session context
    session_manager.add_command(command)
    
    # Generate command preview if needed
    from angela.safety.preview import generate_preview
    preview = await generate_preview(command) if preferences_manager.preferences.ui.show_command_preview else None
    
    # Get adaptive confirmation based on risk level and user history
    confirmed = await get_adaptive_confirmation(
        command=command,
        risk_level=risk_level,
        risk_reason=risk_reason,
        impact=impact,
        preview=preview,
        explanation=explanation,
        natural_request=natural_request,
        dry_run=dry_run
    )
    
    if not confirmed and not dry_run:
        self._logger.info(f"Command execution cancelled by user: {command}")
        return {
            "command": command,
            "success": False,
            "cancelled": True,
            "stdout": "",
            "stderr": "Command execution cancelled by user",
            "return_code": 1,
            "dry_run": dry_run
        }
    
    # Execute the command
    result = await self._execute_with_feedback(command, dry_run)
    
    # Call post-execution hook
    await execution_hooks.post_execute_command(command, result, context)
    
    # Add to history
    history_manager.add_command(
        command=command,
        natural_request=natural_request,
        success=result["success"],
        output=result.get("stdout", ""),
        error=result.get("stderr", ""),
        risk_level=risk_level
    )
    
    # If execution failed, analyze error and suggest fixes
    if not result["success"] and result.get("stderr"):
        result["error_analysis"] = error_analyzer.analyze_error(command, result["stderr"])
        result["fix_suggestions"] = error_analyzer.generate_fix_suggestions(command, result["stderr"])
    
    # Offer to learn from successful executions
    if result["success"] and risk_level > 0:
        from angela.safety.adaptive_confirmation import offer_command_learning
        await offer_command_learning(command)
    
    return result
"""

# Integration steps for Phase 6
INTEGRATION_STEPS = """
To integrate Phase 6 components:

1. Add the new Python files to the project:
   - angela/context/enhancer.py
   - angela/context/file_resolver.py
   - angela/context/file_activity.py
   - angela/execution/hooks.py

2. Update orchestrator.py:
   - Add the import statements at the top
   - Replace process_request method with the updated version
   - Replace _extract_file_path method with the updated version
   - Update execute_command method in adaptive_engine.py with the updated version

3. Update ai/prompts.py:
   - Add the new prompt templates
   - Replace build_prompt function with the updated version
   - Replace build_file_operation_prompt function with the updated version

4. Update execution/engine.py and execution/adaptive_engine.py:
   - Add hooks integration to execution methods

5. Test all components:
   - Test project inference
   - Test file resolution
   - Test file activity tracking
   - Test enhanced prompts

6. Update documentation to reflect the new capabilities
"""

# Installation and usage instructions
INSTALLATION_INSTRUCTIONS = """
# Phase 6: Enhanced Project Context

## Installation

1. Copy the new Python files to their respective directories:
   ```
   cp angela/context/enhancer.py /path/to/angela/context/
   cp angela/context/file_resolver.py /path/to/angela/context/
   cp angela/context/file_activity.py /path/to/angela/context/
   cp angela/execution/hooks.py /path/to/angela/execution/
   ```

2. Update the existing files with the provided code snippets.

3. Install additional dependencies if needed:
   ```
   pip install difflib
   ```

## Usage

The enhanced project context capabilities are automatically used by the system.
When you make a request, Angela will:

1. Detect project type and dependencies
2. Resolve file references in your natural language query
3. Track file activities
4. Use all this information to provide more contextually relevant responses

Example usage:
```
angela "Find all functions in the main file that handle user input"
```

In this example, Angela will:
- Infer what "main file" means in your project
- Find relevant functions
- Track this file viewing in its history
- Use project context to understand what "user input" means in your specific project type
```
</file>

<file path="MD/ImplemenationsMD/planner_implementation.md">
# Advanced Task Planner

## Overview

The Advanced Task Planner extends Angela CLI's orchestration capabilities with comprehensive support for complex step types, rich data flow between steps, and robust error handling.

This enhanced implementation allows Angela to execute sophisticated task plans that involve:

- **Code execution** (Python, JavaScript, Shell)
- **API calls** to external services
- **File operations** with proper permission checks
- **Decision trees** with conditional branching
- **Loops** for iterative processing
- **Variable flow** between steps
- **Error recovery** for resilient execution

## Core Components

### Enhanced Step Types

The Advanced Task Planner supports the following step types:

| Type | Description | Key Parameters |
|------|-------------|----------------|
| `COMMAND` | Execute shell commands | `command` |
| `CODE` | Execute code in various languages | `code`, `language` |
| `FILE` | Perform file operations | `file_path`, `file_content`, `operation` |
| `DECISION` | Branch execution based on conditions | `condition`, `true_branch`, `false_branch` |
| `API` | Make HTTP API calls | `api_url`, `api_method`, `api_params`, `api_payload` |
| `LOOP` | Iterate over a collection | `loop_items`, `loop_body` |

### Data Flow System

The data flow system enables passing information between steps through variables:

- Variables can be referenced in step parameters using `${variable_name}` syntax
- Each step can output variables that subsequent steps can access
- Step results are automatically available to later steps via `${result.step_id.field}` syntax
- Special variables like `loop_item` and `loop_index` are available in loop iterations

### Error Handling & Recovery

The system includes sophisticated error handling:

- Retry mechanism with configurable attempt limits
- Integration with `ErrorRecoveryManager` for intelligent recovery
- Transaction-based execution with rollback capability
- Comprehensive logging and error reporting

## Using Advanced Plans

### Creating an Advanced Plan

An advanced plan is defined using the `AdvancedTaskPlan` model:

```python
plan = AdvancedTaskPlan(
    id="my_plan_id",
    goal="Accomplish a complex task",
    description="A detailed description of the plan",
    steps={
        "step1": AdvancedPlanStep(
            id="step1",
            type=PlanStepType.COMMAND,
            description="First step",
            command="echo 'Hello World'",
            dependencies=[],
            estimated_risk=0
        ),
        "step2": AdvancedPlanStep(
            id="step2",
            type=PlanStepType.DECISION,
            description="Decide next action",
            condition="file exists /tmp/test.txt",
            true_branch=["step3a"],
            false_branch=["step3b"],
            dependencies=["step1"],
            estimated_risk=0
        ),
        # Additional steps...
    },
    entry_points=["step1"],  # Where execution begins
    context={}
)
```

### Executing an Advanced Plan

Plans can be executed through the task planner:

```python
result = await task_planner.execute_plan(
    plan, 
    dry_run=False,
    transaction_id="optional_transaction_id",
    initial_variables={"var1": "value1"}
)
```

The execution result contains information about:
- Overall success/failure
- Execution path taken
- Individual step results
- Variables at end of execution
- Total execution time

## Advanced Step Types in Detail

### CODE Step

Execute code in Python, JavaScript, or Shell:

```python
CodeStep = AdvancedPlanStep(
    id="run_code",
    type=PlanStepType.CODE,
    description="Calculate statistics",
    code="""
# Process data
data = [1, 2, 3, 4, 5]
result = sum(data) / len(data)
print(f"Average: {result}")
    """,
    language="python",
    dependencies=[],
    estimated_risk=1
)
```

The code execution environment:
- Runs in a sandboxed process
- Has access to a limited set of imports
- Can read variables from the execution context
- Returns stdout, stderr, and explicit result variables

### API Step

Make HTTP requests to external services:

```python
ApiStep = AdvancedPlanStep(
    id="call_api",
    type=PlanStepType.API,
    description="Get weather data",
    api_url="https://api.example.com/weather",
    api_method="GET",
    api_params={"city": "London"},
    api_headers={"Authorization": "Bearer ${api_token}"},
    timeout=30,
    dependencies=[],
    estimated_risk=1
)
```

Key features:
- Supports all HTTP methods
- JSON and form data handling
- Response parsing with automatic JSON detection
- Variable interpolation in URL, headers, and payload

### DECISION Step

Branch execution based on conditions:

```python
DecisionStep = AdvancedPlanStep(
    id="check_condition",
    type=PlanStepType.DECISION,
    description="Check if prerequisites are met",
    condition="variable result > 10",
    true_branch=["success_step"],
    false_branch=["fallback_step"],
    dependencies=["previous_step"],
    estimated_risk=0
)
```

Condition types:
- Simple variable comparisons (`variable x == y`)
- File existence checks (`file exists path/to/file`)
- Command success checks (`command success step_id`)
- Output content checks (`output contains pattern in step_id`)
- Custom code conditions using `condition_code` parameter

### LOOP Step

Iterate over collections with dedicated body steps:

```python
LoopStep = AdvancedPlanStep(
    id="process_items",
    type=PlanStepType.LOOP,
    description="Process each item in list",
    loop_items="range(1, 5)",
    loop_body=["process_item_step"],
    dependencies=["setup_step"],
    estimated_risk=1
)
```

Loop items can be:
- Range expressions (`range(start, end, step)`)
- File patterns (`files(*.txt)`)
- Variable references (`${my_list}`)
- JSON arrays
- Comma-separated lists

Within loop iterations, special variables are available:
- `loop_item`: Current item being processed
- `loop_index`: Zero-based index of current iteration
- `loop_first`: Boolean indicating if this is the first iteration
- `loop_last`: Boolean indicating if this is the last iteration

### FILE Step

Perform file operations with proper safety checks:

```python
FileStep = AdvancedPlanStep(
    id="save_results",
    type=PlanStepType.FILE,
    description="Save results to file",
    file_path="/tmp/results.txt",
    file_content="Results: ${step_results}",
    operation="write",
    dependencies=["calculation_step"],
    estimated_risk=1
)
```

Supported operations:
- `read`: Read file content
- `write`: Write content to file
- `delete`: Delete file or directory
- `copy`: Copy file from source to destination
- `move`: Move file from source to destination

## Data Flow Examples

### Referencing Variables in Parameters

```python
# Referencing a variable in a command
CommandStep = AdvancedPlanStep(
    id="use_variable",
    type=PlanStepType.COMMAND,
    description="Use a variable in command",
    command="grep '${search_pattern}' ${filename}",
    dependencies=["previous_step"],
    estimated_risk=0
)
```

### Accessing Step Results

```python
# Access result of a previous step
CodeStep = AdvancedPlanStep(
    id="process_results",
    type=PlanStepType.CODE,
    description="Process previous results",
    code="""
# Get data from previous step
previous_output = variables.get('step1_stdout', '')
line_count = len(previous_output.splitlines())
print(f"Lines: {line_count}")
result = line_count * 2  # Store as explicit result
""",
    dependencies=["step1"],
    estimated_risk=0
)
```

### Setting Output Variables

All step types automatically create output variables:

- `COMMAND` steps: `${step_id}_stdout`, `${step_id}_stderr`, `${step_id}_return_code`
- `CODE` steps: Variables set in code, plus `${step_id}_stdout`, `${step_id}_result`
- `API` steps: `${step_id}_status_code`, `${step_id}_response_text`, `${step_id}_response_json`
- `FILE` steps: `${step_id}_content` (read) or `${step_id}_message` (write/delete/copy/move)
- `DECISION` steps: `${step_id}_condition_result`, `${step_id}_next_branch`
- `LOOP` steps: `${step_id}_iterations`

## Integration with Angela CLI

The Advanced Task Planner is fully integrated with Angela's orchestration system:

- Natural language requests can generate Advanced Task Plans automatically
- The terminal formatter provides rich visualization of plans and results
- Full transaction support with rollback capability
- Error recovery and retry mechanisms seamlessly applied

### Example of Natural Language Usage

```
$ angela "Download sales data from our API, extract monthly figures, calculate growth rates, and generate a summary report"
```

This will analyze the request complexity, create an Advanced Task Plan with appropriate steps, display the plan for confirmation, and execute it with full data flow and error handling.

## Best Practices

1. **Plan Structure**
   - Keep steps small and focused on a single task
   - Use meaningful step IDs and descriptions
   - Organize dependencies carefully to maintain a clear execution flow

2. **Data Flow**
   - Use explicit variable names for clarity
   - Consider creating "collector" steps that format and organize data
   - Be cautious with large variable values to avoid performance issues

3. **Error Handling**
   - Set appropriate retry values for steps that might temporarily fail
   - Consider adding fallback branches in decision steps
   - Use timeout parameters for external operations

4. **Security**
   - Set appropriate risk levels for steps
   - Avoid hardcoding sensitive information in steps
   - Use variable substitution for secure values

5. **Performance**
   - Batch operations when possible in loops
   - Consider using CODE steps for complex data processing instead of multiple COMMAND steps
   - Use dry runs for testing complex plans before actual execution

## Advanced Examples

### Complex Data Processing Pipeline

```python
plan = AdvancedTaskPlan(
    id="data_processing_pipeline",
    goal="Process sales data and generate reports",
    description="Download sales data, extract insights, and create reports",
    steps={
        "step1": AdvancedPlanStep(
            id="step1",
            type=PlanStepType.COMMAND,
            description="Download sales data",
            command="curl -s -o sales_data.csv https://example.com/api/sales",
            dependencies=[],
            estimated_risk=1
        ),
        "step2": AdvancedPlanStep(
            id="step2",
            type=PlanStepType.CODE,
            description="Parse and analyze CSV data",
            code="""
import csv
import statistics

sales_by_month = {}

with open('sales_data.csv', 'r') as f:
    reader = csv.DictReader(f)
    for row in reader:
        month = row['month']
        sales = float(row['sales'])
        if month not in sales_by_month:
            sales_by_month[month] = []
        sales_by_month[month].append(sales)

# Calculate monthly statistics
monthly_stats = {}
for month, sales in sales_by_month.items():
    monthly_stats[month] = {
        'total': sum(sales),
        'average': statistics.mean(sales),
        'median': statistics.median(sales)
    }

# Store as result
result = monthly_stats
print(f"Processed {len(sales_by_month)} months of data")
            """,
            dependencies=["step1"],
            estimated_risk=0,
            language="python"
        ),
        "step3": AdvancedPlanStep(
            id="step3",
            type=PlanStepType.DECISION,
            description="Check if we have enough data",
            condition="variable step2_result.keys().length >= 3",
            condition_type="code",
            condition_code="""
# Check if we have at least 3 months of data
stats = variables.get('step2_result', {})
result = len(stats.keys()) >= 3
            """,
            true_branch=["step4a"],
            false_branch=["step4b"],
            dependencies=["step2"],
            estimated_risk=0
        ),
        "step4a": AdvancedPlanStep(
            id="step4a",
            type=PlanStepType.FILE,
            description="Generate full report",
            file_path="sales_report.md",
            file_content="""# Sales Report

## Monthly Statistics

${step2_result}

Generated on ${current_date}
            """,
            operation="write",
            dependencies=["step3"],
            estimated_risk=1
        ),
        "step4b": AdvancedPlanStep(
            id="step4b",
            type=PlanStepType.COMMAND,
            description="Notify about insufficient data",
            command="echo 'Insufficient data for full report' > notification.txt",
            dependencies=["step3"],
            estimated_risk=0
        )
    },
    entry_points=["step1"],
    context={}
)
```

### Web API Interaction with Error Handling

```python
plan = AdvancedTaskPlan(
    id="api_interaction",
    goal="Fetch and process user data",
    description="Query an API for user data and process the results",
    steps={
        "step1": AdvancedPlanStep(
            id="step1",
            type=PlanStepType.API,
            description="Fetch user list from API",
            api_url="https://api.example.com/users",
            api_method="GET",
            api_headers={
                "Authorization": "Bearer ${api_token}",
                "Content-Type": "application/json"
            },
            timeout=30,
            retry=3,  # Retry up to 3 times
            dependencies=[],
            estimated_risk=1
        ),
        "step2": AdvancedPlanStep(
            id="step2",
            type=PlanStepType.DECISION,
            description="Check API response",
            condition="variable step1_status_code == 200",
            true_branch=["step3"],
            false_branch=["step_error"],
            dependencies=["step1"],
            estimated_risk=0
        ),
        "step3": AdvancedPlanStep(
            id="step3",
            type=PlanStepType.LOOP,
            description="Process each user",
            loop_items="${step1_response_json.users}",
            loop_body=["step4"],
            dependencies=["step2"],
            estimated_risk=0
        ),
        "step4": AdvancedPlanStep(
            id="step4",
            type=PlanStepType.CODE,
            description="Process user info",
            code="""
# Get the current user from loop
user = variables.get('loop_item', {})
user_id = user.get('id')
name = user.get('name')

# Process user data
print(f"Processing user {name} (ID: {user_id})")

# Return structured result
result = {
    'id': user_id,
    'name': name,
    'processed': True,
    'timestamp': datetime.datetime.now().isoformat()
}
            """,
            language="python",
            dependencies=[],
            estimated_risk=0
        ),
        "step_error": AdvancedPlanStep(
            id="step_error",
            type=PlanStepType.FILE,
            description="Log API error",
            file_path="api_error.log",
            file_content="API Error: Status ${step1_status_code}\nResponse: ${step1_response_text}",
            operation="write",
            dependencies=["step2"],
            estimated_risk=1
        )
    },
    entry_points=["step1"],
    context={}
)
```

## Conclusion

The Advanced Task Planner represents a significant enhancement to Angela CLI's capabilities, enabling true autonomous task orchestration with comprehensive error handling and rich data flow. It transforms Angela from a simple command suggestion tool into a powerful automation platform capable of executing complex tasks with minimal user intervention.

Key benefits include:

- **Enhanced autonomy** - Angela can now handle complex multi-step operations with branching logic
- **Improved reliability** - Comprehensive error handling and recovery ensures robust execution
- **Greater flexibility** - Support for code execution, API calls, and iterative processing
- **Better context awareness** - Rich data flow between steps maintains context across the execution pipeline

These capabilities enable advanced use cases including:
- Complex data pipelines
- Multi-service integrations
- Automated troubleshooting with fallback paths
- Dynamic workflow execution based on real-time conditions


"""
Advanced Task Planner Usage Example

This module demonstrates practical usage of the enhanced Advanced Task Planner
with various step types, data flow, and error handling.
"""
import asyncio
import os
import uuid
import json
from pathlib import Path

from angela.intent.planner import (
    task_planner, TaskPlan, PlanStep, 
    AdvancedTaskPlan, AdvancedPlanStep, PlanStepType
)
from angela.shell.formatter import terminal_formatter
from angela.utils.logging import get_logger

logger = get_logger(__name__)

async def demo_advanced_plan():
    """Run a demonstration of an advanced task plan."""
    print("🚀 Starting Advanced Task Planner Demo")
    print("=======================================\n")
    
    # Create an advanced plan for data processing
    plan = create_data_processing_plan()
    
    # Display the plan
    await terminal_formatter.display_advanced_plan(plan)
    
    # Ask for confirmation
    print("\nExecute this plan? (y/n) ", end="")
    response = input().lower()
    
    if response.startswith('y'):
        # Execute the plan
        print("\n📋 Executing Advanced Plan...")
        result = await task_planner.execute_plan(
            plan, 
            dry_run=False,
            initial_variables={
                "data_dir": "./data",
                "output_dir": "./output",
                "min_temperature": 0,
                "max_temperature": 100
            }
        )
        
        # Display execution results
        await terminal_formatter.display_execution_results(plan, result)
        
        # Summarize the results
        if result["success"]:
            print("\n✅ Plan executed successfully!")
            
            # Show the final output if available
            if os.path.exists("./output/report.md"):
                print("\n📄 Generated Report Content:")
                with open("./output/report.md", "r") as f:
                    print(f.read())
        else:
            print("\n❌ Plan execution failed!")
            failed_step = result.get("failed_step")
            if failed_step and failed_step in result.get("results", {}):
                error = result["results"][failed_step].get("error", "Unknown error")
                print(f"\nFailed at step '{failed_step}': {error}")
    else:
        print("\nPlan execution cancelled.")

def create_data_processing_plan() -> AdvancedTaskPlan:
    """
    Create an advanced task plan for processing weather data.
    
    This demonstrates multiple step types, data flow, and error handling.
    
    Returns:
        AdvancedTaskPlan: The complete plan
    """
    plan_id = f"data_processing_{uuid.uuid4().hex[:8]}"
    
    return AdvancedTaskPlan(
        id=plan_id,
        goal="Process weather data and generate a report",
        description="A plan to download, analyze, and visualize weather data",
        steps={
            # Step 1: Set up directories
            "setup_dirs": AdvancedPlanStep(
                id="setup_dirs",
                type=PlanStepType.CODE,
                description="Set up data and output directories",
                code="""
# Create data and output directories if they don't exist
import os

data_dir = variables.get('data_dir', './data')
output_dir = variables.get('output_dir', './output')

os.makedirs(data_dir, exist_ok=True)
os.makedirs(output_dir, exist_ok=True)

print(f"Created directories: {data_dir}, {output_dir}")
result = {"data_dir": data_dir, "output_dir": output_dir}
                """,
                dependencies=[],
                estimated_risk=1,
                language="python"
            ),
            
            # Step 2: Download sample data
            "download_data": AdvancedPlanStep(
                id="download_data",
                type=PlanStepType.COMMAND,
                description="Generate sample weather data",
                command="""
# Generate sample weather data CSV
cat > ${data_dir}/weather_data.csv << EOL
date,location,temperature,humidity,conditions
2023-01-01,New York,32,65,Snowing
2023-01-02,New York,35,60,Cloudy
2023-01-03,New York,28,70,Snowing
2023-01-01,Los Angeles,68,45,Sunny
2023-01-02,Los Angeles,72,40,Sunny
2023-01-03,Los Angeles,70,50,Partly Cloudy
2023-01-01,Chicago,18,70,Snowing
2023-01-02,Chicago,22,65,Snowing
2023-01-03,Chicago,25,60,Cloudy
EOL
""",
                dependencies=["setup_dirs"],
                estimated_risk=1
            ),
            
            # Step 3: Validate data file exists
            "check_data": AdvancedPlanStep(
                id="check_data",
                type=PlanStepType.DECISION,
                description="Check if data file exists",
                condition="file exists ${data_dir}/weather_data.csv",
                true_branch=["analyze_data"],
                false_branch=["handle_missing_data"],
                dependencies=["download_data"],
                estimated_risk=0
            ),
            
            # Step 4: Handle missing data (recovery path)
            "handle_missing_data": AdvancedPlanStep(
                id="handle_missing_data",
                type=PlanStepType.COMMAND,
                description="Generate fallback data if download failed",
                command="""
echo "date,location,temperature,humidity,conditions" > ${data_dir}/weather_data.csv
echo "2023-01-01,Fallback,50,50,Cloudy" >> ${data_dir}/weather_data.csv
""",
                dependencies=["check_data"],
                estimated_risk=1
            ),
            
            # Step 5: Analyze data
            "analyze_data": AdvancedPlanStep(
                id="analyze_data",
                type=PlanStepType.CODE,
                description="Analyze weather data",
                code="""
# Analyze weather data file
import csv
from statistics import mean

data_dir = variables.get('data_dir', './data')
min_temp = variables.get('min_temperature', 0)
max_temp = variables.get('max_temperature', 100)

# Initialize data structures
locations = {}
dates = set()
all_temps = []

# Read the CSV file
with open(f"{data_dir}/weather_data.csv", 'r') as f:
    reader = csv.DictReader(f)
    for row in reader:
        location = row['location']
        temp = float(row['temperature'])
        date = row['date']
        
        # Filter by temperature range
        if min_temp <= temp <= max_temp:
            # Add to locations
            if location not in locations:
                locations[location] = {'temperatures': [], 'conditions': []}
            
            locations[location]['temperatures'].append(temp)
            locations[location]['conditions'].append(row['conditions'])
            
            # Add to all temps
            all_temps.append(temp)
            
            # Add to dates
            dates.add(date)

# Calculate statistics
location_stats = {}
for location, data in locations.items():
    avg_temp = mean(data['temperatures']) if data['temperatures'] else 0
    most_common_condition = max(set(data['conditions']), key=data['conditions'].count)
    location_stats[location] = {
        'avg_temperature': round(avg_temp, 1),
        'most_common_condition': most_common_condition,
        'samples': len(data['temperatures'])
    }

overall_stats = {
    'total_locations': len(locations),
    'total_dates': len(dates),
    'avg_temperature': round(mean(all_temps), 1) if all_temps else 0,
    'min_temperature': min(all_temps) if all_temps else 0,
    'max_temperature': max(all_temps) if all_temps else 0
}

# Store results
result = {
    'location_stats': location_stats,
    'overall_stats': overall_stats
}

print(f"Analyzed data for {len(locations)} locations across {len(dates)} dates")
print(f"Overall average temperature: {overall_stats['avg_temperature']}°F")
                """,
                dependencies=["check_data", "handle_missing_data"],
                estimated_risk=0,
                language="python"
            ),
            
            # Step 6: Check if we have enough data
            "check_analysis": AdvancedPlanStep(
                id="check_analysis",
                type=PlanStepType.DECISION,
                description="Check if analysis found enough data",
                condition="variable analyze_data_result.overall_stats.total_locations > 0",
                true_branch=["process_locations"],
                false_branch=["generate_error_report"],
                dependencies=["analyze_data"],
                estimated_risk=0
            ),
            
            # Step 7: Process each location
            "process_locations": AdvancedPlanStep(
                id="process_locations",
                type=PlanStepType.LOOP,
                description="Process each location",
                loop_items="${Object.keys(analyze_data_result.location_stats)}",
                loop_body=["process_location"],
                dependencies=["check_analysis"],
                estimated_risk=0
            ),
            
            # Step 8: Process a single location
            "process_location": AdvancedPlanStep(
                id="process_location",
                type=PlanStepType.CODE,
                description="Process a single location",
                code="""
# Process a single location
location = variables.get('loop_item')
location_stats = variables.get('analyze_data_result', {}).get('location_stats', {}).get(location, {})
output_dir = variables.get('output_dir', './output')

# Generate markdown for this location
markdown = f"""# Weather Report for {location}

## Statistics
- Average Temperature: {location_stats.get('avg_temperature')}°F
- Most Common Condition: {location_stats.get('most_common_condition')}
- Number of Samples: {location_stats.get('samples')}

Generated on: {__import__('datetime').datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""

# Write to file
output_file = f"{output_dir}/{location.lower().replace(' ', '_')}_report.md"
with open(output_file, 'w') as f:
    f.write(markdown)

print(f"Generated report for {location}: {output_file}")
result = {
    "location": location,
    "output_file": output_file,
    "avg_temperature": location_stats.get('avg_temperature')
}
                """,
                language="python",
                dependencies=[],
                estimated_risk=1
            ),
            
            # Step 9: Generate summary report with API data
            "fetch_weather_icon": AdvancedPlanStep(
                id="fetch_weather_icon",
                type=PlanStepType.API,
                description="Fetch weather icon data",
                api_url="https://httpbin.org/anything",
                api_method="POST",
                api_payload={
                    "request_type": "weather_icons",
                    "conditions": ["Sunny", "Cloudy", "Snowing", "Partly Cloudy"]
                },
                dependencies=["process_locations"],
                estimated_risk=1
            ),
            
            # Step 10a: Generate final report
            "generate_report": AdvancedPlanStep(
                id="generate_report",
                type=PlanStepType.FILE,
                description="Generate final summary report",
                file_path="${output_dir}/report.md",
                file_content="""# Weather Analysis Report

## Overview
- Locations Analyzed: ${analyze_data_result.overall_stats.total_locations}
- Dates Covered: ${analyze_data_result.overall_stats.total_dates}
- Overall Average Temperature: ${analyze_data_result.overall_stats.avg_temperature}°F
- Temperature Range: ${analyze_data_result.overall_stats.min_temperature}°F to ${analyze_data_result.overall_stats.max_temperature}°F

## Location Summaries
${Object.entries(analyze_data_result.location_stats).map(([location, stats]) => 
  `### ${location}
  - Average Temperature: ${stats.avg_temperature}°F
  - Most Common Condition: ${stats.most_common_condition}
  - Samples: ${stats.samples}`
).join('\n\n')}

## API Integration Status
- Weather Icon API Status: ${fetch_weather_icon_status_code}

Report generated on: ${new Date().toISOString()}
""",
                operation="write",
                dependencies=["fetch_weather_icon"],
                estimated_risk=1
            ),
            
            # Step 10b: Generate error report
            "generate_error_report": AdvancedPlanStep(
                id="generate_error_report",
                type=PlanStepType.FILE,
                description="Generate error report",
                file_path="${output_dir}/error_report.md",
                file_content="""# Weather Analysis Error Report

No valid data was found for analysis. Please check the data source.

Error details:
- Data directory: ${setup_dirs_result.data_dir}
- Analysis result: ${JSON.stringify(analyze_data_result)}

Report generated on: ${new Date().toISOString()}
""",
                operation="write",
                dependencies=["check_analysis"],
                estimated_risk=1
            )
        },
        entry_points=["setup_dirs"],
        context={}
    )

# Run the demo if executed directly
if __name__ == "__main__":
    asyncio.run(demo_advanced_plan())
</file>

<file path="MD/ImplemenationsMD/rollback_implementation.md">
# Implementing the Enhanced Rollback System - Integration and Usage Guide

Now that we've created the core components for our transaction-based rollback system, let's explore how these pieces work together and how users can take advantage of this enhanced functionality.

## How the System Works Together

Our enhanced rollback system creates a robust framework for tracking and reverting complex operations. Here's how it all connects:

### 1. Transaction-Based Model

The core innovation is the **transaction-based approach** that groups related operations together. When a user initiates a complex action like:
- Multi-step plans
- File content manipulations
- Multiple file operations

The system creates a transaction with a unique ID and maintains that context throughout the operation's lifecycle. This allows users to roll back entire sequences of operations as a single unit.

### 2. Rich Metadata for Diverse Operations

Each operation type stores custom metadata to enable accurate rollback:

- **File Operations**: Store backup paths and operation details
- **Content Manipulations**: Store diffs between original and modified content
- **Command Executions**: Store the original command and an identified compensating action
- **Plans**: Store the full plan structure for reference

### 3. Integration Points

The system integrates at key points in the application flow:

- **Orchestrator**: Starts transactions at the beginning of complex requests and ends them when complete
- **Task Planner**: Records each step execution with the transaction context
- **Content Analyzer**: Records file content changes with diffs for precise restoration
- **CLI**: Provides user interface for viewing and rolling back operations and transactions

## Usage Guide

### Listing Recent Operations and Transactions

```bash
# List recent operations
angela rollback list

# List recent transactions (groups of operations)
angela rollback list --transactions
```

### Rolling Back Operations

```bash
# Roll back a specific operation by ID
angela rollback operation 123

# Roll back a specific transaction by ID
angela rollback transaction abc-123-def

# Roll back the most recent operation
angela rollback last

# Roll back the most recent transaction
angela rollback last --transaction
```

### Automatic Rollback After Errors

If an error occurs during a multi-step operation, you can use the transaction ID to roll back all successful steps:

```bash
# After seeing an error like:
# "Step 3/5 failed: Permission denied"
# "Transaction ID: abc-123-def"

angela rollback transaction abc-123-def
```

## Implementation Highlights

### 1. Compensating Actions for Commands

The system automatically identifies **compensating actions** for common commands:

- `git add file.txt` → `git reset file.txt`
- `npm install express` → `npm uninstall express`
- `git commit -m "message"` → `git reset --soft HEAD~1`

This is achieved through a rule-based system in the `_identify_compensating_action` method, which analyzes command structure to determine the appropriate undo operation.

### 2. Diff-Based Content Rollback

For file content changes, the system:
1. Generates a unified diff between original and modified content
2. Stores this diff with the operation record
3. Can apply the reverse of this diff during rollback to restore original content

This is more sophisticated than simple file backups because it:
- Handles changes precisely, even if the file has been modified further
- Uses less storage space than full file backups
- Provides better visibility into what changed

### 3. Transaction Management

Transactions are tracked throughout their lifecycle:
- **Started**: When a complex operation begins
- **Completed**: When all steps succeed
- **Failed**: When any step fails
- **Rolled back**: After a successful rollback
- **Cancelled**: If the user cancels the operation

This state management enables better error recovery and user feedback.

## Benefits Over the Previous Rollback System

The enhanced system provides several key improvements:

1. **Operation Grouping**: Related actions are managed as a unit
2. **Diverse Operation Types**: Beyond just files, supports commands and content changes
3. **Rich Metadata**: Stores type-specific data for better rollback accuracy
4. **Command Compensation**: Automatically determines reverse actions for commands
5. **Improved CLI**: Better visibility and control for users
6. **Transaction Isolation**: Changes from different operations don't interfere with each other

## Testing the System

Our comprehensive test suite ensures reliability:

- Tests for transaction management
- Tests for each operation type (files, content, commands)
- Tests for rollback functionality
- Tests for compensating action identification
- Edge case handling

## Next Steps in Rollback Enhancement

To further improve the system, consider:

1. **AI-Assisted Compensating Actions**: Use AI to generate compensating actions for unknown commands
2. **Dependency Analysis**: Automatically determine the order of operations for rollback
3. **Partial Transaction Rollback**: Allow rolling back specific parts of a transaction
4. **Visual Diff Viewing**: Enhance the CLI to show visual diffs of content changes
5. **Remote Operation Tracking**: Support distributed operations across machines

The enhanced rollback system provides a solid foundation for handling complex operations safely, giving users confidence that their actions can be reversed if needed.
</file>

<file path="MD/ImplemenationsMD/shell_enhancement.md">
# Angela CLI Enhanced Shell Integration

## Features

Angela CLI now provides deep shell integration with the following features:

- **Pre/Post Command Execution Hooks**: Angela monitors commands before and after execution
- **Contextual Awareness**: Understands your working directory and project context
- **Proactive Suggestions**: Offers help when commands fail with specific suggestions based on error patterns
- **Inline Feedback**: Shows messages directly in your terminal session without disrupting your workflow
- **Advanced Command Editing**: Edit suggested commands with full keyboard navigation
- **Context-Aware Autocompletion**: Suggests completions based on your current context

## Installation

To install the enhanced shell integration:

```bash
# Run the installer script
bash scripts/install.sh


## Using the Enhanced Features

### Proactive Error Handling

When a command fails, Angela will automatically analyze the error and suggest a fix:

```
$ git push
fatal: The current branch main has no upstream branch.

[Angela] Command failed. Suggestion: Set the upstream branch with: git push --set-upstream origin main
```

### Command Suggestions

Angela can suggest commands based on your context:

```
$ angela suggest-command
[Angela] I suggest this command: git status
Confidence: ★★★★☆ (0.82)
Check the status of your Git repository
Execute? (y/n/e - where 'e' will edit before executing)
```

### Advanced Autocompletion

Press Tab after typing part of a command to see context-aware completions:

```
$ angela rollback [TAB]
list    operation    transaction    last
```

### Terminal Multiplexer Integration

If you use tmux, you can load the tmux integration:

```
$ tmux source-file ~/.local/lib/angela/shell/angela.tmux
```

This adds Angela status indicators to your tmux status bar and provides keybindings.
```

## Additional Enhancements

These implementations fully address all the placeholders and incomplete functionality in the Phase 8 Part 1 code. The enhanced shell integration now provides:

1. Advanced shell hooking via the Bash DEBUG trap, PROMPT_COMMAND, and Zsh preexec/precmd hooks
2. Sophisticated error analysis and proactive suggestions
3. Properly implemented terminal message handling with ANSI escape codes
4. Full prompt_toolkit integration for command editing
5. Rich completion suggestions from the rollback manager
6. Tmux integration for status indicators and keybindings

With these enhancements, Angela now feels much more like an intrinsic part of the shell environment rather than a separate tool, achieving the primary goal of Phase 8.
</file>

<file path="MD/MDHelpers/Files.md">
Okay, here are the 2-sentence explanations for each file in the codebase, providing maximum context within the limit:

1.  `angela/ai/analyzer.py`
    Defines the `ErrorAnalyzer` class to diagnose command execution errors by matching stderr against predefined patterns and historical data. It provides structured analysis and generates actionable fix suggestions based on error type, command structure, and file reference checks.

2.  `angela/ai/confidence.py`
    Introduces the `ConfidenceScorer` class to assess the reliability of AI-generated command suggestions using heuristics. It calculates a score based on factors like command history frequency/success (`history_manager`), complexity matching the request, entity presence, and flag validity.

3.  `angela/ai/content_analyzer_extensions.py`
    Introduces `EnhancedContentAnalyzer` extending the base analyzer with specialized handlers for various languages like TypeScript and data formats like JSON. It routes analysis based on detected file type, using custom AI prompts and parsing logic (e.g., regex for TS types, schema inference for JSON) or falling back to generic analysis.

4.  `angela/ai/file_integration.py`
    Provides functions to parse shell command strings (like `mkdir`, `cp`, `rm`, `echo >`) using regex and shlex to identify file system operation intent and parameters. It translates these parsed commands into structured requests that are then executed safely via functions in the `angela.execution.filesystem` module.

5.  `angela/ai/intent_analyzer.py`
    Defines the `IntentAnalyzer` to interpret the user's goal from natural language requests, normalizing input and using fuzzy matching against predefined patterns. It extracts relevant entities based on the identified intent and can initiate interactive clarification dialogs via `prompt_toolkit` if the user's intent is ambiguous.

6.  `angela/ai/parser.py`
    Provides the `parse_ai_response` function to convert potentially unstructured text responses from the AI into a structured `CommandSuggestion` Pydantic model. It intelligently searches for JSON within markdown code blocks or the raw response, validates against the model, and includes fallback logic using regex to extract at least the command string if parsing fails.

7.  `angela/cli/files_extensions.py`
    Extends the file commands with advanced features like resolving ambiguous file references (`resolve`), extracting paths from text (`extract`), and viewing file usage history (`recent`, `active`). It integrates closely with `file_resolver`, `file_activity_tracker`, and `context_enhancer` to provide these context-aware file operations.

8.  `angela/cli/files.py`
    Defines core file system commands (`ls`, `mkdir`, `rm`, `cp`, `cat`, `write`, `find`, `info`, `rollback`) for the Angela CLI using Typer and Rich. It leverages `angela.execution.filesystem` for operations, `angela.context.manager` for file info, and `angela.execution.rollback` for undo functionality, enhancing standard utilities with context and safety.

9.  `angela/context/enhancer.py`
    Defines the `ContextEnhancer` class responsible for augmenting the basic execution context with richer information. It integrates data from `project_inference` (type, frameworks, dependencies, structure) and `file_activity_tracker` (recent files) to provide a comprehensive understanding of the user's environment.

10. `angela/context/file_activity.py`
    Implements the `FileActivityTracker` to log file system events (create, modify, delete, view) using the `FileActivity` model and `ActivityType` enum. It maintains an in-memory history of recent activities, provides methods to query this history (e.g., `get_recent_activities`, `get_most_active_files`), and integrates with `session_manager`.

11. `angela/context/file_resolver.py`
    Implements the `FileResolver` class to translate natural language file references (e.g., "main file", "config.tx") into actual file paths. It employs multiple strategies including exact path matching, fuzzy name matching, pattern matching, and context from recent files or the project structure, also extracting potential references from text.

12. `angela/context/history.py`
    Defines the `HistoryManager` to persist and analyze command execution history using `CommandRecord` objects stored in JSON. It calculates command usage patterns (`CommandPattern`), success rates, identifies common error/fix sequences, and provides methods to search history.

13. `angela/context/preferences.py`
    Defines the `PreferencesManager` and associated Pydantic models (`UserPreferences`, etc.) to load, save, and manage user-specific settings from `preferences.json`. It determines behavior like command auto-execution based on configured trust levels and maintains lists of explicitly trusted/untrusted commands.

14. `angela/context/project_inference.py`
    Contains the `ProjectInference` class for in-depth analysis of project directories to deduce type, frameworks (`FRAMEWORK_SIGNATURES`), dependencies, structure, and important files. It uses file/directory pattern matching (`PROJECT_SIGNATURES`), dependency file parsing (e.g., `requirements.txt`, `package.json`), and structural analysis, caching results for efficiency.

15. `angela/context/session.py`
    Implements the `SessionManager` and `SessionMemory` class to maintain short-term conversational state, tracking entities (like files or commands) mentioned or used during an interaction. It handles session expiration and provides the current session context (recent commands, results, entities) to other modules like the `Orchestrator`.

16. `angela/core/__init__.py`
    Initializes the 'angela.core' sub-package. Contains essential utilities like the service registry.

17. `angela/core/events.py`
    Defines a simple `EventBus` class for decoupled communication between different parts of the application. It allows components to subscribe to specific event types and publish events with associated data, facilitating asynchronous notifications.

18. `angela/core/registry.py`
    Implements a singleton `ServiceRegistry` class acting as a service locator. It allows components to register themselves by name and be retrieved by other components, breaking circular dependencies.

19. `angela/execution/__init__.py`
    Initializes the 'angela.execution' sub-package. Exposes core execution components.

20. `angela/execution/adaptive_engine.py`
    Defines the `AdaptiveExecutionEngine` which orchestrates command execution with awareness of user context, preferences, and command risk. It integrates safety classification, adaptive confirmation, rich feedback using `Progress`, history logging, and error analysis/recovery suggestions.

21. `angela/execution/filesystem.py`
    Provides high-level, safe functions (e.g., `create_directory`, `delete_file`, `read_file`, `write_file`, `copy_file`, `move_file`) for interacting with the file system. It integrates safety checks via `check_operation_safety` and automatically creates backups in `BACKUP_DIR` before potentially destructive operations to support rollback.

22. `angela/execution/hooks.py`
    Defines the `ExecutionHooks` class to intercept command and file operation execution events. It uses pre/post execution hooks to analyze commands and outcomes, automatically tracking file views, modifications, creations, or deletions via the `file_activity_tracker`.

23. `angela/execution/rollback_commands.py`
    Defines Typer commands for interacting with the enhanced rollback system (`list`, `operation`, `transaction`, `last`). It interfaces with the `RollbackManager` to display operation/transaction history and trigger rollbacks, using `rich` for formatted output.

24. `angela/generation/__init__.py`
    Initializes the 'angela.generation' sub-package containing code generation logic. Makes components like the `CodeGenerationEngine` and `FrameworkGenerator` available.

25. `angela/generation/architecture.py`
    Provides the `ArchitecturalAnalyzer` class and pattern/anti-pattern models (`MvcPattern`, `SingleResponsibilityAntiPattern`, `GodObjectAntiPattern`) to analyze project structure. It detects architectural patterns and anti-patterns using heuristics and AI, generating recommendations for improvement.

26. `angela/generation/planner.py`
    Defines the `ProjectPlanner` and `ProjectArchitecture` models to design the high-level structure and components of a *new* software project before code generation. It interacts with AI (`_build_architecture_prompt`, `_parse_architecture`) to determine components, layers, patterns, and data flow based on a project description.

27. `angela/generation/validators.py`
    Provides code validation functions (`validate_code`, `validate_python`, `validate_javascript`, etc.) for various programming languages. It uses external tools (like `py_compile`, `node --check`, `tsc`) via `subprocess` or basic regex checks to ensure generated code is syntactically correct.

28. `angela/integrations/__init__.py`
    Initializes the 'angela.integrations' sub-package. It triggers the main application initialization via `init_application`.

29. `angela/integrations/enhanced_planner_integration.py`
    Implements the integration of the `EnhancedTaskPlanner` into the main `Orchestrator`. It achieves this by patching methods (like `_process_multi_step_request`) onto the `Orchestrator` class at runtime to enable advanced plan execution.

30. `angela/intent/__init__.py`
    Initializes the 'angela.intent' sub-package related to understanding user intent and planning actions. Exposes core models and the task planner instance.

31. `angela/intent/models.py`
    Defines core Pydantic models `Intent` and `ActionPlan` used primarily in the basic request processing flow. It includes an `IntentType` enum for classifying user requests.

32. `angela/interfaces/__init__.py`
    Initializes the 'angela.interfaces' sub-package. Defines abstract base classes for key components.

33. `angela/interfaces/execution.py`
    Defines Abstract Base Classes (ABCs) for execution components. Includes `CommandExecutor` for basic command execution and `AdaptiveExecutor` for context-aware execution.

34. `angela/interfaces/safety.py`
    Defines the Abstract Base Class (ABC) `SafetyValidator`. Specifies the contract for components responsible for checking command safety and validating operations.

35. `angela/monitoring/__init__.py`
    Initializes the 'angela.monitoring' sub-package for background monitoring. Exposes the main `background_monitor` instance.

36. `angela/monitoring/network_monitor.py`
    Defines the `NetworkMonitor` class to specifically track network connectivity, local service availability (via port checks), and project dependency updates. It runs asynchronous checks and generates proactive suggestions regarding network issues or available package updates.

37. `angela/review/diff_manager.py`
    Provides the `DiffManager` class for generating unified or HTML diffs between text strings, files, or entire directories. It also includes a method (`apply_diff`) to attempt applying a unified diff patch to original content.

38. `angela/review/feedback.py`
    Defines the `FeedbackManager` to process user feedback on generated or existing code. It uses AI (`_build_improvement_prompt`, `_extract_improved_code`) to generate refined code, can orchestrate refinement across multiple files (`refine_project`), and apply the resulting changes (`apply_refinements`).

39. `angela/safety/adaptive_confirmation.py`
    Implements the `get_adaptive_confirmation` function to dynamically decide whether user confirmation is needed before executing a command. It considers command risk, user preferences (`preferences_manager`), command history (`history_manager`), and offers interactive learning (`offer_command_learning`) to adjust trust levels.

40. `angela/safety/classifier.py`
    Provides `classify_command_risk` to categorize shell commands into risk levels (SAFE to CRITICAL) using predefined regex patterns (`RISK_PATTERNS`, `OVERRIDE_PATTERNS`). Includes `analyze_command_impact` to heuristically determine potential effects like file modifications or deletions.

41. `angela/shell/__init__.py`
    Initializes the 'angela.shell' sub-package containing shell integration scripts and formatting utilities. Imports and makes the `terminal_formatter` available.

42. `angela/shell/advanced_formatter.py`
    Provides extensions to the `TerminalFormatter` specifically for displaying complex `AdvancedTaskPlan` objects. It includes methods to render plans, execution results, step details, and errors using `rich` Tables and Trees.

43. `angela/toolchain/ci_cd.py`
    Implements the `CiCdIntegration` class to automatically generate basic CI/CD configuration files for various platforms (GitHub Actions, GitLab CI, Jenkins, etc.). It detects the project type and uses predefined templates or structures (like YAML/Jenkinsfile content) specific to the target platform and project language.

44. `angela/toolchain/git.py`
    Provides the `GitIntegration` class for interacting with Git repositories programmatically. It includes methods to initialize repositories (`init_repository`), stage files (`stage_files`), commit changes (`commit_changes`), create branches (`create_branch`), check status (`get_repository_status`), and generate `.gitignore` files.

45. `angela/toolchain/package_managers.py`
    Defines the `PackageManagerIntegration` class to interact with various language-specific package managers (pip, npm, yarn, poetry, cargo). It detects the appropriate manager based on project files (`detect_package_manager`) and provides a unified interface (`install_dependencies`) to install runtime and development dependencies.

46. `angela/utils/__init__.py`
    Initializes the 'angela.utils' sub-package containing utility functions. Exposes key utilities like the logging setup function.

47. `angela/utils/enhanced_logging.py`
    Defines an `EnhancedLogger` class intended for structured JSON logging with added context tracking. This logger doesn't appear to be actively used in the rest of the codebase, which primarily uses the Loguru setup from `logging.py`.

48. `angela/workflows/__init__.py`
    Initializes the 'angela.workflows' sub-package for managing reusable command sequences. Exposes the main `workflow_manager` instance.

49. `angela/workflows/sharing.py`
    Implements the `WorkflowSharingManager` to enable exporting workflows into packaged `.angela-workflow` zip files and importing them. It manages metadata (`WorkflowExportMetadata`), checksum verification for integrity, and interacts with the `WorkflowManager` to add imported workflows.

50. `MD/ImplemenationsMD/Phase_5_implementation.md`
    Contains Markdown documentation describing the integration and features implemented around Phase 5.5 of development. It details the initialization of features like project inference and network monitoring, and how components like error recovery and enhanced content analysis interact.

51. `MD/ImplemenationsMD/Phase_6_implementation.md`
    Contains Markdown documentation detailing the integration steps and code snippets for implementing Phase 6 features. It focuses on incorporating enhanced project context (enhancer, resolver, activity tracker, hooks) into the orchestrator and prompt system.

52. `MD/ImplemenationsMD/planner_implementation.md`
    Provides Markdown documentation explaining the design and usage of the Advanced Task Planner. It details the enhanced step types (CODE, API, LOOP, etc.), the data flow system, error handling mechanisms, and provides examples of creating and executing complex plans.

53. `MD/ImplemenationsMD/rollback_implementation.md`
    Contains Markdown documentation explaining the enhanced transaction-based rollback system. It describes how operations are grouped, how different operation types (filesystem, content, command) are reverted, and how users interact with the rollback functionality via the CLI.

54. `MD/MDHelpers/context.md`
    A helper Markdown file providing supplementary context and summaries for Python files not included directly in the main codebase package. It serves as a reference to understand the purpose and functionality of modules like `workflow/sharing.py`, `ai/parser.py`, etc.

55. `MD/MDHelpers/Info.md`
    A comprehensive Markdown document providing a high-level analysis of the Angela-CLI project's architecture, purpose, components, and workflows. It acts as an onboarding guide for understanding the codebase structure and core logic based on the provided files.

56. `MD/MDHelpers/tree.md`
    Contains a shell command (`tree`) intended to generate a textual representation of the project's directory structure. This helps visualize the file hierarchy, excluding common noise directories.

57. `MD/PhasesMD/Phase1.md`
    Documents the objectives, implementation details, and test results for Phase 1 (Foundation & Shell Integration) of the Angela-CLI project. It covers the initial project setup, configuration, basic CLI structure, shell hooks, and context management foundation.

58. `MD/PhasesMD/Phase2.md`
    Documents the objectives, implementation details, and test results for Phase 2 (AI Integration & Basic Suggestions). It details the integration of the Gemini API client, prompt engineering, response parsing, and the initial safe execution engine.

59. `MD/PhasesMD/Phase3.md`
    Documents the objectives, implementation details, and test results for Phase 3 (Safety System & File Operations). It covers the implementation of risk classification, command previews, impact analysis, permission checks, dry-run capabilities, file/directory operations, and basic rollback.

60. `MD/PhasesMD/Phase4.md`
    Documents the objectives and implementation details for Phase 4 (Intelligent Interaction & Contextual Execution), split into two parts. It covers enhancements like tolerant NLU, adaptive confirmation, session context, error analysis, and richer feedback mechanisms.

61. `MD/PhasesMD/Phase5.md`
    Documents the objectives and high-level implementation details for Phase 5 (Autonomous Task Orchestration & Proactive Assistance). It covers goal decomposition, content understanding, workflow management, and background monitoring.

62. `MD/PhasesMD/Phase6.md`
    Provides a Markdown guide detailing the implementation steps for Phase 6 (Enhanced Project Context). It outlines how to add new context modules (enhancer, resolver, activity tracker) and integrate them into the orchestrator and prompt system.

63. `MD/PhasesMD/Phase7.md`
    Documents the high-level objectives and components implemented in Phase 7 (Developer Tool Integration). It covers the advanced code generation engine, toolchain integration (Git, package managers, CI/CD), and interactive code review features.

64. `MD/Next-Steps.md`
    Presents a Principal Architect's audit report and strategic recommendations for the Angela-CLI project based on the codebase review. It identifies key areas for improvement, such as packaging, import resolution, consistency, modularity, integration completeness, and provides prioritized suggestions for stabilization and future development.

65. `scripts/install.sh`
    Provides a Bash script to automate the installation of the Angela CLI application. It installs the Python package using pip in editable mode and sets up the necessary shell integration hooks for Bash or Zsh.

66. `scripts/uninstall.sh`
    Provides a Bash script to cleanly uninstall the Angela CLI application. It removes the shell integration hooks from user configuration files (`.bashrc`/`.zshrc`) and optionally removes the configuration directory and the Python package.

67. `.env.example`
    Provides an example structure for the `.env` file. It lists necessary environment variables like `GEMINI_API_KEY` and optional ones like `DEBUG`.

68. `.gitignore`
    Configures Git to ignore specific files and patterns. In this case, it primarily ignores the `.env` file containing sensitive API keys.

69. `Makefile`
    Defines common development tasks like installation (`install`), testing (`test`), linting (`lint`), formatting (`format`), and cleaning (`clean`). It simplifies setting up the development environment (`dev-setup`) and running checks.

70. `pyproject.toml`
    Defines project metadata, build system requirements, and dependencies according to modern Python packaging standards (PEP 517/518). It specifies the project name, version, Python requirement (>=3.9), dependencies (like typer, rich, pydantic, google-generativeai), optional dev dependencies, and configurations for tools like black, isort, mypy, and pytest.

71. `pytest.ini`
    Configures the behavior of the pytest testing framework. Specifies asyncio mode (`strict`) and default fixture scope.

72. `requirements.txt`
    Lists the Python packages required for the project to run. It includes core libraries like `typer`, `rich`, `pydantic`, `google-generativeai`, `loguru`, and testing tools.

73. `setup.py`
    Provides a minimal `setup.py` for compatibility with older build systems or workflows. It primarily delegates the actual configuration to `pyproject.toml`.

74. `angela/ai/__init__.py`
    Initializes the 'angela.ai' sub-package, making AI-related components importable. Exports key classes and instances like `gemini_client`, `content_analyzer`, and `error_analyzer` for use by other modules.

75. `angela/context/file_detector.py`
    Provides the `detect_file_type` function to determine file characteristics like type (source code, image, etc.), language, MIME type, and binary status. It uses a combination of file extensions, filenames (`FILENAME_MAPPING`), shebang lines (`SHEBANG_PATTERNS`), and content analysis (binary checks) for accurate detection.

76. `angela/context/manager.py`
    Implements the `ContextManager`, the core provider of environmental context like the current working directory (CWD) and project root/type detection based on `PROJECT_MARKERS`. It also manages information about the currently focused file and provides cached access to file metadata and directory listings.

77. `angela/execution/error_recovery.py`
    Provides the `ErrorRecoveryManager` to intelligently handle failures during multi-step plan execution using `RecoveryStrategy` enums. It analyzes errors (using `error_analyzer`), generates recovery options (retry, modify, skip) via heuristics or AI, learns from past successes (`_recovery_history`), and supports both automatic and user-guided recovery.

78. `angela/generation/documentation.py`
    Defines the `DocumentationGenerator` for creating project documentation like READMEs, API docs, user guides, and contributing guides. It analyzes the project structure and content, potentially using AI (`_generate_file_docs_with_ai`, `_build_readme_prompt`) to generate comprehensive Markdown documentation.

79. `angela/generation/frameworks.py`
    Provides the `FrameworkGenerator` class with specialized methods (`_generate_react`, `_generate_django`, etc.) for creating standard project boilerplate for various frameworks. It uses predefined structures and AI (`_generate_content`) to generate framework-specific files and configurations, falling back to a generic AI-driven approach if needed.

80. `angela/intent/enhanced_task_planner.py`
    Defines the `EnhancedTaskPlanner` which extends the basic planner to execute `AdvancedTaskPlan` objects containing complex steps like code execution, API calls, loops, and conditional decisions. It manages a `StepExecutionContext` for data flow between steps using variable substitution and includes robust error handling integrated with the `ErrorRecoveryManager`.

81. `angela/review/__init__.py`
    Initializes the 'angela.review' sub-package containing code review related functionalities. Exposes the `diff_manager` and `feedback_manager` instances.

82. `angela/safety/__init__.py`
    Initializes the 'angela.safety' sub-package, consolidating safety-related components. It registers key functions like `check_command_safety` and `validate_command_safety` with the core service registry.

83. `angela/safety/confirmation.py`
    Implements the core user confirmation logic (`get_confirmation`, `requires_confirmation`) using the `rich` library. It displays command details, risk level, impact analysis (`format_impact_analysis`), and previews before prompting the user with `rich.Confirm`. (Largely wrapped by `adaptive_confirmation`).

84. `angela/safety/preview.py`
    Defines the `generate_preview` function and specific previewers (e.g., `preview_rm`, `preview_ls`, `preview_cp`) registered in `PREVIEWABLE_COMMANDS`. It analyzes command arguments and file system state to predict and describe the likely outcome of commands without executing them, using `--dry-run` flags as a fallback.

85. `angela/safety/validator.py`
    Provides functions (`validate_command_safety`, `validate_operation`) to enforce safety policies before execution. It checks commands against `DANGEROUS_PATTERNS`, verifies superuser requirements (`requires_superuser`), and validates file permissions using `os.access`.

86. `angela/shell/angela.zsh`
    Defines the `angela` zsh function providing the shell integration for Zsh users. Its logic mirrors `angela.bash`, capturing user input and invoking the main Python application.

87. `angela/toolchain/__init__.py`
    Initializes the 'angela.toolchain' sub-package, grouping integrations with developer tools. Makes tool integration instances available.

88. `angela/__main__.py`
    Acts as the main executable entry point when running the package with `python -m angela`. It initializes the application using `init_application` and then starts the command-line interface defined in `angela.cli.app`.

89. `angela/config.py`
    Manages application configuration using Pydantic models, loading settings from environment variables (`.env`) and a TOML file (`config.toml`). It provides a global `config_manager` instance for accessing settings like API keys and debug mode throughout the application.

90. `angela/constants.py`
    Defines global constants used throughout the application. Includes application metadata (name, version), file paths (config, logs), API settings (model name, defaults), and safety definitions (risk levels, confirmation requirements).

91. `angela/ai/client.py`
    Implements the `GeminiClient` class to manage interactions with the Google Gemini API, handling request structuring (`GeminiRequest`) and response parsing (`GeminiResponse`). It uses the configured API key and model constants to asynchronously send prompts and receive generated text via the `google-generativeai` library.

92. `angela/ai/content_analyzer.py`
    Defines the base `ContentAnalyzer` class for AI-powered understanding and manipulation of file content. It provides asynchronous methods to analyze, summarize, search within, and modify file text using prompts tailored to file type and user requests, interacting with the `gemini_client`.

93. `angela/context/__init__.py`
    Initializes the 'angela.context' package, making core managers like `context_manager`, `session_manager`, and `history_manager` easily importable. It also schedules the background initialization of project inference via `initialize_project_inference` for improved context awareness.

94. `angela/execution/rollback.py`
    Implements the enhanced `RollbackManager` using `OperationRecord` and `Transaction` models to track filesystem changes, content manipulations (via diffs), and command executions (with compensating actions). It persists history to JSON, manages transaction lifecycles, and provides methods to roll back individual operations or entire transactions.

95. `angela/intent/planner.py`
    Defines core planning models like `PlanStep`, `TaskPlan`, `AdvancedPlanStep`, `AdvancedTaskPlan`, and the `PlanStepType` enum. It includes the base `TaskPlanner` class responsible for generating basic sequential plans or triggering advanced plan generation based on request complexity.

96. `angela/monitoring/background.py`
    Implements the `BackgroundMonitor` class to manage various background monitoring tasks using `asyncio`. It periodically checks Git status, file changes (triggering syntax/lint checks), and system resources, providing proactive suggestions via `terminal_formatter` while managing cooldowns.

97. `angela/shell/angela.bash`
    Defines the `angela` bash function which acts as the primary user interface hook for Bash shells. It handles argument parsing for global flags like `--debug` and routes the user's request to the Python backend (`python -m angela request ...`).

98. `angela/shell/formatter.py`
    Defines the `TerminalFormatter` class using the `rich` library to provide styled and structured console output for various events like commands, results, errors, plans, and suggestions. It supports different output types (`OutputType` enum) and asynchronous streaming (`stream_output`) for real-time feedback.

99. `angela/execution/engine.py`
    Implements the core `ExecutionEngine` for running shell commands asynchronously using `asyncio.create_subprocess_exec`. It captures stdout, stderr, return codes, and records successful operations with the `RollbackManager` via the service registry.

100. `angela/workflows/manager.py`
    Implements the `WorkflowManager` class, using `Workflow` and `WorkflowStep` models, to manage user-defined workflows stored in `workflows.json`. It handles creation (interactively or from natural language via AI), listing, searching, deletion, and execution of workflows, including variable substitution.

101. `angela/generation/engine.py`
    Implements the `CodeGenerationEngine` along with `CodeFile` and `CodeProject` models to manage the generation of entire projects or adding features to existing ones based on descriptions. It plans the structure (`_create_project_plan`), generates content for multiple files in dependency order (`_generate_file_contents`, `_get_ordered_files`), validates the output, and creates the files on disk.

102. `angela/cli/generation.py`
    Defines Typer commands for code generation tasks, such as creating new projects (`create-project`), adding features (`add-feature`), and refining code based on feedback (`refine-code`, `refine-project`). It orchestrates interactions with the `CodeGenerationEngine`, `FeedbackManager`, `GitIntegration`, `PackageManagerIntegration`, `TestFrameworkIntegration`, and `CiCdIntegration` modules to fulfill user generation requests.

103. `angela/cli/workflows.py`
    Implements the command-line interface for managing Angela workflows (`list`, `create`, `run`, `delete`, `show`, `export`, `import`) using Typer and Rich. It interacts with the `WorkflowManager` for core logic and the `WorkflowSharingManager` for import/export functionality, handling user input and variable substitution.

104. `angela/cli/main.py`
    Defines the main Typer application entry point, handling global options like `--debug` and `--version`, and registering primary commands like `request`, `init`, `status`, and `shell`. The crucial `request` command delegates natural language processing to the `Orchestrator`, while `shell` provides an interactive loop.

105. `angela/orchestrator.py`
    Acts as the central coordinator, receiving user requests, determining the request type (`RequestType` enum), and dispatching tasks to appropriate modules (AI client, planners, execution engines, context managers, safety checkers). It integrates enhanced context, file resolution, adaptive execution, workflow management, code generation, and error handling to process user inputs effectively.
</file>

<file path="MD/MDHelpers/Info.md">
**AI Terminal Coder: Project Analysis**

This document provides a comprehensive analysis of the "AI Terminal Coder" project, based strictly on the provided codebase and directory structure. It aims to explain the project's architecture, components, logic, and workflows to a technical individual new to this codebase.

**1. High-Level Project Architecture & Purpose**

*   **Overall Goal & Purpose (Based on Code):**
    The primary goal derived from the code is to create a sophisticated command-line interface (CLI) application named "Angela" that acts as an AI-powered assistant. It interprets natural language user requests, translates them into executable plans (ranging from single shell commands to complex multi-step workflows involving code execution, API calls, and file operations), executes these plans safely within the user's terminal environment, and manages the context of the interaction. Key aspects include safety checks, user confirmation for risky operations, error recovery, context management (history, preferences, project structure), and integration with external tools like Git and package managers.

*   **Core Functionalities & Capabilities:**
    *   **Natural Language Processing:** Interprets user requests using an AI model (Google Gemini).
    *   **Command Generation & Execution:** Translates requests into shell commands and executes them via `execution/engine.py` and `execution/adaptive_engine.py`.
    *   **Task Planning:** Decomposes complex requests into multi-step plans (`intent/planner.py`, `intent/enhanced_task_planner.py`). Supports basic sequential plans and advanced plans with dependencies, conditions, loops, code execution, and API calls.
    *   **Context Management:** Maintains awareness of the current working directory, Git project root/type, command history, user preferences, and session state (`context/`). Includes advanced context enhancement (`context/enhancer.py`) using project inference (`context/project_inference.py`), file activity tracking (`context/file_activity.py`), and reference resolution (`context/file_resolver.py`).
    *   **Safety & Confirmation:** Classifies command risk (`safety/classifier.py`), validates operations (`safety/validator.py`), and uses an adaptive confirmation system based on risk and user history/preferences (`safety/adaptive_confirmation.py`). Includes command previews (`safety/preview.py`).
    *   **File System Operations:** Provides an abstraction layer for safe file/directory operations (create, read, write, delete, copy, move) with rollback capability (`execution/filesystem.py`, `execution/rollback.py`).
    *   **Code Generation & Manipulation:** Generates project structures, code files for various frameworks (`generation/`), documentation (`generation/documentation.py`), and refines code based on feedback (`review/feedback.py`). Includes code validation (`generation/validators.py`).
    *   **Rollback:** Supports undoing operations and entire transactions (`execution/rollback.py`, `execution/rollback_commands.py`).
    *   **Workflow Management:** Allows users to define, save, execute, import, and export reusable command sequences (`workflows/`).
    *   **Toolchain Integration:** Interacts with Git (`toolchain/git.py`), package managers (`toolchain/package_managers.py`), and CI/CD systems (`toolchain/ci_cd.py`).
    *   **Monitoring:** Includes modules for background monitoring of network and system status (`monitoring/`).
    *   **Rich CLI:** Provides a user-friendly interface using Typer and Rich (`cli/`, `shell/`).

*   **Architectural Pattern(s):**
    The architecture is best described as a **Modular Monolith**. While it's a single application, it's clearly divided into distinct functional modules (`ai`, `context`, `execution`, `safety`, `generation`, `intent`, `toolchain`, etc.) with relatively well-defined responsibilities.
    *   **Layered:** There's a clear layering: CLI -> Orchestrator -> Intent/Planning -> Execution/AI -> System Interaction.
    *   **Service Locator:** The `core/registry.py` acts as a simple service locator pattern to decouple components and manage dependencies (e.g., accessing `rollback_manager` or `execution_engine` without direct imports everywhere).
    *   **Component-Based:** Each directory under `angela/` represents a major component.
    *   **Event-Driven (Conceptual):** User input triggers a processing pipeline, but it doesn't use a formal event bus/queue system.
    *   **Orchestration:** The `Orchestrator` class plays a central role in coordinating the flow between different modules.

*   **Key Technology Choices:**
    *   **Language:** Python (>=3.9, based on `pyproject.toml`)
    *   **AI Model:** Google Gemini (via `google-generativeai` library)
    *   **CLI Framework:** Typer
    *   **Rich Terminal UI:** Rich
    *   **Data Validation/Modeling:** Pydantic
    *   **Asynchronous Programming:** `asyncio` is used extensively for I/O-bound tasks (API calls, command execution).
    *   **Configuration:** TOML (`config.toml`), `.env` files (via `python-dotenv`)
    *   **Logging:** Loguru
    *   **Shell Integration:** Custom Bash and Zsh scripts.
    *   **HTTP Client:** `aiohttp` (for API steps in advanced planner)
    *   **Build/Package:** Setuptools, Pip, Make (`Makefile`)
    *   **Testing:** Pytest, pytest-asyncio

**2. Directory and File Structure Breakdown**

*   **(Root Directory)**
    *   **Purpose:** Contains the main project configuration, documentation, scripts, and the core `angela` package.
    *   **Files:** `.env.example`, `.gitignore`, `Makefile`, `pyproject.toml`, `pytest.ini`, `README.md`, `requirements.txt`, `setup.py`.
    *   **Subdirectories:** `angela/`, `integrations/`, `MD/`, `scripts/`, `tests/` (implicitly, though excluded).

*   **`angela/`**
    *   **Purpose:** The main Python package containing all the application's source code.
    *   **Files:** `__init__.py` (initializes application), `__main__.py` (main entry point), `config.py`, `constants.py`, `orchestrator.py`.
    *   **Subdirectories:** `ai/`, `cli/`, `context/`, `core/`, `execution/`, `generation/`, `intent/`, `interfaces/`, `monitoring/`, `review/`, `safety/`, `shell/`, `toolchain/`, `utils/`, `workflows/`.

*   **`angela/ai/`**
    *   **Purpose:** Handles all interactions with the AI model (Gemini), including prompt engineering, API calls, response parsing, intent analysis, and content analysis.
    *   **Files:**
        *   `__init__.py`: Package initializer.
        *   `analyzer.py`: (`ErrorAnalyzer`) Analyzes command errors, suggests fixes by matching patterns and checking command/file structure.
        *   `client.py`: (`GeminiClient`) Manages communication with the Google Gemini API, handles requests and responses.
        *   `confidence.py`: (`ConfidenceScorer`) Scores the AI's confidence in command suggestions based on history, complexity, and entity matching.
        *   `content_analyzer.py`: (`ContentAnalyzer`) Base class for understanding and manipulating file content using AI.
        *   `content_analyzer_extensions.py`: (`EnhancedContentAnalyzer`) Extends `ContentAnalyzer` with support for specific languages (TS, JSON, etc.) and file types. Routes analysis to specialized handlers.
        *   `file_integration.py`: Extracts file system operations (mkdir, rm, cp, mv, etc.) from command strings and provides functions to execute them via the `execution/filesystem.py` module.
        *   `intent_analyzer.py`: (`IntentAnalyzer`, `IntentAnalysisResult`) Performs enhanced Natural Language Understanding (NLU) on user requests, normalizes input, handles ambiguity, and extracts entities. Uses fuzzy matching.
        *   `parser.py`: (`CommandSuggestion`, `parse_ai_response`) Parses JSON responses from the AI into structured `CommandSuggestion` objects. Includes fallback logic.
        *   `prompts.py`: Centralizes prompt engineering. Contains templates and functions (`build_prompt`, `build_file_operation_prompt`, etc.) to construct detailed prompts for the AI, incorporating context (project info, history, file activity, etc.).

*   **`angela/cli/`**
    *   **Purpose:** Defines the command-line interface using Typer, handling user commands and arguments.
    *   **Files:**
        *   `__init__.py`: Initializes the CLI sub-package and registers subcommands.
        *   `files.py`: Defines file system operation commands (`ls`, `mkdir`, `rm`, `cp`, `mv`, `cat`, `write`, `find`, `info`) using `rich` for output and interacting with `execution/filesystem.py` and `context/manager.py`. Includes `rollback` command integration.
        *   `files_extensions.py`: Extends `files.py` with advanced commands (`resolve`, `extract`, `recent`, `active`, `project`) interacting with `context/file_resolver.py`, `context/file_activity.py`, and `context/enhancer.py`.
        *   `generation.py`: Defines CLI commands for code generation (`create-project`, `add-feature`, `refine-code`, `refine-project`, `generate-ci`, `generate-tests`) interacting with `generation/` and `toolchain/` modules.
        *   `main.py`: The main entry point for the Typer application. Defines the root command, global options (`--debug`, `--version`, `--monitor`), and the `request` command, which delegates processing to the `Orchestrator`. Also includes `init` and `status` commands.
        *   `workflows.py`: Defines CLI commands for managing workflows (`list`, `create`, `run`, `delete`, `show`, `export`, `import`) interacting with `workflows/manager.py` and `workflows/sharing.py`.

*   **`angela/context/`**
    *   **Purpose:** Manages the application's understanding of the user's environment, project state, history, and preferences.
    *   **Files:**
        *   `__init__.py`: Initializes the context package, exposes key components, and sets up background project inference.
        *   `enhancer.py`: (`ContextEnhancer`) Enriches the basic context with detailed project info (type, frameworks, dependencies, structure), recent file activity, and file references using other context modules. Includes caching.
        *   `file_activity.py`: (`ActivityType`, `FileActivity`, `FileActivityTracker`) Tracks file system events (create, modify, delete, view), stores activity history, and integrates with the session manager.
        *   `file_detector.py`: (`detect_file_type`, `get_content_preview`) Detects file types and programming languages based on extension, name, MIME type, and content (including shebangs). Provides content previews.
        *   `file_resolver.py`: (`FileResolver`) Resolves potentially ambiguous file references from natural language using exact paths, fuzzy matching, recent files, and context awareness. Extracts references from text.
        *   `history.py`: (`CommandRecord`, `CommandPattern`, `HistoryManager`) Manages command execution history (success/failure, output, errors), calculates command frequency/success rates, and identifies error/fix patterns. Persists history to JSON.
        *   `manager.py`: (`ContextManager`) Core context provider. Tracks CWD, detects project root/type using markers, manages current file context, provides directory listings and file info lookups. Caches file info.
        *   `preferences.py`: (`TrustPreferences`, `UIPreferences`, `ContextPreferences`, `UserPreferences`, `PreferencesManager`) Manages user settings (trust levels, auto-execution, UI behavior, history limits) stored in `preferences.json`.
        *   `project_inference.py`: (`ProjectInference`) Performs deep analysis of project directories to infer type, frameworks, dependencies, important files, and structure. Caches results.
        *   `session.py`: (`EntityReference`, `SessionMemory`, `SessionManager`) Manages short-term conversational memory, tracking entities (files, commands, results) mentioned or used within a session. Handles session expiration.

*   **`angela/core/`**
    *   **Purpose:** Provides core application utilities, like the service registry.
    *   **Files:**
        *   `__init__.py`: Package initializer.
        *   `registry.py`: (`ServiceRegistry`, `registry`) Implements a simple singleton service locator pattern to break circular dependencies between modules by allowing registration and retrieval of services by name.

*   **`angela/execution/`**
    *   **Purpose:** Handles the execution of shell commands and file system operations, including safety checks, rollback, and error recovery.
    *   **Files:**
        *   `__init__.py`: Package initializer.
        *   `adaptive_engine.py`: (`AdaptiveExecutionEngine`) Orchestrates command execution with context-awareness. Integrates risk classification, adaptive confirmation, feedback, history logging, and error analysis/recovery.
        *   `engine.py`: (`ExecutionEngine`) Core engine for running shell commands using `asyncio.create_subprocess_exec`. Captures stdout, stderr, and return code. Records successful operations for rollback.
        *   `error_recovery.py`: (`RecoveryStrategy`, `ErrorRecoveryManager`) Manages error recovery for multi-step plans. Analyzes errors, generates recovery strategies (retry, modify, alternative, etc.) using AI or predefined patterns, and handles guided/automatic recovery.
        *   `filesystem.py`: (`FileSystemError`, `_ensure_backup_dir`, `create_directory`, etc.) Provides high-level, safe functions for common file system operations (create, delete, read, write, copy, move). Includes safety checks and backup creation for rollback.
        *   `hooks.py`: (`ExecutionHooks`) Defines pre- and post-execution hooks for commands and file operations. Used to track file activities via `file_activity_tracker` based on command execution/output or direct file operations.
        *   `rollback.py`: (`OperationRecord`, `Transaction`, `RollbackManager`) Implements the enhanced, transaction-based rollback system. Records various operation types (filesystem, content, command, plan) with necessary undo information (backups, diffs, compensating actions). Manages transaction lifecycle and performs rollback of individual operations or entire transactions.
        *   `rollback_commands.py`: Defines CLI commands (`list`, `operation`, `transaction`, `last`) for interacting with the `RollbackManager`.

*   **`angela/generation/`**
    *   **Purpose:** Contains modules responsible for generating code, project structures, documentation, and related artifacts.
    *   **Files:**
        *   `__init__.py`: Package initializer.
        *   `architecture.py`: (`ArchitecturalPattern`, `AntiPattern`, `MvcPattern`, etc., `ArchitecturalAnalyzer`) Analyzes project architecture, detects patterns (like MVC) and anti-patterns (like Single Responsibility Violation, God Object), and suggests improvements using heuristics and AI.
        *   `documentation.py`: (`DocumentationGenerator`) Generates project documentation like READMEs, API docs (basic structure, relies on AI for details), user guides, and CONTRIBUTING guides using AI based on project analysis.
        *   `engine.py`: (`CodeFile`, `CodeProject`, `CodeGenerationEngine`) Core engine for generating multi-file code projects. Plans project structure (`_create_project_plan`), generates content for each file (`_generate_file_contents`) potentially using AI, manages dependencies, and creates the actual files. Also handles adding features to existing projects.
        *   `frameworks.py`: (`FrameworkGenerator`) Provides specialized generators for creating boilerplate project structures for specific frameworks (React, Next.js, Django, Flask, Spring, Express, FastAPI, Vue, Angular). Uses AI (`_generate_content`) for file content. Includes a generic fallback.
        *   `planner.py`: (`ProjectPlanner`, `ArchitectureComponent`, `ProjectArchitecture`) Focuses on planning the high-level architecture and structure of a *new* project before code generation begins, interacting with AI to design components and their relationships. (Note: Distinct from `intent/planner.py` which plans *tasks*).
        *   `validators.py`: (`validate_code`, `validate_python`, etc.) Provides functions to validate the syntax and basic correctness of generated code for various languages using external tools (like `py_compile`, `node --check`, `tsc`, `javac`) or basic checks.

*   **`angela/intent/`**
    *   **Purpose:** Deals with understanding user intent and planning sequences of actions to fulfill that intent.
    *   **Files:**
        *   `__init__.py`: Package initializer.
        *   `enhanced_task_planner.py`: (`StepExecutionContext`, `DataFlowVariable`, `ExecutionResult`, `EnhancedTaskPlanner`) Extends `TaskPlanner` to execute advanced plans. Manages complex step types (CODE, API, LOOP, DECISION), handles data flow between steps using variables, integrates error recovery, and includes secure code execution sandboxing.
        *   `models.py`: (`IntentType`, `Intent`, `ActionPlan`) Defines Pydantic models for representing user intent and basic action plans (primarily used by older/simpler parts of the system).
        *   `planner.py`: (`PlanStep`, `TaskPlan`, `PlanStepType`, `AdvancedPlanStep`, `AdvancedTaskPlan`, `TaskPlanner`) Core task planning module. Determines task complexity, generates basic (`TaskPlan`) or advanced (`AdvancedTaskPlan`) plans using AI, and provides basic plan execution logic. The `EnhancedTaskPlanner` inherits/replaces parts of this.

*   **`angela/interfaces/`**
    *   **Purpose:** Defines Abstract Base Classes (ABCs) to enforce contracts for key components, promoting modularity.
    *   **Files:**
        *   `__init__.py`: Package initializer.
        *   `execution.py`: (`CommandExecutor`, `AdaptiveExecutor`) Defines interfaces for command execution components.
        *   `safety.py`: (`SafetyValidator`) Defines interfaces for safety validation components.

*   **`angela/monitoring/`**
    *   **Purpose:** Implements background monitoring capabilities for proactive assistance.
    *   **Files:**
        *   `__init__.py`: Package initializer, exposes `background_monitor`.
        *   `background.py`: (`BackgroundMonitor`) Orchestrates various background monitoring tasks (Git status, file changes, system resources). Manages suggestions and cooldowns.
        *   `network_monitor.py`: (`NetworkMonitor`) Specifically monitors network status, local services (ports), external APIs, and dependency updates. Provides network-related suggestions.

*   **`angela/review/`**
    *   **Purpose:** Handles code review aspects, including diff generation and processing user feedback.
    *   **Files:**
        *   `__init__.py`: Package initializer.
        *   `diff_manager.py`: (`DiffManager`) Generates unified and HTML diffs between strings or files. Can also apply diffs (though potentially simplified). Handles directory diffs.
        *   `feedback_manager.py`: (`FeedbackManager`) Processes user feedback on code. Uses AI to generate improved code based on feedback, generates diffs, and can apply refinements to single files or entire projects.

*   **`angela/safety/`**
    *   **Purpose:** Enforces safety constraints, classifies risk, and manages user confirmations.
    *   **Files:**
        *   `__init__.py`: Package initializer, registers safety functions with the core registry.
        *   `adaptive_confirmation.py`: (`get_adaptive_confirmation`, `offer_command_learning`) Implements the context-aware confirmation logic. Decides whether to prompt the user based on risk level, preferences, and command history. Handles different confirmation UI levels (simple vs. detailed). Offers to trust commands after successful high-risk executions.
        *   `classifier.py`: (`classify_command_risk`, `analyze_command_impact`) Classifies command risk based on predefined regex patterns (critical, high, medium, low, safe). Analyzes potential command impact (affected files, operations, destructive nature).
        *   `confirmation.py`: (`requires_confirmation`, `format_impact_analysis`, `get_confirmation`) Provides the core user confirmation UI logic using `rich` and `prompt_toolkit`. Displays command, risk, impact, and preview before asking for confirmation. (Note: Largely superseded/wrapped by `adaptive_confirmation.py`).
        *   `preview.py`: (`generate_preview`, `preview_mkdir`, etc.) Generates previews of what specific commands (`ls`, `rm`, `cp`, `mv`, etc.) are likely to do by analyzing arguments and checking the file system. Includes a generic fallback using `--dry-run` flags where possible.
        *   `validator.py`: (`ValidationError`, `validate_command_safety`, `requires_superuser`, etc.) Performs stricter validation checks against dangerous patterns (e.g., `rm -rf /`, `chmod 777`), checks for required superuser privileges, and validates file permissions for operations.

*   **`angela/shell/`**
    *   **Purpose:** Contains shell integration scripts and terminal formatting logic.
    *   **Files:**
        *   `__init__.py`: Package initializer, imports formatters.
        *   `advanced_formatter.py`: Extends `TerminalFormatter` with methods specifically for displaying advanced task plans (`display_advanced_plan`), execution results (`display_execution_results`), step details, and step errors using `rich` components like Tables and Trees.
        *   `angela.bash`: Bash shell integration script. Defines the `angela` function, handles flags (`--debug`, `--version`, `--help`), and routes commands/requests to the Python backend (`python -m angela ...`).
        *   `angela.zsh`: Zsh shell integration script (similar functionality to `angela.bash`).
        *   `formatter.py`: (`OutputType`, `TerminalFormatter`) Core terminal output formatting class using `rich`. Provides methods for printing commands, outputs (stdout, stderr, info, errors), error analysis, task plans, workflows, file analysis/manipulation results, and suggestions with appropriate styling and syntax highlighting. Includes async output streaming.

*   **`angela/toolchain/`**
    *   **Purpose:** Integrates with common developer tools like Git, package managers, and CI/CD systems.
    *   **Files:**
        *   `__init__.py`: Package initializer.
        *   `ci_cd.py`: (`CiCdIntegration`) Detects project type and generates basic CI/CD configuration files (`.github/workflows/`, `.gitlab-ci.yml`, `Jenkinsfile`, `.travis.yml`, `.circleci/config.yml`) based on project type and platform.
        *   `git.py`: (`GitIntegration`) Provides functions for interacting with Git repositories (init, stage, commit, branch creation, status checking). Includes `.gitignore` generation.
        *   `package_managers.py`: (`PackageManagerIntegration`) Detects and interacts with package managers (pip, npm, yarn, poetry, cargo) to install project dependencies.

*   **`angela/utils/`**
    *   **Purpose:** Contains utility functions, primarily logging setup.
    *   **Files:**
        *   `__init__.py`: Package initializer, exposes logging functions.
        *   `logging.py`: (`setup_logging`, `get_logger`) Configures application-wide logging using Loguru, setting up console and file handlers with specified formats and rotation.

*   **`angela/workflows/`**
    *   **Purpose:** Manages user-defined, reusable sequences of commands (workflows).
    *   **Files:**
        *   `__init__.py`: Package initializer, exposes `workflow_manager`.
        *   `manager.py`: (`WorkflowStep`, `Workflow`, `WorkflowManager`) Defines workflow models. Manages loading, saving, creating (interactively or from natural language via AI), listing, searching, deleting, and executing workflows. Persists workflows to JSON. Handles variable substitution during execution.
        *   `sharing.py`: (`WorkflowExportMetadata`, `WorkflowSharingManager`) Handles exporting workflows to shareable package files (`.angela-workflow` zip archives containing metadata and workflow data) and importing them. Includes checksum verification.

*   **`integrations/`**
    *   **Purpose:** Contains integration code, potentially for specific phases or external systems. (Note: The content provided suggests these might be for orchestrating features added in specific development phases or integrating the enhanced planner).
    *   **Files:**
        *   `__init__.py`: Package initializer, appears to call `init_application`.
        *   `enhanced_planner_integration.py`: *Crucial integration point*. Patches the `Orchestrator._process_multi_step_request` method to use the `EnhancedTaskPlanner`. Adds helper methods to the Orchestrator for handling advanced plan execution, display, confirmation, and variable extraction. Ensures the advanced planner is used for complex tasks.
        *   `integrations5.py`: (`PhaseIntegration`) Seems designed to initialize and manage features introduced around Phase 5/5.5 (Project Inference, Network Monitoring, Error Recovery, Enhanced Content Analysis). Provides status checks and context gathering related to these features.
        *   `integrations6.py`: Appears to contain *code snippets* and instructions for integrating Phase 6 features (Context Enhancer, File Resolver, File Activity, Execution Hooks) into the existing codebase, particularly updating the `Orchestrator` and `prompts.py`.

*   **`MD/`**
    *   **Purpose:** Contains Markdown documentation files describing the project, its phases, and specific features like the planner and rollback system.
    *   **Files:** `Info.md`, `NextSteps.md`, `Phase[1-7].md`, `context.md`, `planner_implementation.md`, `planner.py` (duplicate?), `rollback.md`, `tree.md`.

*   **`scripts/`**
    *   **Purpose:** Contains shell scripts for installation and uninstallation.
    *   **Files:** `install.sh`, `uninstall.sh`.

**3. Core Logic & Data Flow ("The Flow Explanation")**

*   **Application Initiation:**
    1.  The user types `angela <command> <args>` in their terminal.
    2.  The shell integration (`angela.bash` or `angela.zsh`) captures this.
    3.  It executes `python -m angela <command> <args>`.
    4.  `angela/__main__.py` runs.
    5.  `angela.init_application()` is called (from `angela/__init__.py`). This registers services (like `execution_engine`, `orchestrator`, `rollback_manager`) with the `core/registry.py` and crucially applies the `enhanced_planner_integration` patch.
    6.  The Typer app (`angela/cli/main.py:app`) is invoked.
    7.  Typer parses the command and arguments.
    8.  If it's the `request` command, `cli/main.py:request` function is called.
    9.  This function calls `orchestrator.process_request(...)`.

*   **Use Case 1: User asks AI to code a Python script (`angela generate create-project "simple flask api" --project-type python`)**
    1.  **Input:** CLI parses the command (`generate create-project`) and arguments. `cli/generation.py:create_project` is called.
    2.  **Processing:** `create_project` calls `generation/engine.py:code_generation_engine.generate_project`.
    3.  **Planning:** `generate_project` calls `_create_project_plan`. This involves:
        *   Determining project type (`python`).
        *   Building a prompt (`_build_project_planning_prompt`) describing the request and project type.
        *   Calling Gemini API (`ai/client.py`).
        *   Parsing the response (`_parse_project_plan`) into a `CodeProject` object (a list of `CodeFile` objects with paths and purposes, but empty content initially).
    4.  **Content Generation:** `generate_project` then calls `_generate_file_contents`. This iterates through the planned `CodeFile` objects (potentially in batches based on dependencies):
        *   For each file, it builds a specific prompt (`_build_file_content_prompt`) including file path, purpose, project context, and potentially content of dependency files already generated.
        *   Calls Gemini API (`ai/client.py`) for each file's content.
        *   Extracts the code (`_extract_code_from_response`).
        *   Validates the code (`generation/validators.py`). If invalid, it might attempt a fix using another AI call.
        *   Stores the generated content in the `CodeFile` object within the `CodeProject`.
    5.  **File Creation:** `create_project` (if not `--dry-run`) calls `code_generation_engine.create_project_files`.
        *   This function iterates through the `CodeFile` objects in dependency order (`_get_ordered_files`).
        *   It uses `execution/filesystem.py:create_directory` and `execution/filesystem.py:write_file` to create the actual directory structure and write the generated content to disk.
    6.  **Toolchain (Optional):** `create_project` might call `toolchain/git.py:git_integration.init_repository`, `toolchain/package_managers.py:package_manager_integration.install_dependencies`, etc., based on flags.
    7.  **Output:** Confirmation messages are printed to the console via `rich`.

*   **Use Case 2: User asks AI to deploy a web app (`angela request "deploy the project in staging"`)**
    1.  **Input:** `cli/main.py:request` gets the request string.
    2.  **Orchestration:** `orchestrator.process_request` is called.
    3.  **Context:** `ContextManager` provides CWD, project info. `ContextEnhancer` adds details. `SessionManager` provides conversation history. `FileResolver` looks for file mentions (likely none here).
    4.  **Request Type:** `_determine_request_type` likely identifies this as `MULTI_STEP` due to complexity.
    5.  **Planning:** `_process_multi_step_request` (patched by `enhanced_planner_integration.py`) is called.
        *   It calls `task_planner.plan_task` (which is actually `EnhancedTaskPlanner`).
        *   `plan_task` determines complexity (`advanced`).
        *   It builds a planning prompt (`_build_advanced_planning_prompt`) including the goal and context.
        *   Calls Gemini API (`ai/client.py`).
        *   Parses the response (`_parse_advanced_plan_response`) into an `AdvancedTaskPlan` object containing steps (likely `COMMAND` type for git, ssh, docker etc.).
    6.  **Confirmation:** The plan is displayed (`advanced_formatter.py:display_advanced_plan`). User confirmation is sought (`_confirm_advanced_plan`).
    7.  **Execution:** If confirmed, `task_planner.execute_plan` (actually `EnhancedTaskPlanner.execute_advanced_plan`) runs the `AdvancedTaskPlan`.
        *   It iterates through steps based on dependencies and `entry_points`.
        *   For each `COMMAND` step, `_execute_command_step` calls `execution/engine.py` to run the command (e.g., `git push`, `ssh server 'docker restart container'`).
        *   Results (stdout, stderr, success) are stored. Variables might be set/read.
        *   Error recovery (`error_recovery.py`) is triggered if a step fails.
        *   Rollback information is recorded (`rollback.py`).
    8.  **Output:** Execution results are displayed (`advanced_formatter.py:display_execution_results`).

*   **Use Case 3: User asks AI to organize files (`angela request "find all .log files in ~/logs older than 7 days and move them to ~/old_logs"`)**
    1.  **Input:** `cli/main.py:request`.
    2.  **Orchestration:** `orchestrator.process_request`.
    3.  **Context:** CWD, project info, etc. `FileResolver` identifies paths `~/logs`, `~/old_logs`.
    4.  **Request Type:** Likely `MULTI_STEP`.
    5.  **Planning:** `_process_multi_step_request` -> `task_planner.plan_task`.
        *   AI generates a plan (likely `AdvancedTaskPlan`). Steps might include:
            *   A `COMMAND` step: `find ~/logs -name '*.log' -type f -mtime +7 -print0` (or similar, maybe using Python code). Output saved to a variable (e.g., `found_files`).
            *   A `COMMAND` or `FILE` step: `mkdir -p ~/old_logs`.
            *   A `LOOP` step iterating over `found_files`. Loop body contains a `COMMAND` or `FILE` step: `mv ${loop_item} ~/old_logs`.
    6.  **Confirmation:** Plan displayed, user confirms.
    7.  **Execution:** `EnhancedTaskPlanner.execute_advanced_plan` runs the plan.
        *   Executes `find` command, stores output in `found_files` variable.
        *   Executes `mkdir`.
        *   Enters `LOOP` step. `_execute_loop_step` iterates:
            *   For each item (`${loop_item}`), executes `mv` command (`_execute_command_step`).
        *   Error recovery and rollback are active.
    8.  **Output:** Execution results displayed.

*   **Central Data Structures / State Management:**
    *   `context/manager.py:ContextManager`: Holds CWD, project root/type, current file. Refreshed per request.
    *   `context/session.py:SessionManager`: Holds `SessionMemory` (entities, recent commands/results) for conversational context. Persists between requests within a timeout period.
    *   `context/history.py:HistoryManager`: Persists long-term command history (`CommandRecord`) and derived patterns (`CommandPattern`) to JSON files.
    *   `context/preferences.py:PreferencesManager`: Loads/saves user preferences (`UserPreferences` model) from JSON.
    *   `intent/enhanced_task_planner.py:EnhancedTaskPlanner._variables`: Dictionary holding `DataFlowVariable` objects during the execution of an *advanced* plan. Used to pass data between steps.
    *   `execution/rollback.py:RollbackManager`: Stores `OperationRecord` objects (in memory, loaded from JSON) and `Transaction` objects (in memory/JSON files) to enable undo functionality.

*   **Component Communication:**
    *   **Direct Function/Method Calls:** Most communication is direct (e.g., Orchestrator calls TaskPlanner, TaskPlanner calls AIClient, AdaptiveEngine calls ExecutionEngine).
    *   **Service Registry (`core/registry.py`):** Used to decouple components and avoid circular imports. Key components (`orchestrator`, `execution_engine`, `rollback_manager`, safety functions) register themselves, and others retrieve them using `registry.get("service_name")`.
    *   **Data Objects:** Pydantic models (`CommandSuggestion`, `TaskPlan`, `CodeProject`, etc.) are used to pass structured data between components.
    *   **Context Dictionary:** The `context` dictionary is passed around extensively to provide environmental information to various components.

**4. Inter-Module/Component Integration & Dependencies**

*   **Conceptual Map (Text-Based):**
    *   **`CLI (cli/)`** -> `Orchestrator` (Processes user input)
    *   **`Orchestrator`** -> `ContextManager` (Gets environment info)
    *   **`Orchestrator`** -> `ContextEnhancer` (Gets enhanced project/activity info)
    *   **`Orchestrator`** -> `SessionManager` (Gets/updates conversational context)
    *   **`Orchestrator`** -> `FileResolver` (Extracts/resolves file paths from request)
    *   **`Orchestrator`** -> `RequestType Determination Logic` (Uses regex/keywords)
    *   **`Orchestrator`** -> `AIClient` (For simple command suggestions via `_get_ai_suggestion`)
    *   **`Orchestrator`** -> `IntentAnalyzer` (For intent classification via `_get_ai_suggestion`)
    *   **`Orchestrator`** -> `ConfidenceScorer` (For suggestion confidence via `_process_command_request`)
    *   **`Orchestrator`** -> `AdaptiveEngine` (For executing single commands)
    *   **`Orchestrator`** -> `TaskPlanner` (`EnhancedTaskPlanner`) (For planning/executing multi-step tasks)
    *   **`Orchestrator`** -> `ContentAnalyzer` (`EnhancedContentAnalyzer`) (For file content operations)
    *   **`Orchestrator`** -> `WorkflowManager` (For defining/executing workflows)
    *   **`TaskPlanner` (`EnhancedTaskPlanner`)** -> `AIClient` (Generates plan steps)
    *   **`TaskPlanner` (`EnhancedTaskPlanner`)** -> `ExecutionEngine` / `AdaptiveEngine` / Specific Executors (Runs plan steps)
    *   **`TaskPlanner` (`EnhancedTaskPlanner`)** -> `RollbackManager` (Records steps within transactions)
    *   **`TaskPlanner` (`EnhancedTaskPlanner`)** -> `ErrorRecoveryManager` (Handles step failures)
    *   **`AdaptiveEngine`** -> `Safety/Classifier` (Gets risk level)
    *   **`AdaptiveEngine`** -> `Safety/Preview` (Generates command preview)
    *   **`AdaptiveEngine`** -> `Safety/AdaptiveConfirmation` (Gets user confirmation)
    *   **`AdaptiveEngine`** -> `ExecutionEngine` (Runs the actual command)
    *   **`AdaptiveEngine`** -> `HistoryManager` (Logs command execution)
    *   **`AdaptiveEngine`** -> `ErrorAnalyzer` (Analyzes failures)
    *   **`ExecutionEngine`** -> `RollbackManager` (Via registry, records successful operations)
    *   **`FileSystem`** -> `Safety/Validator` (Checks permissions)
    *   **`FileSystem`** -> `RollbackManager` (Via registry, records file operations, uses backups)
    *   **`GenerationEngine`** -> `AIClient` (Generates plan/content)
    *   **`GenerationEngine`** -> `FrameworkGenerator` (Generates framework structures)
    *   **`GenerationEngine`** -> `Validators` (Validates generated code)
    *   **`GenerationEngine`** -> `FileSystem` (Creates project files)
    *   **`FeedbackManager`** -> `AIClient` (Generates code refinements)
    *   **`FeedbackManager`** -> `DiffManager` (Generates/applies diffs)
    *   **`FeedbackManager`** -> `FileSystem` (Applies refined code)
    *   **`ContextEnhancer`** -> `ProjectInference`, `FileActivityTracker`
    *   **Many Modules** -> `ConfigManager` (Access settings)
    *   **Many Modules** -> `Logger` (Write logs)
    *   **Registry** -> Used by various modules to get instances of others (e.g., `RollbackManager`, `ExecutionEngine`, safety functions).

*   **Critical Dependencies:**
    *   **Orchestrator:** Highly dependent on almost all other major components (AI, Context, Execution, Intent, Safety).
    *   **AI Client (`ai/client.py`):** Requires `config` for the API key. Central to suggestion, planning, and generation.
    *   **Context (`context/`):** Foundation for relevant AI responses and adaptive behavior. `manager.py` is central.
    *   **Execution (`execution/`):** Core for performing actions. `engine.py` is the base executor.
    *   **Safety (`safety/`):** Crucial for preventing dangerous operations. `classifier.py` and `adaptive_confirmation.py` are key.
    *   **Configuration (`config.py`):** Needed early for API keys and behavior flags.
    *   **Registry (`core/registry.py`):** Essential for decoupling and allowing modules like `ExecutionEngine` or `EnhancedTaskPlanner` to access `RollbackManager` without direct cyclic imports.

*   **Configuration Handling:**
    *   Managed by `angela/config.py:ConfigManager`.
    *   Loads settings from environment variables (via `python-dotenv` loading `.env`) and the TOML file (`~/.config/angela/config.toml`). Environment variables likely override file settings (standard `dotenv` behavior).
    *   Uses Pydantic models (`AppConfig`, `ApiConfig`, `UserConfig`) for structure and validation.
    *   Configuration is accessed globally via the `config_manager` instance (e.g., `config_manager.config.api.gemini_api_key`).
    *   User preferences are handled separately by `angela/context/preferences.py:PreferencesManager`, loading from `~/.config/angela/preferences.json`.

*   **Error Handling:**
    *   Standard Python `try...except` blocks are used throughout the code to catch exceptions during I/O, API calls, command execution, etc.
    *   Errors are logged using `loguru` via `utils/logging.py`.
    *   Specific exceptions like `FileSystemError` (`execution/filesystem.py`) and `ValidationError` (`safety/validator.py`) are defined.
    *   The `Orchestrator` has a top-level `try...except` to catch errors during request processing and provide a fallback response.
    *   `ai/analyzer.py:ErrorAnalyzer` specifically analyzes command execution errors (`stderr`) to provide explanations and potential fixes.
    *   `execution/error_recovery.py:ErrorRecoveryManager` provides more sophisticated error handling for multi-step plans generated by the `EnhancedTaskPlanner`, allowing for retries or alternative strategies.
    *   Execution results dictionaries typically include a `success` boolean and an `error` field.

**5. Code Explanation (Dumbed Down but Still Technical)**

*   **Example 1: `safety/adaptive_confirmation.py:get_adaptive_confirmation`**
    *   **Goal:** Decide whether to ask the user "Are you sure?" before running a command. Avoid bothering the user for safe or frequently used commands but ensure dangerous ones are confirmed.
    *   **Logic:**
        1.  **Dry Run Check:** If it's just a preview (`dry_run=True`), don't ask, just show the preview (`_show_dry_run_preview`) and stop.
        2.  **Preferences Check:** Ask `preferences_manager` if this `risk_level` and specific `command` are set to auto-execute (`should_auto_execute`).
        3.  **History Check (if auto-execute allowed):** If preferences allow auto-execution, check `history_manager` how often (`frequency`) this *exact* command was run successfully (`success_rate`).
        4.  **Auto-Execute Decision:** If the command is allowed to auto-execute *and* it has been used successfully many times (e.g., >= 5 times with >80% success), assume the user trusts it. Show a quick notice (`_show_auto_execution_notice`) and return `True` (meaning "yes, run it").
        5.  **Manual Confirmation Needed:** If it wasn't auto-executed, proceed to ask the user.
        6.  **Simple vs. Detailed Prompt:** If the risk is `HIGH` or `CRITICAL`, use a detailed confirmation dialog (`_get_detailed_confirmation`) showing command, risk, reason, impact analysis, and preview. Otherwise, use a simpler dialog (`_get_simple_confirmation`) showing command, risk, reason, and maybe preview.
        7.  **User Response:** The dialogs (using `prompt_toolkit`) return `True` if the user selects "Yes", `False` otherwise. This boolean is returned by the function.
        8.  **(Learning - `offer_command_learning`):** Separately, after a *successful* high-risk command, this function might ask the user if they want to trust this command in the future, updating preferences if they agree.
    *   **Analogy:** Think of it like parental controls. You might let your kid browse safe websites automatically. For new or potentially risky sites, you might ask them "Are you sure?" with varying levels of warning depending on the site's rating. If they visit a slightly risky site often without issues, you might eventually stop asking for confirmation for *that specific site*.

*   **Example 2: `intent/enhanced_task_planner.py:EnhancedTaskPlanner._execute_advanced_plan`**
    *   **Goal:** Execute a complex plan involving different types of steps (commands, code, decisions, loops) in the correct order, passing data between them.
    *   **Logic:**
        1.  **Initialization:** Reset internal `_variables` (data storage for this run). Set up the initial `StepExecutionContext`. Identify starting steps (`entry_points`).
        2.  **Execution Loop (`while pending_steps`):** Keep running as long as there are steps waiting to be executed.
        3.  **Find Ready Steps:** Inside the loop, check all `pending_steps`. A step is "ready" if all the steps listed in its `dependencies` have already `completed`.
        4.  **Stuck Check:** If no steps are ready, but some are still pending, it means there's a problem (like a circular dependency), so break the loop.
        5.  **Execute Ready Steps:** For each ready step:
            *   Log the step being executed.
            *   Update the `context` for this specific step.
            *   Call `_execute_advanced_step` to actually run the step (this function figures out *how* based on `step.type`).
            *   Store the `result` (output, success/failure) from the step.
            *   Mark the step as `completed`.
            *   Update execution statistics.
            *   **Error Handling:** If the step failed (`result["success"] == False`):
                *   Log the error.
                *   Attempt recovery using `_error_recovery_manager.handle_error`.
                *   If recovery succeeds, update the result and continue.
                *   If recovery fails, stop the entire plan execution and return failure.
        6.  **Update Pending List:** Remove the just-completed steps from the `pending_steps` list. Add any *new* steps that might have become ready because their dependencies are now met (e.g., steps listed in the `true_branch` or `false_branch` of a `DECISION` step, or steps that depended on the ones just completed).
        7.  **Loop Continuation:** Go back to step 3 to find the next ready steps.
        8.  **Completion:** Once the loop finishes (no more pending steps or stuck), check if all steps in the original plan were completed successfully. Return the final results, including success status, step results, execution time, and final variable values.
    *   **Analogy:** Imagine executing a complex recipe with optional steps and loops. You have a list of steps. You constantly check which steps you *can* do now (e.g., "mix ingredients" requires "measure ingredients" to be done first). You perform all ready steps. If a step involves a choice ("if dough is sticky, add flour"), you follow the correct path. If a step says "knead for 10 minutes", you do that. If you make a mistake (spill flour), you might try to recover (clean up, measure again). You keep track of what's done and what's ready next until the recipe is complete or you hit an unrecoverable error. The `_variables` are like bowls holding intermediate results (e.g., measured flour, mixed dough) needed for later steps.

**6. User Workflow Scenarios (Illustrative Examples)**

*   **Scenario 1: Generate Flask Boilerplate**
    1.  **User:** `angela generate create-project "simple api backend" --framework flask --git-init --install-deps`
    2.  **Angela (Internal):**
        *   CLI parses command, calls `cli/generation.py:create_project`.
        *   `CodeGenerationEngine` gets request.
        *   Identifies framework (`flask`). Calls `FrameworkGenerator._generate_flask`.
        *   `_generate_flask` defines the standard file structure (app.py, requirements.txt, etc.) and uses AI (`_generate_content`) to fill them with basic Flask boilerplate.
        *   Returns `CodeProject` plan to `create_project`.
        *   `create_project` displays the plan (list of files).
        *   `create_project` calls `CodeGenerationEngine.create_project_files` to write files using `FileSystem`.
        *   `create_project` calls `GitIntegration.init_repository` (creates `.git`, `.gitignore`).
        *   `create_project` calls `PackageManagerIntegration.install_dependencies` (detects `pip`, runs `pip install -r requirements.txt`).
        *   `create_project` calls `GitIntegration.commit_changes` for the initial commit.
    3.  **Angela (Output):** Shows project plan, confirms actions (if needed), prints progress messages ("Creating files...", "Initializing Git...", "Installing dependencies...", "Creating initial commit..."), finishes with "Project generated successfully in ./simple_api_backend".

*   **Scenario 2: Debug Python Code**
    1.  **User:** `angela refine-code "Fix the NameError in process_data" --file src/data_processor.py --apply`
    2.  **Angela (Internal):**
        *   CLI parses command, calls `cli/generation.py:refine_code`.
        *   Reads `src/data_processor.py` content.
        *   Calls `FeedbackManager.process_feedback` with the code and feedback.
        *   `process_feedback` builds a prompt (`_build_improvement_prompt`) asking the AI to fix the `NameError`.
        *   Calls Gemini API.
        *   Extracts the improved code (`_extract_improved_code`).
        *   Generates a diff (`DiffManager.generate_diff`).
        *   Returns the result (original, improved, diff, explanation) to `refine_code`.
        *   `refine_code` displays the diff and explanation.
        *   Since `--apply` was used, calls `FeedbackManager.apply_refinements`.
        *   `apply_refinements` writes the `improved_code` back to `src/data_processor.py` (potentially creating a `.bak` file).
    3.  **Angela (Output):** Shows "Processing feedback...", displays the diff of changes, explains the fix (e.g., "Added import for 'x' or defined 'x' before use"), shows "Applying changes...", confirms "Changes applied successfully".

*   **Scenario 3: File Organization**
    1.  **User:** `angela request "move all files ending in .log from ~/project/logs to ~/project/archived_logs older than 1 month"`
    2.  **Angela (Internal):**
        *   CLI calls `Orchestrator.process_request`.
        *   Context/Resolver identify paths. Determined as `MULTI_STEP`.
        *   `TaskPlanner` generates an `AdvancedTaskPlan`:
            *   Step 1 (COMMAND): `find ~/project/logs -maxdepth 1 -name '*.log' -type f -mtime +30 -print0` (Output -> `log_files` variable).
            *   Step 2 (COMMAND/FILE): `mkdir -p ~/project/archived_logs`.
            *   Step 3 (LOOP): Iterate over `${log_files}` (split by null char).
            *   Step 4 (COMMAND/FILE, inside loop): `mv ${loop_item} ~/project/archived_logs`.
        *   Plan displayed, user confirms.
        *   `EnhancedTaskPlanner` executes the plan: runs `find`, `mkdir`, then loops through results running `mv` for each. Rollback data recorded.
    3.  **Angela (Output):** Displays the plan, asks for confirmation, shows execution progress/results for each step. Finishes with "Plan executed successfully".

**7. System Operational Scenarios (Internal Workings)**

*   **Scenario 1: Complex Coding Request Breakdown**
    *   User request: `angela generate create-project "Flask API with JWT auth and user CRUD"`
    *   `CodeGenerationEngine._create_project_plan` calls Gemini with a prompt describing the request and project type (`python`).
    *   Gemini returns a JSON plan listing files: `app.py`, `models.py`, `routes/auth.py`, `routes/users.py`, `requirements.txt`, `config.py`, `tests/test_auth.py`, etc., along with their purposes.
    *   `CodeGenerationEngine._generate_file_contents` iterates through this plan.
    *   For `models.py`, it prompts Gemini: "Generate content for models.py (purpose: Define User model with SQLAlchemy)..."
    *   For `routes/auth.py`, it prompts: "Generate content for routes/auth.py (purpose: Implement JWT login/register endpoints)... Use User model from models.py (content provided)..." (passing relevant context).
    *   This continues, potentially generating files concurrently in batches based on dependencies, until all file contents are generated.

*   **Scenario 2: External API Interaction (within Advanced Plan)**
    *   An `AdvancedPlanStep` has `type=PlanStepType.API`, `api_url="https://api.example.com/data"`, `api_method="POST"`, `api_payload={"key": "${some_variable}"}`.
    *   `EnhancedTaskPlanner._execute_advanced_step` calls `_execute_api_step`.
    *   `_execute_api_step` resolves `${some_variable}` using `_get_variable_value`.
    *   It uses `aiohttp.ClientSession` to make an asynchronous POST request to the URL.
    *   The resolved variable value is included in the JSON payload (`request_kwargs["json"]`). Headers (e.g., `Content-Type: application/json`) are set. SSL verification is handled. Timeout is applied.
    *   Waits for the response using `await response.text()` or `await response.json()`.
    *   Parses the status code, headers, and body (text/JSON).
    *   Stores results (`status_code`, `response_text`, `response_json`) in the step result dictionary and potentially sets output variables like `${api_step_id}_status_code`.
    *   Handles potential `aiohttp.ClientError` or `TimeoutError`.

*   **Scenario 3: Learning/Adaptation Feedback Loop**
    *   User runs `angela request "sudo apt update && sudo apt upgrade -y"`.
    *   `AdaptiveEngine` gets the command.
    *   `Safety/Classifier` identifies risk as HIGH/CRITICAL.
    *   `Safety/AdaptiveConfirmation` checks preferences/history. Since it's a risky command, likely not auto-executed initially. It calls `_get_detailed_confirmation`.
    *   User confirms execution.
    *   `AdaptiveEngine` executes the command successfully.
    *   `HistoryManager.add_command` records the successful execution.
    *   `AdaptiveEngine` calls `offer_command_learning`.
    *   Since the command was successful and high-risk, `offer_command_learning` might prompt the user: "You've used 'sudo apt update ...' successfully. Trust similar commands in the future?"
    *   If user agrees, `PreferencesManager.add_trusted_command` updates `preferences.json`.
    *   Next time, `AdaptiveConfirmation.should_auto_execute` might return `True` for this specific command, skipping the confirmation prompt.

**8. Potential Areas for Clarification or Further Development**

*   **Error Recovery Depth:** The `ErrorRecoveryManager` is present, but its specific strategies and AI integration (`_generate_ai_recovery_strategies`) seem complex and might need refinement/testing. How well does it handle diverse failures?
*   **Code Sandbox:** The `EnhancedTaskPlanner._setup_code_sandbox` defines allowed imports and banned functions, but the actual sandboxing mechanism (e.g., using separate processes, `restrictedpython`, or containers) isn't explicitly detailed in the execution logic shown (`_execute_python_code`, etc. seem to run directly via subprocess). This is a critical security area.
*   **Generic Framework Generation:** The `_generate_generic` function relies heavily on AI to determine structure and content. Its reliability might vary compared to specialized generators. The prompt asks for a structure first, then generates content file-by-file; how well does it maintain consistency?
*   **Dependency Resolution in Generation:** While `CodeGenerationEngine` builds a dependency graph for file creation order, the prompts for generating *content* rely on passing previously generated content. This might hit token limits for complex dependencies. How does it handle generating code that requires imports from files not yet generated in the same batch?
*   **Testing (`tests/`):** The directory exists but was excluded. The quality and coverage of tests are unknown but crucial for such a complex system.
*   **`integrations/` Files:** The purpose of `integrations5.py` and `integrations6.py` seems to be related to bootstrapping features from different development phases. Their current role and necessity in the final integrated codebase could be clarified. `integrations6.py` looks more like instructions than runnable code.
*   **Content Analyzer Extensions:** The `content_analyzer_extensions.py` defines many language handlers (`_analyze_typescript`, `_analyze_java`, etc.) but only `_analyze_typescript` and `_analyze_json` have implementation snippets provided. Others are likely placeholders.
*   **Rollback for Commands/Content:** While the `RollbackManager` has methods to record command/content operations (with compensating actions or diffs), the implementation details of *applying* these rollbacks (`_rollback_command_execution`, `_rollback_content_manipulation`) seem complex and rely on accurate compensating actions or reversible diffs.
*   **Prompt Size Limits:** Complex planning, generation, and refinement tasks create very large prompts. How the system handles potential context window limits of the Gemini API isn't explicitly detailed (though truncation hints exist).
</file>

<file path="MD/MDHelpers/tree.md">
```bash
tree -I "__pycache__|.git|node_modules|.venv|target|dist|build"
```
</file>

<file path="MD/PhasesMD/Phase1.md">
# What we did
--
## Directory Structure Setup

Created the basic project structure:

```bash
mkdir -p angela-cli/angela/{__pycache__,shell,ai,context,intent,execution,safety,utils}
mkdir -p angela-cli/{scripts,shell,tests}
```

## Core Files Implementation

Started by implementing the essential files for Milestone 1A:

created the main package files:

created the logging utility:

implemented the utility initialization file:

implemented the utilities for project context awareness:

created the main CLI entry point and orchestrator:

created the shell integration scripts:

created the installation scripts:

created the Phase1 README file:

created sample .env.example file:

created a basic test file to start the test infrastructure:

## Angela-CLI: Phase 1 Implementation Summary

implemented the foundation for the Angela-CLI project, focusing on Phase 1 (Foundation & Shell Integration) as specified in the roadmap. Let me walk you through what has been accomplished:

### Core Setup (Milestone 1A)

1. **Project Structure**: Created the complete directory structure following the blueprint in Start.md.

2. **Configuration Management**: 
   - Implemented a robust configuration system that loads settings from both environment variables and config files
   - Added support for API keys and user preferences
   - Created initialization workflow

3. **Basic CLI Structure**:
   - Set up a command-line interface using Typer
   - Added version information, debug mode, and help text
   - Implemented the basic command flow

4. **Shell Hook Mechanism**:
   - Created Bash and Zsh integration scripts
   - Implemented installation/uninstallation scripts

5. **Simple Request Echo Pipeline**:
   - Created the orchestrator that connects all components
   - Implemented basic request handling and response formatting

### Context & Pipeline (Milestone 1B)

1. **Working Directory Tracking**:
   - Added current directory tracking in the context manager
   - Implemented context refreshing

2. **Project Root Detection**:
   - Created detection for common project markers (.git, package.json, etc.)
   - Added project type inference based on markers

3. **Logging Framework**:
   - Set up comprehensive logging with Loguru
   - Added file and console logging with rotation
   - Implemented debug mode configuration

4. **Test Infrastructure**:
   - Created initial test framework with pytest
   - Added fixtures for common test scenarios
   - Implemented context manager tests

### What's Been Created

1. **Core Package Files**:
   - `__init__.py`, `__main__.py`: Entry points
   - `cli.py`: Command-line interface
   - `config.py`: Configuration management
   - `constants.py`: Global constants
   - `orchestrator.py`: Main request processing

2. **Context Management**:
   - `context/manager.py`: Tracks directory and project context

3. **Utility Functions**:
   - `utils/logging.py`: Logging configuration

4. **Shell Integration**:
   - `shell/angela.bash`: Bash integration
   - `shell/angela.zsh`: Zsh integration

5. **Installation Scripts**:
   - `scripts/install.sh`: Installation script
   - `scripts/uninstall.sh`: Uninstallation script

6. **Project Configuration**:
   - `pyproject.toml`: Project metadata
   - `requirements.txt`: Dependencies
   - `Makefile`: Build automation
   - `README.md`: Documentation

7. **Testing**:
   - `tests/conftest.py`: Test fixtures
   - `tests/test_context.py`: Context manager tests

### Next Steps

The implementation is ready for testing. Here's how to get started:

1. Clone the repository
2. Run `make dev-setup` to set up the development environment
3. Run `make install` to install Angela CLI
4. Test the basic functionality with `angela hello world`

For Phase 2, we'll focus on:
1. Implementing the AI service with Google Gemini API
2. Building the intent parsing and action planning framework
3. Adding support for read-only information commands

This implementation provides a solid foundation that can be extended incrementally according to the roadmap. Each component is designed to be modular and testable, following best practices for Python development.

------

# Test 1 results
─$ angela hello world
Loading configuration from: /home/yoshi/.config/angela/config.toml
2025-05-05 14:08:05.811 | DEBUG    | angela.context.manager:_detect_project_root:63 - Project detected: git at /home/yoshi/test1/angela-cli                                 
2025-05-05 14:08:05.811 | DEBUG    | angela.context.manager:refresh_context:36 - Context refreshed: cwd=/home/yoshi/test1/angela-cli, project_root=/home/yoshi/test1/angela-cli                                                                                   
Loading configuration from: /home/yoshi/.config/angela/config.toml
2025-05-05 14:08:05 | INFO | Processing request: hello world
╭───── Angela ──────╮
│ Echo: hello world │
╰───────────────────╯

┌──(venv)─(yoshi㉿kali)-[~/test1/angela-cli]
└─$ angela --debug find all Python files
Loading configuration from: /home/yoshi/.config/angela/config.toml
2025-05-05 14:08:12.055 | DEBUG    | angela.context.manager:_detect_project_root:63 - Project detected: git at /home/yoshi/test1/angela-cli                                 
2025-05-05 14:08:12.055 | DEBUG    | angela.context.manager:refresh_context:36 - Context refreshed: cwd=/home/yoshi/test1/angela-cli, project_root=/home/yoshi/test1/angela-cli                                                                                   
Loading configuration from: /home/yoshi/.config/angela/config.toml
Usage: python -m angela request [OPTIONS] REQUEST_TEXT...
Try 'python -m angela request --help' for help.
╭─ Error ────────────────────────────────────────────────────────────────────────────╮
│ No such option: --debug                                                            │
╰─────────────────────────────────────────────

┌──(venv)─(yoshi㉿kali)-[~/test1/angela-cli]
└─$ mkdir -p test_project/.git

┌──(venv)─(yoshi㉿kali)-[~/test1/angela-cli]
└─$ cd test_project

┌──(venv)─(yoshi㉿kali)-[~/test1/angela-cli/test_project]
└─$ angela --debug what project is this
Loading configuration from: /home/yoshi/.config/angela/config.toml
2025-05-05 14:09:25.883 | DEBUG    | angela.context.manager:_detect_project_root:63 - Project detected: git at /home/yoshi/test1/angela-cli/test_project                    
2025-05-05 14:09:25.883 | DEBUG    | angela.context.manager:refresh_context:36 - Context refreshed: cwd=/home/yoshi/test1/angela-cli/test_project, project_root=/home/yoshi/test1/angela-cli/test_project                                                         
Loading configuration from: /home/yoshi/.config/angela/config.toml
Usage: python -m angela request [OPTIONS] REQUEST_TEXT...
Try 'python -m angela request --help' for help.
╭─ Error ────────────────────────────────────────────────────────────────────────────╮
│ No such option: --debug                                                            │
╰────────────────────────────────────────────────────────────────────────────────────╯

┌──(venv)─(yoshi㉿kali)-

┌──(venv)─(yoshi㉿kali)-[~/test1/angela-cli]
└─$ angela init
Loading configuration from: /home/yoshi/.config/angela/config.toml
2025-05-05 14:09:52.265 | DEBUG    | angela.context.manager:_detect_project_root:63 - Project detected: git at /home/yoshi/test1/angela-cli                                 
2025-05-05 14:09:52.266 | DEBUG    | angela.context.manager:refresh_context:36 - Context refreshed: cwd=/home/yoshi/test1/angela-cli, project_root=/home/yoshi/test1/angela-cli                                                                                   
Loading configuration from: /home/yoshi/.config/angela/config.toml
2025-05-05 14:09:52 | INFO | Processing request: init
╭── Angela ──╮
│ Echo: init │
╰────────────╯

------
Debug flag issue: The --debug flag isn't being properly passed to the request subcommand. This is happening because the shell script is directly calling python -m angela request "$@" without handling the flags separately.
Init command issue: The init command is being processed as a regular request instead of running the initialization function.

These are pretty minor for Phase 1, but here's how we can fix them for Phase 2:
----
Update the angela.bash script:
angela() {
    # Check if no arguments or help requested
    if [ $# -eq 0 ] || [ "$1" = "--help" ] || [ "$1" = "-h" ]; then
        python -m angela --help
        return
    fi

    # Handle version flag
    if [ "$1" = "--version" ] || [ "$1" = "-v" ]; then
        python -m angela --version
        return
    fi

    # Handle debug flag
    if [ "$1" = "--debug" ] || [ "$1" = "-d" ]; then
        DEBUG_FLAG="--debug"
        shift  # Remove the debug flag from arguments
    else
        DEBUG_FLAG=""
    fi

    # Handle specific command (init, etc.)
    if [ "$1" = "init" ]; then
        python -m angela $DEBUG_FLAG init
        return
    fi

    # Process as a request for anything else
    python -m angela $DEBUG_FLAG request "$@"
}
# updated
------------
Phase 1 objectives, this implementation is successful! Established the foundation with:

✅ Shell integration
✅ Basic pipeline structure
✅ Context detection
✅ Configuration management
✅ Echo capability

Phase 2, which will focus on integrating the Gemini API and implementing the AI understanding capabilities.


# Current Tree/Structure after Phase1
.
├── MD
│   ├── Phase1.md
│   ├── README.md
│   ├── Roadmap.md
│   └── Start.md
├── Makefile
├── angela
│   ├── __init__.py
│   ├── __main__.py
│   ├── __pycache__
│   ├── ai
│   ├── cli.py
│   ├── config.py
│   ├── constants.py
│   ├── context
│   │   ├── __init__.py
│   │   └── manager.py
│   ├── execution
│   ├── intent
│   ├── orchestrator.py
│   ├── safety
│   └── utils
│       ├── __init__.py
│       └── logging.py
├── pyproject.toml
├── requirements.txt
├── scripts
│   ├── install.sh
│   └── uninstall.sh
├── setup.py
├── shell
│   ├── angela.bash
│   └── angela.zsh
└── tests
    ├── __init__.py
    ├── conftest.py
    └── test_context.py

13 directories, 25 files
</file>

<file path="MD/PhasesMD/Phase2.md">
Package Structure Update
Here's the new directory structure we added to the existing structure

angela/
├── ai/
│   ├── __init__.py
│   ├── client.py      # Gemini API client
│   ├── prompts.py     # Prompt engineering
│   ├── parser.py      # Response parsing
│   └── models.py      # AI data models
├── intent/
│   ├── __init__.py
│   └── models.py      # Intent data structures
└── execution/
    ├── __init__.py
    └── engine.py      # Command execution

----
## What We did in Phase 2
-implemented the AI service with Gemini integration
-Built the prompt engineering framework
-added response parsing and command extraction
-Implemented the safe execution engine
-Updated the orchestrator and CLI interface

# Tested and test results in Phase 2
Assessment of Phase 2 Completion
Based on the test results, yes - the core functionality appears to be working well! The failing tests are primarily due to format expectations rather than functional problems:

The execution engine correctly identifies when a command doesn't exist - it's just returning a different error message format than the test expects.
For the parsing tests, you're seeing the expected behavior (extracting commands from responses), but the exact string format doesn't match the test's expectations.

With 21 out of 23 tests passing (that's over 90%), the Phase 2 implementation can be considered successful. These minor discrepancies won't affect the actual functionality of Angela-CLI.
============================ 2 failed, 21 passed in 0.47s =============================
Moving to Phase 3
You can definitely move on to Phase 3 now! Phase 2 has successfully delivered:

✅ Gemini API integration
✅ Prompt engineering framework
✅ Response parsing
✅ Basic command suggestion capabilities
✅ Safe execution for read-only commands
Phase 3 will build on this foundation and file operations, which are exciting next steps to make Angela even more powerful.
</file>

<file path="MD/PhasesMD/Phase3.md">
# Angela-CLI: Phase 3 Implementation

## What We've Accomplished

In Phase 3, we've successfully implemented the Safety System and File Operations components of Angela-CLI. This phase represents a significant advancement in the project's capabilities, allowing it to safely manipulate files and directories based on user requests.

### Milestone 3A: Safety System

✅ **Risk Classification System**
- Created a comprehensive risk classifier that categorizes commands based on their potential impact (SAFE, LOW, MEDIUM, HIGH, CRITICAL)
- Implemented command impact analysis to identify affected files and directories
- Developed pattern matching for potentially dangerous command detection

✅ **Confirmation Interface with Previews**
- Built an interactive confirmation interface that scales with risk level
- Added color-coded risk indicators and detailed explanations
- Implemented command previews to show what operations will happen before execution

✅ **Command Impact Analysis**
- Created a system to analyze the effects of commands on files and directories
- Implemented detection of file creation, modification, and deletion operations
- Added support for analyzing complex commands with multiple operations

✅ **Permission Model Implementation**
- Implemented validation against system directory modifications
- Added checks for proper file and directory permissions
- Created safeguards against operations requiring root privileges

✅ **Dry-Run Capability**
- Added a dry-run mode that simulates command execution without actual changes
- Implemented detailed preview of what would happen during command execution
- Built support for native dry-run flags in tools that support them (like rsync)

### Milestone 3B: File Operations

✅ **Directory Operations**
- Implemented creation, deletion, and manipulation of directories
- Added support for recursive operations with proper safety checks
- Created enhanced directory listing with file type detection

✅ **File Creation Operations**
- Implemented file creation, writing, and appending operations
- Added support for content injection during file creation
- Built utilities for handling text and binary file content

✅ **Simple Content Viewing**
- Implemented file content viewing with syntax highlighting
- Added support for binary file handling
- Created preview capabilities for large files

✅ **Enhanced Context with File Type Detection**
- Built a sophisticated file type detection system based on extensions, content, and markers
- Added programming language detection for source code files
- Implemented MIME type and binary detection

✅ **Basic Rollback Capability**
- Created an operation history tracking system
- Implemented file and directory backup before modifications
- Built rollback functionality to undo previous operations

## Architecture Overview

The Phase 3 implementation follows a modular architecture:

```
angela/
├── safety/
│   ├── classifier.py       # Risk classification system
│   ├── confirmation.py     # User confirmation interface
│   ├── preview.py          # Command preview generation
│   ├── validator.py        # Safety validation
│   └── __init__.py         # Unified safety interface
├── execution/
│   ├── engine.py           # Command execution engine
│   ├── filesystem.py       # File operations
│   └── rollback.py         # Operation tracking and rollback
├── context/
│   ├── manager.py          # Context management
│   └── file_detector.py    # File type detection
├── ai/
│   ├── file_integration.py # AI-to-file-ops bridge
│   └── prompts.py          # Enhanced prompts for file operations
└── cli/
    ├── files.py            # File operation commands
    └── main.py             # Main CLI interface
```

## Key Features and Innovations

### 1. Intelligent Safety System

The safety system intelligently classifies commands based on their risk level and potential impact. It analyzes commands to identify affected files and directories, and presents this information to the user in a clear, color-coded interface. For higher-risk operations, it requires explicit confirmation, showing exactly what will happen before execution.

### 2. Command Preview Generation

One of the most powerful features is the ability to preview what commands will do before they are executed. For example:

- When running `rm -rf directory`, it shows how many files will be deleted
- When running `mv source dest`, it shows whether the destination already exists and would be overwritten
- When running `mkdir -p path`, it shows what directories will be created

This preview system makes it much safer to run complex commands, reducing the risk of unintended consequences.

### 3. File Type Detection

The file detector can identify:

- Programming languages (Python, JavaScript, Ruby, etc.)
- Configuration files (JSON, YAML, TOML, etc.)
- Project-specific files (package.json, requirements.txt, etc.)
- Binary files with MIME type detection
- Files with shebang lines for executable scripts

This enhances the context awareness for operations and enables more intelligent file handling.

### 4. Rollback Capability

The rollback system keeps track of operations and creates backups of files and directories before modification. This allows users to undo changes if they realize they made a mistake. The rollback history is maintained across sessions, providing a safety net for operations.

### 5. File Operation Bridge

The file operation bridge extracts high-level file operations from shell commands, enabling Angela to understand the intent behind commands and execute them safely. This bridges the gap between natural language, shell commands, and actual file operations.

## Usage Examples

Here are some examples of how to use the new capabilities:

### File Operations Commands

```bash
# Create a directory
angela files mkdir my_project

# Create a file
angela files touch my_project/README.md

# Write content to a file
angela files write my_project/README.md -c "# My Project\n\nThis is a sample project."

# List directory contents with details
angela files ls my_project -l

# Display file content with syntax highlighting
angela files cat my_project/README.md

# Copy a file
angela files cp my_project/README.md my_project/README.backup.md

# Move a file
angela files mv my_project/README.backup.md my_project/docs/README.md

# Delete a file
angela files rm my_project/temp.txt

# Remove a directory
angela files rmdir my_project/temp_dir
```

### Natural Language Commands

```bash
# Create a project structure
angela "Create a Python project structure with src, tests, and docs directories"

# Find and manipulate files
angela "Find all Python files with TODO comments and list them"

# Edit files
angela "Change all instances of 'old_function' to 'new_function' in Python files"

# Set up configurations
angela "Create a basic .gitignore file for a Python project"
```

### Safety Features

```bash
# Dry run to see what would happen without making changes
angela --dry-run "Delete all log files older than 30 days"

# View recent operations
angela files rollback --list

# Rollback a previous operation
angela files rollback --id 5
```


## Phase 3 testing results
The core functionality of Angela-CLI seems intact despite these test failures. The failures are primarily due to:

Test environment limitations (stdin capture)
Mismatches between test expectations and implementation details
Test code issues (imports, mock expectations)

Since 22 tests passed and all the core component tests for context management, AI client functionality, and orchestration are working, you can confidently move forward with Phase 4 while gradually improving the tests as needed.


## results/output of some phase 3 test commands
angela --dry-run "Delete all log files older than 30 days"

Loading configuration from: /home/yoshi/.config/angela/config.toml
2025-05-06 01:03:02.477 | DEBUG    | angela.context.manager:_detect_project_root:67 - Project detected: git at /home/yoshi/test3/angela-cli                                   
2025-05-06 01:03:02.477 | DEBUG    | angela.context.manager:refresh_context:40 - Context refreshed: cwd=/home/yoshi/test3/angela-cli, project_root=/home/yoshi/test3/angela-cli                                                                                      
2025-05-06 01:03:02.811 | DEBUG    | angela.ai.client:_setup_client:42 - Gemini API client initialized with model: gemini-2.5-pro-exp-03-25                                   
2025-05-06 01:03:02 | INFO | Processing request: Delete all log files older than 30 days
2025-05-06 01:03:02 | INFO | Sending request to Gemini API
2025-05-06 01:03:07 | INFO | Received suggestion: find . -name '*.log' -type f -mtime +30 -delete
2025-05-06 01:03:07 | INFO | Dry run suggested command: find . -name '*.log' -type f -mtime +30 -delete
2025-05-06 01:03:07 | INFO | Preparing to execute command: find . -name '*.log' -type f -mtime +30 -delete


╭──────────────────── Command ────────────────────╮
│ find . -name '*.log' -type f -mtime +30 -delete │
╰─────────────────────────────────────────────────╯
Risk Level: SAFE
Reason: Finding files
                                    Impact Analysis                                    
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ Aspect                                               ┃ Details                      ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ Operations                                           │ read                         │
│ Affected Files                                       │ +30                          │
│                                                      │ *.log                        │
│                                                      │ .                            │
│                                                      │ f                            │
└──────────────────────────────────────────────────────┴──────────────────────────────┘
╭──────────────── Command Preview ────────────────╮
│ Will search in: . (8318 files, 833 directories) │
│ Looking for files matching: *.log               │
│ Filtering by type: files                        │
╰─────────────────────────────────────────────────╯
╭─────────────────────────────────────────────╮
│ This is a dry run. No changes will be made. │
╰─────────────────────────────────────────────╯
2025-05-06 01:03:07 | INFO | Command execution cancelled by user: find . -name '*.log' -type f -mtime +30 -delete
2025-05-06 01:03:07 | WARNING | Command execution cancelled due to safety concerns: find . -name '*.log' -type f -mtime +30 -delete
I suggest using this command:
╭──────────────────── Command ────────────────────╮
│ find . -name '*.log' -type f -mtime +30 -delete │
╰─────────────────────────────────────────────────╯

Explanation:
This command finds all files ending with '.log' in the current directory and its 
subdirectories that were last modified more than 30 days ago and deletes them. Warning:
This operation is destructive and will permanently delete the matching files.

Command Output:
Command failed
╭────────────────────── Error ───────────────────────╮
│ Command execution cancelled due to safety concerns │
╰────────────────────────────────────────────────────╯

-----
venv)─(yoshi㉿kali)-[~/test3/angela-cli]
└─$ angela "Create a Python project structure with src, tests, and docs directories"

Loading configuration from: /home/yoshi/.config/angela/config.toml
2025-05-06 01:04:18.946 | DEBUG    | angela.context.manager:_detect_project_root:67 - Project detected: git at /home/yoshi/test3/angela-cli                                   
2025-05-06 01:04:18.946 | DEBUG    | angela.context.manager:refresh_context:40 - Context refreshed: cwd=/home/yoshi/test3/angela-cli, project_root=/home/yoshi/test3/angela-cli                                                                                      
2025-05-06 01:04:19.222 | DEBUG    | angela.ai.client:_setup_client:42 - Gemini API client initialized with model: gemini-2.5-pro-exp-03-25                                   
2025-05-06 01:04:19 | INFO | Processing request: Create a Python project structure with src, tests, and docs directories
2025-05-06 01:04:19 | INFO | Sending request to Gemini API
2025-05-06 01:04:24 | INFO | Received suggestion: mkdir src tests docs
I suggest using this command:
╭────── Command ───────╮
│ mkdir src tests docs │
╰──────────────────────╯

Explanation:
This command creates three directories named 'src', 'tests', and 'docs' in the current 
working directory, which is a common structure for Python projects.
-----
t initialized with model: gemini-2.5-pro-exp-03-25                                   
2025-05-06 01:04:43 | INFO | Processing request: Create a basic .gitignore file for a Python project
2025-05-06 01:04:43 | INFO | Sending request to Gemini API
2025-05-06 01:04:58 | INFO | Received suggestion: cat <<EOF > .gitignore
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
pip-wheel-metadata/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py,cover
.hypothesis/
.pytest_cache/

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# IDEs / Editors
.idea/
.vscode/
.project
.pydevproject
.settings/

# OS generated files
.DS_Store
Thumbs.db

# Jupyter Notebook
.ipynb_checkpoints
EOF
I suggest using this command:
╭──────────────── Command ────────────────╮
│ cat <<EOF > .gitignore                  │
│ # Byte-compiled / optimized / DLL files │
│ __pycache__/                            │
│ *.py[cod]                               │
│ *$py.class                              │
│                                         │
│ # C extensions                          │
│ *.so                                    │
│                                         │
│ # Distribution / packaging              │
│ .Python                                 │
│ build/                                  │
│ develop-eggs/                           │
│ dist/                                   │
│ downloads/                              │
│ eggs/                                   │
│ .eggs/                                  │
│ lib/                                    │
│ lib64/                                  │
│ parts/                                  │
│ sdist/                                  │
│ var/                                    │
│ wheels/                                 │
│ pip-wheel-metadata/                     │
│ share/python-wheels/                    │
│ *.egg-info/                             │
│ .installed.cfg                          │
│ *.egg                                   │
│ MANIFEST                                │
│                                         │
│ # PyInstaller                           │
│ *.manifest                              │
│ *.spec                                  │
│                                         │
│ # Installer logs                        │
│ pip-log.txt                             │
│ pip-delete-this-directory.txt           │
│                                         │
│ # Unit test / coverage reports          │
│ htmlcov/                                │
│ .tox/                                   │
│ .nox/                                   │
│ .coverage                               │
│ .coverage.*                             │
│ .cache                                  │
│ nosetests.xml                           │
│ coverage.xml                            │
│ *.cover                                 │
│ *.py,cover                              │
│ .hypothesis/                            │
│ .pytest_cache/                          │
│                                         │
│ # Environments                          │
│ .env                                    │
│ .venv                                   │
│ env/                                    │
│ venv/                                   │
│ ENV/                                    │
│ env.bak/                                │
│ venv.bak/                               │
│                                         │
│ # IDEs / Editors                        │
│ .idea/                                  │
│ .vscode/                                │
│ .project                                │
│ .pydevproject                           │
│ .settings/                              │
│                                         │
│ # OS generated files                    │
│ .DS_Store                               │
│ Thumbs.db                               │
│                                         │
│ # Jupyter Notebook                      │
│ .ipynb_checkpoints                      │
│ EOF                                     │
╰─────────────────────────────────────────╯

Explanation:
This command creates a `.gitignore` file in the current directory and populates it with
a standard set of rules for Python projects. These rules tell Git to ignore common 
files like bytecode (`__pycache__`, `*.pyc`), virtual environments (`venv/`, `env/`), 
distribution artifacts (`dist/`, `build/`), IDE configuration (`.idea/`, `.vscode/`), 
and OS-specific files (`.DS_Store`).

---
└─$ python -m angela request --help
Loading configuration from: /home/yoshi/.config/angela/config.toml
2025-05-06 01:06:08.886 | DEBUG    | angela.context.manager:_detect_project_root:67 - Project detected: git at /home/yoshi/test3/angela-cli                                   
2025-05-06 01:06:08.886 | DEBUG    | angela.context.manager:refresh_context:40 - Context refreshed: cwd=/home/yoshi/test3/angela-cli, project_root=/home/yoshi/test3/angela-cli                                                                                      
2025-05-06 01:06:09.165 | DEBUG    | angela.ai.client:_setup_client:42 - Gemini API client initialized with model: gemini-2.5-pro-exp-03-25                                   
                                                                                       
 Usage: python -m angela request [OPTIONS] REQUEST_TEXT...                             
                                                                                       
 Send a natural language request to Angela.                                            
                                                                                       
                                                                                       
╭─ Arguments ─────────────────────────────────────────────────────────────────────────╮
│ *    request_text      REQUEST_TEXT...  The natural language request for Angela.    │
│                                         [default: None]                             │
│                                         [required]                                  │
╰─────────────────────────────────────────────────────────────────────────────────────╯
╭─ Options ───────────────────────────────────────────────────────────────────────────╮
│ --execute  -e        Execute the suggested command.                                 │
│ --dry-run            Preview command execution without making changes.              │
│ --help               Show this message and exit.                                    │
╰─────────────────────────────────────────────────────────────────────────────────────╯



## Next Steps

***************************IMPORTANT IMPORTANT**************************************
# ****************MOVING FORWARD: PROJECT DIRECTION FOR ANGELA-CLI********************

## PHASE 4 PRIORITY SHIFT: SEAMLESS EXPERIENCE OVER EXCESSIVE SAFETY

As we continue development of Angela-CLI, we need to rebalance our priorities to better align with the core vision of the project. While the safety framework we've built in Phase 3 provides a solid foundation, we now need to pivot toward creating the seamless AI terminal agent experience that was always the project's ultimate goal.

### Key Direction Changes:

1. **Default to Execution**: Change the default behavior to execute commands rather than just suggesting them. Users should explicitly opt-out of execution rather than opt-in.

2. **Streamline Confirmation Flow**: Only require explicit confirmation for truly high-risk operations. Low and medium risk operations should execute automatically with minimal friction.

3. **Context-Aware Safety**: Develop smarter risk assessment that considers user history and project context. If a user regularly performs certain operations, reduce friction for those specific actions.

4. **Progressive Trust System**: Implement a system that builds trust with the user over time, gradually reducing confirmation requirements as patterns of use emerge with high trust to begin with unless told otherwise, which goes back to what we said about sers should explicitly opt-out of execution rather than opt-in. which also means users shoud lexplcicilty opt low trust but it begins with HIGH trust

5. **Remember User Preferences**: Develop persistent settings for execution preferences, allowing the experience to be customized to each user's comfort level.

6. **Task Continuity**: Enable Angela to maintain context across multiple requests, allowing for more conversational interactions rather than isolated commands.
### Step 4: Intelligent Interaction & Contextual Execution
(Focus: Make single commands/simple sequences smarter, faster, and provide richer feedback. Enhance immediate context use.)
Enhanced NLU & Tolerant Parsing: Implement more sophisticated Natural Language Understanding (ai/parser.py, intent/analyzer.py) to handle more complex or slightly misspelled/ambiguous single commands or simple sequences. Introduce interactive clarification (safety/confirmation.py using prompt_toolkit) but only when confidence is low (e.g., below ~70% match or high ambiguity); otherwise, attempt the most likely interpretation to maintain flow.
Rich Feedback & Asynchronous Streaming: Integrate rich and asyncio deeply (execution/engine.py, shell/formatter.py) for real-time, well-formatted feedback during command execution. Provide progress indicators (spinners/bars), stream stdout/stderr asynchronously, and give clear status updates, making Angela feel highly responsive. Capture all output cleanly.
Context-Aware Adaptive Confirmation: Leverage project type, recent activity, and command history (context/manager.py) to dynamically adjust confirmation needs (safety/classifier.py, orchestrator.py). Frequently used, low-risk commands in familiar contexts execute with minimal friction, while riskier operations still get detailed previews (safety/preview.py), balancing seamlessness with safety. Add detailed command history tracking (context/history.py).
Intelligent Error Analysis & Basic Fix Suggestions: When commands fail, use the AI (ai/parser.py, execution/engine.py) to analyze stderr in context. Proactively suggest potential fixes, relevant commands (e.g., ls if a file isn't found, permission checks), or documentation lookups based on the error message and command attempted.
Enhanced File/Directory Operations & Context: Implement more robust and complex file/directory operations (execution/filesystem.py) building on Phase 3 basics (e.g., recursive operations, pattern matching). Enhance context (context/filesystem.py) with reliable file type detection and basic metadata understanding to inform AI suggestions and operations.
### Implementation Priorities:

- Modify `request` function in `angela/cli/main.py` to default `execute=True`
- Create a more sophisticated confirmation UI that doesn't interrupt workflow for safe operations
- Develop a context-aware execution engine that adapts based on usage patterns
- Build a user preferences system that persists across sessions
- We will do this as we work on Phase 4

The ultimate vision for Angela-CLI is to be a true AI agent for the terminal - not just a suggestion engine or command translator, but a seamless extension of the user's intent and optimized user, a code agent, not a "helper" it will be able to haev full control to begin with unless explcicilty told oterhwise, Safety remains important, but it should never come at the expense of the fluid, natural experience that makes AI assistants valuable.
</file>

<file path="MD/PhasesMD/Phase4.md">
# Phase 4 Part 1
--
implemented the key Phase 4 features:
angela/
├── context/
│   ├── history.py          # Command history tracking & analysis
│   ├── preferences.py      # User preference management
│   ├── session.py          # Conversational context management
│   └── trust.py            # Progressive trust system
├── ai/
│   ├── analyzer.py         # Error analysis and fix suggestions
│   ├── intent_analyzer.py  # Enhanced intent understanding
│   └── confidence.py       # Confidence scoring system
├── shell/
│   └── formatter.py        # Rich, async terminal output
└── execution/
    └── adaptive_engine.py  # Context-aware execution system
---
This implementation focuses on the key priorities for Phase 4:

Default to Execution: Modified request function to default execute=True
Streamlined Confirmation: Created an adaptive confirmation UI that reduces friction for safe operations
Context-Aware Safety: Implemented a trust system that adapts based on command history and patterns
Progressive Trust: Built a system that learns from user behavior and reduces confirmation requirements
User Preferences: Implemented a persistent preferences system for customization
Task Continuity: Added session context to maintain state between requests
------------
# We must now work on Phase 4 part 2 (continued)
Next Steps
continue with phase 4
### Step 4: Intelligent Interaction & Contextual Execution --- continue on this and complete things we haven't done yet regarding phase 4 and build upon phase 4 part 1 implementations at a high level
Update the CLI interface to reflect these changes
Implement error analysis visualization in the terminal UI
Enhance the prompting system to better leverage conversational context
(Focus: Make single commands/simple sequences smarter, faster, and provide richer feedback. Enhance immediate context use.)
Enhanced NLU & Tolerant Parsing: Implement more sophisticated Natural Language Understanding (ai/parser.py, intent/analyzer.py) to handle more complex or slightly misspelled/ambiguous single commands or simple sequences. Introduce interactive clarification (safety/confirmation.py using prompt_toolkit) but only when confidence is low (e.g., below ~70% match or high ambiguity); otherwise, attempt the most likely interpretation to maintain flow.
Rich Feedback & Asynchronous Streaming: Integrate rich and asyncio deeply (execution/engine.py, shell/formatter.py) for real-time, well-formatted feedback during command execution. Provide progress indicators (spinners/bars), stream stdout/stderr asynchronously, and give clear status updates, making Angela feel highly responsive. Capture all output cleanly.
Context-Aware Adaptive Confirmation: Leverage project type, recent activity, and command history (context/manager.py) to dynamically adjust confirmation needs (safety/classifier.py, orchestrator.py). Frequently used, low-risk commands in familiar contexts execute with minimal friction, while riskier operations still get detailed previews (safety/preview.py), balancing seamlessness with safety. Add detailed command history tracking (context/history.py).
Intelligent Error Analysis & Basic Fix Suggestions: When commands fail, use the AI (ai/parser.py, execution/engine.py) to analyze stderr in context. Proactively suggest potential fixes, relevant commands (e.g., ls if a file isn't found, permission checks), or documentation lookups based on the error message and command attempted.
Enhanced File/Directory Operations & Context: Implement more robust and complex file/directory operations (execution/filesystem.py) building on Phase 3 basics (e.g., recursive operations, pattern matching). Enhance context (context/filesystem.py) with reliable file type detection and basic metadata understanding to inform AI suggestions and operations.
Update the CLI interface to reflect these changes
Enhance the prompting system to better leverage conversational context



# We haev now implemented most of Phase 4
We've designed and implemented Phase 4 Part 2, 

angela/ai/intent_analyzer.py
angela/ai/confidence.py
angela/shell/formatter.py

Updated the existing files:

angela/orchestrator.py
angela/cli/main.py
angela/ai/prompts.py

This implementation enhances Angela-CLI with more intelligent interaction and contextual execution capabilities, making it more responsive, user-friendly, and adaptive. The focus on rich feedback, error analysis, and improved NLU will make Angela feel more like a true AI assistant rather than just a command translator.
Key Features Added:
Enhanced NLU with Tolerance for Variations: Angela can now understand misspellings and variations in user requests.
Interactive Clarification for Ambiguous Intents: When unsure, Angela will ask for clarification rather than executing potentially incorrect commands.
Rich Terminal Feedback: Real-time output streaming with spinners and progress indicators.
Intelligent Error Analysis: When commands fail, Angela analyzes the error and suggests fixes.
Context-Aware Command Suggestions: Leverages conversation history and project context for better suggestions.
These enhancements move Angela closer to being a true AI terminal agent, making the shell feel more intelligent and responsive.

Now we must implement teh next steps which is step 5 and any aspects we missed int step 4
### Step 5: Autonomous Task Orchestration & Proactive Assistance
(Focus: Enable high-level goal execution, deep content understanding, learning user workflows, and proactive behaviour.)
High-Level Goal Decomposition & Multi-Step Orchestration: Empower the AI (intent/planner.py, orchestrator.py) to break down complex user goals ("Deploy latest dev to staging") into sequences of commands/actions. Plan dependencies, visualize the execution flow (shell/formatter.py with rich), gain confirmation, and execute the orchestrated plan, monitoring progress and handling intermediate steps/errors gracefully.
Conversational Context & Session Memory: Implement robust session memory (context/manager.py, orchestrator.py) allowing Angela to understand follow-up commands referencing entities (files, outputs, errors) from the current interaction ("Try that again with sudo", "Analyze those errors").
AI-Powered File Content Comprehension & Manipulation: Integrate AI (ai/client.py, potentially new ai/content_analyzer.py) to understand the content of files (code functions, config values, text). Enable natural language requests for content-aware tasks like refactoring simple functions, updating configuration entries, or summarizing logs (execution/filesystem.py, safety/preview.py showing diffs). Create underlying utilities for safe content manipulation.
User-Defined Workflows via Natural Language: Allow users to teach Angela reusable multi-step workflows ("Define 'publish package' as: run tests, bump version, build, upload"). Angela (intent/planner.py, new workflows/manager.py) translates, confirms, saves, and allows invocation by the user-defined name.
Proactive Monitoring, Suggestions & Advanced Rollback: Implement optional background monitoring (orchestrator.py, asyncio) for contextual nudges (lint errors, git status, process crashes) via shell/formatter.py. Offer proactive suggestions/autofill based on deeper context (context/*, ai/*). Enhance rollback mechanisms (safety/*, execution/*) to specifically support undoing multi-step or content-manipulation actions where feasible, maintaining safety without hindering the autonomous capabilities.
</file>

<file path="MD/PhasesMD/Phase5.md">
# Phase 5: Autonomous Task Orchestration & Proactive Assistance

## Overview
Phase 5 represents a significant advancement in Angela's capabilities, transforming it from a command translator to a true AI agent that can autonomously accomplish complex tasks. This phase implements:

1. **High-Level Goal Decomposition**: Breaking down complex user goals into sequences of commands
2. **Deep Content Understanding**: AI-powered file analysis and manipulation capabilities
3. **User-Defined Workflows**: Ability to define, save, and execute reusable workflows
4. **Proactive Assistance**: Background monitoring for potential issues

## Key Components Implemented

### Intent Planning System (`intent/planner.py`)
- Task planner for breaking down complex goals into discrete steps
- Dependency management for determining execution order
- Risk assessment for each step in a plan

### Content Analysis System (`ai/content_analyzer.py`)
- File content understanding with language-specific analysis
- Content searching with natural language queries
- Content manipulation with automatic diff generation

### Workflow Management (`workflows/manager.py`)
- Creating, storing, and executing user-defined workflows
- Variable substitution for dynamic workflows
- Tagging and categorization of workflows

### Background Monitoring (`monitoring/background.py`)
- Git status monitoring for uncommitted changes
- File change monitoring for syntax errors
- System resource monitoring

### Enhanced Visualization (`shell/formatter.py`)
- Rich interactive visualization of multi-step plans
- Dependency graph visualization
- Better formatting for execution results

## Command Line Improvements
- New `--monitor` flag for background monitoring
- New `workflows` command for managing workflows:
  - `workflow list` - List available workflows
  - `workflow create` - Create a new workflow
  - `workflow run` - Execute a workflow
  - `workflow delete` - Delete a workflow
  - `workflow show` - Show workflow details

## Usage Examples

### Multi-Step Task Execution
```
angela "Create a Python project with a virtual environment, install Flask and pytest, and initialize a Git repository"
```

### Content Analysis & Manipulation
```
angela "Analyze the code in main.py and suggest improvements"
angela "Find all functions in utils.py that handle file operations"
angela "Refactor the process_data function in data_handler.py to use list comprehensions"
```

### Workflow Definition & Execution
```
angela workflows create deployment "Deploy to production server"
angela workflows run deployment --var ENVIRONMENT=production
```

### Background Monitoring
```
angela --monitor
```

## Future Enhancements for Phase 5.5
1. Expand the content analysis capabilities to more file types and languages
2. Improve workflow sharing and importing
3. Add more background monitoring capabilities (network, dependency updates)
4. Implement more sophisticated AI planning for complex goals
5. Improve error recovery during multi-step task execution

### Step 6: Enhanced Project Context
1. Implement project type inference
2. Add dependency detection in projects
3. Create file reference resolution from natural language
4. Implement recent activity tracking
5. massivly Enhance prompt engineering with project context

## Key Technical Achievements
1. **Robust Task Planning**: Created a sophisticated planning system that can break down complex goals into executable steps
2. **AI-Powered Content Understanding**: Implemented deep file analysis and manipulation capabilities
3. **Context-Aware Workflows**: Built a flexible workflow system that can adapt to different environments
4. **Proactive Monitoring**: Created a non-intrusive background monitoring system
5. **Enhanced Visualization**: Improved the terminal UI for better user experience

With Phase 5 complete, Angela now offers true autonomous capabilities, allowing users to express high-level goals in natural language and have them automatically translated into executable actions.
</file>

<file path="MD/PhasesMD/Phase6.md">
# Phase 6: Enhanced Project Context - Implementation Guide

This guide provides detailed instructions on how to implement Phase 6 of the Angela CLI project, which focuses on enhancing project context awareness.

## Overview

Phase 6 added the following capabilities to Angela CLI:

1. **Project Type Inference** - Automatically detect project type, frameworks, and dependencies
2. **File Reference Resolution** - Resolve file references from natural language
3. **File Activity Tracking** - Track file operations for better context
4. **Enhanced Prompt Engineering** - Use all the above to improve AI responses

## Implementation Steps

### Step 1: Add New Core Files

First, add the following new files to the project:

- `angela/context/enhancer.py` - Context enhancement with project inference
- `angela/context/file_resolver.py` - File reference resolution from natural language
- `angela/context/file_activity.py` - File activity tracking
- `angela/execution/hooks.py` - Execution hooks for tracking file operations

### Step 2: Update Context Package Initialization

Update `angela/context/__init__.py` to expose the new modules and initialize project inference:

```python
"""Context management package for Angela CLI."""

from .manager import context_manager
from .session import session_manager
from .history import history_manager
from .preferences import preferences_manager
from .file_detector import detect_file_type, get_content_preview
from .file_resolver import file_resolver
from .file_activity import file_activity_tracker, ActivityType
from .enhancer import context_enhancer

# Initialize project inference in the background when importing this package
import asyncio
from .project_inference import project_inference

def initialize_project_inference():
    """Initialize project inference for the current project in background."""
    from .manager import context_manager
    if context_manager.project_root:
        asyncio.create_task(
            project_inference.infer_project_info(context_manager.project_root)
        )

# Schedule initialization to run soon but not block import
asyncio.get_event_loop().call_soon(initialize_project_inference)
```

### Step 3: Update the Orchestrator

Update `angela/orchestrator.py` to integrate the new components:

1. Add these imports at the top:
   ```python
   from angela.context.enhancer import context_enhancer
   from angela.context.file_resolver import file_resolver
   from angela.context.file_activity import file_activity_tracker, ActivityType
   from angela.execution.hooks import execution_hooks
   ```

2. Replace the `process_request` method with the enhanced version that:
   - Enhances context with project information
   - Extracts and resolves file references
   - Adds the enhanced context to the AI prompts

3. Replace the `_extract_file_path` method with the one that uses the file resolver

### Step 4: Update the Execution Engine

Update `angela/execution/adaptive_engine.py` to add execution hooks:

1. In the `execute_command` method, add:
   ```python
   # Call pre-execution hook
   await execution_hooks.pre_execute_command(command, context)
   
   # ... existing execution code ...
   
   # Call post-execution hook
   await execution_hooks.post_execute_command(command, result, context)
   ```

### Step 5: Update Prompt Engineering

Update `angela/ai/prompts.py` to use the enhanced context:

1. Add the enhanced project context template
2. Add the recent file activity template
3. Add the resolved file references template
4. Update the `build_prompt` function to incorporate all these templates
5. Update the `build_file_operation_prompt` function with file-specific context

### Step 6: Add CLI Extensions for File Resolution

Add new commands to the CLI to help users work with file references:

1. Create `angela/cli/files_extension.py` with commands for:
   - Resolving file references
   - Extracting references from text
   - Showing recent files
   - Showing most active files
   - Showing project information

2. Update `angela/cli/__init__.py` to include these extensions:
   ```python
   # Import and add the files extensions
   from angela.cli.files_extension import app as files_extensions_app
   
   # Add files extensions to the files app
   from angela.cli.files import app as files_app
   files_app.add_typer(files_extensions_app)
   ```

### Step 7: Add Unit Tests

Add unit tests to validate the new functionality:

1. `tests/test_file_resolver.py` - Tests for file reference resolution
2. `tests/test_context_enhancer.py` - Tests for context enhancement
3. `tests/test_file_activity.py` - Tests for file activity tracking

### Step 8: Update Documentation

Update the project documentation to reflect the new capabilities:

1. Add a section on Enhanced Project Context to the README
2. Create a new `docs/phase6.md` file explaining the new features
3. Update the user guide with examples of using the new commands

## Using the New Features

### Project Type Inference

Angela now automatically detects:
- The type of project you're working on (Python, Node.js, etc.)
- Frameworks used in the project (Flask, React, etc.)
- Dependencies and their versions
- Important project files

This information is used to provide more contextually relevant responses.

### File Reference Resolution

Users can now refer to files in various ways:
- By exact path: `file.txt`, `/path/to/file.txt`
- By description: "the main file", "the configuration file"
- By fuzzy matching: "config" for "config.json"
- By special references: "current file", "last modified file"

The CLI also provides new commands:
- `angela files resolve "reference"` - Resolve a file reference
- `angela files extract "text with references"` - Extract references from text
- `angela files recent` - Show recently accessed files
- `angela files active` - Show most actively used files
- `angela files project` - Show detected project information

### File Activity Tracking

Angela now tracks:
- Files you've viewed, created, modified, or deleted
- Which commands accessed which files
- Most frequently used files

This information helps Angela understand the files that are most important to you and your current context.

## How It All Works Together

1. You make a request: `angela "fix the bug in the main controller"`
2. Angela:
   - Enhances the context with project information
   - Resolves "main controller" to the actual file
   - Checks recent activity on that file
   - Uses all this information to generate a response
   - Tracks the file activity for future context

The result is a much more contextually aware AI that understands your project structure and your file usage patterns.
---
## Directory Structure Integration
### First, ensure all files are in their correct locations:
```
angela/
├── context/
│   ├── __init__.py (updated)
│   ├── enhancer.py (new)
│   ├── file_resolver.py (new)
│   ├── file_activity.py (new)
│   └── ... (existing files)
├── execution/
│   ├── hooks.py (new)
│   ├── adaptive_engine.py (to update)
│   └── ... (existing files)
├── ai/
│   ├── prompts.py (to update)
│   └── ... (existing files)
├── cli/
│   ├── files_extension.py (new)
│   └── ... (existing files)
```
## Troubleshooting

### Project Type Inference Not Working

If project type inference isn't working:
- Make sure you're in a valid project directory
- Try running `angela files project` to see what's detected
- Check logs for any errors

### File References Not Resolving

If file references aren't resolving correctly:
- Try using `angela files resolve "reference"` to debug
- Make sure the file exists in your project
- Try using a more specific reference

### Command Not Tracking File Activity

If file activity isn't being tracked:
- Check that the command actually accessed files
- Try using `angela files recent` to see tracked activities
- Run commands through Angela to ensure they're tracked
</file>

<file path="MD/PhasesMD/Phase7.md">
In this Phase 7 implementation, I've added comprehensive developer tool integration to Angela CLI, focusing on these key areas:

Advanced Code Generation Engine

Core generation engine for creating entire projects from descriptions
Project planner for designing comprehensive architectures
File content generation with inter-file dependency resolution
Code validation with language-specific syntax checkers


Toolchain Integration

Git integration for repository initialization and change management
Package manager integration (npm, pip, cargo, etc.) for dependency installation
Test framework integration to generate appropriate tests
CI/CD platform integration for DevOps configuration


Interactive Code Review

Diff management for comparing original and improved code
Feedback processing for refining existing code
Project-wide refinement based on natural language feedback


CLI Extensions

New commands for creating projects, adding features, and refining code
Interface for generating tests and CI configurations
Rich terminal output for better user experience



This implementation brings together all the previous phases (context awareness, file operations, workflow management) to provide a comprehensive developer experience. Users can now describe what they want in natural language, and Angela CLI will generate the appropriate code structures, handle dependencies, initialize source control, generate tests, and set up CI/CD pipelines.
Next Steps
After implementing Phase 7, here are some potential next steps for further enhancing Angela CLI:

Advanced Language Support

Add more language-specific generators and validators
Support for specialized frameworks (e.g., React, Django, Spring)
Language-specific refactoring and optimization suggestions


Collaborative Coding Improvements

Pull request generation and management
Code review suggestions based on common patterns
Integration with code quality tools (ESLint, Pylint, etc.)


Architectural Analysis

Deeper understanding of project architecture
Suggestions for architectural improvements
Detection of anti-patterns and technical debt


Project Evolution Tracking

Long-term project understanding
Context-aware suggestions based on project history
Performance and quality metrics over time


Enhanced Context Awareness

Integration with more developer tools (IDEs, issue trackers)
Documentation generation and management
Learning from user coding patterns and preferences



These improvements would further cement Angela CLI as an intelligent assistant throughout the entire software development lifecycle.
</file>

<file path="scripts/uninstall.sh">
#!/bin/bash
# Angela CLI Uninstallation Script

set -e

# ANSI color codes
GREEN='\033[0;32m'
BLUE='\033[0;34m'
RED='\033[0;31m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

echo -e "${BLUE}╔════════════════════════════════════════╗${NC}"
echo -e "${BLUE}║        Angela CLI Uninstallation       ║${NC}"
echo -e "${BLUE}╚════════════════════════════════════════╝${NC}"
echo

# Confirm uninstallation
echo -e "${YELLOW}Are you sure you want to uninstall Angela CLI? (y/n)${NC}"
read -r CONFIRM
if [[ ! "$CONFIRM" =~ ^[Yy]$ ]]; then
    echo -e "${RED}Uninstallation cancelled.${NC}"
    exit 0
fi

# Function to remove Bash integration
remove_bash_integration() {
    echo -e "${YELLOW}Removing Bash integration...${NC}"
    BASH_RC="$HOME/.bashrc"
    
    if grep -q "# Angela CLI Integration" "$BASH_RC"; then
        # Remove integration from .bashrc
        sed -i '/# Angela CLI Integration/,/# End Angela CLI Integration/d' "$BASH_RC"
        echo -e "${GREEN}Bash integration removed successfully!${NC}"
    else
        echo -e "${YELLOW}No Angela CLI integration found in $BASH_RC${NC}"
    fi
}

# Function to remove Zsh integration
remove_zsh_integration() {
    echo -e "${YELLOW}Removing Zsh integration...${NC}"
    ZSH_RC="$HOME/.zshrc"
    
    if grep -q "# Angela CLI Integration" "$ZSH_RC"; then
        # Remove integration from .zshrc
        sed -i '/# Angela CLI Integration/,/# End Angela CLI Integration/d' "$ZSH_RC"
        echo -e "${GREEN}Zsh integration removed successfully!${NC}"
    else
        echo -e "${YELLOW}No Angela CLI integration found in $ZSH_RC${NC}"
    fi
}

# Remove both integrations to ensure complete uninstallation
remove_bash_integration
remove_zsh_integration

# Remove configuration
echo -e "${YELLOW}Would you like to remove Angela CLI configuration? (y/n)${NC}"
read -r REMOVE_CONFIG
if [[ "$REMOVE_CONFIG" =~ ^[Yy]$ ]]; then
    CONFIG_DIR="$HOME/.config/angela"
    if [ -d "$CONFIG_DIR" ]; then
        rm -rf "$CONFIG_DIR"
        echo -e "${GREEN}Configuration removed successfully!${NC}"
    else
        echo -e "${YELLOW}No configuration directory found.${NC}"
    fi
fi

# Uninstall Python package
echo -e "${YELLOW}Would you like to uninstall the Angela CLI Python package? (y/n)${NC}"
read -r UNINSTALL_PACKAGE
if [[ "$UNINSTALL_PACKAGE" =~ ^[Yy]$ ]]; then
    echo -e "${YELLOW}Uninstalling Angela CLI Python package...${NC}"
    pip uninstall -y angela-cli
    echo -e "${GREEN}Python package uninstalled successfully!${NC}"
fi

echo
echo -e "${GREEN}╔════════════════════════════════════════╗${NC}"
echo -e "${GREEN}║   Angela CLI uninstalled successfully! ║${NC}"
echo -e "${GREEN}╚════════════════════════════════════════╝${NC}"
echo
echo -e "${YELLOW}Please restart your terminal for changes to take effect.${NC}"
echo
</file>

<file path=".env.example">
# Angela CLI Environment Variables

# Google Gemini API Key
# Get your API key from https://ai.google.dev/
GEMINI_API_KEY=your_gemini_api_key_here

# Debug mode (true/false)
DEBUG=false
</file>

<file path=".gitignore">
.env
</file>

<file path="Makefile">
.PHONY: install uninstall dev-setup clean test lint format

# Installation
install:
	@echo "Installing Angela CLI..."
	bash scripts/install.sh

uninstall:
	@echo "Uninstalling Angela CLI..."
	bash scripts/uninstall.sh

# Development
dev-setup:
	@echo "Setting up development environment..."
	pip install -e ".[dev]"
	@echo "Development environment set up successfully!"

# Testing
test:
	@echo "Running tests..."
	pytest

# Linting and formatting
lint:
	@echo "Running linters..."
	flake8 angela tests
	mypy angela tests

format:
	@echo "Formatting code..."
	black angela tests
	isort angela tests

# Cleaning
clean:
	@echo "Cleaning up..."
	rm -rf build/
	rm -rf dist/
	rm -rf *.egg-info
	rm -rf .pytest_cache
	rm -rf .mypy_cache
	find . -type d -name __pycache__ -exec rm -rf {} +
	find . -type f -name "*.pyc" -delete
	@echo "Cleanup complete!"

# Help
help:
	@echo "Angela CLI Makefile"
	@echo ""
	@echo "Usage:"
	@echo "  make install      Install Angela CLI"
	@echo "  make uninstall    Uninstall Angela CLI"
	@echo "  make dev-setup    Set up development environment"
	@echo "  make test         Run tests"
	@echo "  make lint         Run linters"
	@echo "  make format       Format code"
	@echo "  make clean        Clean up build artifacts"
	@echo "  make help         Show this help message"

# Default target
.DEFAULT_GOAL := help
</file>

<file path="pytest.ini">
[pytest]
asyncio_mode = strict
asyncio_default_fixture_loop_scope = function
</file>

<file path="requirements.txt">
# Core dependencies
typer>=0.9.0
rich>=13.4.2
pydantic>=2.0.0
click>=8.1.3

# Shell integration
pexpect>=4.8.0
prompt_toolkit>=3.0.38

# Configuration
python-dotenv>=1.0.0
tomli>=2.0.1; python_version < "3.11"

# API communication
aiohttp>=3.8.5
google-generativeai>=0.1.0

# Testing
pytest>=7.3.1
pytest-asyncio>=0.21.0

# Utilities
loguru>=0.7.0
</file>

<file path="setup.py">
from setuptools import setup

# Use pyproject.toml for project configuration
if __name__ == "__main__":
    setup()
</file>

<file path="angela/ai/__init__.py">
# angela/ai/__init__.py
"""
AI components for Angela CLI.
"""
from angela.ai.analyzer import error_analyzer
from angela.ai.client import gemini_client, GeminiRequest
from angela.ai.parser import parse_ai_response, CommandSuggestion
from angela.ai.prompts import build_prompt
from angela.ai.content_analyzer import content_analyzer
from angela.ai.confidence import confidence_scorer
</file>

<file path="angela/ai/content_analyzer_extensions.py">
# angela/ai/content_analyzer_extensions.py

from typing import Dict, Any, Union, Optional
from pathlib import Path
import re
import json

from angela.ai.content_analyzer import ContentAnalyzer, content_analyzer
from angela.utils.logging import get_logger

logger = get_logger(__name__)

class EnhancedContentAnalyzer(ContentAnalyzer):
    """Extended content analyzer with support for additional file types and languages."""
    
    # Language-specific analysis handlers 
    LANGUAGE_HANDLERS = {
        # Existing handlers
        "Python": "_analyze_python",
        "JavaScript": "_analyze_javascript",
        "HTML": "_analyze_html",
        "CSS": "_analyze_css",
        
        # New handlers
        "TypeScript": "_analyze_typescript",
        "Java": "_analyze_java",
        "Rust": "_analyze_rust",
        "Go": "_analyze_go",
        "Ruby": "_analyze_ruby",
        "PHP": "_analyze_php",
        "C": "_analyze_c",
        "CPP": "_analyze_cpp",
        "CSharp": "_analyze_csharp",
        "Swift": "_analyze_swift",
        "Kotlin": "_analyze_kotlin",
        
        # Data formats
        "JSON": "_analyze_json",
        "YAML": "_analyze_yaml",
        "XML": "_analyze_xml",
        "CSV": "_analyze_csv",
        
        # Config files
        "Dockerfile": "_analyze_dockerfile",
        "Makefile": "_analyze_makefile",
    }
    
   async def analyze_content(self, file_path, request=None):
        """Override the base analyze_content method to use specialized analyzers."""
        result = await super().analyze_content(file_path, request)
        
        # If we got an error, return it
        if "error" in result:
            return result
        
        # Check if we have a specialized analyzer for this file type
        file_type = result.get("type", "unknown")
        language = result.get("language", "unknown").lower()
        
        specialized_analyzer = self._specialized_analyzers.get(language)
        if specialized_analyzer:
            try:
                enhanced_result = await specialized_analyzer(file_path, request)
                if enhanced_result:
                    # Merge the enhanced result with the base result
                    result.update(enhanced_result)
            except Exception as e:
                self._logger.error(f"Error in specialized analyzer for {language}: {str(e)}")
        
        return result
    
    async def _analyze_python(self, file_path, request=None):
        """Specialized analyzer for Python files."""
        # Example implementation - you would expand this
        import ast
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Parse the AST
            tree = ast.parse(content)
            
            # Extract classes and functions
            classes = []
            functions = []
            
            for node in ast.walk(tree):
                if isinstance(node, ast.ClassDef):
                    classes.append({
                        "name": node.name,
                        "line": node.lineno,
                        "methods": [m.name for m in node.body if isinstance(m, ast.FunctionDef)]
                    })
                elif isinstance(node, ast.FunctionDef):
                    if not any(isinstance(parent, ast.ClassDef) for parent in ast.iter_path(tree, node)):
                        functions.append({
                            "name": node.name,
                            "line": node.lineno,
                            "args": [a.arg for a in node.args.args]
                        })
            
            return {
                "classes": classes,
                "functions": functions,
                "imports": self._extract_python_imports(content)
            }
        except Exception as e:
            self._logger.error(f"Error analyzing Python file: {str(e)}")
            return None
    
    def _extract_python_imports(self, content):
        """Extract import statements from Python code."""
        import_pattern = r'^(?:from\s+(\S+)\s+)?import\s+(.+)$'
        imports = []
        
        for line in content.splitlines():
            line = line.strip()
            match = re.match(import_pattern, line)
            if match:
                from_module, imported = match.groups()
                imports.append({
                    "from_module": from_module,
                    "imported": [name.strip() for name in imported.split(',')]
                })
        
        return imports
    
    async def _analyze_typescript(self, file_path, request=None):
        """Specialized analyzer for TypeScript files."""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Extract interfaces and types
            types = self._extract_typescript_types(content)
            
            # For more complex analysis, we can use the AI
            prompt = f"""
                Analyze this TypeScript file and extract key information:
                
                ```typescript
                {content[:20000]}  # Limit for large files
                ```
                
                Identify and describe:
                1. Interfaces and their properties
                2. Type definitions
                3. Classes and their methods
                4. Key functions and their purposes
                5. Design patterns used
                6. Dependencies and imports
                
                Format your response as a structured analysis.
                """
                
            # Call AI for analysis
            response = await self._get_ai_analysis(prompt)
            
            return {
                "types": types,
                "ai_analysis": response
            }
        except Exception as e:
            self._logger.error(f"Error analyzing TypeScript file: {str(e)}")
            return None
    
    def _extract_typescript_types(self, content: str) -> List[Dict[str, Any]]:
        """Extract interface and type definitions from TypeScript code."""
        interface_pattern = r'interface\s+(\w+)(?:\s+extends\s+(\w+))?\s*\{([^}]*)\}'
        type_pattern = r'type\s+(\w+)\s*=\s*(.+?);'
        
        interfaces = []
        for match in re.finditer(interface_pattern, content, re.DOTALL):
            name, extends, body = match.groups()
            properties = {}
            
            # Parse properties
            prop_pattern = r'(\w+)(?:\?)?:\s*([^;]+);'
            for prop_match in re.finditer(prop_pattern, body):
                prop_name, prop_type = prop_match.groups()
                properties[prop_name] = prop_type.strip()
            
            interfaces.append({
                "name": name,
                "extends": extends,
                "properties": properties
            })
        
        types = []
        for match in re.finditer(type_pattern, content, re.DOTALL):
            name, definition = match.groups()
            types.append({
                "name": name,
                "definition": definition.strip()
            })
        
        return interfaces + types
    
    async def _analyze_javascript(self, file_path, request=None):
        """Specialized analyzer for JavaScript files."""
        # Similar implementation to TypeScript but without type information
        pass
    
    async def _analyze_json(self, file_path, request=None):
        """Specialized analyzer for JSON files."""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Parse the JSON
            data = json.loads(content)
            
            # Infer schema
            schema = self._infer_json_schema(data)
            
            return {
                "schema": schema,
                "keys": list(data.keys()) if isinstance(data, dict) else [],
                "array_length": len(data) if isinstance(data, list) else None,
                "data_preview": str(data)[:1000] + "..." if len(str(data)) > 1000 else str(data)
            }
        except Exception as e:
            self._logger.error(f"Error analyzing JSON file: {str(e)}")
            return None
    
    def _infer_json_schema(self, data):
        """Infer a simple schema from JSON data."""
        if isinstance(data, dict):
            schema = {}
            for key, value in data.items():
                schema[key] = self._get_type(value)
            return {"type": "object", "properties": schema}
        elif isinstance(data, list):
            if not data:
                return {"type": "array", "items": {"type": "unknown"}}
            
            # Get the type of the first item
            first_item_type = self._get_type(data[0])
            
            # Check if all items have the same type
            same_type = all(self._get_type(item) == first_item_type for item in data)
            
            if same_type:
                return {"type": "array", "items": first_item_type}
            else:
                return {"type": "array", "items": {"type": "mixed"}}
        else:
            return self._get_type(data)
    
    def _get_type(self, value):
        """Get the type of a JSON value."""
        if value is None:
            return {"type": "null"}
        elif isinstance(value, bool):
            return {"type": "boolean"}
        elif isinstance(value, int):
            return {"type": "integer"}
        elif isinstance(value, float):
            return {"type": "number"}
        elif isinstance(value, str):
            return {"type": "string"}
        elif isinstance(value, dict):
            schema = {}
            for key, val in value.items():
                schema[key] = self._get_type(val)
            return {"type": "object", "properties": schema}
        elif isinstance(value, list):
            if not value:
                return {"type": "array", "items": {"type": "unknown"}}
            return {"type": "array", "items": self._get_type(value[0])}
        else:
            return {"type": "unknown"}
    
    async def _analyze_yaml(self, file_path, request=None):
        """Specialized analyzer for YAML files."""
        # Implementation similar to JSON
        pass
    
    async def _analyze_markdown(self, file_path, request=None):
        """Specialized analyzer for Markdown files."""
        # Extract headings, links, etc.
        pass
    
    async def _analyze_html(self, file_path, request=None):
        """Specialized analyzer for HTML files."""
        # Extract elements, links, scripts, etc.
        pass
    
    async def _analyze_css(self, file_path, request=None):
        """Specialized analyzer for CSS files."""
        # Extract selectors, properties, etc.
        pass
    
    async def _analyze_sql(self, file_path, request=None):
        """Specialized analyzer for SQL files."""
        # Extract tables, queries, etc.
        pass
    
    async def _get_ai_analysis(self, prompt):
        """Get analysis from the AI service."""
        api_request = GeminiRequest(
            prompt=prompt,
            max_tokens=4000
        )
        
        response = await gemini_client.generate_text(api_request)
        return response.text
</file>

<file path="angela/ai/semantic_analyzer.py">
"""
Semantic code analysis for Angela CLI.

This module provides deep code understanding capabilities, extracting semantic
information from source code files to enable context-aware assistance.
"""
import os
import re
import ast
import json
import asyncio
import importlib.util
from pathlib import Path
from typing import Dict, Any, List, Tuple, Optional, Set, Union, NamedTuple
from collections import defaultdict

from angela.utils.logging import get_logger
from angela.context.file_detector import detect_file_type
from angela.ai.client import gemini_client, GeminiRequest

logger = get_logger(__name__)

class CodeEntity:
    """Base class for code entities like functions, classes, and variables."""
    
    def __init__(self, name: str, line_start: int, line_end: int, filename: str):
        self.name = name
        self.line_start = line_start
        self.line_end = line_end
        self.filename = filename
        self.references: List[Tuple[str, int]] = []  # (filename, line)
        self.dependencies: List[str] = []  # Names of other entities this depends on
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization."""
        return {
            "name": self.name,
            "type": self.__class__.__name__,
            "line_start": self.line_start,
            "line_end": self.line_end,
            "filename": self.filename,
            "references": self.references,
            "dependencies": self.dependencies
        }
    
    def __str__(self) -> str:
        return f"{self.__class__.__name__}(name={self.name}, file={Path(self.filename).name}:{self.line_start}-{self.line_end})"


class Function(CodeEntity):
    """Represents a function or method in code."""
    
    def __init__(self, name: str, line_start: int, line_end: int, filename: str, 
                 params: List[str], docstring: Optional[str] = None,
                 is_method: bool = False, decorators: List[str] = None,
                 return_type: Optional[str] = None, class_name: Optional[str] = None):
        super().__init__(name, line_start, line_end, filename)
        self.params = params
        self.docstring = docstring
        self.is_method = is_method
        self.decorators = decorators or []
        self.return_type = return_type
        self.class_name = class_name
        self.called_functions: List[str] = []
        self.complexity: Optional[int] = None  # Cyclomatic complexity
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization."""
        result = super().to_dict()
        result.update({
            "params": self.params,
            "docstring": self.docstring,
            "is_method": self.is_method,
            "decorators": self.decorators,
            "return_type": self.return_type,
            "class_name": self.class_name,
            "called_functions": self.called_functions,
            "complexity": self.complexity
        })
        return result


class Class(CodeEntity):
    """Represents a class in code."""
    
    def __init__(self, name: str, line_start: int, line_end: int, filename: str,
                 docstring: Optional[str] = None, base_classes: List[str] = None,
                 decorators: List[str] = None):
        super().__init__(name, line_start, line_end, filename)
        self.docstring = docstring
        self.base_classes = base_classes or []
        self.decorators = decorators or []
        self.methods: Dict[str, Function] = {}
        self.attributes: Dict[str, Variable] = {}
        self.nested_classes: Dict[str, 'Class'] = {}
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization."""
        result = super().to_dict()
        result.update({
            "docstring": self.docstring,
            "base_classes": self.base_classes,
            "decorators": self.decorators,
            "methods": {name: method.to_dict() for name, method in self.methods.items()},
            "attributes": {name: attr.to_dict() for name, attr in self.attributes.items()},
            "nested_classes": {name: cls.to_dict() for name, cls in self.nested_classes.items()}
        })
        return result


class Variable(CodeEntity):
    """Represents a variable or attribute in code."""
    
    def __init__(self, name: str, line_start: int, line_end: int, filename: str,
                 var_type: Optional[str] = None, value: Optional[str] = None,
                 is_attribute: bool = False, class_name: Optional[str] = None,
                 is_constant: bool = False):
        super().__init__(name, line_start, line_end, filename)
        self.var_type = var_type
        self.value = value
        self.is_attribute = is_attribute
        self.class_name = class_name
        self.is_constant = is_constant
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization."""
        result = super().to_dict()
        result.update({
            "var_type": self.var_type,
            "value": self.value,
            "is_attribute": self.is_attribute,
            "class_name": self.class_name,
            "is_constant": self.is_constant
        })
        return result


class Import(CodeEntity):
    """Represents an import statement."""
    
    def __init__(self, name: str, line_start: int, line_end: int, filename: str,
                 import_path: str, is_from: bool = False, alias: Optional[str] = None):
        super().__init__(name, line_start, line_end, filename)
        self.import_path = import_path
        self.is_from = is_from
        self.alias = alias
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization."""
        result = super().to_dict()
        result.update({
            "import_path": self.import_path,
            "is_from": self.is_from,
            "alias": self.alias
        })
        return result


class Module:
    """Represents a code module (file) with its entities."""
    
    def __init__(self, filename: str):
        self.filename = filename
        self.imports: Dict[str, Import] = {}
        self.functions: Dict[str, Function] = {}
        self.classes: Dict[str, Class] = {}
        self.variables: Dict[str, Variable] = {}
        self.docstring: Optional[str] = None
        self.language: Optional[str] = None
        self.dependencies: List[str] = []
        self.last_modified: Optional[float] = None
        self.code_metrics: Dict[str, Any] = {}
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization."""
        return {
            "filename": self.filename,
            "imports": {name: imp.to_dict() for name, imp in self.imports.items()},
            "functions": {name: func.to_dict() for name, func in self.functions.items()},
            "classes": {name: cls.to_dict() for name, cls in self.classes.items()},
            "variables": {name: var.to_dict() for name, var in self.variables.items()},
            "docstring": self.docstring,
            "language": self.language,
            "dependencies": self.dependencies,
            "last_modified": self.last_modified,
            "code_metrics": self.code_metrics
        }

    def get_summary(self) -> Dict[str, Any]:
        """Get a simplified summary of the module."""
        return {
            "filename": self.filename,
            "name": Path(self.filename).name,
            "language": self.language,
            "class_count": len(self.classes),
            "function_count": len(self.functions),
            "import_count": len(self.imports),
            "docstring": self.docstring[:100] + "..." if self.docstring and len(self.docstring) > 100 else self.docstring,
            "classes": list(self.classes.keys()),
            "key_functions": list(self.functions.keys())[:5] + (["..."] if len(self.functions) > 5 else []),
            "dependencies": self.dependencies
        }


class SemanticAnalyzer:
    """
    Semantic code analyzer that extracts deeper meaning from source files.
    
    This class provides:
    1. Extraction of code structure (functions, classes, variables)
    2. Analysis of dependencies and references
    3. Code metrics and complexity information
    4. Integration with the LLM for deeper insights
    """
    
    def __init__(self):
        self._logger = logger
        self._modules: Dict[str, Module] = {}
        self._language_analyzers: Dict[str, callable] = {
            "python": self._analyze_python_file,
            "javascript": self._analyze_javascript_file,
            "typescript": self._analyze_typescript_file,
            "java": self._analyze_with_llm,
            "c#": self._analyze_with_llm,
            "c++": self._analyze_with_llm,
            "ruby": self._analyze_with_llm,
            "go": self._analyze_with_llm,
            "rust": self._analyze_with_llm
        }
        self._cache_valid_time = 300  # Seconds before a cached analysis is considered stale
    
    async def analyze_file(self, file_path: Union[str, Path]) -> Optional[Module]:
        """
        Analyze a source code file to extract semantic information.
        
        Args:
            file_path: Path to the file to analyze
            
        Returns:
            Module object with semantic information or None if analysis failed
        """
        path_obj = Path(file_path)
        
        # Check if we have a recent cached analysis
        if str(path_obj) in self._modules:
            module = self._modules[str(path_obj)]
            if module.last_modified and path_obj.stat().st_mtime <= module.last_modified:
                self._logger.debug(f"Using cached analysis for {path_obj}")
                return module
        
        # Check if file exists
        if not path_obj.exists():
            self._logger.warning(f"File not found for semantic analysis: {path_obj}")
            return None
        
        # Detect file type
        file_info = detect_file_type(path_obj)
        language = file_info.get("language", "").lower()
        
        # Skip if this isn't a supported code file
        if not language or language.lower() not in self._language_analyzers:
            self._logger.debug(f"Unsupported language for semantic analysis: {language} in {path_obj}")
            return None
        
        # Create a new module
        module = Module(str(path_obj))
        module.language = language
        module.last_modified = path_obj.stat().st_mtime
        
        try:
            # Call the appropriate analyzer based on language
            analyzer = self._language_analyzers.get(language.lower(), self._analyze_with_llm)
            
            if asyncio.iscoroutinefunction(analyzer):
                result = await analyzer(path_obj, module)
            else:
                result = analyzer(path_obj, module)
            
            if result:
                self._modules[str(path_obj)] = module
                self._logger.info(f"Completed semantic analysis of {path_obj}")
                return module
        except Exception as e:
            self._logger.exception(f"Error analyzing {path_obj}: {str(e)}")
        
        return None
    
    async def analyze_project_files(self, project_root: Union[str, Path], max_files: int = 100) -> Dict[str, Module]:
        """
        Analyze multiple source files within a project.
        
        Args:
            project_root: Root directory of the project
            max_files: Maximum number of files to analyze
            
        Returns:
            Dictionary of file paths to Module objects
        """
        root_path = Path(project_root)
        
        # Find source code files
        source_files = []
        
        for language, _ in self._language_analyzers.items():
            extensions = self._get_extensions_for_language(language)
            for ext in extensions:
                source_files.extend(list(root_path.glob(f"**/*{ext}")))
        
        # Exclude files that shouldn't be analyzed
        exclude_patterns = [
            "**/node_modules/**", "**/venv/**", "**/.venv/**",
            "**/.git/**", "**/build/**", "**/dist/**",
            "**/__pycache__/**", "**/.pytest_cache/**"
        ]
        
        for pattern in exclude_patterns:
            source_files = [f for f in source_files if not self._matches_glob_pattern(str(f), pattern)]
        
        # Limit to max files
        source_files = source_files[:max_files]
        
        # Analyze each file
        analysis_results = {}
        
        for file_path in source_files:
            module = await self.analyze_file(file_path)
            if module:
                analysis_results[str(file_path)] = module
        
        # Analyze references between modules
        self._analyze_cross_module_references(analysis_results)
        
        return analysis_results
    
    def _get_extensions_for_language(self, language: str) -> List[str]:
        """Get file extensions for a given language."""
        extensions_map = {
            "python": [".py", ".pyi", ".pyx"],
            "javascript": [".js", ".jsx", ".mjs"],
            "typescript": [".ts", ".tsx"],
            "java": [".java"],
            "c#": [".cs"],
            "c++": [".cpp", ".cc", ".h", ".hpp"],
            "ruby": [".rb"],
            "go": [".go"],
            "rust": [".rs"]
        }
        
        return extensions_map.get(language.lower(), [])
    
    def _matches_glob_pattern(self, path: str, pattern: str) -> bool:
        """Check if a path matches a glob pattern."""
        import fnmatch
        return fnmatch.fnmatch(path, pattern)
    
    def _analyze_python_file(self, file_path: Path, module: Module) -> bool:
        """
        Analyze a Python file using the ast module.
        
        Args:
            file_path: Path to the Python file
            module: Module object to populate
            
        Returns:
            True if analysis was successful, False otherwise
        """
        # Read the file content
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except Exception as e:
            self._logger.error(f"Error reading Python file {file_path}: {str(e)}")
            return False
        
        # Parse the AST
        try:
            tree = ast.parse(content, filename=str(file_path))
            
            # Get module docstring
            module.docstring = ast.get_docstring(tree)
            
            # Visit all nodes in the AST to extract information
            for node in ast.walk(tree):
                # Extract imports
                if isinstance(node, ast.Import):
                    for name in node.names:
                        import_name = name.asname or name.name
                        module.imports[import_name] = Import(
                            name=import_name,
                            line_start=node.lineno,
                            line_end=node.lineno,
                            filename=str(file_path),
                            import_path=name.name,
                            is_from=False,
                            alias=name.asname
                        )
                        module.dependencies.append(name.name)
                
                elif isinstance(node, ast.ImportFrom):
                    module_name = node.module or ""
                    for name in node.names:
                        import_name = name.asname or name.name
                        full_path = f"{module_name}.{name.name}" if module_name else name.name
                        module.imports[import_name] = Import(
                            name=import_name,
                            line_start=node.lineno,
                            line_end=node.lineno,
                            filename=str(file_path),
                            import_path=full_path,
                            is_from=True,
                            alias=name.asname
                        )
                        module.dependencies.append(full_path)
                
                # Extract functions
                elif isinstance(node, ast.FunctionDef) or isinstance(node, ast.AsyncFunctionDef):
                    # Check if we're inside a class
                    parent_class = None
                    for ancestor in ast.iter_fields(tree):
                        if isinstance(ancestor[1], list):
                            for item in ancestor[1]:
                                if isinstance(item, ast.ClassDef) and node in item.body:
                                    parent_class = item.name
                                    break
                    
                    # Get function parameters
                    params = []
                    for arg in node.args.args:
                        params.append(arg.arg)
                    
                    # Get decorators
                    decorators = []
                    for decorator in node.decorator_list:
                        if isinstance(decorator, ast.Name):
                            decorators.append(decorator.id)
                        elif isinstance(decorator, ast.Attribute):
                            decorators.append(f"{decorator.value.id}.{decorator.attr}")
                        elif isinstance(decorator, ast.Call):
                            if isinstance(decorator.func, ast.Name):
                                decorators.append(decorator.func.id)
                            elif isinstance(decorator.func, ast.Attribute):
                                decorators.append(f"{decorator.func.value.id}.{decorator.func.attr}")
                    
                    # Get return type annotation if available
                    return_type = None
                    if node.returns:
                        return_type = self._get_type_annotation(node.returns)
                    
                    # Create function entity
                    function = Function(
                        name=node.name,
                        line_start=node.lineno,
                        line_end=self._get_last_line(node),
                        filename=str(file_path),
                        params=params,
                        docstring=ast.get_docstring(node),
                        is_method=parent_class is not None,
                        decorators=decorators,
                        return_type=return_type,
                        class_name=parent_class
                    )
                    
                    # Extract called functions
                    for child in ast.walk(node):
                        if isinstance(child, ast.Call):
                            if isinstance(child.func, ast.Name):
                                function.called_functions.append(child.func.id)
                            elif isinstance(child.func, ast.Attribute):
                                if isinstance(child.func.value, ast.Name):
                                    function.called_functions.append(f"{child.func.value.id}.{child.func.attr}")
                    
                    # Calculate cyclomatic complexity
                    function.complexity = self._calculate_complexity(node)
                    
                    # Store the function in the appropriate place
                    if parent_class and parent_class in module.classes:
                        module.classes[parent_class].methods[node.name] = function
                    else:
                        module.functions[node.name] = function
                
                # Extract classes
                elif isinstance(node, ast.ClassDef):
                    # Get base classes
                    base_classes = []
                    for base in node.bases:
                        if isinstance(base, ast.Name):
                            base_classes.append(base.id)
                        elif isinstance(base, ast.Attribute):
                            base_classes.append(f"{base.value.id}.{base.attr}")
                    
                    # Get decorators
                    decorators = []
                    for decorator in node.decorator_list:
                        if isinstance(decorator, ast.Name):
                            decorators.append(decorator.id)
                    
                    # Create class entity
                    class_entity = Class(
                        name=node.name,
                        line_start=node.lineno,
                        line_end=self._get_last_line(node),
                        filename=str(file_path),
                        docstring=ast.get_docstring(node),
                        base_classes=base_classes,
                        decorators=decorators
                    )
                    
                    # Look for class attributes
                    for child in node.body:
                        if isinstance(child, ast.Assign):
                            for target in child.targets:
                                if isinstance(target, ast.Name):
                                    # Get value as string
                                    value = None
                                    if isinstance(child.value, ast.Constant):
                                        value = str(child.value.value)
                                    
                                    # Create attribute entity
                                    attribute = Variable(
                                        name=target.id,
                                        line_start=child.lineno,
                                        line_end=child.lineno,
                                        filename=str(file_path),
                                        var_type=None,  # No type annotation in assign
                                        value=value,
                                        is_attribute=True,
                                        class_name=node.name
                                    )
                                    
                                    class_entity.attributes[target.id] = attribute
                        
                        elif isinstance(child, ast.AnnAssign) and isinstance(child.target, ast.Name):
                            # Get type annotation
                            var_type = self._get_type_annotation(child.annotation)
                            
                            # Get value as string
                            value = None
                            if child.value and isinstance(child.value, ast.Constant):
                                value = str(child.value.value)
                            
                            # Create attribute entity
                            attribute = Variable(
                                name=child.target.id,
                                line_start=child.lineno,
                                line_end=child.lineno,
                                filename=str(file_path),
                                var_type=var_type,
                                value=value,
                                is_attribute=True,
                                class_name=node.name
                            )
                            
                            class_entity.attributes[child.target.id] = attribute
                    
                    module.classes[node.name] = class_entity
                
                # Extract global variables
                elif isinstance(node, ast.Assign) and all(isinstance(target, ast.Name) for target in node.targets):
                    for target in node.targets:
                        # Skip private variables
                        if target.id.startswith('_'):
                            continue
                        
                        # Get value as string
                        value = None
                        if isinstance(node.value, ast.Constant):
                            value = str(node.value.value)
                        
                        # Check if this is a constant
                        is_constant = target.id.isupper()
                        
                        # Create variable entity
                        variable = Variable(
                            name=target.id,
                            line_start=node.lineno,
                            line_end=node.lineno,
                            filename=str(file_path),
                            var_type=None,  # No type annotation in assign
                            value=value,
                            is_constant=is_constant
                        )
                        
                        module.variables[target.id] = variable
                
                elif isinstance(node, ast.AnnAssign) and isinstance(node.target, ast.Name):
                    # Skip private variables
                    if node.target.id.startswith('_'):
                        continue
                    
                    # Get type annotation
                    var_type = self._get_type_annotation(node.annotation)
                    
                    # Get value as string
                    value = None
                    if node.value and isinstance(node.value, ast.Constant):
                        value = str(node.value.value)
                    
                    # Check if this is a constant
                    is_constant = node.target.id.isupper()
                    
                    # Create variable entity
                    variable = Variable(
                        name=node.target.id,
                        line_start=node.lineno,
                        line_end=node.lineno,
                        filename=str(file_path),
                        var_type=var_type,
                        value=value,
                        is_constant=is_constant
                    )
                    
                    module.variables[node.target.id] = variable
            
            # Calculate code metrics
            module.code_metrics = {
                "total_lines": len(content.splitlines()),
                "code_lines": len([line for line in content.splitlines() if line.strip() and not line.strip().startswith('#')]),
                "comment_lines": len([line for line in content.splitlines() if line.strip().startswith('#')]),
                "blank_lines": len([line for line in content.splitlines() if not line.strip()]),
                "function_count": len(module.functions),
                "class_count": len(module.classes),
                "import_count": len(module.imports),
                "complexity": sum(func.complexity or 0 for func in module.functions.values()),
                "average_function_size": sum(func.line_end - func.line_start for func in module.functions.values()) / len(module.functions) if module.functions else 0
            }
            
            return True
        
        except SyntaxError as e:
            self._logger.warning(f"Syntax error in Python file {file_path}: {str(e)}")
            return False
            
        except Exception as e:
            self._logger.error(f"Error parsing Python file {file_path}: {str(e)}")
            return False
    
    def _get_type_annotation(self, annotation) -> Optional[str]:
        """Extract type annotation string from AST node."""
        if isinstance(annotation, ast.Name):
            return annotation.id
        elif isinstance(annotation, ast.Attribute):
            if isinstance(annotation.value, ast.Name):
                return f"{annotation.value.id}.{annotation.attr}"
            return annotation.attr
        elif isinstance(annotation, ast.Subscript):
            if isinstance(annotation.value, ast.Name):
                if isinstance(annotation.slice, ast.Name):
                    return f"{annotation.value.id}[{annotation.slice.id}]"
                elif isinstance(annotation.slice, ast.Constant):
                    return f"{annotation.value.id}[{annotation.slice.value}]"
                return f"{annotation.value.id}[...]"
            return "..."
        return None
    
    def _get_last_line(self, node) -> int:
        """Get the last line number of an AST node."""
        # If the node has an end_lineno attribute (Python 3.8+), use it
        if hasattr(node, 'end_lineno'):
            return node.end_lineno
        
        # Otherwise, find the maximum lineno in the node and its children
        max_lineno = node.lineno
        for child in ast.iter_child_nodes(node):
            max_lineno = max(max_lineno, self._get_last_line(child))
        return max_lineno
    
    def _calculate_complexity(self, node) -> int:
        """Calculate cyclomatic complexity of a function."""
        complexity = 1  # Start with 1 (default path)
        
        # Count branches
        for child in ast.walk(node):
            if isinstance(child, (ast.If, ast.While, ast.For, ast.IfExp)):
                complexity += 1
            elif isinstance(child, ast.BoolOp) and isinstance(child.op, ast.And):
                complexity += len(child.values) - 1
            elif isinstance(child, ast.BoolOp) and isinstance(child.op, ast.Or):
                complexity += len(child.values) - 1
            elif isinstance(child, ast.Try):
                complexity += len(child.handlers)  # Count except blocks
        
        return complexity
    
    async def _analyze_javascript_file(self, file_path: Path, module: Module) -> bool:
        """
        Analyze a JavaScript file using a simple regex-based approach or LLM.
        
        Args:
            file_path: Path to the JavaScript file
            module: Module object to populate
            
        Returns:
            True if analysis was successful, False otherwise
        """
        # For non-Python files, we'll use a simple regex-based approach for now
        # In a real implementation, you might want to use language-specific parsers
        
        try:
            # Read the file content
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Extract imports/requires
            import_patterns = [
                r'import\s+{([^}]+)}\s+from\s+[\'"]([^\'"]+)[\'"]',  # import { x, y } from 'module'
                r'import\s+(\w+)\s+from\s+[\'"]([^\'"]+)[\'"]',  # import x from 'module'
                r'import\s+[\'"]([^\'"]+)[\'"]',  # import 'module'
                r'const\s+{([^}]+)}\s+=\s+require\([\'"]([^\'"]+)[\'"]\)',  # const { x, y } = require('module')
                r'const\s+(\w+)\s+=\s+require\([\'"]([^\'"]+)[\'"]\)'  # const x = require('module')
            ]
            
            line_num = 1
            for line in content.splitlines():
                for pattern in import_patterns:
                    for match in re.finditer(pattern, line):
                        if len(match.groups()) == 2:
                            names, module_path = match.groups()
                            if ',' in names:
                                # Multiple imports
                                for name in names.split(','):
                                    name = name.strip()
                                    if name:
                                        module.imports[name] = Import(
                                            name=name,
                                            line_start=line_num,
                                            line_end=line_num,
                                            filename=str(file_path),
                                            import_path=f"{module_path}.{name}",
                                            is_from=True
                                        )
                                        module.dependencies.append(module_path)
                            else:
                                # Single import
                                name = names.strip()
                                module.imports[name] = Import(
                                    name=name,
                                    line_start=line_num,
                                    line_end=line_num,
                                    filename=str(file_path),
                                    import_path=module_path,
                                    is_from=True
                                )
                                module.dependencies.append(module_path)
                        else:
                            # Simple import
                            module_path = match.group(1)
                            module.dependencies.append(module_path)
                line_num += 1
            
            # Extract functions
            function_patterns = [
                r'function\s+(\w+)\s*\(([^)]*)\)',  # function name(params)
                r'const\s+(\w+)\s*=\s*(?:async\s*)?\([^)]*\)\s*=>\s*{',  # const name = (params) => {
                r'let\s+(\w+)\s*=\s*(?:async\s*)?\([^)]*\)\s*=>\s*{',  # let name = (params) => {
                r'var\s+(\w+)\s*=\s*(?:async\s*)?\([^)]*\)\s*=>\s*{',  # var name = (params) => {
                r'async\s+function\s+(\w+)\s*\(([^)]*)\)'  # async function name(params)
            ]
            
            for pattern in function_patterns:
                for match in re.finditer(pattern, content, re.MULTILINE):
                    name = match.group(1)
                    params = []
                    if len(match.groups()) > 1:
                        params = [p.strip() for p in match.group(2).split(',') if p.strip()]
                    
                    start_line = content[:match.start()].count('\n') + 1
                    end_line = start_line + content[match.start():].split('{', 1)[1].count('\n')
                    
                    function = Function(
                        name=name,
                        line_start=start_line,
                        line_end=end_line if end_line > start_line else start_line + 5,  # Estimate if we couldn't find the end
                        filename=str(file_path),
                        params=params
                    )
                    
                    module.functions[name] = function
            
            # Extract classes
            class_pattern = r'class\s+(\w+)(?:\s+extends\s+(\w+))?\s*{'
            for match in re.finditer(class_pattern, content, re.MULTILINE):
                name = match.group(1)
                base_classes = []
                if match.group(2):
                    base_classes.append(match.group(2))
                
                start_line = content[:match.start()].count('\n') + 1
                
                # Try to find the end of the class
                class_content = content[match.start():]
                open_braces = 0
                for i, char in enumerate(class_content):
                    if char == '{':
                        open_braces += 1
                    elif char == '}':
                        open_braces -= 1
                        if open_braces == 0:
                            end_line = start_line + class_content[:i+1].count('\n')
                            break
                else:
                    end_line = start_line + 20  # Estimate if we couldn't find the end
                
                class_entity = Class(
                    name=name,
                    line_start=start_line,
                    line_end=end_line,
                    filename=str(file_path),
                    base_classes=base_classes
                )
                
                module.classes[name] = class_entity
            
            # Calculate code metrics
            module.code_metrics = {
                "total_lines": len(content.splitlines()),
                "code_lines": len([line for line in content.splitlines() if line.strip() and not line.strip().startswith('//')]),
                "comment_lines": len([line for line in content.splitlines() if line.strip().startswith('//')]),
                "blank_lines": len([line for line in content.splitlines() if not line.strip()]),
                "function_count": len(module.functions),
                "class_count": len(module.classes),
                "import_count": len(module.imports)
            }
            
            return True
            
        except Exception as e:
            self._logger.error(f"Error analyzing JavaScript file {file_path}: {str(e)}")
            return False
    
    async def _analyze_typescript_file(self, file_path: Path, module: Module) -> bool:
        """
        Analyze a TypeScript file.
        
        Args:
            file_path: Path to the TypeScript file
            module: Module object to populate
            
        Returns:
            True if analysis was successful, False otherwise
        """
        # Start with JavaScript analysis
        js_result = await self._analyze_javascript_file(file_path, module)
        
        if not js_result:
            return False
        
        try:
            # Read the file content
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Extract interfaces
            interface_pattern = r'interface\s+(\w+)(?:\s+extends\s+(\w+))?\s*{'
            for match in re.finditer(interface_pattern, content, re.MULTILINE):
                name = match.group(1)
                base_classes = []
                if match.group(2):
                    base_classes.append(match.group(2))
                
                start_line = content[:match.start()].count('\n') + 1
                
                # Try to find the end of the interface
                interface_content = content[match.start():]
                open_braces = 0
                for i, char in enumerate(interface_content):
                    if char == '{':
                        open_braces += 1
                    elif char == '}':
                        open_braces -= 1
                        if open_braces == 0:
                            end_line = start_line + interface_content[:i+1].count('\n')
                            break
                else:
                    end_line = start_line + 10  # Estimate if we couldn't find the end
                
                # Treat interfaces as classes for simplicity
                class_entity = Class(
                    name=name,
                    line_start=start_line,
                    line_end=end_line,
                    filename=str(file_path),
                    base_classes=base_classes
                )
                
                module.classes[name] = class_entity
            
            # Extract types
            type_pattern = r'type\s+(\w+)\s*=\s*\{[^}]*\}'
            for match in re.finditer(type_pattern, content, re.MULTILINE):
                name = match.group(1)
                
                start_line = content[:match.start()].count('\n') + 1
                end_line = start_line + content[match.start():match.end()].count('\n')
                
                # For simplicity, we'll store types as variables
                variable = Variable(
                    name=name,
                    line_start=start_line,
                    line_end=end_line,
                    filename=str(file_path),
                    var_type="type",
                    is_constant=True
                )
                
                module.variables[name] = variable
            
            # Update functions and class methods with type information
            for name, function in module.functions.items():
                # Try to find the function with type annotations
                function_pattern = fr'function\s+{re.escape(name)}\s*\([^)]*\)\s*:\s*(\w+)'
                match = re.search(function_pattern, content)
                if match:
                    function.return_type = match.group(1)
            
            return True
            
        except Exception as e:
            self._logger.error(f"Error analyzing TypeScript file {file_path}: {str(e)}")
            return False
    
    async def _analyze_with_llm(self, file_path: Path, module: Module) -> bool:
        """
        Use the LLM to analyze files when language-specific parsers aren't available.
        
        Args:
            file_path: Path to the file
            module: Module object to populate
            
        Returns:
            True if analysis was successful, False otherwise
        """
        try:
            # Read the file content
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Limit content size for LLM
            if len(content) > 20000:
                self._logger.warning(f"File {file_path} is too large for LLM analysis, truncating")
                content = content[:20000] + "\n... [truncated]"
            
            # Detect language
            file_info = detect_file_type(file_path)
            language = file_info.get("language", "unknown")
            
            # Build prompt for the LLM
            prompt = f"""
Analyze this {language} source code and extract the key semantic information:

```{language}
{content}
```

Please return a JSON response with the following structure:
{{
  "imports": [
    {{ "name": "import_name", "path": "import_path", "line": line_number }}
  ],
  "functions": [
    {{ "name": "function_name", "start_line": start_line, "end_line": end_line, "params": ["param1", "param2"], "return_type": "return_type", "complexity": estimated_complexity }}
  ],
  "classes": [
    {{ 
      "name": "class_name", 
      "start_line": start_line, 
      "end_line": end_line, 
      "base_classes": ["base1", "base2"],
      "methods": [
        {{ "name": "method_name", "start_line": start_line, "end_line": end_line, "params": ["param1", "param2"] }}
      ],
      "attributes": [
        {{ "name": "attr_name", "type": "attr_type", "line": line_number }}
      ]
    }}
  ],
  "variables": [
    {{ "name": "var_name", "type": "var_type", "line": line_number, "is_constant": true_or_false }}
  ],
  "docstring": "module_level_docstring_if_any",
  "code_metrics": {{
    "total_lines": total_line_count,
    "function_count": number_of_functions,
    "class_count": number_of_classes,
    "complexity": estimated_overall_complexity
  }}
}}

Ensure your JSON is valid. Don't include any comments or explanations outside the JSON.
"""
            # Call AI service
            api_request = GeminiRequest(
                prompt=prompt,
                max_tokens=4000,
                temperature=0.1  # Low temperature for more deterministic output
            )
            
            response = await gemini_client.generate_text(api_request)
            
            # Parse the response
            try:
                # Try to extract JSON from the response
                response_text = response.text
                
                # Look for JSON block
                json_match = re.search(r'```(?:json)?\s*(.*?)\s*```', response_text, re.DOTALL)
                if json_match:
                    response_text = json_match.group(1)
                
                # Try to parse the JSON
                data = json.loads(response_text)
                
                # Populate the module with the extracted information
                
                # Module docstring
                if "docstring" in data:
                    module.docstring = data["docstring"]
                
                # Imports
                for imp in data.get("imports", []):
                    name = imp.get("name", "")
                    if name:
                        module.imports[name] = Import(
                            name=name,
                            line_start=imp.get("line", 1),
                            line_end=imp.get("line", 1),
                            filename=str(file_path),
                            import_path=imp.get("path", "")
                        )
                        if imp.get("path"):
                            module.dependencies.append(imp.get("path"))
                
                # Functions
                for func in data.get("functions", []):
                    name = func.get("name", "")
                    if name:
                        module.functions[name] = Function(
                            name=name,
                            line_start=func.get("start_line", 1),
                            line_end=func.get("end_line", 1),
                            filename=str(file_path),
                            params=func.get("params", []),
                            return_type=func.get("return_type"),
                            complexity=func.get("complexity")
                        )
                
                # Classes
                for cls in data.get("classes", []):
                    name = cls.get("name", "")
                    if name:
                        class_entity = Class(
                            name=name,
                            line_start=cls.get("start_line", 1),
                            line_end=cls.get("end_line", 1),
                            filename=str(file_path),
                            base_classes=cls.get("base_classes", [])
                        )
                        
                        # Add methods
                        for method in cls.get("methods", []):
                            method_name = method.get("name", "")
                            if method_name:
                                class_entity.methods[method_name] = Function(
                                    name=method_name,
                                    line_start=method.get("start_line", 1),
                                    line_end=method.get("end_line", 1),
                                    filename=str(file_path),
                                    params=method.get("params", []),
                                    is_method=True,
                                    class_name=name
                                )
                        
                        # Add attributes
                        for attr in cls.get("attributes", []):
                            attr_name = attr.get("name", "")
                            if attr_name:
                                class_entity.attributes[attr_name] = Variable(
                                    name=attr_name,
                                    line_start=attr.get("line", 1),
                                    line_end=attr.get("line", 1),
                                    filename=str(file_path),
                                    var_type=attr.get("type"),
                                    is_attribute=True,
                                    class_name=name
                                )
                        
                        module.classes[name] = class_entity
                
                # Variables
                for var in data.get("variables", []):
                    name = var.get("name", "")
                    if name:
                        module.variables[name] = Variable(
                            name=name,
                            line_start=var.get("line", 1),
                            line_end=var.get("line", 1),
                            filename=str(file_path),
                            var_type=var.get("type"),
                            is_constant=var.get("is_constant", False)
                        )
                
                # Code metrics
                if "code_metrics" in data:
                    module.code_metrics = data["code_metrics"]
                
                return True
                
            except json.JSONDecodeError as e:
                self._logger.error(f"Error parsing LLM response as JSON: {str(e)}")
                return False
                
        except Exception as e:
            self._logger.error(f"Error in LLM analysis for {file_path}: {str(e)}")
            return False
    
    def _analyze_cross_module_references(self, modules: Dict[str, Module]) -> None:
        """
        Analyze references between modules to build a dependency graph.
        
        Args:
            modules: Dictionary of modules to analyze
        """
        # Build a map of entity names to their modules
        entity_map = {}
        
        for module_path, module in modules.items():
            # Add functions
            for func_name in module.functions:
                entity_map[func_name] = module_path
            
            # Add classes
            for class_name in module.classes:
                entity_map[class_name] = module_path
        
        # Look for references
        for module_path, module in modules.items():
            # Check function calls
            for func_name, func in module.functions.items():
                for called_func in func.called_functions:
                    # Ignore method calls (with dots)
                    if '.' in called_func:
                        continue
                    
                    if called_func in entity_map and entity_map[called_func] != module_path:
                        # Found a reference to a function in another module
                        target_module = modules[entity_map[called_func]]
                        if called_func in target_module.functions:
                            target_func = target_module.functions[called_func]
                            target_func.references.append((module_path, func.line_start))
                            func.dependencies.append(called_func)
            
            # Check class inheritance
            for class_name, cls in module.classes.items():
                for base_class in cls.base_classes:
                    # Ignore qualified base classes
                    if '.' in base_class:
                        continue
                    
                    if base_class in entity_map and entity_map[base_class] != module_path:
                        # Found a reference to a class in another module
                        target_module = modules[entity_map[base_class]]
                        if base_class in target_module.classes:
                            target_class = target_module.classes[base_class]
                            target_class.references.append((module_path, cls.line_start))
                            cls.dependencies.append(base_class)
                            
    
    def find_related_entities(self, entity_name: str, project_files: Dict[str, Module]) -> List[Dict[str, Any]]:
        """
        Find entities related to a given entity in the project.
        
        Args:
            entity_name: Name of the entity to find relations for
            project_files: Dictionary of modules in the project
            
        Returns:
            List of related entities with relationship information
        """
        related_entities = []
        
        # Look for entities that reference or are referenced by the target entity
        for module_path, module in project_files.items():
            # Check functions
            for func_name, func in module.functions.items():
                # Check if this is our target entity
                if func_name == entity_name:
                    # Find functions that call this one
                    for other_module_path, other_module in project_files.items():
                        for other_func_name, other_func in other_module.functions.items():
                            if entity_name in other_func.called_functions:
                                related_entities.append({
                                    "name": other_func_name,
                                    "type": "function",
                                    "relationship": "calls",
                                    "filename": other_module_path,
                                    "line": other_func.line_start
                                })
                
                # Check if this function calls our target entity
                if entity_name in func.called_functions:
                    related_entities.append({
                        "name": func_name,
                        "type": "function",
                        "relationship": "called_by",
                        "filename": module_path,
                        "line": func.line_start
                    })
            
            # Check classes
            for class_name, cls in module.classes.items():
                # Check if this is our target entity
                if class_name == entity_name:
                    # Find classes that inherit from this one
                    for other_module_path, other_module in project_files.items():
                        for other_class_name, other_class in other_module.classes.items():
                            if entity_name in other_class.base_classes:
                                related_entities.append({
                                    "name": other_class_name,
                                    "type": "class",
                                    "relationship": "inherits_from",
                                    "filename": other_module_path,
                                    "line": other_class.line_start
                                })
                
                # Check if this class inherits from our target entity
                if entity_name in cls.base_classes:
                    related_entities.append({
                        "name": class_name,
                        "type": "class",
                        "relationship": "extended_by",
                        "filename": module_path,
                        "line": cls.line_start
                    })
                
                # Check class methods
                for method_name, method in cls.methods.items():
                    if entity_name in method.called_functions:
                        related_entities.append({
                            "name": f"{class_name}.{method_name}",
                            "type": "method",
                            "relationship": "called_by",
                            "filename": module_path,
                            "line": method.line_start
                        })
        
        return related_entities
    
    async def analyze_entity_usage(self, entity_name: str, project_root: Union[str, Path], depth: int = 1) -> Dict[str, Any]:
        """
        Analyze how a specific entity is used throughout the project.
        
        Args:
            entity_name: Name of the entity to analyze
            project_root: Root directory of the project
            depth: Relationship depth to explore
            
        Returns:
            Dictionary with entity usage information
        """
        root_path = Path(project_root)
        
        # Analyze project files first
        project_files = await self.analyze_project_files(root_path)
        
        # Find the entity in the project
        entity_info = None
        entity_module = None
        entity_type = None
        
        for module_path, module in project_files.items():
            # Check functions
            if entity_name in module.functions:
                entity_info = module.functions[entity_name].to_dict()
                entity_module = module
                entity_type = "function"
                break
            
            # Check classes
            if entity_name in module.classes:
                entity_info = module.classes[entity_name].to_dict()
                entity_module = module
                entity_type = "class"
                break
            
            # Check variables
            if entity_name in module.variables:
                entity_info = module.variables[entity_name].to_dict()
                entity_module = module
                entity_type = "variable"
                break
            
            # Check for class methods
            for class_name, cls in module.classes.items():
                if entity_name in cls.methods:
                    entity_info = cls.methods[entity_name].to_dict()
                    entity_info["class_name"] = class_name
                    entity_module = module
                    entity_type = "method"
                    break
                
                # Check for full qualified method name (class.method)
                if "." in entity_name:
                    class_part, method_part = entity_name.split(".", 1)
                    if class_name == class_part and method_part in cls.methods:
                        entity_info = cls.methods[method_part].to_dict()
                        entity_info["class_name"] = class_name
                        entity_module = module
                        entity_type = "method"
                        break
        
        if not entity_info:
            return {
                "entity_name": entity_name,
                "found": False,
                "message": f"Entity '{entity_name}' not found in the project"
            }
        
        # Find related entities
        related = self.find_related_entities(entity_name, project_files)
        
        # For methods, also check the class name if it's a qualified name
        if "." in entity_name and not related:
            class_part = entity_name.split(".", 1)[0]
            class_related = self.find_related_entities(class_part, project_files)
            related.extend(class_related)
        
        # Get recursive related entities if depth > 1
        if depth > 1:
            next_level = []
            for related_entity in related:
                name = related_entity["name"]
                if "." in name:  # Skip qualified names for simplicity
                    continue
                    
                sub_related = self.find_related_entities(name, project_files)
                for sub in sub_related:
                    if sub not in next_level and sub not in related:
                        sub["relationship_depth"] = 2
                        next_level.append(sub)
            
            related.extend(next_level)
        
        # Build result
        result = {
            "entity_name": entity_name,
            "found": True,
            "type": entity_type,
            "filename": entity_info["filename"],
            "line_start": entity_info["line_start"],
            "line_end": entity_info["line_end"],
            "related_entities": related,
            "details": entity_info
        }
        
        if entity_type == "function" or entity_type == "method":
            # Add information about function parameters
            result["parameters"] = entity_info.get("params", [])
            result["return_type"] = entity_info.get("return_type")
            result["complexity"] = entity_info.get("complexity")
            
            # If it's a method, add class information
            if entity_type == "method":
                result["class_name"] = entity_info.get("class_name")
                
                # Get class info
                if entity_module and entity_info.get("class_name") in entity_module.classes:
                    class_info = entity_module.classes[entity_info["class_name"]].to_dict()
                    result["class_details"] = {
                        "base_classes": class_info.get("base_classes", []),
                        "method_count": len(class_info.get("methods", {})),
                        "attribute_count": len(class_info.get("attributes", {}))
                    }
        
        elif entity_type == "class":
            # Add class-specific information
            result["base_classes"] = entity_info.get("base_classes", [])
            result["method_count"] = len(entity_info.get("methods", {}))
            result["attribute_count"] = len(entity_info.get("attributes", {}))
            result["methods"] = list(entity_info.get("methods", {}).keys())
            result["attributes"] = list(entity_info.get("attributes", {}).keys())
        
        elif entity_type == "variable":
            # Add variable-specific information
            result["var_type"] = entity_info.get("var_type")
            result["value"] = entity_info.get("value")
            result["is_constant"] = entity_info.get("is_constant", False)
        
        return result
    
    async def summarize_code_entity(self, entity_name: str, project_root: Union[str, Path]) -> str:
        """
        Generate a natural language summary of a code entity.
        
        Args:
            entity_name: Name of the entity to summarize
            project_root: Root directory of the project
            
        Returns:
            String with a natural language summary
        """
        # First, get the entity usage information
        usage_info = await self.analyze_entity_usage(entity_name, project_root)
        
        if not usage_info.get("found", False):
            return f"Could not find entity '{entity_name}' in the project."
        
        # Create a detailed prompt for the LLM
        entity_type = usage_info.get("type", "unknown")
        filename = usage_info.get("filename", "unknown")
        
        # Read the actual file content around the entity definition
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                file_content = f.read()
            
            lines = file_content.splitlines()
            start_line = max(0, usage_info.get("line_start", 1) - 1)  # Lines are 1-indexed
            end_line = min(len(lines), usage_info.get("line_end", start_line + 10))
            
            entity_code = "\n".join(lines[start_line:end_line])
            
            # Get the language
            file_info = detect_file_type(Path(filename))
            language = file_info.get("language", "").lower()
            
            # Build the prompt
            prompt = f"""
You are reviewing code and need to provide a clear, concise summary of a specific code entity.

Entity Name: {entity_name}
Entity Type: {entity_type}
File: {Path(filename).name}
Language: {language}

Here is the code for this entity:
```{language}
{entity_code}
```

Additional Information:
"""
            
            if entity_type == "function" or entity_type == "method":
                params = usage_info.get("parameters", [])
                return_type = usage_info.get("return_type", "unknown")
                complexity = usage_info.get("complexity", "unknown")
                
                prompt += f"""
- Parameters: {', '.join(params)}
- Return Type: {return_type}
- Complexity: {complexity}
"""
                
                if entity_type == "method":
                    class_name = usage_info.get("class_name", "unknown")
                    prompt += f"- Part of Class: {class_name}\n"
                    
                    class_details = usage_info.get("class_details", {})
                    if class_details:
                        base_classes = class_details.get("base_classes", [])
                        if base_classes:
                            prompt += f"- Class Inherits From: {', '.join(base_classes)}\n"
            
            elif entity_type == "class":
                base_classes = usage_info.get("base_classes", [])
                methods = usage_info.get("methods", [])
                attributes = usage_info.get("attributes", [])
                
                prompt += f"""
- Base Classes: {', '.join(base_classes) if base_classes else 'None'}
- Methods: {', '.join(methods[:5]) + ('...' if len(methods) > 5 else '') if methods else 'None'}
- Attributes: {', '.join(attributes[:5]) + ('...' if len(attributes) > 5 else '') if attributes else 'None'}
"""
            
            elif entity_type == "variable":
                var_type = usage_info.get("var_type", "unknown")
                value = usage_info.get("value", "unknown")
                is_constant = usage_info.get("is_constant", False)
                
                prompt += f"""
- Type: {var_type}
- Value: {value}
- Is Constant: {is_constant}
"""
            
            # Add relationship information
            related = usage_info.get("related_entities", [])
            if related:
                callers = [r["name"] for r in related if r.get("relationship") == "calls"]
                called = [r["name"] for r in related if r.get("relationship") == "called_by"]
                inherits = [r["name"] for r in related if r.get("relationship") == "inherits_from"]
                extends = [r["name"] for r in related if r.get("relationship") == "extended_by"]
                
                prompt += "\nRelationships:\n"
                
                if callers:
                    prompt += f"- Called by: {', '.join(callers[:5]) + ('...' if len(callers) > 5 else '')}\n"
                
                if called:
                    prompt += f"- Calls: {', '.join(called[:5]) + ('...' if len(called) > 5 else '')}\n"
                
                if inherits:
                    prompt += f"- Inherits from: {', '.join(inherits)}\n"
                
                if extends:
                    prompt += f"- Extended by: {', '.join(extends[:5]) + ('...' if len(extends) > 5 else '')}\n"
            
            prompt += """
Based on the code and information provided, give a concise, useful summary of what this entity does,
its role in the codebase, and any notable design patterns or implementation details. Keep the summary
focused and to-the-point - ideally 3-5 sentences.
"""
            
            # Call AI service
            api_request = GeminiRequest(
                prompt=prompt,
                max_tokens=1000,
                temperature=0.3
            )
            
            response = await gemini_client.generate_text(api_request)
            
            return response.text.strip()
            
        except Exception as e:
            self._logger.error(f"Error generating summary for {entity_name}: {str(e)}")
            return f"Error generating summary for {entity_name}: {str(e)}"
    
    async def get_entity_code(self, entity_name: str, project_root: Union[str, Path]) -> Optional[str]:
        """
        Get the source code for a specific entity.
        
        Args:
            entity_name: Name of the entity to get code for
            project_root: Root directory of the project
            
        Returns:
            String with the entity's source code or None if not found
        """
        # First, get the entity usage information
        usage_info = await self.analyze_entity_usage(entity_name, project_root)
        
        if not usage_info.get("found", False):
            return None
        
        # Get the file path and line range
        filename = usage_info.get("filename")
        start_line = usage_info.get("line_start", 1)
        end_line = usage_info.get("line_end", start_line)
        
        # Read the file content
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                
            # Get the specified line range (adjust for 0-based indexing)
            start_idx = max(0, start_line - 1)
            end_idx = min(len(lines), end_line)
            
            return "".join(lines[start_idx:end_idx])
            
        except Exception as e:
            self._logger.error(f"Error getting code for {entity_name}: {str(e)}")
            return None
    
    def get_module_dependencies(self, modules: Dict[str, Module]) -> Dict[str, List[str]]:
        """
        Get a map of module dependencies.
        
        Args:
            modules: Dictionary of modules to analyze
            
        Returns:
            Dictionary with module paths as keys and lists of dependencies as values
        """
        dependencies = {}
        
        for module_path, module in modules.items():
            dependencies[module_path] = module.dependencies
        
        return dependencies
    
    def calculate_project_metrics(self, modules: Dict[str, Module]) -> Dict[str, Any]:
        """
        Calculate metrics for the entire project.
        
        Args:
            modules: Dictionary of modules to analyze
            
        Returns:
            Dictionary with project metrics
        """
        total_lines = 0
        code_lines = 0
        comment_lines = 0
        blank_lines = 0
        function_count = 0
        class_count = 0
        complexity = 0
        
        for module in modules.values():
            metrics = module.code_metrics
            total_lines += metrics.get("total_lines", 0)
            code_lines += metrics.get("code_lines", 0)
            comment_lines += metrics.get("comment_lines", 0)
            blank_lines += metrics.get("blank_lines", 0)
            function_count += metrics.get("function_count", 0) + sum(len(cls.methods) for cls in module.classes.values())
            class_count += metrics.get("class_count", 0)
            complexity += metrics.get("complexity", 0)
        
        # Calculate percentages
        comment_ratio = comment_lines / code_lines if code_lines > 0 else 0
        blank_ratio = blank_lines / total_lines if total_lines > 0 else 0
        average_function_complexity = complexity / function_count if function_count > 0 else 0
        
        return {
            "total_lines": total_lines,
            "code_lines": code_lines,
            "comment_lines": comment_lines,
            "blank_lines": blank_lines,
            "function_count": function_count,
            "class_count": class_count,
            "complexity": complexity,
            "comment_ratio": comment_ratio,
            "blank_ratio": blank_ratio,
            "average_function_complexity": average_function_complexity,
            "module_count": len(modules),
            "file_count": len(modules)
        }

# Global semantic analyzer instance
semantic_analyzer = SemanticAnalyzer()
</file>

<file path="angela/context/file_detector.py">
"""
File type detection for Angela CLI.

This module provides functionality to detect file types and languages
to enhance context awareness for operations.
"""
import re
import os
import mimetypes
from pathlib import Path
from typing import Dict, Any, Optional, List, Tuple

from angela.utils.logging import get_logger

logger = get_logger(__name__)

# Initialize mimetypes
mimetypes.init()

# Map of file extensions to programming languages
LANGUAGE_EXTENSIONS = {
    # Web
    '.html': 'HTML',
    '.htm': 'HTML',
    '.css': 'CSS',
    '.js': 'JavaScript',
    '.jsx': 'JavaScript (React)',
    '.ts': 'TypeScript',
    '.tsx': 'TypeScript (React)',
    
    # Python
    '.py': 'Python',
    '.pyi': 'Python Interface',
    '.pyx': 'Cython',
    '.ipynb': 'Jupyter Notebook',
    
    # Ruby
    '.rb': 'Ruby',
    '.erb': 'Ruby (ERB)',
    '.rake': 'Ruby (Rake)',
    
    # Java/JVM
    '.java': 'Java',
    '.kt': 'Kotlin',
    '.groovy': 'Groovy',
    '.scala': 'Scala',
    
    # C/C++
    '.c': 'C',
    '.h': 'C Header',
    '.cpp': 'C++',
    '.cc': 'C++',
    '.hpp': 'C++ Header',
    
    # C#
    '.cs': 'C#',
    
    # Go
    '.go': 'Go',
    
    # Rust
    '.rs': 'Rust',
    
    # Swift
    '.swift': 'Swift',
    
    # PHP
    '.php': 'PHP',
    
    # Shell
    '.sh': 'Shell (Bash)',
    '.bash': 'Bash',
    '.zsh': 'Zsh',
    '.fish': 'Fish',
    
    # Configuration
    '.json': 'JSON',
    '.yaml': 'YAML',
    '.yml': 'YAML',
    '.toml': 'TOML',
    '.ini': 'INI',
    '.cfg': 'Config',
    '.conf': 'Config',
    
    # Markup
    '.md': 'Markdown',
    '.rst': 'reStructuredText',
    '.xml': 'XML',
    '.svg': 'SVG',
    
    # Data
    '.csv': 'CSV',
    '.tsv': 'TSV',
    '.txt': 'Text',
    '.log': 'Log',
    
    # Documents
    '.pdf': 'PDF',
    '.doc': 'MS Word',
    '.docx': 'MS Word',
    '.xls': 'MS Excel',
    '.xlsx': 'MS Excel',
    '.ppt': 'MS PowerPoint',
    '.pptx': 'MS PowerPoint',
    
    # Images
    '.jpg': 'JPEG Image',
    '.jpeg': 'JPEG Image',
    '.png': 'PNG Image',
    '.gif': 'GIF Image',
    '.bmp': 'BMP Image',
    '.webp': 'WebP Image',
    
    # Audio
    '.mp3': 'MP3 Audio',
    '.wav': 'WAV Audio',
    '.ogg': 'OGG Audio',
    '.flac': 'FLAC Audio',
    
    # Video
    '.mp4': 'MP4 Video',
    '.avi': 'AVI Video',
    '.mkv': 'MKV Video',
    '.mov': 'MOV Video',
    
    # Archives
    '.zip': 'ZIP Archive',
    '.tar': 'TAR Archive',
    '.gz': 'GZIP Archive',
    '.bz2': 'BZIP2 Archive',
    '.xz': 'XZ Archive',
    '.7z': '7-Zip Archive',
    '.rar': 'RAR Archive',
    
    # Executables
    '.exe': 'Windows Executable',
    '.dll': 'Windows Library',
    '.so': 'Shared Object',
    '.dylib': 'macOS Library',
    
    # Other
    '.sql': 'SQL',
    '.db': 'Database',
    '.sqlite': 'SQLite Database',
}

# Mapping of file names to types
FILENAME_MAPPING = {
    'Dockerfile': 'Docker',
    'docker-compose.yml': 'Docker Compose',
    'docker-compose.yaml': 'Docker Compose',
    '.dockerignore': 'Docker',
    'Makefile': 'Makefile',
    'CMakeLists.txt': 'CMake',
    'package.json': 'Node.js',
    'package-lock.json': 'Node.js',
    'yarn.lock': 'Yarn',
    'requirements.txt': 'Python',
    'setup.py': 'Python',
    'pyproject.toml': 'Python',
    'Pipfile': 'Python (Pipenv)',
    'Pipfile.lock': 'Python (Pipenv)',
    'Gemfile': 'Ruby',
    'Gemfile.lock': 'Ruby',
    'build.gradle': 'Gradle',
    'build.gradle.kts': 'Gradle (Kotlin)',
    'pom.xml': 'Maven',
    'Cargo.toml': 'Rust',
    'Cargo.lock': 'Rust',
    '.gitignore': 'Git',
    '.gitattributes': 'Git',
    '.gitlab-ci.yml': 'GitLab CI',
    '.travis.yml': 'Travis CI',
    'Jenkinsfile': 'Jenkins',
    '.editorconfig': 'EditorConfig',
    '.eslintrc': 'ESLint',
    '.eslintrc.js': 'ESLint',
    '.eslintrc.json': 'ESLint',
    '.prettierrc': 'Prettier',
    '.prettierrc.js': 'Prettier',
    '.prettierrc.json': 'Prettier',
    'tsconfig.json': 'TypeScript',
    'tslint.json': 'TSLint',
    '.babelrc': 'Babel',
    'babel.config.js': 'Babel',
    'webpack.config.js': 'Webpack',
    'rollup.config.js': 'Rollup',
    'vite.config.js': 'Vite',
    'jest.config.js': 'Jest',
    '.env': 'Environment Variables',
    '.env.example': 'Environment Variables',
    'README.md': 'Documentation',
    'LICENSE': 'License',
    'CHANGELOG.md': 'Changelog',
    'CONTRIBUTING.md': 'Documentation',
    'CODE_OF_CONDUCT.md': 'Documentation',
}

# Language-specific shebang patterns
SHEBANG_PATTERNS = [
    (r'^#!/bin/bash', 'Bash'),
    (r'^#!/usr/bin/env\s+bash', 'Bash'),
    (r'^#!/bin/sh', 'Shell'),
    (r'^#!/usr/bin/env\s+sh', 'Shell'),
    (r'^#!/usr/bin/python', 'Python'),
    (r'^#!/usr/bin/env\s+python', 'Python'),
    (r'^#!/usr/bin/node', 'JavaScript'),
    (r'^#!/usr/bin/env\s+node', 'JavaScript'),
    (r'^#!/usr/bin/ruby', 'Ruby'),
    (r'^#!/usr/bin/env\s+ruby', 'Ruby'),
    (r'^#!/usr/bin/perl', 'Perl'),
    (r'^#!/usr/bin/env\s+perl', 'Perl'),
    (r'^#!/usr/bin/php', 'PHP'),
    (r'^#!/usr/bin/env\s+php', 'PHP'),
]

# Mapping of MIME type prefixes to general types
MIME_TYPE_MAPPING = {
    'image/': 'image',
    'audio/': 'audio',
    'video/': 'video',
    'text/': 'text',
    'application/pdf': 'document',
    'application/msword': 'document',
    'application/vnd.openxmlformats-officedocument': 'document',
    'application/zip': 'archive',
    'application/x-tar': 'archive',
    'application/x-gzip': 'archive',
    'application/x-bzip2': 'archive',
    'application/x-xz': 'archive',
    'application/x-7z-compressed': 'archive',
    'application/x-rar-compressed': 'archive',
}


# In angela/context/file_detector.py - update the detect_file_type function

def detect_file_type(path: Path) -> Dict[str, Any]:
    """
    Detect the type of a file based on extension, content, and other heuristics.
    
    Args:
        path: The path to the file.
        
    Returns:
        A dictionary with file type information.
    """
    result = {
        'type': 'unknown',
        'language': None,
        'mime_type': None,
        'binary': False,
        'encoding': None,
    }
    
    try:
        if not path.exists():
            return result
        
        # Check if it's a directory
        if path.is_dir():
            result['type'] = 'directory'
            return result
        
        # Get file name and extension
        name = path.name
        extension = path.suffix.lower()
        
        # Check if it's a known file by name
        if name in FILENAME_MAPPING:
            result['type'] = FILENAME_MAPPING[name]
            
        # Get MIME type
        mime_type, encoding = mimetypes.guess_type(str(path))
        if mime_type:
            result['mime_type'] = mime_type
            result['encoding'] = encoding
            
            # Get general type from MIME
            main_type = mime_type.split('/')[0]
            result['type'] = main_type
        
        # Detect language based on extension
        if extension in LANGUAGE_EXTENSIONS:
            result['language'] = LANGUAGE_EXTENSIONS[extension]
            result['type'] = 'source_code'  # Set type to source_code when a language is detected
        
        # Special case for known project files
        if name == "requirements.txt":
            result['type'] = "Python"  # Force correct type for requirements.txt
            
        # For text files without a clear type, check for shebangs
        if extension in ['.txt', ''] or not result['language']:
            try:
                # Read the first line of the file
                with open(path, 'r', errors='ignore') as f:
                    first_line = f.readline().strip()
                
                # Check for shebang patterns
                for pattern, language in SHEBANG_PATTERNS:
                    if re.match(pattern, first_line):
                        result['language'] = language
                        result['type'] = 'source_code'  # Set the type for scripting files with shebangs
                        break
            except UnicodeDecodeError:
                # File is likely binary
                result['binary'] = True
                result['type'] = 'binary'
        
        # Check if the file is binary
        if not result['binary'] and not result['type'] == 'directory':
            try:
                with open(path, 'rb') as f:
                    chunk = f.read(4096)
                    # Check for null bytes (common in binary files)
                    if b'\0' in chunk:
                        result['binary'] = True
                        if not result['type'] or result['type'] == 'unknown':
                            result['type'] = 'binary'
            except IOError:
                pass
        
        return result
    
    except Exception as e:
        logger.exception(f"Error detecting file type for {path}: {str(e)}")
        return result


def get_content_preview(path: Path, max_lines: int = 10, max_chars: int = 1000) -> Optional[str]:
    """
    Get a preview of a file's content.
    
    Args:
        path: The path to the file.
        max_lines: Maximum number of lines to preview.
        max_chars: Maximum number of characters to preview.
        
    Returns:
        A string with the file preview, or None if the file is not readable.
    """
    try:
        if not path.exists() or not path.is_file():
            return None
        
        # Check file type
        file_info = detect_file_type(path)
        if file_info['binary']:
            return "[Binary file]"
        
        # Read the file content
        with open(path, 'r', errors='replace') as f:
            lines = []
            total_chars = 0
            
            for i, line in enumerate(f):
                if i >= max_lines:
                    lines.append("...")
                    break
                
                if total_chars + len(line) > max_chars:
                    # Truncate the line if it would exceed max_chars
                    available_chars = max_chars - total_chars
                    if available_chars > 3:
                        lines.append(line[:available_chars - 3] + "...")
                    break
                
                lines.append(line.rstrip('\n'))
                total_chars += len(line)
        
        return '\n'.join(lines)
    
    except Exception as e:
        logger.exception(f"Error getting content preview for {path}: {str(e)}")
        return None
</file>

<file path="angela/context/manager.py">
"""
Context management for Angela CLI.
"""
import os
from pathlib import Path
from typing import Optional, Dict, Any, List, Set

from angela.constants import PROJECT_MARKERS
from angela.utils.logging import get_logger
from angela.context.file_detector import detect_file_type, get_content_preview

logger = get_logger(__name__)


class ContextManager:
    """
    Manages context information about the current environment.
    
    The context includes:
    - Current working directory
    - Project root (if detected)
    - Project type (if detected)
    - File details for current or specified path
    """
    
    def __init__(self):
        self._cwd: Path = Path.cwd()
        self._project_root: Optional[Path] = None
        self._project_type: Optional[str] = None
        self._current_file: Optional[Path] = None
        self._file_cache: Dict[str, Dict[str, Any]] = {}
        
        # Initialize context
        self.refresh_context()
    
    def refresh_context(self) -> None:
        """Refresh all context information."""
        self._update_cwd()
        self._detect_project_root()
        logger.debug(f"Context refreshed: cwd={self._cwd}, project_root={self._project_root}")
    
    def _update_cwd(self) -> None:
        """Update the current working directory."""
        self._cwd = Path.cwd()
    
    def _detect_project_root(self) -> None:
        """
        Detect the project root by looking for marker files.
        
        Traverses up from the current directory until a marker is found or
        the filesystem root is reached.
        """
        self._project_root = None
        self._project_type = None
        
        # Start from current directory
        current_dir = self._cwd
        
        # Walk up the directory tree
        while current_dir != current_dir.parent:  # Stop at filesystem root
            # Check for project markers
            for marker in PROJECT_MARKERS:
                marker_path = current_dir / marker
                if marker_path.exists():
                    self._project_root = current_dir
                    self._project_type = self._determine_project_type(marker)
                    logger.debug(f"Project detected: {self._project_type} at {self._project_root}")
                    return
            
            # Move up to parent directory
            current_dir = current_dir.parent
    
    def _determine_project_type(self, marker: str) -> str:
        """
        Determine the project type based on the marker file.
        
        Args:
            marker: The marker file that was found.
            
        Returns:
            A string representing the project type.
        """
        marker_to_type = {
            ".git": "git",
            "package.json": "node",
            "requirements.txt": "python",
            "Cargo.toml": "rust",
            "pom.xml": "maven",
            "build.gradle": "gradle",
            "Dockerfile": "docker",
            "docker-compose.yml": "docker-compose",
            "CMakeLists.txt": "cmake",
            "Makefile": "make",
        }
        
        return marker_to_type.get(marker, "unknown")
    
    def set_current_file(self, file_path: Path) -> None:
        """
        Set the current file being worked on.
        
        Args:
            file_path: The path to the current file.
        """
        self._current_file = file_path
    
    def get_file_info(self, path: Optional[Path] = None) -> Dict[str, Any]:
        """
        Get information about a file or the current file.
        
        Args:
            path: The path to get information about, or None to use the current file.
            
        Returns:
            A dictionary with file information, or an empty dict if no file is available.
        """
        file_path = path or self._current_file
        if not file_path:
            return {}
        
        # Check if we have cached information
        cache_key = str(file_path)
        if cache_key in self._file_cache:
            return self._file_cache[cache_key]
        
        # If file doesn't exist, return minimal info
        if not file_path.exists():
            return {
                "path": str(file_path),
                "exists": False,
                "name": file_path.name,
                "extension": file_path.suffix,
            }
        
        # Get basic file info
        stat = file_path.stat()
        
        # Get detailed file type info
        type_info = detect_file_type(file_path)
        
        # Create the result
        result = {
            "path": str(file_path),
            "exists": True,
            "name": file_path.name,
            "extension": file_path.suffix,
            "size": stat.st_size,
            "modified": stat.st_mtime,
            "is_dir": file_path.is_dir(),
            "type": type_info["type"],
            "language": type_info["language"],
            "mime_type": type_info["mime_type"],
            "binary": type_info["binary"],
        }
        
        # Cache the result
        self._file_cache[cache_key] = result
        
        return result
    
    def get_directory_contents(self, path: Optional[Path] = None, include_hidden: bool = False) -> List[Dict[str, Any]]:
        """
        Get information about the contents of a directory.
        
        Args:
            path: The directory path to examine, or None to use the current directory.
            include_hidden: Whether to include hidden files (starting with .).
            
        Returns:
            A list of dictionaries with information about each item in the directory.
        """
        dir_path = path or self._cwd
        if not dir_path.is_dir():
            return []
        
        result = []
        
        try:
            for item in dir_path.iterdir():
                # Skip hidden files unless requested
                if not include_hidden and item.name.startswith('.'):
                    continue
                
                # Get information about this item
                item_info = self.get_file_info(item)
                result.append(item_info)
            
            # Sort by directories first, then by name
            result.sort(key=lambda x: (not x["is_dir"], x["name"].lower()))
            
            return result
        
        except Exception as e:
            logger.exception(f"Error getting directory contents for {dir_path}: {str(e)}")
            return []
    
    def get_file_preview(self, path: Optional[Path] = None, max_lines: int = 10) -> Optional[str]:
        """
        Get a preview of a file's contents.
        
        Args:
            path: The file path to preview, or None to use the current file.
            max_lines: Maximum number of lines to preview.
            
        Returns:
            A string with a preview of the file's contents, or None if not available.
        """
        file_path = path or self._current_file
        if not file_path or not file_path.is_file():
            return None
        
        return get_content_preview(file_path, max_lines=max_lines)
    
    def find_files(
        self, 
        pattern: str, 
        base_dir: Optional[Path] = None, 
        max_depth: int = 10,
        include_hidden: bool = False
    ) -> List[Path]:
        """
        Find files matching a pattern.
        
        Args:
            pattern: The glob pattern to match.
            base_dir: The directory to start from, or None to use the current directory.
            max_depth: Maximum directory depth to search.
            include_hidden: Whether to include hidden files (starting with .).
            
        Returns:
            A list of paths matching the pattern.
        """
        start_dir = base_dir or self._cwd
        if not start_dir.is_dir():
            return []
        
        result = []
        
        try:
            # Use Path.glob for pattern matching
            for path in start_dir.glob(pattern):
                # Skip hidden files unless requested
                if not include_hidden and any(part.startswith('.') for part in path.parts):
                    continue
                
                result.append(path)
            
            return result
        
        except Exception as e:
            logger.exception(f"Error finding files with pattern {pattern}: {str(e)}")
            return []
    
    @property
    def cwd(self) -> Path:
        """Get the current working directory."""
        return self._cwd
    
    @property
    def project_root(self) -> Optional[Path]:
        """Get the detected project root."""
        return self._project_root
    
    @property
    def project_type(self) -> Optional[str]:
        """Get the detected project type."""
        return self._project_type
    
    @property
    def is_in_project(self) -> bool:
        """Check if the current directory is within a project."""
        return self._project_root is not None
    
    @property
    def relative_path(self) -> Optional[Path]:
        """Get the path relative to the project root."""
        if not self._project_root:
            return None
        
        return self._cwd.relative_to(self._project_root)
    
    @property
    def current_file(self) -> Optional[Path]:
        """Get the current file being worked on."""
        return self._current_file
    
    def get_context_dict(self) -> Dict[str, Any]:
        """
        Get a dictionary representation of the current context.
        
        Returns:
            A dictionary with context information.
        """
        context = {
            "cwd": str(self._cwd),
            "project_root": str(self._project_root) if self._project_root else None,
            "project_type": self._project_type,
            "is_in_project": self.is_in_project,
            "relative_path": str(self.relative_path) if self.relative_path else None,
        }
        
        # Add information about the current file if available
        if self._current_file:
            context["current_file"] = self.get_file_info(self._current_file)
        
        return context


# Global context manager instance
context_manager = ContextManager()
</file>

<file path="angela/execution/error_recovery.py">
# angela/execution/error_recovery.py

import os
import re
import asyncio
import tempfile
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple, Set, Union
from enum import Enum

from angela.ai.client import gemini_client, GeminiRequest
from angela.ai.analyzer import error_analyzer
from angela.context import context_manager
from angela.utils.logging import get_logger
from angela.shell.formatter import terminal_formatter, OutputType

logger = get_logger(__name__)

class RecoveryStrategy(Enum):
    """Types of error recovery strategies."""
    RETRY = "retry"                 # Simple retry
    MODIFY_COMMAND = "modify"       # Modify the command and retry
    ALTERNATIVE_COMMAND = "alternative"  # Try an alternative command
    PREPARE_ENV = "prepare"         # Prepare the environment and retry
    REVERT_CHANGES = "revert"       # Revert changes and retry
    SKIP = "skip"                   # Skip the step and continue
    ABORT = "abort"                 # Abort the plan execution

class ErrorRecoveryManager:
    """
    Manager for error recovery during multi-step execution.
    
    This class provides:
    1. Analysis of execution errors
    2. Automatic recovery strategies
    3. Guided recovery with user input
    4. Learning from successful recoveries
    """
    
    def __init__(self):
        """Initialize the error recovery manager."""
        self._logger = logger
        self._recovery_history = {}  
        self._success_patterns = {}
        
            
    async def handle_error(
        self, 
        step: Any, 
        error_result: Dict[str, Any], 
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Handle an error during step execution with enhanced recovery learning.
        
        Args:
            step: The step that failed
            error_result: The execution result with error information
            context: Context information
            
        Returns:
            Updated execution result with recovery information
        """
        self._logger.info(f"Handling error for step {step.id if hasattr(step, 'id') else 'unknown'}")
        
        # Extract error information
        command = error_result.get("command") or getattr(step, "command", None)
        stderr = error_result.get("stderr", "")
        error_msg = error_result.get("error", "")
        
        if not command or (not stderr and not error_msg):
            # Not enough information to recover
            self._logger.warning("Insufficient information for error recovery")
            return error_result
        
        # Analyze the error
        analysis = await self._analyze_error(command, stderr or error_msg)
        
        # Get error pattern for historical matching
        error_pattern = self._extract_error_pattern(error_result)
        
        # Generate recovery strategies
        recovery_strategies = await self._generate_recovery_strategies(command, analysis, context)
        
        # Check if we have historical successes for this error pattern
        if error_pattern in self._success_patterns:
            self._logger.info(f"Found historical recovery strategies for error pattern: {error_pattern}")
            # Add strategies from successful historical recoveries
            for strategy_record in self._success_patterns[error_pattern]:
                historical_strategy = {
                    "type": strategy_record["type"],
                    "command": strategy_record["command"],
                    "description": f"Previously successful strategy (used {strategy_record['success_count']} times)",
                    "confidence": min(0.5 + (strategy_record["success_count"] * 0.1), 0.9),
                    "source": "history"
                }
                # Add to beginning of strategies list if not already present
                if not any(s["type"] == historical_strategy["type"] and s["command"] == historical_strategy["command"] 
                        for s in recovery_strategies):
                    recovery_strategies.insert(0, historical_strategy)
        
        # Prioritize strategies based on historical success
        prioritized_strategies = self._prioritize_strategies_by_history(recovery_strategies)
        
        # Record error analysis and strategies
        result = dict(error_result)
        result["error_analysis"] = analysis
        result["recovery_strategies"] = prioritized_strategies
        
        # Check if we can auto-recover
        if prioritized_strategies and self._can_auto_recover(prioritized_strategies[0]):
            # Attempt automatic recovery
            recovery_result = await self._execute_recovery_strategy(
                prioritized_strategies[0], step, error_result, context
            )
            
            # Update the result
            result["recovery_attempted"] = True
            result["recovery_strategy"] = prioritized_strategies[0]
            result["recovery_success"] = recovery_result.get("success", False)
            
            # Learn from this recovery attempt
            await self._learn_from_recovery_result(recovery_result, step, error_result, context)
            
            # If recovery succeeded, replace the result
            if recovery_result.get("success", False):
                self._logger.info(f"Automatic recovery succeeded for step {getattr(step, 'id', 'unknown')}")
                result.update(recovery_result)
        else:
            # Guided recovery with user input
            recovery_result = await self._guided_recovery(prioritized_strategies, step, error_result, context)
            
            # Update the result
            result["recovery_attempted"] = recovery_result is not None
            if recovery_result:
                result["recovery_strategy"] = recovery_result.get("strategy", {})
                result["recovery_success"] = recovery_result.get("success", False)
                
                # Learn from this recovery attempt
                await self._learn_from_recovery_result(recovery_result, step, error_result, context)
                
                # If recovery succeeded, replace the result
                if recovery_result.get("success", False):
                    self._logger.info(f"Guided recovery succeeded for step {getattr(step, 'id', 'unknown')}")
                    result.update(recovery_result)
        
        return result
    
    async def _learn_from_recovery_result(
        self, 
        recovery_result: Dict[str, Any], 
        step: Any, 
        error_result: Dict[str, Any], 
        context: Dict[str, Any]
    ) -> None:
        """
        Learn from recovery attempts to improve future strategies.
        
        Args:
            recovery_result: Result from the recovery attempt
            step: The step that failed
            error_result: Original error information
            context: Context information
        """
        if recovery_result.get("success", False):
            strategy = recovery_result.get("strategy", recovery_result.get("recovery_strategy", {}))
            strategy_type = strategy.get("type")
            error_pattern = self._extract_error_pattern(error_result)
            
            self._logger.debug(f"Learning from successful recovery of type {strategy_type} for pattern {error_pattern}")
            
            if strategy_type and error_pattern:
                # Update recovery history
                strategy_key = f"{strategy_type}:{strategy.get('command', '')}"
                if strategy_key not in self._recovery_history:
                    self._recovery_history[strategy_key] = {"success_count": 0}
                
                self._recovery_history[strategy_key]["success_count"] += 1
                self._recovery_history[strategy_key]["last_success"] = datetime.now().isoformat()
                
                # Record successful strategy for this error pattern
                if error_pattern not in self._success_patterns:
                    self._success_patterns[error_pattern] = []
                
                # Check if strategy already exists for this pattern
                existing_strategy = next(
                    (s for s in self._success_patterns[error_pattern] 
                     if s["type"] == strategy_type and s["command"] == strategy.get("command", "")),
                    None
                )
                
                if existing_strategy:
                    # Update existing strategy
                    existing_strategy["success_count"] += 1
                    existing_strategy["last_success"] = datetime.now().isoformat()
                else:
                    # Add new strategy record
                    strategy_record = {
                        "type": strategy_type,
                        "command": strategy.get("command", ""),
                        "success_count": 1,
                        "last_success": datetime.now().isoformat()
                    }
                    self._success_patterns[error_pattern].append(strategy_record)
                
                # Publish learning event if event_bus is available
                try:
                    if 'event_bus' in globals() or hasattr(self, 'event_bus'):
                        event_bus_obj = globals().get('event_bus', getattr(self, 'event_bus', None))
                        if event_bus_obj and hasattr(event_bus_obj, 'publish'):
                            await event_bus_obj.publish("recovery:learning", {
                                "error_pattern": error_pattern,
                                "successful_strategy": strategy_type,
                                "timestamp": datetime.now().isoformat()
                            })
                except Exception as e:
                    self._logger.error(f"Error publishing learning event: {str(e)}")
    
    def _extract_error_pattern(
        self, 
        error_result: Dict[str, Any]
    ) -> str:
        """
        Extract a pattern that identifies the type of error.
        
        Args:
            error_result: Error information
            
        Returns:
            String pattern identifying the error type
        """
        stderr = error_result.get("stderr", "")
        error_msg = error_result.get("error", "")
        
        # Use stderr or error message
        error_text = stderr or error_msg
        
        # Try to extract the most specific part of the error
        # This is a simplified approach - can be made more sophisticated
        
        # Check for common error patterns
        patterns = self._get_common_error_patterns()
        
        for pattern, pattern_name in patterns:
            if re.search(pattern, error_text, re.IGNORECASE):
                return pattern_name
        
        # If no specific pattern matches, return a more generic one
        # based on the first line of the error
        first_line = error_text.split('\n')[0][:50]
        if first_line:
            return f"generic:{first_line}"
        
        return "unknown_error"
    
    def _prioritize_strategies_by_history(
        self, 
        strategies: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        Prioritize recovery strategies based on historical success.
        
        Args:
            strategies: List of recovery strategies
            
        Returns:
            Prioritized list of strategies
        """
        # Create a copy of the strategies to avoid modifying the original
        prioritized = list(strategies)
        
        # Adjust confidence based on historical success
        for strategy in prioritized:
            strategy_key = f"{strategy.get('type')}:{strategy.get('command', '')}"
            
            # Check history for this strategy
            if strategy_key in self._recovery_history:
                history = self._recovery_history[strategy_key]
                success_count = history.get("success_count", 0)
                
                # Boost confidence based on success count
                # Original confidence is weighted at 60%, historical at 40%
                original_confidence = strategy.get("confidence", 0.5)
                history_confidence = min(0.3 + (success_count * 0.1), 0.9)
                
                # Combine confidences
                adjusted_confidence = (original_confidence * 0.6) + (history_confidence * 0.4)
                strategy["confidence"] = min(adjusted_confidence, 0.95)
                
                # Add metadata about historical success
                strategy["history"] = {
                    "success_count": success_count,
                    "last_success": history.get("last_success", "unknown")
                }
        
        # Sort by confidence (highest first)
        return sorted(prioritized, key=lambda s: s.get("confidence", 0), reverse=True)
    
    async def _analyze_error(self, command: str, error: str) -> Dict[str, Any]:
        """
        Analyze an error to determine its cause and possible fixes.
        
        Args:
            command: The command that failed
            error: The error message
            
        Returns:
            Error analysis result
        """
        # Use the error analyzer to analyze the error
        analysis = error_analyzer.analyze_error(command, error)
        
        # Generate fix suggestions
        suggestions = error_analyzer.generate_fix_suggestions(command, error)
        analysis["fix_suggestions"] = suggestions
        
        # Add error patterns
        error_patterns = analysis.get("error_patterns", [])
        if not error_patterns:
            # Try to match common error patterns
            for pattern in self._get_common_error_patterns():
                if re.search(pattern["pattern"], error, re.IGNORECASE):
                    error_patterns.append({
                        "pattern": pattern["pattern"],
                        "description": pattern["description"],
                        "fixes": pattern["fixes"]
                    })
        
        analysis["error_patterns"] = error_patterns
        
        return analysis
    
    async def _generate_recovery_strategies(
        self, 
        command: str, 
        analysis: Dict[str, Any], 
        context: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """
        Generate recovery strategies based on error analysis.
        
        Args:
            command: The command that failed
            analysis: Error analysis result
            context: Context information
            
        Returns:
            List of recovery strategies
        """
        strategies = []
        
        # Check if we have fix suggestions
        if analysis.get("fix_suggestions"):
            for suggestion in analysis["fix_suggestions"]:
                # Parse the suggestion to generate a recovery strategy
                strategy = self._parse_fix_suggestion(suggestion, command)
                if strategy:
                    strategies.append(strategy)
        
        # Check for error patterns
        if analysis.get("error_patterns"):
            for pattern in analysis["error_patterns"]:
                for fix in pattern.get("fixes", []):
                    strategy = self._create_strategy_from_pattern_fix(fix, command)
                    if strategy and not any(s["command"] == strategy["command"] for s in strategies):
                        strategies.append(strategy)
        
        # If no strategies yet, use AI to generate strategies
        if not strategies:
            ai_strategies = await self._generate_ai_recovery_strategies(command, analysis, context)
            strategies.extend(ai_strategies)
        
        # Always add retry and skip as fallback strategies
        if not any(s["type"] == RecoveryStrategy.RETRY.value for s in strategies):
            strategies.append({
                "type": RecoveryStrategy.RETRY.value,
                "command": command,
                "description": "Retry the command without changes",
                "confidence": 0.3
            })
        
        # Add skip strategy
        strategies.append({
            "type": RecoveryStrategy.SKIP.value,
            "command": None,
            "description": "Skip this step and continue with the plan",
            "confidence": 0.2
        })
        
        # Sort strategies by confidence
        strategies.sort(key=lambda s: s.get("confidence", 0), reverse=True)
        
        return strategies
    
    def _parse_fix_suggestion(self, suggestion: str, command: str) -> Optional[Dict[str, Any]]:
        """
        Parse a fix suggestion into a recovery strategy.
        
        Args:
            suggestion: The fix suggestion
            command: The original command
            
        Returns:
            Recovery strategy or None if parsing fails
        """
        # Check for suggested commands in the form of "Try: command"
        command_match = re.search(r'try:?\s*`?([^`]+)`?', suggestion, re.IGNORECASE)
        if command_match:
            suggested_command = command_match.group(1).strip()
            return {
                "type": RecoveryStrategy.MODIFY_COMMAND.value,
                "command": suggested_command,
                "description": suggestion,
                "confidence": 0.8
            }
        
        # Check for permission issues
        if "permission" in suggestion.lower():
            if "sudo" not in command.lower() and not command.strip().startswith("sudo "):
                # Add sudo to the command
                sudo_command = f"sudo {command}"
                return {
                    "type": RecoveryStrategy.MODIFY_COMMAND.value,
                    "command": sudo_command,
                    "description": "Add sudo to the command for elevated privileges",
                    "confidence": 0.7
                }
        
        # Check for missing file or directory suggestions
        if "file not found" in suggestion.lower() or "directory not found" in suggestion.lower():
            mkdir_match = re.search(r'mkdir\s+([^\s]+)', suggestion, re.IGNORECASE)
            if mkdir_match:
                dir_path = mkdir_match.group(1)
                return {
                    "type": RecoveryStrategy.PREPARE_ENV.value,
                    "command": f"mkdir -p {dir_path}",
                    "description": f"Create the directory {dir_path} and retry",
                    "confidence": 0.7,
                    "retry_original": True
                }
        
        # General suggestion without a specific command
        return {
            "type": RecoveryStrategy.ALTERNATIVE_COMMAND.value,
            "command": None,  # Will be filled in by AI
            "description": suggestion,
            "confidence": 0.5
        }
    
    def _create_strategy_from_pattern_fix(self, fix: str, command: str) -> Optional[Dict[str, Any]]:
        """
        Create a recovery strategy from a pattern fix.
        
        Args:
            fix: The fix description
            command: The original command
            
        Returns:
            Recovery strategy or None if parsing fails
        """
        # Check for command suggestions
        command_match = re.search(r'`([^`]+)`', fix)
        if command_match:
            suggested_command = command_match.group(1).strip()
            return {
                "type": RecoveryStrategy.ALTERNATIVE_COMMAND.value,
                "command": suggested_command,
                "description": fix,
                "confidence": 0.7
            }
        
        # Check for common actions
        if "install" in fix.lower():
            # Extract package name
            pkg_match = re.search(r'install\s+(\w+)', fix, re.IGNORECASE)
            if pkg_match:
                pkg_name = pkg_match.group(1)
                return {
                    "type": RecoveryStrategy.PREPARE_ENV.value,
                    "command": f"apt-get install -y {pkg_name}",
                    "description": f"Install missing package: {pkg_name}",
                    "confidence": 0.7,
                    "retry_original": True
                }
        
        return None
    
    async def _generate_ai_recovery_strategies(
        self, 
        command: str, 
        analysis: Dict[str, Any], 
        context: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """
        Generate recovery strategies using the AI.
        
        Args:
            command: The command that failed
            analysis: Error analysis result
            context: Context information
            
        Returns:
            List of AI-generated recovery strategies
        """
        # Build a prompt for strategy generation
        error_summary = analysis.get("error_summary", "Unknown error")
        possible_cause = analysis.get("possible_cause", "Unknown cause")
        
        prompt = f"""
Generate recovery strategies for a failed command execution.

Failed command: `{command}`
Error summary: {error_summary}
Possible cause: {possible_cause}

Generate 2-3 specific recovery strategies, each with:
1. A specific command to execute
2. A description of what the strategy does
3. A confidence level (0.0-1.0)

Format your response as JSON:
[
  {{
    "type": "modify",
    "command": "modified command",
    "description": "Description of the strategy",
    "confidence": 0.8
  }},
  {{
    "type": "prepare",
    "command": "preparation command",
    "description": "Prepare the environment",
    "confidence": 0.7,
    "retry_original": true
  }}
]

Valid strategy types:
- modify: Modify the original command
- alternative: Use an alternative command
- prepare: Prepare the environment and retry
- revert: Revert changes and retry
"""
        
        # Call the AI service
        api_request = GeminiRequest(prompt=prompt, max_tokens=1000)
        api_response = await gemini_client.generate_text(api_request)
        
        # Parse the response
        try:
            # Extract JSON from the response
            import re
            import json
            
            json_match = re.search(r'```(?:json)?\s*(.*?)\s*```', api_response.text, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
            else:
                json_str = api_response.text
            
            # Parse the JSON
            strategies = json.loads(json_str)
            
            # Validate and normalize strategies
            valid_strategies = []
            for strategy in strategies:
                if isinstance(strategy, dict) and "type" in strategy and "command" in strategy:
                    # Ensure type is valid
                    try:
                        RecoveryStrategy(strategy["type"])
                        valid_strategies.append(strategy)
                    except ValueError:
                        # Invalid strategy type, skip it
                        pass
            
            return valid_strategies
            
        except Exception as e:
            self._logger.error(f"Error parsing AI recovery strategies: {str(e)}")
            return []
    
    def _can_auto_recover(self, strategy: Dict[str, Any]) -> bool:
        """
        Determine if a strategy can be applied automatically.
        
        Args:
            strategy: The recovery strategy
            
        Returns:
            True if auto-recovery is possible, False otherwise
        """
        # High confidence strategies can be auto-applied
        if strategy.get("confidence", 0) >= 0.8:
            return True
        
        # Certain strategy types can always be auto-applied
        auto_types = [
            RecoveryStrategy.RETRY.value
        ]
        
        if strategy.get("type") in auto_types:
            return True
        
        # Check if the strategy has been successful in the past
        strategy_key = f"{strategy.get('type')}:{strategy.get('command')}"
        if self._recovery_history.get(strategy_key, {}).get("success_count", 0) > 0:
            return True
        
        return False
    
    async def _execute_recovery_strategy(
        self, 
        strategy: Dict[str, Any], 
        step: Any, 
        error_result: Dict[str, Any], 
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Execute a recovery strategy.
        
        Args:
            strategy: The recovery strategy to execute
            step: The step that failed
            error_result: The original error result
            context: Context information
            
        Returns:
            Updated execution result
        """
        self._logger.info(f"Executing recovery strategy: {strategy.get('type')}")
        
        # Import here to avoid circular imports
        from angela.execution.engine import execution_engine
        
        result = {
            "strategy": strategy,
            "original_error": error_result.get("error"),
            "original_stderr": error_result.get("stderr")
        }
        
        try:
            # Execute based on strategy type
            strategy_type = strategy.get("type")
            
            if strategy_type == RecoveryStrategy.RETRY.value:
                # Simple retry of the original command
                command = getattr(step, "command", None) or error_result.get("command")
                if command:
                    stdout, stderr, return_code = await execution_engine.execute_command(
                        command,
                        check_safety=False  # Skip safety checks for retry
                    )
                    
                    result.update({
                        "command": command,
                        "stdout": stdout,
                        "stderr": stderr,
                        "return_code": return_code,
                        "success": return_code == 0
                    })
                else:
                    result.update({
                        "error": "No command available for retry",
                        "success": False
                    })
            
            elif strategy_type in [RecoveryStrategy.MODIFY_COMMAND.value, 
                                RecoveryStrategy.ALTERNATIVE_COMMAND.value]:
                # Execute modified or alternative command
                command = strategy.get("command")
                if command:
                    stdout, stderr, return_code = await execution_engine.execute_command(
                        command,
                        check_safety=True  # Safety checks for new commands
                    )
                    
                    result.update({
                        "command": command,
                        "stdout": stdout,
                        "stderr": stderr,
                        "return_code": return_code,
                        "success": return_code == 0
                    })
                    
                    # If successful and requested, retry the original command
                    if return_code == 0 and strategy.get("retry_original"):
                        original_command = getattr(step, "command", None) or error_result.get("command")
                        if original_command:
                            self._logger.info(f"Retrying original command: {original_command}")
                            stdout, stderr, return_code = await execution_engine.execute_command(
                                original_command,
                                check_safety=False
                            )
                            
                            result.update({
                                "original_retry": {
                                    "command": original_command,
                                    "stdout": stdout,
                                    "stderr": stderr,
                                    "return_code": return_code,
                                    "success": return_code == 0
                                }
                            })
                            
                            # Update overall success based on original command retry
                            result["success"] = return_code == 0
                else:
                    result.update({
                        "error": "No command specified in strategy",
                        "success": False
                    })
            
            elif strategy_type == RecoveryStrategy.PREPARE_ENV.value:
                # Execute preparation command
                command = strategy.get("command")
                if command:
                    stdout, stderr, return_code = await execution_engine.execute_command(
                        command,
                        check_safety=True
                    )
                    
                    result.update({
                        "preparation": {
                            "command": command,
                            "stdout": stdout,
                            "stderr": stderr,
                            "return_code": return_code,
                            "success": return_code == 0
                        }
                    })
                    
                    # If preparation succeeded and requested, retry the original command
                    if return_code == 0 and strategy.get("retry_original"):
                        original_command = getattr(step, "command", None) or error_result.get("command")
                        if original_command:
                            self._logger.info(f"Retrying original command after preparation: {original_command}")
                            stdout, stderr, return_code = await execution_engine.execute_command(
                                original_command,
                                check_safety=False
                            )
                            
                            result.update({
                                "command": original_command,
                                "stdout": stdout,
                                "stderr": stderr,
                                "return_code": return_code,
                                "success": return_code == 0
                            })
                        else:
                            result.update({
                                "error": "No original command available for retry",
                                "success": False
                            })
                    else:
                        # No retry requested or preparation failed
                        result["success"] = return_code == 0
                else:
                    result.update({
                        "error": "No preparation command specified in strategy",
                        "success": False
                    })
            
            elif strategy_type == RecoveryStrategy.REVERT_CHANGES.value:
                # Revert changes (simplified implementation)
                result.update({
                    "message": "Revert changes not implemented",
                    "success": False
                })
            
            elif strategy_type == RecoveryStrategy.SKIP.value:
                # Skip the step
                result.update({
                    "message": "Step skipped",
                    "success": True,
                    "skipped": True
                })
            
            else:
                result.update({
                    "error": f"Unknown strategy type: {strategy_type}",
                    "success": False
                })
            
            # Update recovery history
            if result.get("success"):
                strategy_key = f"{strategy.get('type')}:{strategy.get('command')}"
                if strategy_key in self._recovery_history:
                    self._recovery_history[strategy_key]["success_count"] += 1
                    self._recovery_history[strategy_key]["last_success"] = datetime.now()
                else:
                    self._recovery_history[strategy_key] = {
                        "success_count": 1,
                        "failure_count": 0,
                        "last_success": datetime.now()
                    }
            
            return result
            
        except Exception as e:
            self._logger.exception(f"Error executing recovery strategy: {str(e)}")
            return {
                "strategy": strategy,
                "error": str(e),
                "success": False
            }
    
    async def _guided_recovery(
        self, 
        strategies: List[Dict[str, Any]], 
        step: Any, 
        error_result: Dict[str, Any], 
        context: Dict[str, Any]
    ) -> Optional[Dict[str, Any]]:
        """
        Guide the user through recovery options.
        
        Args:
            strategies: Available recovery strategies
            step: The step that failed
            error_result: The original error result
            context: Context information
            
        Returns:
            Recovery result or None if aborted
        """
        if not strategies:
            return None
        
        # Display recovery options
        terminal_formatter.print_output(
            "Command execution failed. The following recovery options are available:",
            OutputType.WARNING,
            title="Recovery Options"
        )
        
        # Display the error
        terminal_formatter.print_output(
            error_result.get("stderr", "") or error_result.get("error", "Unknown error"),
            OutputType.ERROR,
            title="Error"
        )
        
        # Show strategies
        for i, strategy in enumerate(strategies):
            description = strategy.get("description", "No description")
            command = strategy.get("command", "No command")
            
            if strategy.get("type") == RecoveryStrategy.SKIP.value:
                terminal_formatter.print_output(
                    f"Option {i+1}: [Skip] {description}",
                    OutputType.INFO
                )
            else:
                terminal_formatter.print_output(
                    f"Option {i+1}: {description}\n  Command: {command}",
                    OutputType.INFO
                )
        
        # Add abort option
        terminal_formatter.print_output(
            f"Option {len(strategies)+1}: [Abort] Abort execution",
            OutputType.WARNING
        )
        
        # Get user selection
        from prompt_toolkit.shortcuts import input_dialog
        selection = input_dialog(
            title="Select Recovery Option",
            text="Enter option number:",
        ).run()
        
        if not selection or not selection.isdigit():
            return None
        
        option = int(selection)
        
        # Handle abort option
        if option == len(strategies) + 1:
            return {
                "message": "Execution aborted by user",
                "success": False,
                "aborted": True
            }
        
        # Handle strategy selection
        if 1 <= option <= len(strategies):
            selected_strategy = strategies[option - 1]
            
            # Execute the selected strategy
            return await self._execute_recovery_strategy(
                selected_strategy, step, error_result, context
            )
        
        return None
    
    def _get_common_error_patterns(self) -> List[Dict[str, Any]]:
        """
        Get common error patterns and fix suggestions.
        
        Returns:
            List of error pattern dictionaries
        """
        return [
            {
                "pattern": r'permission denied|cannot access|operation not permitted',
                "description": "Permission denied error",
                "fixes": [
                    "Try running the command with sudo: `sudo {command}`",
                    "Check file permissions with `ls -l {path}`",
                    "Change file permissions with `chmod +x {path}`"
                ]
            },
            {
                "pattern": r'command not found|not installed|no such file or directory',
                "description": "Command or file not found",
                "fixes": [
                    "Install the package containing the command",
                    "Check if the path is correct",
                    "Use `which {command}` to check if the command is in PATH"
                ]
            },
            {
                "pattern": r'syntax error|invalid option|unrecognized option',
                "description": "Command syntax error",
                "fixes": [
                    "Check the command syntax with `man {command}`",
                    "Remove problematic options or flags",
                    "Ensure quotes and brackets are properly matched"
                ]
            },
            {
                "pattern": r'cannot connect|connection refused|network is unreachable',
                "description": "Network connection error",
                "fixes": [
                    "Check if the host is reachable with `ping {host}`",
                    "Verify network connectivity",
                    "Ensure the service is running with `systemctl status {service}`"
                ]
            },
            {
                "pattern": r'disk quota exceeded|no space left on device|file system is full',
                "description": "Disk space issue",
                "fixes": [
                    "Free up disk space with `df -h` to check and `rm` to remove files",
                    "Clean up temporary files with `apt-get clean` or `yum clean all`",
                    "Compress large files with `gzip {file}`"
                ]
            },
            {
                "pattern": r'resource temporarily unavailable|resource busy|device or resource busy',
                "description": "Resource busy error",
                "fixes": [
                    "Wait and try again later",
                    "Check what processes are using the resource with `lsof {path}`",
                    "Terminate competing processes with `kill {pid}`"
                ]
            }
        ]
</file>

<file path="angela/execution/rollback_commands.py">
# angela/cli/rollback_commands.py
"""
CLI commands for enhanced rollback functionality.
"""
import asyncio
import typer
from pathlib import Path
from typing import Optional, List

from rich.console import Console
from rich.panel import Panel
from rich.table import Table
from rich import print as rich_print
from rich.prompt import Confirm
from rich.syntax import Syntax

from angela.execution.rollback import rollback_manager
from angela.utils.logging import get_logger

logger = get_logger(__name__)
console = Console()

app = typer.Typer(help="Rollback commands for undoing operations")

@app.command("list", help="List recent operations that can be rolled back")
def list_operations(
    limit: int = typer.Option(10, help="Maximum number of operations to show"),
    transactions: bool = typer.Option(False, help="Show transactions instead of individual operations")
):
    """List recent operations or transactions that can be rolled back."""
    if transactions:
        # Show transactions
        transaction_list = asyncio.run(rollback_manager.get_recent_transactions(limit))
        
        if not transaction_list:
            console.print("[yellow]No transactions found.[/yellow]")
            return
        
        # Create a table for the transactions
        table = Table(title="Recent Transactions")
        table.add_column("ID", style="cyan")
        table.add_column("Timestamp", style="green")
        table.add_column("Description", style="white")
        table.add_column("Status", style="yellow")
        table.add_column("Operations", style="blue")
        table.add_column("Can Rollback", style="red")
        
        # Add rows for each transaction
        for transaction in transaction_list:
            table.add_row(
                transaction["id"],
                transaction["timestamp"],
                transaction["description"],
                transaction["status"],
                str(transaction["operation_count"]),
                "✓" if transaction["can_rollback"] else "✗"
            )
        
        # Display the table
        console.print(table)
        
        # Show usage hint
        console.print("\n[bold]Use the following command to roll back a transaction:[/bold]")
        console.print("  [blue]angela rollback transaction <ID>[/blue]")
    
    else:
        # Show individual operations
        operation_list = asyncio.run(rollback_manager.get_recent_operations(limit))
        
        if not operation_list:
            console.print("[yellow]No operations found.[/yellow]")
            return
        
        # Create a table for the operations
        table = Table(title="Recent Operations")
        table.add_column("ID", style="cyan")
        table.add_column("Timestamp", style="green")
        table.add_column("Type", style="white")
        table.add_column("Description", style="blue")
        table.add_column("Can Rollback", style="red")
        table.add_column("Transaction", style="yellow")
        
        # Add rows for each operation
        for operation in operation_list:
            transaction_info = operation.get("transaction")
            transaction_desc = f"{transaction_info['description']} ({transaction_info['status']})" if transaction_info else "None"
            
            table.add_row(
                str(operation["id"]),
                operation["timestamp"],
                operation["operation_type"],
                operation["description"],
                "✓" if operation["can_rollback"] else "✗",
                transaction_desc
            )
        
        # Display the table
        console.print(table)
        
        # Show usage hint
        console.print("\n[bold]Use the following command to roll back an operation:[/bold]")
        console.print("  [blue]angela rollback operation <ID>[/blue]")


@app.command("operation", help="Roll back a specific operation")
def rollback_operation(
    operation_id: int = typer.Argument(..., help="ID of the operation to roll back"),
    force: bool = typer.Option(False, help="Skip confirmation prompt")
):
    """Roll back a specific operation by ID."""
    # Get operation details
    operation_list = asyncio.run(rollback_manager.get_recent_operations(100))
    
    # Find the operation
    operation = None
    for op in operation_list:
        if op["id"] == operation_id:
            operation = op
            break
    
    if not operation:
        console.print(f"[red]Operation with ID {operation_id} not found.[/red]")
        return
    
    # Check if the operation can be rolled back
    if not operation["can_rollback"]:
        console.print("[red]This operation cannot be rolled back.[/red]")
        return
    
    # Display operation details
    console.print(Panel(
        f"[bold]Type:[/bold] {operation['operation_type']}\n"
        f"[bold]Description:[/bold] {operation['description']}\n"
        f"[bold]Timestamp:[/bold] {operation['timestamp']}",
        title="Operation Details",
        expand=False
    ))
    
    # Get confirmation
    if not force and not Confirm.ask("Are you sure you want to roll back this operation?"):
        console.print("[yellow]Rollback cancelled.[/yellow]")
        return
    
    # Execute the rollback
    with console.status("[bold green]Rolling back operation...[/bold green]"):
        success = asyncio.run(rollback_manager.rollback_operation(operation_id))
    
    # Show the result
    if success:
        console.print("[green]Operation successfully rolled back.[/green]")
    else:
        console.print("[red]Failed to roll back operation.[/red]")


@app.command("transaction", help="Roll back an entire transaction")
def rollback_transaction(
    transaction_id: str = typer.Argument(..., help="ID of the transaction to roll back"),
    force: bool = typer.Option(False, help="Skip confirmation prompt")
):
    """Roll back all operations in a transaction."""
    # Get transaction details
    transaction_list = asyncio.run(rollback_manager.get_recent_transactions(100))
    
    # Find the transaction
    transaction = None
    for tx in transaction_list:
        if tx["id"] == transaction_id:
            transaction = tx
            break
    
    if not transaction:
        console.print(f"[red]Transaction with ID {transaction_id} not found.[/red]")
        return
    
    # Check if the transaction can be rolled back
    if not transaction["can_rollback"]:
        console.print("[red]This transaction cannot be rolled back.[/red]")
        return
    
    # Display transaction details
    console.print(Panel(
        f"[bold]Description:[/bold] {transaction['description']}\n"
        f"[bold]Status:[/bold] {transaction['status']}\n"
        f"[bold]Timestamp:[/bold] {transaction['timestamp']}\n"
        f"[bold]Operation count:[/bold] {transaction['operation_count']}",
        title="Transaction Details",
        expand=False
    ))
    
    # Get confirmation
    if not force and not Confirm.ask("Are you sure you want to roll back this entire transaction?"):
        console.print("[yellow]Rollback cancelled.[/yellow]")
        return
    
    # Execute the rollback
    with console.status("[bold green]Rolling back transaction...[/bold green]"):
        result = asyncio.run(rollback_manager.rollback_transaction(transaction_id))
    
    # Show the result
    if result["success"]:
        console.print(f"[green]Transaction successfully rolled back. {result['rolled_back']} operations reverted.[/green]")
    else:
        console.print(f"[red]Transaction rollback failed or partially succeeded. "
                     f"{result['rolled_back']} operations reverted, {result['failed']} operations failed.[/red]")
        
        # Show details of failed operations
        if result["failed"] > 0 and "results" in result:
            failed_ops = [r for r in result["results"] if not r["success"]]
            
            if failed_ops:
                console.print("\n[bold]Failed operations:[/bold]")
                for op in failed_ops:
                    console.print(f"- ID {op['operation_id']}: {op['description']} - {op.get('error', 'Unknown error')}")


@app.command("last", help="Roll back the most recent operation or transaction")
def rollback_last(
    transaction: bool = typer.Option(False, help="Roll back the last transaction instead of the last operation"),
    force: bool = typer.Option(False, help="Skip confirmation prompt")
):
    """Roll back the most recent operation or transaction."""
    if transaction:
        # Get the most recent transaction
        transactions = asyncio.run(rollback_manager.get_recent_transactions(1))
        
        if not transactions:
            console.print("[yellow]No transactions found.[/yellow]")
            return
        
        # Use the first (most recent) transaction
        transaction_id = transactions[0]["id"]
        
        # Call the rollback_transaction function
        rollback_transaction(transaction_id, force)
    else:
        # Get the most recent operation
        operations = asyncio.run(rollback_manager.get_recent_operations(1))
        
        if not operations:
            console.print("[yellow]No operations found.[/yellow]")
            return
        
        # Use the first (most recent) operation
        operation_id = operations[0]["id"]
        
        # Call the rollback_operation function
        rollback_operation(operation_id, force)


# To be used for integration with the main CLI
def register_commands(parent_app: typer.Typer):
    """Register rollback commands with a parent Typer app."""
    parent_app.add_typer(app, name="rollback", help="Commands for rolling back operations")
</file>

<file path="angela/execution/rollback.py">
"""
Enhanced rollback functionality for Angela CLI operations.

This module provides the ability to undo complex, multi-step operations
by tracking and reverting individual actions within a transaction.
It supports rolling back different types of operations including:
- File system operations (create, modify, delete files and directories)
- Content manipulations (AI-driven file changes)
- Command executions (with compensating actions)
"""
import os
import json
import shlex
import uuid
import shutil
import asyncio
import tempfile
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional, List, Tuple, Union, Set

from angela.utils.logging import get_logger
from angela.execution.filesystem import BACKUP_DIR
from angela.review.diff_manager import diff_manager
from angela.execution.engine import execution_engine

logger = get_logger(__name__)

# File to store operation history for rollback
HISTORY_FILE = BACKUP_DIR / "operation_history.json"
TRANSACTION_DIR = BACKUP_DIR / "transactions"

# Operation types
OP_FILE_SYSTEM = "filesystem"     # File system operations (create, delete, etc.)
OP_CONTENT = "content"            # Content manipulation operations
OP_COMMAND = "command"            # Command execution operations
OP_PLAN = "plan"                  # Plan execution operations


class OperationRecord:
    """Record of an operation for rollback purposes."""
    
    def __init__(
        self,
        operation_type: str,
        params: Dict[str, Any],
        timestamp: Optional[datetime] = None,
        backup_path: Optional[str] = None,
        transaction_id: Optional[str] = None,
        step_id: Optional[str] = None,
        undo_info: Optional[Dict[str, Any]] = None
    ):
        self.operation_type = operation_type
        self.params = params
        self.timestamp = timestamp or datetime.now()
        self.backup_path = backup_path
        self.transaction_id = transaction_id
        self.step_id = step_id
        self.undo_info = undo_info or {}
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert the record to a dictionary for storage."""
        return {
            "operation_type": self.operation_type,
            "params": self.params,
            "timestamp": self.timestamp.isoformat(),
            "backup_path": str(self.backup_path) if self.backup_path else None,
            "transaction_id": self.transaction_id,
            "step_id": self.step_id,
            "undo_info": self.undo_info
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'OperationRecord':
        """Create a record from a dictionary."""
        return cls(
            operation_type=data["operation_type"],
            params=data["params"],
            timestamp=datetime.fromisoformat(data["timestamp"]),
            backup_path=data["backup_path"],
            transaction_id=data.get("transaction_id"),
            step_id=data.get("step_id"),
            undo_info=data.get("undo_info", {})
        )


class Transaction:
    """A group of operations that form a single logical action."""
    
    def __init__(
        self,
        transaction_id: str,
        description: str,
        timestamp: Optional[datetime] = None,
        status: str = "started"  # started, completed, failed, rolled_back
    ):
        self.transaction_id = transaction_id
        self.description = description
        self.timestamp = timestamp or datetime.now()
        self.status = status
        self.operation_ids: List[int] = []
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert the transaction to a dictionary for storage."""
        return {
            "transaction_id": self.transaction_id,
            "description": self.description,
            "timestamp": self.timestamp.isoformat(),
            "status": self.status,
            "operation_ids": self.operation_ids
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'Transaction':
        """Create a transaction from a dictionary."""
        transaction = cls(
            transaction_id=data["transaction_id"],
            description=data["description"],
            timestamp=datetime.fromisoformat(data["timestamp"]),
            status=data["status"]
        )
        transaction.operation_ids = data.get("operation_ids", [])
        return transaction


class RollbackManager:
    """Manager for operation history and rollback functionality."""
    
    def __init__(self):
        """Initialize the rollback manager."""
        self._ensure_directories()
        self._operations = self._load_history()
        self._transactions = self._load_transactions()
        self._active_transactions: Dict[str, Transaction] = {}
        self._command_compensations = self._load_command_compensations()
    
    def _ensure_directories(self):
        """Ensure the history file and transaction directory exist."""
        BACKUP_DIR.mkdir(parents=True, exist_ok=True)
        TRANSACTION_DIR.mkdir(parents=True, exist_ok=True)
        if not HISTORY_FILE.exists():
            self._save_history([])
    
    def _load_history(self) -> List[OperationRecord]:
        """Load operation history from the history file."""
        try:
            with open(HISTORY_FILE, 'r') as f:
                data = json.load(f)
            
            return [OperationRecord.from_dict(item) for item in data]
        
        except Exception as e:
            logger.error(f"Error loading operation history: {str(e)}")
            return []
    
    def _save_history(self, operations: List[OperationRecord]):
        """Save operation history to the history file."""
        try:
            with open(HISTORY_FILE, 'w') as f:
                json.dump([op.to_dict() for op in operations], f, indent=2)
        
        except Exception as e:
            logger.error(f"Error saving operation history: {str(e)}")
    
    def _load_transactions(self) -> Dict[str, Transaction]:
        """Load transactions from the transaction directory."""
        transactions = {}
        try:
            for file in TRANSACTION_DIR.glob("*.json"):
                try:
                    with open(file, 'r') as f:
                        data = json.load(f)
                        transaction = Transaction.from_dict(data)
                        transactions[transaction.transaction_id] = transaction
                except Exception as e:
                    logger.error(f"Error loading transaction {file}: {str(e)}")
        except Exception as e:
            logger.error(f"Error loading transactions: {str(e)}")
        
        return transactions
    
    def _save_transaction(self, transaction: Transaction):
        """Save a transaction to its file."""
        try:
            file_path = TRANSACTION_DIR / f"{transaction.transaction_id}.json"
            with open(file_path, 'w') as f:
                json.dump(transaction.to_dict(), f, indent=2)
        except Exception as e:
            logger.error(f"Error saving transaction {transaction.transaction_id}: {str(e)}")
    
    def _load_command_compensations(self) -> Dict[str, str]:
        """Load command compensation rules from a file."""
        compensations = {}
        
        # Define built-in command compensations
        built_in = {
            # Git compensations
            "git add": "git reset",               # Unstage files
            "git commit": "git reset --soft HEAD~1",  # Undo last commit
            "git push": "git push -f origin HEAD~1:${branch}",  # Force push previous commit
            "git branch": "git branch -D",        # Delete branch
            
            # Package manager compensations
            "npm install": "npm uninstall",       # Uninstall npm package
            "pip install": "pip uninstall -y",    # Uninstall pip package
            "apt-get install": "apt-get remove",  # Remove apt package
            
            # File operations (as fallbacks)
            "mkdir": "rmdir",                     # Remove directory
            "touch": "rm",                        # Remove file
        }
        
        # Add the built-in compensations
        compensations.update(built_in)
        
        # TODO: Load custom compensations from a file
        
        return compensations
    
    async def start_transaction(self, description: str) -> str:
        """
        Start a new transaction.
        
        Args:
            description: Description of the transaction
            
        Returns:
            Transaction ID
        """
        transaction_id = str(uuid.uuid4())
        transaction = Transaction(transaction_id, description)
        
        # Add to active transactions
        self._active_transactions[transaction_id] = transaction
        
        # Save the transaction
        self._save_transaction(transaction)
        
        logger.info(f"Started transaction {transaction_id}: {description}")
        return transaction_id
    
    async def end_transaction(self, transaction_id: str, status: str = "completed") -> bool:
        """
        End a transaction.
        
        Args:
            transaction_id: Transaction ID
            status: Transaction status ("completed" or "failed")
            
        Returns:
            True if successful, False otherwise
        """
        if transaction_id not in self._active_transactions:
            logger.error(f"Transaction {transaction_id} not found in active transactions")
            return False
        
        # Update the transaction
        transaction = self._active_transactions[transaction_id]
        transaction.status = status
        
        # Save the transaction
        self._save_transaction(transaction)
        
        # Add to transactions dict
        self._transactions[transaction_id] = transaction
        
        # Remove from active transactions
        del self._active_transactions[transaction_id]
        
        logger.info(f"Ended transaction {transaction_id} with status: {status}")
        return True
    
    async def record_operation(
        self,
        operation_type: str,
        params: Dict[str, Any],
        backup_path: Optional[Union[str, Path]] = None,
        transaction_id: Optional[str] = None,
        step_id: Optional[str] = None,
        undo_info: Optional[Dict[str, Any]] = None
    ) -> Optional[int]:
        """
        Record an operation for potential rollback.
        
        Args:
            operation_type: The type of operation.
            params: Parameters of the operation.
            backup_path: Path to the backup, if one was created.
            transaction_id: ID of the transaction this operation belongs to.
            step_id: ID of the step in the plan this operation belongs to.
            undo_info: Additional information needed for undoing the operation.
            
        Returns:
            Index of the operation in the history or None on error
        """
        try:
            # Create the operation record
            record = OperationRecord(
                operation_type=operation_type,
                params=params,
                backup_path=str(backup_path) if backup_path else None,
                transaction_id=transaction_id,
                step_id=step_id,
                undo_info=undo_info or {}
            )
            
            # Add to operations list
            operation_id = len(self._operations)
            self._operations.append(record)
            
            # Update transaction if provided
            if transaction_id:
                if transaction_id in self._active_transactions:
                    self._active_transactions[transaction_id].operation_ids.append(operation_id)
                    self._save_transaction(self._active_transactions[transaction_id])
                elif transaction_id in self._transactions:
                    self._transactions[transaction_id].operation_ids.append(operation_id)
                    self._save_transaction(self._transactions[transaction_id])
                else:
                    logger.warning(f"Transaction {transaction_id} not found when recording operation")
            
            # Save updated history
            self._save_history(self._operations)
            
            logger.debug(f"Recorded operation: {operation_type} (ID: {operation_id})")
            return operation_id
        
        except Exception as e:
            logger.error(f"Error recording operation: {str(e)}")
            return None
    
    async def record_file_operation(
        self,
        operation_type: str,
        params: Dict[str, Any],
        backup_path: Optional[Union[str, Path]] = None,
        transaction_id: Optional[str] = None,
        step_id: Optional[str] = None
    ) -> Optional[int]:
        """
        Record a file system operation for potential rollback.
        
        Args:
            operation_type: The type of file operation.
            params: Parameters of the operation.
            backup_path: Path to the backup, if one was created.
            transaction_id: ID of the transaction this operation belongs to.
            step_id: ID of the step in the plan this operation belongs to.
            
        Returns:
            Index of the operation in the history or None on error
        """
        return await self.record_operation(
            operation_type=OP_FILE_SYSTEM,
            params={
                "file_operation": operation_type,
                **params
            },
            backup_path=backup_path,
            transaction_id=transaction_id,
            step_id=step_id
        )
    
    async def record_content_manipulation(
        self,
        file_path: Union[str, Path],
        original_content: str,
        modified_content: str,
        instruction: Optional[str] = None,
        transaction_id: Optional[str] = None,
        step_id: Optional[str] = None
    ) -> Optional[int]:
        """
        Record a content manipulation operation for potential rollback.
        
        Args:
            file_path: Path to the file that was modified.
            original_content: Original content of the file.
            modified_content: Modified content of the file.
            instruction: The instruction that caused the modification.
            transaction_id: ID of the transaction this operation belongs to.
            step_id: ID of the step in the plan this operation belongs to.
            
        Returns:
            Index of the operation in the history or None on error
        """
        try:
            # Generate diff between original and modified content
            diff = diff_manager.generate_diff(original_content, modified_content)
            
            # Record the operation
            return await self.record_operation(
                operation_type=OP_CONTENT,
                params={
                    "file_path": str(file_path),
                    "instruction": instruction
                },
                transaction_id=transaction_id,
                step_id=step_id,
                undo_info={
                    "diff": diff,
                    "has_changes": original_content != modified_content
                }
            )
        
        except Exception as e:
            logger.error(f"Error recording content manipulation: {str(e)}")
            return None
    
    async def record_command_execution(
        self,
        command: str,
        return_code: int,
        stdout: str,
        stderr: str,
        cwd: Optional[str] = None,
        transaction_id: Optional[str] = None,
        step_id: Optional[str] = None
    ) -> Optional[int]:
        """
        Record a command execution for potential rollback.
        
        Args:
            command: The command that was executed.
            return_code: Return code of the command.
            stdout: Standard output of the command.
            stderr: Standard error of the command.
            cwd: Current working directory when the command was executed.
            transaction_id: ID of the transaction this operation belongs to.
            step_id: ID of the step in the plan this operation belongs to.
            
        Returns:
            Index of the operation in the history or None on error
        """
        try:
            # Determine the compensating action for this command
            compensating_action = await self._identify_compensating_action(
                command=command,
                stdout=stdout,
                stderr=stderr,
                cwd=cwd
            )
            
            # Record the operation
            return await self.record_operation(
                operation_type=OP_COMMAND,
                params={
                    "command": command,
                    "return_code": return_code,
                    "cwd": cwd or str(Path.cwd())
                },
                transaction_id=transaction_id,
                step_id=step_id,
                undo_info={
                    "compensating_action": compensating_action,
                    "stdout": stdout[:1000] if stdout else "",  # Truncate for storage
                    "stderr": stderr[:1000] if stderr else ""   # Truncate for storage
                }
            )
        
        except Exception as e:
            logger.error(f"Error recording command execution: {str(e)}")
            return None
    
    async def record_plan_execution(
        self,
        plan_id: str,
        goal: str,
        plan_data: Dict[str, Any],
        transaction_id: Optional[str] = None
    ) -> Optional[int]:
        """
        Record a plan execution for potential rollback.
        
        Args:
            plan_id: ID of the plan that was executed.
            goal: Goal of the plan.
            plan_data: Plan data structure.
            transaction_id: ID of the transaction this operation belongs to.
            
        Returns:
            Index of the operation in the history or None on error
        """
        try:
            # Record the operation
            return await self.record_operation(
                operation_type=OP_PLAN,
                params={
                    "plan_id": plan_id,
                    "goal": goal
                },
                transaction_id=transaction_id,
                undo_info={
                    "plan_data": plan_data
                }
            )
        
        except Exception as e:
            logger.error(f"Error recording plan execution: {str(e)}")
            return None
    
    async def get_recent_operations(self, limit: int = 10) -> List[Dict[str, Any]]:
        """
        Get a list of recent operations that can be rolled back.
        
        Args:
            limit: Maximum number of operations to return.
            
        Returns:
            A list of operation details.
        """
        try:
            # Get the most recent operations, up to the limit
            recent = self._operations[-limit:] if self._operations else []
            
            # Convert to a more user-friendly format
            result = []
            for i, op in enumerate(reversed(recent)):
                # Create a more readable description
                description = self._get_operation_description(op)
                
                # Determine if the operation can be rolled back
                can_rollback = bool(op.backup_path) or op.operation_type in [OP_CONTENT, OP_COMMAND]
                
                # Get transaction info if available
                transaction_info = None
                if op.transaction_id:
                    if op.transaction_id in self._transactions:
                        transaction = self._transactions[op.transaction_id]
                        transaction_info = {
                            "id": transaction.transaction_id,
                            "description": transaction.description,
                            "status": transaction.status
                        }
                    elif op.transaction_id in self._active_transactions:
                        transaction = self._active_transactions[op.transaction_id]
                        transaction_info = {
                            "id": transaction.transaction_id,
                            "description": transaction.description,
                            "status": transaction.status
                        }
                
                result.append({
                    "id": len(self._operations) - i - 1,  # Original index in the full list
                    "timestamp": op.timestamp.strftime("%Y-%m-%d %H:%M:%S"),
                    "operation_type": op.operation_type,
                    "description": description,
                    "can_rollback": can_rollback,
                    "transaction": transaction_info
                })
            
            return result
        
        except Exception as e:
            logger.error(f"Error getting recent operations: {str(e)}")
            return []
    
    async def get_recent_transactions(self, limit: int = 5) -> List[Dict[str, Any]]:
        """
        Get a list of recent transactions that can be rolled back.
        
        Args:
            limit: Maximum number of transactions to return.
            
        Returns:
            A list of transaction details.
        """
        try:
            # Combine active and completed transactions
            all_transactions = list(self._transactions.values()) + list(self._active_transactions.values())
            
            # Sort by timestamp (newest first)
            all_transactions.sort(key=lambda t: t.timestamp, reverse=True)
            
            # Take only the most recent up to the limit
            recent = all_transactions[:limit]
            
            # Convert to a more user-friendly format
            result = []
            for transaction in recent:
                # Count operations in this transaction
                operation_count = len(transaction.operation_ids)
                
                # Determine if the transaction can be rolled back
                can_rollback = transaction.status == "completed" and operation_count > 0
                
                result.append({
                    "id": transaction.transaction_id,
                    "timestamp": transaction.timestamp.strftime("%Y-%m-%d %H:%M:%S"),
                    "description": transaction.description,
                    "status": transaction.status,
                    "operation_count": operation_count,
                    "can_rollback": can_rollback
                })
            
            return result
        
        except Exception as e:
            logger.error(f"Error getting recent transactions: {str(e)}")
            return []
    
    def _get_operation_description(self, op: OperationRecord) -> str:
        """Generate a human-readable description of an operation."""
        try:
            if op.operation_type == OP_FILE_SYSTEM:
                file_operation = op.params.get("file_operation", "unknown")
                
                if file_operation == "create_file":
                    return f"Created file: {op.params.get('path', 'unknown')}"
                
                elif file_operation == "write_file":
                    return f"Wrote to file: {op.params.get('path', 'unknown')}"
                
                elif file_operation == "delete_file":
                    return f"Deleted file: {op.params.get('path', 'unknown')}"
                
                elif file_operation == "create_directory":
                    return f"Created directory: {op.params.get('path', 'unknown')}"
                
                elif file_operation == "delete_directory":
                    return f"Deleted directory: {op.params.get('path', 'unknown')}"
                
                elif file_operation == "copy_file":
                    return f"Copied file from {op.params.get('source', 'unknown')} to {op.params.get('destination', 'unknown')}"
                
                elif file_operation == "move_file":
                    return f"Moved file from {op.params.get('source', 'unknown')} to {op.params.get('destination', 'unknown')}"
                
                else:
                    return f"{file_operation}: {op.params}"
            
            elif op.operation_type == OP_CONTENT:
                file_path = op.params.get("file_path", "unknown")
                instruction = op.params.get("instruction", "Modified content")
                return f"Modified content of {file_path}: {instruction}"
            
            elif op.operation_type == OP_COMMAND:
                command = op.params.get("command", "unknown")
                return f"Executed command: {command}"
            
            elif op.operation_type == OP_PLAN:
                goal = op.params.get("goal", "unknown")
                return f"Executed plan: {goal}"
            
            else:
                return f"{op.operation_type}: {op.params}"
                
        except Exception as e:
            logger.error(f"Error generating operation description: {str(e)}")
            return "Unknown operation"
    
    async def _identify_compensating_action(
        self,
        command: str,
        stdout: str,
        stderr: str,
        cwd: Optional[str] = None
    ) -> Optional[str]:
        """
        Identify a compensating action for a command.
        
        Args:
            command: The command that was executed.
            stdout: Standard output of the command.
            stderr: Standard error of the command.
            cwd: Current working directory when the command was executed.
            
        Returns:
            Compensating action command or None if not available.
        """
        try:
            # Parse the command
            tokens = shlex.split(command)
            if not tokens:
                return None
            
            base_cmd = tokens[0]
            
            # Check for common commands with known compensations
            for cmd_pattern, compensation in self._command_compensations.items():
                if command.startswith(cmd_pattern):
                    # Extract arguments to construct the compensation
                    args = tokens[len(cmd_pattern.split()):]
                    if not args:
                        continue
                    
                    # Special handling for different command types
                    if cmd_pattern == "git add":
                        # git reset <files>
                        return f"{compensation} {' '.join(args)}"
                    
                    elif cmd_pattern == "git push":
                        # Extract branch from command or use current branch
                        branch = None
                        for i, arg in enumerate(tokens):
                            if i > 0 and arg not in ["-f", "--force", "-u", "--set-upstream"]:
                                branch = arg
                                break
                        
                        if not branch:
                            # Get current branch
                            branch = "$(git rev-parse --abbrev-ref HEAD)"
                        
                        # Substitute ${branch} in the compensation
                        return compensation.replace("${branch}", branch)
                    
                    elif cmd_pattern in ["npm install", "pip install", "apt-get install"]:
                        # Extract package names, skipping flags
                        packages = []
                        for arg in args:
                            if not arg.startswith("-"):
                                packages.append(arg)
                        
                        if packages:
                            return f"{compensation} {' '.join(packages)}"
                    
                    else:
                        # Generic compensation with all arguments
                        return f"{compensation} {' '.join(args)}"
            
            # No known compensation found
            return None
            
        except Exception as e:
            logger.error(f"Error identifying compensating action: {str(e)}")
            return None
    
    async def rollback_operation(self, operation_id: int) -> bool:
        """
        Roll back an operation by its ID.
        
        Args:
            operation_id: The ID of the operation to roll back.
            
        Returns:
            True if the rollback was successful, False otherwise.
        """
        try:
            # Validate the operation ID
            if operation_id < 0 or operation_id >= len(self._operations):
                logger.error(f"Invalid operation ID: {operation_id}")
                return False
            
            # Get the operation record
            op = self._operations[operation_id]
            
            # Roll back based on operation type
            if op.operation_type == OP_FILE_SYSTEM:
                success = await self._rollback_file_operation(op)
            elif op.operation_type == OP_CONTENT:
                success = await self._rollback_content_manipulation(op)
            elif op.operation_type == OP_COMMAND:
                success = await self._rollback_command_execution(op)
            elif op.operation_type == OP_PLAN:
                success = await self._rollback_plan_execution(op)
            else:
                logger.error(f"Unsupported operation type for rollback: {op.operation_type}")
                return False
            
            # If rollback was successful, update the operations list
            if success:
                # If this operation is part of a transaction, we don't remove it here
                # Instead, we'll handle it in rollback_transaction
                if not op.transaction_id:
                    self._operations = self._operations[:operation_id]
                    self._save_history(self._operations)
                
                logger.info(f"Successfully rolled back operation {operation_id}: {op.operation_type}")
                return True
            else:
                logger.error(f"Failed to roll back operation {operation_id}: {op.operation_type}")
                return False
                
        except Exception as e:
            logger.exception(f"Error rolling back operation {operation_id}: {str(e)}")
            return False
    
    async def _rollback_file_operation(self, op: OperationRecord) -> bool:
        """
        Roll back a file system operation.
        
        Args:
            op: The operation record.
            
        Returns:
            True if successful, False otherwise.
        """
        try:
            file_operation = op.params.get("file_operation")
            
            if file_operation == "create_file":
                # For file creation, delete the created file
                path = Path(op.params.get("path", ""))
                if path.exists() and path.is_file():
                    path.unlink()
                    logger.info(f"Rolled back file creation: {path}")
                    return True
                else:
                    logger.warning(f"File no longer exists: {path}")
                    return True  # Consider it success if file is already gone
            
            elif file_operation in ["write_file", "delete_file"]:
                # For file writing/deletion, restore from backup
                path = Path(op.params.get("path", ""))
                backup_path = op.backup_path
                
                if not backup_path:
                    logger.error(f"No backup path for {file_operation} operation")
                    return False
                
                backup_path_obj = Path(backup_path)
                if not backup_path_obj.exists():
                    logger.error(f"Backup file not found: {backup_path}")
                    return False
                
                # Create parent directory if it doesn't exist
                path.parent.mkdir(parents=True, exist_ok=True)
                
                # Restore the file
                shutil.copy2(backup_path_obj, path)
                logger.info(f"Restored file from backup: {path}")
                return True
            
            elif file_operation == "create_directory":
                # For directory creation, delete the created directory
                path = Path(op.params.get("path", ""))
                if path.exists() and path.is_dir():
                    # Use rmtree to handle non-empty directories
                    shutil.rmtree(path)
                    logger.info(f"Rolled back directory creation: {path}")
                    return True
                else:
                    logger.warning(f"Directory no longer exists: {path}")
                    return True  # Consider it success if directory is already gone
            
            elif file_operation == "delete_directory":
                # For directory deletion, restore from backup
                path = Path(op.params.get("path", ""))
                backup_path = op.backup_path
                
                if not backup_path:
                    logger.error(f"No backup path for {file_operation} operation")
                    return False
                
                backup_path_obj = Path(backup_path)
                if not backup_path_obj.exists():
                    logger.error(f"Backup directory not found: {backup_path}")
                    return False
                
                # Create parent directory if it doesn't exist
                path.parent.mkdir(parents=True, exist_ok=True)
                
                # Restore the directory
                if path.exists():
                    shutil.rmtree(path)  # Remove existing directory first
                shutil.copytree(backup_path_obj, path)
                logger.info(f"Restored directory from backup: {path}")
                return True
            
            elif file_operation in ["copy_file", "move_file"]:
                # For copy/move, multiple files may need to be restored
                destination = Path(op.params.get("destination", ""))
                backup_path = op.backup_path
                
                if not backup_path:
                    logger.error(f"No backup path for {file_operation} operation")
                    return False
                
                # Restore the destination if it was overwritten
                if destination.exists() and backup_path:
                    backup_path_obj = Path(backup_path)
                    if backup_path_obj.exists():
                        if backup_path_obj.is_file():
                            shutil.copy2(backup_path_obj, destination)
                            logger.info(f"Restored destination file: {destination}")
                        else:
                            shutil.rmtree(destination, ignore_errors=True)
                            shutil.copytree(backup_path_obj, destination)
                            logger.info(f"Restored destination directory: {destination}")
                
                # For move operations, also delete the destination
                if file_operation == "move_file":
                    source = Path(op.params.get("source", ""))
                    if destination.exists():
                        # Restore the source copy if available
                        if source.exists():
                            logger.warning(f"Source already exists, not restoring: {source}")
                        else:
                            # Create parent directory if needed
                            source.parent.mkdir(parents=True, exist_ok=True)
                            
                            if destination.is_file():
                                # Copy destination back to source
                                shutil.copy2(destination, source)
                                logger.info(f"Restored source file: {source}")
                            else:
                                # Copy directory
                                shutil.copytree(destination, source)
                                logger.info(f"Restored source directory: {source}")
                        
                        # Remove destination
                        if destination.is_file():
                            destination.unlink()
                        else:
                            shutil.rmtree(destination)
                        logger.info(f"Removed destination: {destination}")
                
                return True
            
            else:
                logger.error(f"Unsupported file operation for rollback: {file_operation}")
                return False
                
        except Exception as e:
            logger.exception(f"Error rolling back file operation: {str(e)}")
            return False
    
    async def _rollback_content_manipulation(self, op: OperationRecord) -> bool:
        """
        Roll back a content manipulation operation.
        
        Args:
            op: The operation record.
            
        Returns:
            True if successful, False otherwise.
        """
        try:
            file_path = op.params.get("file_path")
            if not file_path:
                logger.error("No file path in content manipulation operation")
                return False
            
            path_obj = Path(file_path)
            if not path_obj.exists() or not path_obj.is_file():
                logger.error(f"File not found: {file_path}")
                return False
            
            # Check if there was a diff
            diff = op.undo_info.get("diff")
            if not diff:
                logger.error("No diff found in content manipulation undo info")
                return False
            
            # Read the current content
            try:
                with open(path_obj, 'r', encoding='utf-8', errors='replace') as f:
                    current_content = f.read()
            except Exception as e:
                logger.error(f"Error reading current file content: {str(e)}")
                return False
            
            # Apply the reversed diff
            # The diff is from original to modified, so we reverse it
            # In this simple approach, we swap "+" and "-" in the diff
            reversed_diff = ""
            for line in diff.splitlines():
                if line.startswith('+'):
                    reversed_diff += '-' + line[1:] + '\n'
                elif line.startswith('-'):
                    reversed_diff += '+' + line[1:] + '\n'
                else:
                    reversed_diff += line + '\n'
            
            # Try to apply the reversed diff
            result, success = diff_manager.apply_diff(current_content, reversed_diff)
            
            if not success:
                logger.error("Failed to apply reversed diff")
                return False
            
            # Write the reverted content back to the file
            try:
                with open(path_obj, 'w', encoding='utf-8') as f:
                    f.write(result)
            except Exception as e:
                logger.error(f"Error writing reverted content: {str(e)}")
                return False
            
            logger.info(f"Successfully rolled back content changes for {file_path}")
            return True
            
        except Exception as e:
            logger.exception(f"Error rolling back content manipulation: {str(e)}")
            return False
    
    async def _rollback_command_execution(self, op: OperationRecord) -> bool:
        """
        Roll back a command execution operation.
        
        Args:
            op: The operation record.
            
        Returns:
            True if successful, False otherwise.
        """
        try:
            # Get the compensating action
            compensating_action = op.undo_info.get("compensating_action")
            if not compensating_action:
                logger.warning(f"No compensating action available for command: {op.params.get('command')}")
                return False
            
            # Get the working directory
            cwd = op.params.get("cwd")
            
            # Execute the compensating action
            logger.info(f"Executing compensating action: {compensating_action}")
            stdout, stderr, return_code = await execution_engine.execute_command(
                compensating_action,
                check_safety=False,  # Skip safety checks for compensating actions
                working_dir=cwd
            )
            
            # Check if the compensating action was successful
            if return_code != 0:
                logger.error(f"Compensating action failed: {stderr}")
                return False
            
            logger.info(f"Successfully executed compensating action: {compensating_action}")
            return True
            
        except Exception as e:
            logger.exception(f"Error rolling back command execution: {str(e)}")
            return False
    
    async def _rollback_plan_execution(self, op: OperationRecord) -> bool:
        """
        Roll back a plan execution operation.
        
        Args:
            op: The operation record.
            
        Returns:
            True if successful, False otherwise.
        """
        # For plan execution, there's not much to do at this level
        # as the individual operations within the plan should be rolled back
        logger.info(f"Rolled back plan execution: {op.params.get('goal')}")
        return True
    
    async def rollback_transaction(self, transaction_id: str) -> Dict[str, Any]:
        """
        Roll back all operations in a transaction.
        
        Args:
            transaction_id: ID of the transaction to roll back.
            
        Returns:
            Dictionary with rollback results.
        """
        try:
            # Find the transaction
            if transaction_id in self._transactions:
                transaction = self._transactions[transaction_id]
            elif transaction_id in self._active_transactions:
                transaction = self._active_transactions[transaction_id]
            else:
                return {
                    "success": False,
                    "error": f"Transaction not found: {transaction_id}",
                    "transaction_id": transaction_id
                }
            
            # Collect all operations in this transaction
            operation_ids = transaction.operation_ids
            if not operation_ids:
                logger.warning(f"No operations found in transaction: {transaction_id}")
                return {
                    "success": True,
                    "message": "No operations to roll back",
                    "transaction_id": transaction_id,
                    "rolled_back": 0,
                    "failed": 0
                }
            
            # Sort operations in reverse order (most recent first)
            operation_ids.sort(reverse=True)
            
            # Roll back each operation
            rolled_back = 0
            failed = 0
            results = []
            
            for op_id in operation_ids:
                if op_id >= len(self._operations):
                    logger.error(f"Invalid operation ID in transaction: {op_id}")
                    failed += 1
                    results.append({
                        "operation_id": op_id,
                        "success": False,
                        "error": "Invalid operation ID"
                    })
                    continue
                
                # Roll back this operation
                op = self._operations[op_id]
                description = self._get_operation_description(op)
                
                success = await self.rollback_operation(op_id)
                if success:
                    rolled_back += 1
                    results.append({
                        "operation_id": op_id,
                        "operation_type": op.operation_type,
                        "description": description,
                        "success": True
                    })
                else:
                    failed += 1
                    results.append({
                        "operation_id": op_id,
                        "operation_type": op.operation_type,
                        "description": description,
                        "success": False,
                        "error": "Rollback failed"
                    })
            
            # Update transaction status
            transaction.status = "rolled_back"
            self._save_transaction(transaction)
            
            # Return the results
            return {
                "success": failed == 0,
                "transaction_id": transaction_id,
                "rolled_back": rolled_back,
                "failed": failed,
                "total": len(operation_ids),
                "results": results
            }
            
        except Exception as e:
            logger.exception(f"Error rolling back transaction {transaction_id}: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "transaction_id": transaction_id
            }
    
    async def create_backup_file(self, path: Path) -> Optional[Path]:
        """
        Create a backup of a file for potential rollback.
        
        Args:
            path: The path of the file to back up.
            
        Returns:
            The path of the backup file or None if backup failed.
        """
        try:
            # Ensure backup directory exists
            BACKUP_DIR.mkdir(parents=True, exist_ok=True)
            
            # Create a unique backup filename
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_name = f"{path.name}.{timestamp}.bak"
            backup_path = BACKUP_DIR / backup_name
            
            # Copy the file to the backup location
            shutil.copy2(path, backup_path)
            logger.debug(f"Created backup of {path} at {backup_path}")
            
            return backup_path
        
        except Exception as e:
            logger.warning(f"Failed to create backup of {path}: {str(e)}")
            return None
    
    async def create_backup_directory(self, path: Path) -> Optional[Path]:
        """
        Create a backup of a directory for potential rollback.
        
        Args:
            path: The path of the directory to back up.
            
        Returns:
            The path of the backup directory or None if backup failed.
        """
        try:
            # Ensure backup directory exists
            BACKUP_DIR.mkdir(parents=True, exist_ok=True)
            
            # Create a unique backup directory name
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_name = f"{path.name}.{timestamp}.bak"
            backup_path = BACKUP_DIR / backup_name
            
            # Copy the directory to the backup location
            shutil.copytree(path, backup_path)
            logger.debug(f"Created backup of directory {path} at {backup_path}")
            
            return backup_path
        
        except Exception as e:
            logger.warning(f"Failed to create backup of directory {path}: {str(e)}")
            return None

# Global rollback manager instance
rollback_manager = RollbackManager()
</file>

<file path="angela/generation/documentation.py">
# angela/generation/documentation.py
"""
Documentation generation for Angela CLI.

This module provides capabilities for generating documentation for projects,
including READMEs, API docs, and user guides.
"""
import os
import asyncio
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple, Union
import json
import re

from angela.ai.client import gemini_client, GeminiRequest
from angela.utils.logging import get_logger
from angela.context import context_manager

logger = get_logger(__name__)

class DocumentationGenerator:
    """
    Generator for project documentation.
    """
    
    def __init__(self):
        """Initialize the documentation generator."""
        self._logger = logger
    
    async def generate_readme(
        self, 
        project_path: Union[str, Path],
        project_info: Optional[Dict[str, Any]] = None,
        context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Generate a README file for a project.
        
        Args:
            project_path: Path to the project
            project_info: Optional project information
            context: Additional context information
            
        Returns:
            Dictionary with the generated README
        """
        self._logger.info(f"Generating README for project at {project_path}")
        
        # Analyze project if project_info not provided
        if not project_info:
            project_info = await self._analyze_project(project_path, context)
        
        # Build prompt for the AI
        prompt = self._build_readme_prompt(project_info)
        
        # Call AI service
        api_request = GeminiRequest(
            prompt=prompt,
            max_tokens=4000,
            temperature=0.3
        )
        
        self._logger.debug("Sending README generation request to AI service")
        response = await gemini_client.generate_text(api_request)
        
        # Extract README content from the response
        readme_content = self._extract_markdown_content(response.text)
        
        return {
            "content": readme_content,
            "file_name": "README.md",
            "project_path": str(project_path)
        }
    
    async def generate_api_docs(
        self, 
        project_path: Union[str, Path],
        files: Optional[List[Dict[str, Any]]] = None,
        context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Generate API documentation for a project.
        
        Args:
            project_path: Path to the project
            files: Optional list of files to document
            context: Additional context information
            
        Returns:
            Dictionary with the generated API docs
        """
        self._logger.info(f"Generating API docs for project at {project_path}")
        
        # Convert to Path object
        project_path = Path(project_path)
        
        # Get files if not provided
        if not files:
            project_info = await self._analyze_project(project_path, context)
            files = project_info.get("files", [])
        
        # Filter for source code files
        source_files = [f for f in files if f.get("type") == "source_code"]
        
        # Determine project type
        project_type = "unknown"
        if context and "enhanced_project" in context:
            project_type = context["enhanced_project"].get("type", "unknown")
        elif any(f.get("path", "").endswith(".py") for f in source_files):
            project_type = "python"
        elif any(f.get("path", "").endswith((".js", ".jsx", ".ts", ".tsx")) for f in source_files):
            project_type = "node"
        elif any(f.get("path", "").endswith(".java") for f in source_files):
            project_type = "java"
        
        # Generate docs based on project type
        if project_type == "python":
            return await self._generate_python_api_docs(project_path, source_files)
        elif project_type == "node":
            return await self._generate_js_api_docs(project_path, source_files)
        elif project_type == "java":
            return await self._generate_java_api_docs(project_path, source_files)
        else:
            return await self._generate_generic_api_docs(project_path, source_files)
    
    async def generate_user_guide(
        self, 
        project_path: Union[str, Path],
        project_info: Optional[Dict[str, Any]] = None,
        context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Generate a user guide for a project.
        
        Args:
            project_path: Path to the project
            project_info: Optional project information
            context: Additional context information
            
        Returns:
            Dictionary with the generated user guide
        """
        self._logger.info(f"Generating user guide for project at {project_path}")
        
        # Analyze project if project_info not provided
        if not project_info:
            project_info = await self._analyze_project(project_path, context)
        
        # Build prompt for the AI
        prompt = self._build_user_guide_prompt(project_info)
        
        # Call AI service
        api_request = GeminiRequest(
            prompt=prompt,
            max_tokens=6000,
            temperature=0.3
        )
        
        self._logger.debug("Sending user guide generation request to AI service")
        response = await gemini_client.generate_text(api_request)
        
        # Extract user guide content from the response
        guide_content = self._extract_markdown_content(response.text)
        
        return {
            "content": guide_content,
            "file_name": "USER_GUIDE.md",
            "project_path": str(project_path)
        }
    
    async def generate_contributing_guide(
        self, 
        project_path: Union[str, Path],
        project_info: Optional[Dict[str, Any]] = None,
        context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Generate a CONTRIBUTING guide for a project.
        
        Args:
            project_path: Path to the project
            project_info: Optional project information
            context: Additional context information
            
        Returns:
            Dictionary with the generated contributing guide
        """
        self._logger.info(f"Generating contributing guide for project at {project_path}")
        
        # Analyze project if project_info not provided
        if not project_info:
            project_info = await self._analyze_project(project_path, context)
        
        # Build prompt for the AI
        prompt = self._build_contributing_prompt(project_info)
        
        # Call AI service
        api_request = GeminiRequest(
            prompt=prompt,
            max_tokens=4000,
            temperature=0.3
        )
        
        self._logger.debug("Sending contributing guide generation request to AI service")
        response = await gemini_client.generate_text(api_request)
        
        # Extract contributing guide content from the response
        guide_content = self._extract_markdown_content(response.text)
        
        return {
            "content": guide_content,
            "file_name": "CONTRIBUTING.md",
            "project_path": str(project_path)
        }
    
    async def _analyze_project(
        self, 
        project_path: Union[str, Path],
        context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Analyze a project to gather information for documentation.
        
        Args:
            project_path: Path to the project
            context: Additional context information
            
        Returns:
            Dictionary with project information
        """
        self._logger.info(f"Analyzing project at {project_path}")
        
        # Convert to Path object
        project_path = Path(project_path)
        
        # Use context if available
        if context and "enhanced_project" in context:
            return {
                "project_type": context["enhanced_project"].get("type", "unknown"),
                "frameworks": context["enhanced_project"].get("frameworks", {}),
                "dependencies": context["enhanced_project"].get("dependencies", {}),
                "files": context.get("files", []),
                "path": str(project_path),
                "name": project_path.name
            }
        
        # Perform a simplified project analysis
        project_info = {
            "project_type": "unknown",
            "frameworks": {},
            "dependencies": {},
            "files": [],
            "path": str(project_path),
            "name": project_path.name
        }
        
        # Determine project type
        if (project_path / "requirements.txt").exists() or (project_path / "setup.py").exists() or (project_path / "pyproject.toml").exists():
            project_info["project_type"] = "python"
        elif (project_path / "package.json").exists():
            project_info["project_type"] = "node"
        elif (project_path / "pom.xml").exists() or (project_path / "build.gradle").exists():
            project_info["project_type"] = "java"
        
        # Get dependencies
        if project_info["project_type"] == "python":
            if (project_path / "requirements.txt").exists():
                try:
                    with open(project_path / "requirements.txt", 'r') as f:
                        deps = [line.strip() for line in f if line.strip() and not line.strip().startswith('#')]
                        project_info["dependencies"] = {"runtime": deps}
                except Exception as e:
                    self._logger.error(f"Error reading requirements.txt: {str(e)}")
        elif project_info["project_type"] == "node":
            if (project_path / "package.json").exists():
                try:
                    with open(project_path / "package.json", 'r') as f:
                        package_data = json.load(f)
                        project_info["dependencies"] = {
                            "runtime": list(package_data.get("dependencies", {}).keys()),
                            "development": list(package_data.get("devDependencies", {}).keys())
                        }
                        # Get project name
                        if "name" in package_data:
                            project_info["name"] = package_data["name"]
                except Exception as e:
                    self._logger.error(f"Error reading package.json: {str(e)}")
        
        # Collect file information
        for root, _, filenames in os.walk(project_path):
            for filename in filenames:
                # Skip common directories to ignore
                if any(ignored in root for ignored in [".git", "__pycache__", "node_modules", "venv", ".idea", ".vscode"]):
                    continue
                
                file_path = Path(root) / filename
                rel_path = file_path.relative_to(project_path)
                
                # Skip files over 1MB
                if file_path.stat().st_size > 1000000:
                    continue
                
                # Get basic file info
                file_info = {
                    "path": str(rel_path),
                    "full_path": str(file_path),
                    "type": None,
                    "language": None,
                    "content": None
                }
                
                # Try to determine file type and language
                try:
                    from angela.context.file_detector import detect_file_type
                    type_info = detect_file_type(file_path)
                    file_info["type"] = type_info.get("type")
                    file_info["language"] = type_info.get("language")
                    
                    # Read content for source code files and documentation files
                    if file_info["type"] in ["source_code", "document"] and file_path.stat().st_size < 100000:
                        with open(file_path, 'r', encoding='utf-8', errors='replace') as f:
                            file_info["content"] = f.read()
                except Exception as e:
                    self._logger.debug(f"Error analyzing file {file_path}: {str(e)}")
                
                project_info["files"].append(file_info)
        
        # Try to find entry points
        project_info["entry_points"] = self._find_entry_points(project_info)
        
        return project_info
    
    def _find_entry_points(self, project_info: Dict[str, Any]) -> List[str]:
        """
        Find potential entry points for the project.
        
        Args:
            project_info: Project information
            
        Returns:
            List of potential entry point files
        """
        entry_points = []
        
        if project_info["project_type"] == "python":
            # Look for Python entry points
            main_files = [f for f in project_info["files"] if f.get("path") in [
                "main.py", "__main__.py", "app.py", "server.py", "run.py"
            ]]
            
            # If no common entry point, look for files with main function
            if not main_files:
                for file_info in project_info["files"]:
                    if file_info.get("content") and "if __name__ == '__main__'" in file_info.get("content"):
                        main_files.append(file_info)
            
            entry_points.extend([f.get("path") for f in main_files])
            
        elif project_info["project_type"] == "node":
            # Look for Node.js entry points
            main_files = [f for f in project_info["files"] if f.get("path") in [
                "index.js", "server.js", "app.js", "main.js"
            ]]
            
            # Check package.json main field
            for file_info in project_info["files"]:
                if file_info.get("path") == "package.json" and file_info.get("content"):
                    try:
                        package_data = json.loads(file_info.get("content"))
                        if "main" in package_data:
                            main_file = package_data["main"]
                            # Add to entry points if not already there
                            if main_file not in [f.get("path") for f in main_files]:
                                main_files.append({"path": main_file})
                    except Exception:
                        pass
            
            entry_points.extend([f.get("path") for f in main_files])
        
        return entry_points
    
    def _build_readme_prompt(self, project_info: Dict[str, Any]) -> str:
        """
        Build a prompt for README generation.
        
        Args:
            project_info: Project information
            
        Returns:
            Prompt string for the AI service
        """
        prompt = f"""
You are an expert technical writer tasked with creating a comprehensive README.md file for a {project_info.get('project_type', 'software')} project named "{project_info.get('name', 'Project')}".

Project details:
- Type: {project_info.get('project_type', 'Unknown')}
"""
        
        # Add dependencies information
        if "dependencies" in project_info:
            prompt += "- Dependencies:\n"
            
            if "runtime" in project_info["dependencies"]:
                runtime_deps = project_info["dependencies"]["runtime"]
                if runtime_deps:
                    prompt += f"  - Runtime: {', '.join(runtime_deps[:10])}"
                    if len(runtime_deps) > 10:
                        prompt += f" and {len(runtime_deps) - 10} more"
                    prompt += "\n"
            
            if "development" in project_info["dependencies"]:
                dev_deps = project_info["dependencies"]["development"]
                if dev_deps:
                    prompt += f"  - Development: {', '.join(dev_deps[:10])}"
                    if len(dev_deps) > 10:
                        prompt += f" and {len(dev_deps) - 10} more"
                    prompt += "\n"
        
        # Add entry points information
        if "entry_points" in project_info and project_info["entry_points"]:
            prompt += f"- Entry points: {', '.join(project_info['entry_points'])}\n"
        
        # Add file structure information
        file_types = {}
        for file_info in project_info.get("files", []):
            file_type = file_info.get("type")
            if file_type:
                if file_type not in file_types:
                    file_types[file_type] = []
                file_types[file_type].append(file_info.get("path"))
        
        prompt += "- File structure summary:\n"
        for file_type, files in file_types.items():
            prompt += f"  - {file_type} files: {len(files)}\n"
        
        # Add main source files
        source_files = file_types.get("source_code", [])
        if source_files:
            prompt += "- Main source files (up to 10):\n"
            for file in source_files[:10]:
                prompt += f"  - {file}\n"
        
        prompt += """
Create a comprehensive README.md file that follows these best practices:
1. Clear project title and description
2. Installation instructions
3. Usage examples
4. Features list
5. API documentation overview (if applicable)
6. Project structure explanation
7. Contributing guidelines reference
8. License information
9. Badges for build status, version, etc. (if applicable)

The README should be well-formatted with Markdown, including:
- Proper headings (# for main title, ## for sections, etc.)
- Code blocks with appropriate syntax highlighting
- Lists (ordered and unordered)
- Links to important resources
- Tables where appropriate

Make the README user-friendly, comprehensive, and professional.
"""
        
        return prompt
    
    async def _generate_python_api_docs(
        self, 
        project_path: Path,
        source_files: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        Generate API documentation for a Python project.
        
        Args:
            project_path: Path to the project
            source_files: List of source files
            
        Returns:
            Dictionary with the generated API docs
        """
        self._logger.info("Generating Python API docs")
        
        # Filter for Python files
        python_files = [f for f in source_files if f.get("path", "").endswith(".py")]
        
        # Organize files by module/package
        modules = {}
        
        for file_info in python_files:
            file_path = file_info.get("path", "")
            
            # Skip __init__.py files with no content
            if file_path.endswith("__init__.py") and not file_info.get("content", "").strip():
                continue
            
            # Determine module name
            if "/" in file_path:
                # File in a package
                package_parts = file_path.split("/")
                module_name = ".".join(package_parts[:-1])
                if module_name not in modules:
                    modules[module_name] = []
                modules[module_name].append(file_info)
            else:
                # File in root
                module_name = "root"
                if module_name not in modules:
                    modules[module_name] = []
                modules[module_name].append(file_info)
        
        # Generate docs for each module
        module_docs = {}
        
        for module_name, files in modules.items():
            module_docs[module_name] = await self._generate_python_module_docs(module_name, files)
        
        # Create docs structure
        docs_structure = {
            "index.md": self._generate_python_docs_index(modules, project_path.name),
            "modules": module_docs
        }
        
        return {
            "structure": docs_structure,
            "format": "markdown",
            "project_path": str(project_path)
        }
    
    async def _generate_python_module_docs(
        self, 
        module_name: str,
        files: List[Dict[str, Any]]
    ) -> Dict[str, str]:
        """
        Generate documentation for a Python module.
        
        Args:
            module_name: Name of the module
            files: List of files in the module
            
        Returns:
            Dictionary mapping file names to documentation content
        """
        module_docs = {}
        
        for file_info in files:
            file_path = file_info.get("path", "")
            content = file_info.get("content", "")
            
            if not content:
                continue
            
            # Extract file name without extension
            file_name = os.path.basename(file_path)
            doc_name = os.path.splitext(file_name)[0]
            
            # Parse Python content
            doc_content = await self._parse_python_file(file_path, content)
            
            # Generate markdown
            markdown = f"""# {doc_name}

{doc_content.get('module_docstring', 'No description available.')}

## Classes

"""
            # Add classes
            for class_name, class_info in doc_content.get("classes", {}).items():
                markdown += f"### {class_name}\n\n{class_info.get('docstring', 'No description available.')}\n\n"
                
                # Add methods
                if class_info.get("methods"):
                    markdown += "#### Methods\n\n"
                    for method_name, method_info in class_info.get("methods", {}).items():
                        markdown += f"##### `{method_name}{method_info.get('signature', '()') }`\n\n{method_info.get('docstring', 'No description available.')}\n\n"
            
            # Add functions
            if doc_content.get("functions"):
                markdown += "## Functions\n\n"
                for func_name, func_info in doc_content.get("functions", {}).items():
                    markdown += f"### `{func_name}{func_info.get('signature', '()') }`\n\n{func_info.get('docstring', 'No description available.')}\n\n"
            
            module_docs[doc_name + ".md"] = markdown
        
        return module_docs
    
    async def _parse_python_file(self, file_path: str, content: str) -> Dict[str, Any]:
        """
        Parse Python file for documentation.
        
        Args:
            file_path: Path to the file
            content: File content
            
        Returns:
            Dictionary with parsed documentation
        """
        # Basic structure
        doc_info = {
            "module_docstring": "",
            "classes": {},
            "functions": {}
        }
        
        # Extract module docstring
        module_docstring_match = re.search(r'"""(.*?)"""', content, re.DOTALL)
        if module_docstring_match:
            doc_info["module_docstring"] = module_docstring_match.group(1).strip()
        
        # Extract classes
        class_pattern = r'class\s+(\w+)(?:\([^)]*\))?:\s*(?:"""(.*?)""")?'
        for match in re.finditer(class_pattern, content, re.DOTALL):
            class_name = match.group(1)
            class_docstring = match.group(2) if match.group(2) else ""
            
            # Get class content
            class_start = match.end()
            class_content = ""
            
            # Find the end of the class (by indentation)
            for line in content[class_start:].splitlines():
                if line.strip() and not line.startswith(" ") and not line.startswith("\t"):
                    break
                class_content += line + "\n"
            
            # Extract methods
            methods = {}
            method_pattern = r'^\s+def\s+(\w+)\s*\((self(?:,\s*[^)]*)?)\):\s*(?:"""(.*?)""")?'
            for method_match in re.finditer(method_pattern, class_content, re.MULTILINE | re.DOTALL):
                method_name = method_match.group(1)
                method_signature = method_match.group(2).strip()
                method_docstring = method_match.group(3) if method_match.group(3) else ""
                
                methods[method_name] = {
                    "signature": f"({method_signature})",
                    "docstring": method_docstring.strip()
                }
            
            doc_info["classes"][class_name] = {
                "docstring": class_docstring.strip(),
                "methods": methods
            }
        
        # Extract functions
        function_pattern = r'^def\s+(\w+)\s*\(([^)]*)\):\s*(?:"""(.*?)""")?'
        for match in re.finditer(function_pattern, content, re.MULTILINE | re.DOTALL):
            func_name = match.group(1)
            func_signature = match.group(2).strip()
            func_docstring = match.group(3) if match.group(3) else ""
            
            doc_info["functions"][func_name] = {
                "signature": f"({func_signature})",
                "docstring": func_docstring.strip()
            }
        
        return doc_info
    
    def _generate_python_docs_index(self, modules: Dict[str, List[Dict[str, Any]]], project_name: str) -> str:
        """
        Generate index page for Python API docs.
        
        Args:
            modules: Dictionary mapping module names to files
            project_name: Name of the project
            
        Returns:
            Markdown content for index page
        """
        markdown = f"""# {project_name} API Documentation

## Modules

"""
        # Add module links
        for module_name, files in modules.items():
            if module_name == "root":
                markdown += "### Root Module\n\n"
            else:
                markdown += f"### {module_name}\n\n"
            
            for file_info in files:
                file_path = file_info.get("path", "")
                file_name = os.path.basename(file_path)
                doc_name = os.path.splitext(file_name)[0]
                
                markdown += f"- [{doc_name}](modules/{doc_name}.md)\n"
            
            markdown += "\n"
        
        return markdown
    
    async def _generate_js_api_docs(
        self, 
        project_path: Path,
        source_files: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        Generate API documentation for a JavaScript/TypeScript project.
        
        Args:
            project_path: Path to the project
            source_files: List of source files
            
        Returns:
            Dictionary with the generated API docs
        """
        self._logger.info("Generating JavaScript/TypeScript API docs")
        
        # Filter for JS/TS files
        js_files = [f for f in source_files if f.get("path", "").endswith((".js", ".jsx", ".ts", ".tsx"))]
        
        # Organize files by directory
        directories = {}
        
        for file_info in js_files:
            file_path = file_info.get("path", "")
            
            if "/" in file_path:
                # File in a directory
                dir_parts = file_path.split("/")
                dir_name = dir_parts[0]
                if dir_name not in directories:
                    directories[dir_name] = []
                directories[dir_name].append(file_info)
            else:
                # File in root
                dir_name = "root"
                if dir_name not in directories:
                    directories[dir_name] = []
                directories[dir_name].append(file_info)
        
        # Generate docs for each directory
        dir_docs = {}
        
        for dir_name, files in directories.items():
            dir_docs[dir_name] = await self._generate_js_directory_docs(dir_name, files)
        
        # Create docs structure
        docs_structure = {
            "index.md": self._generate_js_docs_index(directories, project_path.name),
            "modules": dir_docs
        }
        
        return {
            "structure": docs_structure,
            "format": "markdown",
            "project_path": str(project_path)
        }
    
    async def _generate_js_directory_docs(
        self, 
        dir_name: str,
        files: List[Dict[str, Any]]
    ) -> Dict[str, str]:
        """
        Generate documentation for a JavaScript/TypeScript directory.
        
        Args:
            dir_name: Name of the directory
            files: List of files in the directory
            
        Returns:
            Dictionary mapping file names to documentation content
        """
        dir_docs = {}
        
        for file_info in files:
            file_path = file_info.get("path", "")
            content = file_info.get("content", "")
            
            if not content:
                continue
            
            # Extract file name without extension
            file_name = os.path.basename(file_path)
            doc_name = os.path.splitext(file_name)[0]
            
            # Parse JS/TS content
            is_typescript = file_path.endswith((".ts", ".tsx"))
            doc_content = await self._parse_js_file(file_path, content, is_typescript)
            
            # Generate markdown
            markdown = f"""# {doc_name}

{doc_content.get('file_description', 'No description available.')}

## Exports

"""
            # Add classes
            for class_name, class_info in doc_content.get("classes", {}).items():
                markdown += f"### Class: {class_name}\n\n{class_info.get('description', 'No description available.')}\n\n"
                
                # Add methods
                if class_info.get("methods"):
                    markdown += "#### Methods\n\n"
                    for method_name, method_info in class_info.get("methods", {}).items():
                        markdown += f"##### `{method_name}{method_info.get('signature', '()') }`\n\n{method_info.get('description', 'No description available.')}\n\n"
            
            # Add functions
            if doc_content.get("functions"):
                markdown += "## Functions\n\n"
                for func_name, func_info in doc_content.get("functions", {}).items():
                    markdown += f"### `{func_name}{func_info.get('signature', '()') }`\n\n{func_info.get('description', 'No description available.')}\n\n"
            
            # Add interfaces (TypeScript only)
            if is_typescript and doc_content.get("interfaces"):
                markdown += "## Interfaces\n\n"
                for interface_name, interface_info in doc_content.get("interfaces", {}).items():
                    markdown += f"### Interface: {interface_name}\n\n{interface_info.get('description', 'No description available.')}\n\n"
                    
                    if interface_info.get("properties"):
                        markdown += "#### Properties\n\n"
                        for prop_name, prop_info in interface_info.get("properties", {}).items():
                            markdown += f"- `{prop_name}: {prop_info.get('type', 'any')}` - {prop_info.get('description', 'No description available.')}\n"
                    
                    markdown += "\n"
            
            dir_docs[doc_name + ".md"] = markdown
        
        return dir_docs
    
    async def _parse_js_file(
        self, 
        file_path: str, 
        content: str, 
        is_typescript: bool = False
    ) -> Dict[str, Any]:
        """
        Parse JavaScript/TypeScript file for documentation.
        
        Args:
            file_path: Path to the file
            content: File content
            is_typescript: Whether the file is TypeScript
            
        Returns:
            Dictionary with parsed documentation
        """
        # Basic structure
        doc_info = {
            "file_description": "",
            "classes": {},
            "functions": {}
        }
        
        if is_typescript:
            doc_info["interfaces"] = {}
        
        # Extract file description from initial comment block
        file_comment_match = re.search(r'/\*\*(.*?)\*/', content, re.DOTALL)
        if file_comment_match:
            doc_info["file_description"] = self._parse_js_comment(file_comment_match.group(1))
        
        # Extract classes
        class_pattern = r'(?:export\s+)?class\s+(\w+)(?:\s+extends\s+\w+)?(?:\s+implements\s+[\w,\s]+)?\s*{([^}]*\/\*\*.*?\*\/)?'
        for match in re.finditer(class_pattern, content, re.DOTALL):
            class_name = match.group(1)
            class_content = match.group(0)
            
            # Extract class comment
            class_comment_match = re.search(r'/\*\*(.*?)\*/', class_content, re.DOTALL)
            class_description = self._parse_js_comment(class_comment_match.group(1)) if class_comment_match else ""
            
            # Extract methods
            methods = {}
            method_pattern = r'(?:public|private|protected)?\s*(\w+)\s*\(([^)]*)\)(?:\s*:\s*[\w<>[\],\s]+)?(?:\s*{)?(?:\s*/\*\*(.*?)\*\/)?'
            for method_match in re.finditer(method_pattern, class_content, re.DOTALL):
                method_name = method_match.group(1)
                method_signature = method_match.group(2).strip()
                method_comment = method_match.group(3) if method_match.group(3) else ""
                
                methods[method_name] = {
                    "signature": f"({method_signature})",
                    "description": self._parse_js_comment(method_comment)
                }
            
            doc_info["classes"][class_name] = {
                "description": class_description,
                "methods": methods
            }
        
        # Extract functions
        function_pattern = r'(?:export\s+)?(?:function|const|let|var)\s+(\w+)\s*(?:=\s*(?:function)?\s*)?(?:\([^)]*\))(?:\s*:\s*[\w<>[\],\s]+)?(?:\s*=>)?(?:\s*{)?(?:\s*/\*\*(.*?)\*\/)?'
        for match in re.finditer(function_pattern, content, re.DOTALL):
            func_name = match.group(1)
            func_comment = match.group(2) if match.group(2) else ""
            
            # Determine signature (simplified)
            func_signature_match = re.search(r'\(([^)]*)\)', match.group(0))
            func_signature = func_signature_match.group(1) if func_signature_match else ""
            
            doc_info["functions"][func_name] = {
                "signature": f"({func_signature})",
                "description": self._parse_js_comment(func_comment)
            }
        
        # Extract TypeScript interfaces
        if is_typescript:
            interface_pattern = r'(?:export\s+)?interface\s+(\w+)(?:\s+extends\s+[\w,\s]+)?\s*{([^}]*)}'
            for match in re.finditer(interface_pattern, content, re.DOTALL):
                interface_name = match.group(1)
                interface_content = match.group(2)
                
                # Extract interface comment
                interface_comment_match = re.search(r'/\*\*(.*?)\*/', match.group(0), re.DOTALL)
                interface_description = self._parse_js_comment(interface_comment_match.group(1)) if interface_comment_match else ""
                
                # Extract properties
                properties = {}
                property_pattern = r'(\w+)(?:\?)?:\s*([\w<>[\],\s|]+)(?:;)?\s*(?://\s*(.*))?'
                for prop_match in re.finditer(property_pattern, interface_content):
                    prop_name = prop_match.group(1)
                    prop_type = prop_match.group(2).strip()
                    prop_comment = prop_match.group(3) if prop_match.group(3) else ""
                    
                    properties[prop_name] = {
                        "type": prop_type,
                        "description": prop_comment.strip()
                    }
                
                doc_info["interfaces"][interface_name] = {
                    "description": interface_description,
                    "properties": properties
                }
        
        return doc_info
    
    def _parse_js_comment(self, comment: str) -> str:
        """
        Parse JSDoc comment.
        
        Args:
            comment: JSDoc comment
            
        Returns:
            Parsed description
        """
        # Remove * at the beginning of lines
        lines = [line.strip().lstrip('*') for line in comment.splitlines()]
        
        # Join and clean up
        description = " ".join(line for line in lines if line and not line.startswith('@'))
        
        return description.strip()
    
    def _generate_js_docs_index(self, directories: Dict[str, List[Dict[str, Any]]], project_name: str) -> str:
        """
        Generate index page for JavaScript/TypeScript API docs.
        
        Args:
            directories: Dictionary mapping directory names to files
            project_name: Name of the project
            
        Returns:
            Markdown content for index page
        """
        markdown = f"""# {project_name} API Documentation

## Modules

"""
        # Add directory links
        for dir_name, files in directories.items():
            if dir_name == "root":
                markdown += "### Root Module\n\n"
            else:
                markdown += f"### {dir_name}\n\n"
            
            for file_info in files:
                file_path = file_info.get("path", "")
                file_name = os.path.basename(file_path)
                doc_name = os.path.splitext(file_name)[0]
                
                markdown += f"- [{doc_name}](modules/{doc_name}.md)\n"
            
            markdown += "\n"
        
        return markdown
    
    async def _generate_java_api_docs(
        self, 
        project_path: Path,
        source_files: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        Generate API documentation for a Java project.
        
        Args:
            project_path: Path to the project
            source_files: List of source files
            
        Returns:
            Dictionary with the generated API docs
        """
        self._logger.info("Generating Java API docs")
        
        # Filter for Java files
        java_files = [f for f in source_files if f.get("path", "").endswith(".java")]
        
        # Organize files by package
        packages = {}
        
        for file_info in java_files:
            file_path = file_info.get("path", "")
            content = file_info.get("content", "")
            
            if not content:
                continue
            
            # Extract package name
            package_match = re.search(r'package\s+([\w.]+);', content)
            if package_match:
                package_name = package_match.group(1)
            else:
                package_name = "default"
            
            if package_name not in packages:
                packages[package_name] = []
            packages[package_name].append(file_info)
        
        # Generate docs for each package
        package_docs = {}
        
        for package_name, files in packages.items():
            package_docs[package_name] = await self._generate_java_package_docs(package_name, files)
        
        # Create docs structure
        docs_structure = {
            "index.md": self._generate_java_docs_index(packages, project_path.name),
            "packages": package_docs
        }
        
        return {
            "structure": docs_structure,
            "format": "markdown",
            "project_path": str(project_path)
        }
    
    async def _generate_java_package_docs(
        self, 
        package_name: str,
        files: List[Dict[str, Any]]
    ) -> Dict[str, str]:
        """
        Generate documentation for a Java package.
        
        Args:
            package_name: Name of the package
            files: List of files in the package
            
        Returns:
            Dictionary mapping file names to documentation content
        """
        package_docs = {}
        
        for file_info in files:
            file_path = file_info.get("path", "")
            content = file_info.get("content", "")
            
            if not content:
                continue
            
            # Extract file name without extension
            file_name = os.path.basename(file_path)
            class_name = os.path.splitext(file_name)[0]
            
            # Parse Java content
            doc_content = await self._parse_java_file(file_path, content)
            
            # Generate markdown
            markdown = f"""# {class_name}

Package: `{package_name}`

{doc_content.get('class_javadoc', 'No description available.')}

"""
            # Add class info
            if "is_interface" in doc_content and doc_content["is_interface"]:
                markdown += "## Interface Methods\n\n"
            else:
                markdown += "## Methods\n\n"
            
            for method_name, method_info in doc_content.get("methods", {}).items():
                markdown += f"### `{method_name}{method_info.get('signature', '()') }`\n\n{method_info.get('javadoc', 'No description available.')}\n\n"
                
                # Add parameters documentation
                if method_info.get("params"):
                    markdown += "#### Parameters\n\n"
                    for param_name, param_desc in method_info.get("params", {}).items():
                        markdown += f"- `{param_name}` - {param_desc}\n"
                    markdown += "\n"
                
                # Add return documentation
                if method_info.get("returns"):
                    markdown += f"#### Returns\n\n{method_info.get('returns')}\n\n"
                
                # Add throws documentation
                if method_info.get("throws"):
                    markdown += "#### Throws\n\n"
                    for exception, desc in method_info.get("throws", {}).items():
                        markdown += f"- `{exception}` - {desc}\n"
                    markdown += "\n"
            
            # Add fields
            if doc_content.get("fields"):
                markdown += "## Fields\n\n"
                for field_name, field_info in doc_content.get("fields", {}).items():
                    markdown += f"### `{field_info.get('type', 'Object')} {field_name}`\n\n{field_info.get('javadoc', 'No description available.')}\n\n"
            
            package_docs[class_name + ".md"] = markdown
        
        return package_docs
    
    async def _parse_java_file(self, file_path: str, content: str) -> Dict[str, Any]:
        """
        Parse Java file for documentation.
        
        Args:
            file_path: Path to the file
            content: File content
            
        Returns:
            Dictionary with parsed documentation
        """
        # Basic structure
        doc_info = {
            "class_javadoc": "",
            "methods": {},
            "fields": {}
        }
        
        # Check if it's an interface
        if re.search(r'(?:public\s+)?interface\s+\w+', content):
            doc_info["is_interface"] = True
        
        # Extract class javadoc
        class_javadoc_match = re.search(r'/\*\*(.*?)\*/', content, re.DOTALL)
        if class_javadoc_match:
            doc_info["class_javadoc"] = self._parse_javadoc(class_javadoc_match.group(1))
        
        # Extract methods
        method_pattern = r'(?:/\*\*(.*?)\*/\s*)?(?:public|private|protected)?\s+(?:static\s+)?(?:final\s+)?(?:[\w<>[\],\s]+)\s+(\w+)\s*\(([^)]*)\)(?:\s+throws\s+[\w,\s]+)?(?:\s*{)?'
        for match in re.finditer(method_pattern, content, re.DOTALL):
            javadoc = match.group(1)
            method_name = match.group(2)
            params_str = match.group(3)
            
            # Skip constructor if it has the same name as the class
            class_name = os.path.splitext(os.path.basename(file_path))[0]
            if method_name == class_name:
                continue
            
            # Parse javadoc
            javadoc_info = self._parse_javadoc_with_tags(javadoc) if javadoc else {}
            
            # Format parameters
            formatted_params = []
            for param in params_str.split(","):
                param = param.strip()
                if param:
                    parts = param.split()
                    if len(parts) >= 2:
                        param_type = " ".join(parts[:-1])
                        param_name = parts[-1]
                        formatted_params.append(f"{param_type} {param_name}")
            
            # Extract throws info
            throws_match = re.search(r'throws\s+([\w,\s]+)', match.group(0))
            throws = throws_match.group(1).split(",") if throws_match else []
            
            method_info = {
                "signature": f"({', '.join(formatted_params)})",
                "javadoc": javadoc_info.get("description", ""),
                "params": javadoc_info.get("params", {}),
                "returns": javadoc_info.get("returns", ""),
                "throws": javadoc_info.get("throws", {})
            }
            
            doc_info["methods"][method_name] = method_info
        
        # Extract fields
        field_pattern = r'(?:/\*\*(.*?)\*/\s*)?(?:public|private|protected)?\s+(?:static\s+)?(?:final\s+)?(?:[\w<>[\],\s]+)\s+(\w+)\s*(?:=\s*[^;]+)?;'
        for match in re.finditer(field_pattern, content, re.DOTALL):
            javadoc = match.group(1)
            field_declaration = match.group(0)
            
            # Extract field name and type
            field_name = match.group(2)
            
            # Extract field type
            type_match = re.search(r'(?:public|private|protected)?\s+(?:static\s+)?(?:final\s+)?([\w<>[\],\s]+)\s+\w+\s*(?:=|;)', field_declaration)
            field_type = type_match.group(1).strip() if type_match else "Object"
            
            # Parse javadoc
            field_javadoc = self._parse_javadoc(javadoc) if javadoc else ""
            
            doc_info["fields"][field_name] = {
                "type": field_type,
                "javadoc": field_javadoc
            }
        
        return doc_info
    
    def _parse_javadoc(self, javadoc: str) -> str:
        """
        Parse basic Javadoc comment.
        
        Args:
            javadoc: Javadoc comment
            
        Returns:
            Parsed description
        """
        if not javadoc:
            return ""
        
        # Remove * at the beginning of lines
        lines = [line.strip().lstrip('*') for line in javadoc.splitlines()]
        
        # Join and clean up
        description = " ".join(line for line in lines if line and not line.startswith('@'))
        
        return description.strip()
    
    def _parse_javadoc_with_tags(self, javadoc: str) -> Dict[str, Any]:
        """
        Parse Javadoc comment with tags.
        
        Args:
            javadoc: Javadoc comment
            
        Returns:
            Dictionary with parsed javadoc
        """
        if not javadoc:
            return {"description": ""}
        
        result = {
            "description": "",
            "params": {},
            "returns": "",
            "throws": {}
        }
        
        # Remove * at the beginning of lines
        lines = [line.strip().lstrip('*') for line in javadoc.splitlines()]
        
        # Extract description (text before tags)
        description_lines = []
        tag_lines = []
        in_description = True
        
        for line in lines:
            if line.startswith('@'):
                in_description = False
                tag_lines.append(line)
            elif in_description:
                description_lines.append(line)
            else:
                tag_lines.append(line)
        
        result["description"] = " ".join(line for line in description_lines if line).strip()
        
        # Process tags
        current_tag = None
        current_text = []
        
        for line in tag_lines:
            if line.startswith('@'):
                # Save previous tag
                if current_tag and current_text:
                    self._add_tag_to_result(result, current_tag, " ".join(current_text).strip())
                
                # Start new tag
                parts = line.split(' ', 1)
                current_tag = parts[0][1:]  # Remove @ and get tag name
                current_text = [parts[1].strip()] if len(parts) > 1 else []
            elif current_tag:
                current_text.append(line)
        
        # Save last tag
        if current_tag and current_text:
            self._add_tag_to_result(result, current_tag, " ".join(current_text).strip())
        
        return result
    
    def _add_tag_to_result(self, result: Dict[str, Any], tag: str, text: str) -> None:
        """
        Add a parsed javadoc tag to the result.
        
        Args:
            result: Result dictionary
            tag: Tag name
            text: Tag text
        """
        if tag == "param":
            # Extract parameter name
            parts = text.split(' ', 1)
            if len(parts) > 1:
                param_name = parts[0]
                param_description = parts[1]
                result["params"][param_name] = param_description
        elif tag == "return":
            result["returns"] = text
        elif tag in ["throws", "exception"]:
            # Extract exception class
            parts = text.split(' ', 1)
            if len(parts) > 1:
                exception_class = parts[0]
                exception_description = parts[1]
                result["throws"][exception_class] = exception_description
    
    def _generate_java_docs_index(self, packages: Dict[str, List[Dict[str, Any]]], project_name: str) -> str:
        """
        Generate index page for Java API docs.
        
        Args:
            packages: Dictionary mapping package names to files
            project_name: Name of the project
            
        Returns:
            Markdown content for index page
        """
        markdown = f"""# {project_name} API Documentation

## Packages

"""
        # Add package links
        for package_name, files in packages.items():
            markdown += f"### {package_name}\n\n"
            
            for file_info in files:
                file_path = file_info.get("path", "")
                file_name = os.path.basename(file_path)
                class_name = os.path.splitext(file_name)[0]
                
                markdown += f"- [{class_name}](packages/{class_name}.md)\n"
            
            markdown += "\n"
        
        return markdown
    
    async def _generate_generic_api_docs(
        self, 
        project_path: Path,
        source_files: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        Generate generic API documentation for an unknown project type.
        
        Args:
            project_path: Path to the project
            source_files: List of source files
            
        Returns:
            Dictionary with the generated API docs
        """
        self._logger.info("Generating generic API docs")
        
        # Organize files by directory
        directories = {}
        
        for file_info in source_files:
            file_path = file_info.get("path", "")
            
            if "/" in file_path:
                # File in a directory
                dir_parts = file_path.split("/")
                dir_name = dir_parts[0]
                if dir_name not in directories:
                    directories[dir_name] = []
                directories[dir_name].append(file_info)
            else:
                # File in root
                dir_name = "root"
                if dir_name not in directories:
                    directories[dir_name] = []
                directories[dir_name].append(file_info)
        
        # Generate docs for each directory
        dir_docs = {}
        
        for dir_name, files in directories.items():
            dir_docs[dir_name] = await self._generate_generic_directory_docs(dir_name, files)
        
        # Create docs structure
        docs_structure = {
            "index.md": self._generate_generic_docs_index(directories, project_path.name),
            "modules": dir_docs
        }
        
        return {
            "structure": docs_structure,
            "format": "markdown",
            "project_path": str(project_path)
        }
    
    async def _generate_generic_directory_docs(
        self, 
        dir_name: str,
        files: List[Dict[str, Any]]
    ) -> Dict[str, str]:
        """
        Generate documentation for a generic directory.
        
        Args:
            dir_name: Name of the directory
            files: List of files in the directory
            
        Returns:
            Dictionary mapping file names to documentation content
        """
        dir_docs = {}
        
        for file_info in files:
            file_path = file_info.get("path", "")
            content = file_info.get("content", "")
            
            if not content:
                continue
            
            # Extract file name without extension
            file_name = os.path.basename(file_path)
            doc_name = os.path.splitext(file_name)[0]
            
            # Generate markdown using AI
            markdown = await self._generate_file_docs_with_ai(file_info)
            
            dir_docs[doc_name + ".md"] = markdown
        
        return dir_docs
    
    def _generate_generic_docs_index(self, directories: Dict[str, List[Dict[str, Any]]], project_name: str) -> str:
        """
        Generate index page for generic API docs.
        
        Args:
            directories: Dictionary mapping directory names to files
            project_name: Name of the project
            
        Returns:
            Markdown content for index page
        """
        markdown = f"""# {project_name} API Documentation

## Modules

"""
        # Add directory links
        for dir_name, files in directories.items():
            if dir_name == "root":
                markdown += "### Root Module\n\n"
            else:
                markdown += f"### {dir_name}\n\n"
            
            for file_info in files:
                file_path = file_info.get("path", "")
                file_name = os.path.basename(file_path)
                doc_name = os.path.splitext(file_name)[0]
                
                markdown += f"- [{doc_name}](modules/{doc_name}.md)\n"
            
            markdown += "\n"
        
        return markdown
    
    async def _generate_file_docs_with_ai(self, file_info: Dict[str, Any]) -> str:
        """
        Generate documentation for a file using AI.
        
        Args:
            file_info: File information
            
        Returns:
            Markdown documentation
        """
        file_path = file_info.get("path", "")
        content = file_info.get("content", "")
        language = file_info.get("language", "Unknown")
        
        # Build prompt for AI
        prompt = f"""
You are an expert technical writer tasked with documenting a {language} file.

File path: {file_path}

File content:
```
{content[:5000] if len(content) > 5000 else content}
```
{f"..." if len(content) > 5000 else ""}

Create comprehensive documentation in Markdown format for this file, including:
1. File overview/purpose
2. Main functions/classes/components
3. Usage examples (if applicable)
4. Any dependencies or relationships with other files (if detectable)

Follow these formatting guidelines:
- Use Markdown headings appropriately (# for title, ## for sections, etc.)
- Use code blocks with appropriate syntax highlighting
- Document parameters, return values, and exceptions where applicable
- Be concise but thorough

DO NOT reproduce the entire file content - focus on documenting functionality and usage.
"""
        
        # Call AI service
        api_request = GeminiRequest(
            prompt=prompt,
            max_tokens=3000,
            temperature=0.2
        )
        
        self._logger.debug(f"Sending file documentation request to AI for {file_path}")
        response = await gemini_client.generate_text(api_request)
        
        # Extract documentation
        return response.text
    
    def _build_user_guide_prompt(self, project_info: Dict[str, Any]) -> str:
        """
        Build a prompt for user guide generation.
        
        Args:
            project_info: Project information
            
        Returns:
            Prompt string for the AI service
        """
        prompt = f"""
You are an expert technical writer tasked with creating a comprehensive user guide for a {project_info.get('project_type', 'software')} project named "{project_info.get('name', 'Project')}".

Project details:
- Type: {project_info.get('project_type', 'Unknown')}
"""
        
        # Add dependencies information
        if "dependencies" in project_info:
            prompt += "- Dependencies:\n"
            
            if "runtime" in project_info["dependencies"]:
                runtime_deps = project_info["dependencies"]["runtime"]
                if runtime_deps:
                    prompt += f"  - Runtime: {', '.join(runtime_deps[:10])}"
                    if len(runtime_deps) > 10:
                        prompt += f" and {len(runtime_deps) - 10} more"
                    prompt += "\n"
        
        # Add entry points information
        if "entry_points" in project_info and project_info["entry_points"]:
            prompt += f"- Entry points: {', '.join(project_info['entry_points'])}\n"
        
        # Add important source files
        source_files = [f for f in project_info.get("files", []) if f.get("type") == "source_code"]
        if source_files:
            prompt += "- Important source files:\n"
            for file in source_files[:5]:  # Limit to 5 files
                prompt += f"  - {file.get('path')}\n"
        
        prompt += """
Create a comprehensive user guide that follows these best practices:
1. Introduction and overview
2. Getting started (installation, setup)
3. Basic usage
4. Advanced features
5. Troubleshooting
6. API/command reference
7. Examples and use cases

The user guide should be well-formatted with Markdown, including:
- Proper headings (# for main title, ## for sections, etc.)
- Code blocks with appropriate syntax highlighting
- Lists (ordered and unordered)
- Tables where appropriate
- Screenshots (described with placeholders)

Make the user guide user-friendly, comprehensive, and suitable for users with varying levels of technical expertise.
"""
        
        return prompt
    
    def _build_contributing_prompt(self, project_info: Dict[str, Any]) -> str:
        """
        Build a prompt for contributing guide generation.
        
        Args:
            project_info: Project information
            
        Returns:
            Prompt string for the AI service
        """
        prompt = f"""
You are an expert technical writer tasked with creating a comprehensive CONTRIBUTING.md file for a {project_info.get('project_type', 'software')} project named "{project_info.get('name', 'Project')}".

Project details:
- Type: {project_info.get('project_type', 'Unknown')}
"""
        
        # Add file structure information
        file_types = {}
        for file_info in project_info.get("files", []):
            file_type = file_info.get("type")
            if file_type:
                if file_type not in file_types:
                    file_types[file_type] = []
                file_types[file_type].append(file_info.get("path"))
        
        prompt += "- File structure summary:\n"
        for file_type, files in file_types.items():
            prompt += f"  - {file_type} files: {len(files)}\n"
        
        prompt += """
Create a comprehensive CONTRIBUTING.md file that follows these best practices:
1. Introduction and welcome message
2. Code of conduct reference
3. Getting started for contributors
4. Development environment setup
5. Coding standards and conventions
6. Pull request process
7. Issue reporting guidelines
8. Testing instructions
9. Documentation guidelines

The contributing guide should be well-formatted with Markdown, including:
- Proper headings (# for main title, ## for sections, etc.)
- Code blocks with appropriate syntax highlighting
- Lists (ordered and unordered)
- Links to important resources

Make the contributing guide friendly, comprehensive, and helpful for new contributors.
"""
        
        return prompt
    
    def _extract_markdown_content(self, content: str) -> str:
        """
        Extract markdown content from AI response.
        
        Args:
            content: AI response text
            
        Returns:
            Markdown content
        """
        # Check if content is already markdown
        if content.startswith('#') or content.startswith('# '):
            return content
        
        # Try to extract markdown from code blocks
        markdown_match = re.search(r'```(?:markdown)?\s*(.*?)\s*```', content, re.DOTALL)
        if markdown_match:
            return markdown_match.group(1)
        
        # Otherwise, just return the response
        return content

# Global documentation generator instance
documentation_generator = DocumentationGenerator()
</file>

<file path="angela/generation/frameworks.py">
# angela/generation/frameworks.py
"""
Specialized framework generators for Angela CLI.

This module provides framework-specific code generation capabilities
for popular frameworks like React, Django, Spring, etc.
"""
import os
import asyncio
from pathlib import Path
from typing import Dict, Any, List, Optional, Union, Tuple
import json
import re
import logging

from angela.ai.client import gemini_client, GeminiRequest
from angela.utils.logging import get_logger
from angela.generation.engine import CodeFile

logger = get_logger(__name__)

class FrameworkGenerator:
    """
    Generator for framework-specific code structures.
    
    This class provides specialized generation capabilities for various
    web and application frameworks, creating standardized project structures
    with appropriate files, configurations, and boilerplate code.
    """
    
    def __init__(self):
        """Initialize the framework generator with registered framework handlers."""
        self._logger = logger
        self._logger.info("Initializing FrameworkGenerator")
        
        # Register specialized framework generators
        self._framework_generators = {
            "react": self._generate_react,
            "django": self._generate_django,
            "flask": self._generate_flask,
            "spring": self._generate_spring,
            "express": self._generate_express,
            "fastapi": self._generate_fastapi,
            "vue": self._generate_vue,
            "angular": self._generate_angular
        }
        
        # Framework to project type mapping for better type inference
        self._framework_project_types = {
            "react": "node",
            "vue": "node",
            "angular": "node",
            "express": "node",
            "django": "python",
            "flask": "python",
            "fastapi": "python",
            "spring": "java",
            "rails": "ruby",
            "laravel": "php"
        }
        
        self._logger.debug(f"Registered frameworks: {', '.join(self._framework_generators.keys())}")
    
    async def generate_framework_structure(
        self, 
        framework: str,
        description: str,
        output_dir: Union[str, Path],
        options: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Generate a framework-specific project structure.
        
        Args:
            framework: Framework to generate for (e.g., "react", "django")
            description: Description of the project
            output_dir: Directory where the project should be generated
            options: Additional options for the framework (e.g., typescript, variant)
            
        Returns:
            Dictionary with generation results containing:
            - success: Whether generation was successful
            - framework: The framework that was generated
            - files: List of CodeFile objects
            - project_type: Type of project (node, python, etc.)
            - Additional framework-specific information
            
        Raises:
            ValueError: If the framework is not recognized and generic generation fails
        """
        options = options or {}
        framework = framework.lower()
        self._logger.info(f"Generating {framework} structure for: {description}")
        
        try:
            # Get the specialized generator function if available
            generator_func = self._framework_generators.get(framework)
            
            if generator_func:
                # Use specialized generator
                self._logger.debug(f"Using specialized generator for {framework}")
                return await generator_func(description, output_dir, options)
            else:
                # Fallback to generic generator
                self._logger.debug(f"No specialized generator for {framework}, using generic generator")
                return await self._generate_generic(framework, description, output_dir, options)
        except Exception as e:
            self._logger.error(f"Error generating {framework} project: {str(e)}", exc_info=True)
            return {
                "success": False,
                "framework": framework,
                "error": f"Failed to generate {framework} project: {str(e)}",
                "files": []
            }
    
    async def list_supported_frameworks(self) -> List[Dict[str, Any]]:
        """
        Get a list of supported frameworks with details.
        
        Returns:
            List of framework information dictionaries
        """
        frameworks = []
        
        # Add specialized frameworks
        for framework in self._framework_generators.keys():
            frameworks.append({
                "name": framework,
                "type": "specialized",
                "project_type": self._framework_project_types.get(framework, "unknown")
            })
        
        # We could add more supported frameworks here that would use the generic generator
        additional_frameworks = [
            {"name": "svelte", "project_type": "node"},
            {"name": "rails", "project_type": "ruby"},
            {"name": "laravel", "project_type": "php"},
            {"name": "dotnet", "project_type": "csharp"}
        ]
        
        for framework in additional_frameworks:
            if framework["name"] not in self._framework_generators:
                framework["type"] = "generic"
                frameworks.append(framework)
        
        return frameworks
    
    async def _generate_react(
        self,
        description: str,
        output_dir: Union[str, Path],
        options: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Generate a React project structure.
        
        Args:
            description: Description of the project
            output_dir: Output directory
            options: Additional options
            
        Returns:
            Dictionary with generation results
        """
        self._logger.info(f"Generating React project: {description}")
        
        # Determine React variant (Next.js, Create React App, etc.)
        variant = options.get("variant", "cra").lower()
        
        if variant == "nextjs":
            # Call Next.js generator
            return await self._generate_nextjs(description, output_dir, options)
        
        # Default: Create React App structure
        files = []
        
        # Define project structure
        structure = [
            {
                "path": "public/index.html",
                "content": await self._generate_content("react/index.html", description, options),
                "purpose": "Main HTML file",
                "language": "html"
            },
            {
                "path": "src/index.js",
                "content": await self._generate_content("react/index.js", description, options),
                "purpose": "Application entry point",
                "language": "javascript"
            },
            {
                "path": "src/App.js",
                "content": await self._generate_content("react/App.js", description, options),
                "purpose": "Main application component",
                "language": "javascript"
            },
            {
                "path": "src/App.css",
                "content": await self._generate_content("react/App.css", description, options),
                "purpose": "Application styles",
                "language": "css"
            },
            {
                "path": "package.json",
                "content": await self._generate_content("react/package.json", description, options),
                "purpose": "NPM package configuration",
                "language": "json"
            },
            {
                "path": "README.md",
                "content": await self._generate_content("react/README.md", description, options),
                "purpose": "Project documentation",
                "language": "markdown"
            }
        ]
        
        # TypeScript support
        if options.get("typescript", False):
            # Replace .js files with .tsx
            structure = [
                {
                    "path": f.get("path").replace(".js", ".tsx") if f.get("path").endswith(".js") else f.get("path"),
                    "content": await self._generate_content(f.get("path").replace(".js", ".tsx") if f.get("path").endswith(".js") else f.get("path"), description, options),
                    "purpose": f.get("purpose"),
                    "language": "typescript" if f.get("language") == "javascript" else f.get("language")
                }
                for f in structure
            ]
            
            # Add TypeScript config
            structure.append({
                "path": "tsconfig.json",
                "content": await self._generate_content("react/tsconfig.json", description, options),
                "purpose": "TypeScript configuration",
                "language": "json"
            })
        
        # Add testing setup if requested
        if options.get("testing", False):
            test_files = await self._generate_react_testing_files(description, options)
            structure.extend(test_files)
        
        # Generate files
        for file_info in structure:
            files.append(CodeFile(
                path=file_info["path"],
                content=file_info["content"],
                purpose=file_info["purpose"],
                dependencies=[],
                language=file_info["language"]
            ))
        
        return {
            "success": True,
            "framework": "react",
            "variant": variant,
            "files": files,
            "project_type": "node"
        }
    
    async def _generate_nextjs(
        self,
        description: str,
        output_dir: Union[str, Path],
        options: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Generate a Next.js project structure.
        
        Args:
            description: Description of the project
            output_dir: Output directory
            options: Additional options
            
        Returns:
            Dictionary with generation results
        """
        self._logger.info(f"Generating Next.js project: {description}")
        
        files = []
        
        # Define project structure
        structure = [
            {
                "path": "pages/index.js",
                "content": await self._generate_content("nextjs/pages/index.js", description, options),
                "purpose": "Home page component",
                "language": "javascript"
            },
            {
                "path": "pages/_app.js",
                "content": await self._generate_content("nextjs/pages/_app.js", description, options),
                "purpose": "Application wrapper component",
                "language": "javascript"
            },
            {
                "path": "styles/globals.css",
                "content": await self._generate_content("nextjs/styles/globals.css", description, options),
                "purpose": "Global styles",
                "language": "css"
            },
            {
                "path": "package.json",
                "content": await self._generate_content("nextjs/package.json", description, options),
                "purpose": "NPM package configuration",
                "language": "json"
            },
            {
                "path": "next.config.js",
                "content": await self._generate_content("nextjs/next.config.js", description, options),
                "purpose": "Next.js configuration",
                "language": "javascript"
            },
            {
                "path": "README.md",
                "content": await self._generate_content("nextjs/README.md", description, options),
                "purpose": "Project documentation",
                "language": "markdown"
            }
        ]
        
        # Add app directory structure if using the new App Router pattern
        if options.get("app_router", False):
            structure.extend([
                {
                    "path": "app/page.js",
                    "content": await self._generate_content("nextjs/app/page.js", description, options),
                    "purpose": "Home page using App Router",
                    "language": "javascript"
                },
                {
                    "path": "app/layout.js",
                    "content": await self._generate_content("nextjs/app/layout.js", description, options),
                    "purpose": "Root layout using App Router",
                    "language": "javascript"
                }
            ])
        
        # TypeScript support
        if options.get("typescript", False):
            # Replace .js files with .tsx
            structure = [
                {
                    "path": f.get("path").replace(".js", ".tsx") if f.get("path").endswith(".js") else f.get("path"),
                    "content": await self._generate_content(f.get("path").replace(".js", ".tsx") if f.get("path").endswith(".js") else f.get("path"), description, options),
                    "purpose": f.get("purpose"),
                    "language": "typescript" if f.get("language") == "javascript" else f.get("language")
                }
                for f in structure
            ]
            
            # Add TypeScript config
            structure.append({
                "path": "tsconfig.json",
                "content": await self._generate_content("nextjs/tsconfig.json", description, options),
                "purpose": "TypeScript configuration",
                "language": "json"
            })
        
        # Generate files
        for file_info in structure:
            files.append(CodeFile(
                path=file_info["path"],
                content=file_info["content"],
                purpose=file_info["purpose"],
                dependencies=[],
                language=file_info["language"]
            ))
        
        return {
            "success": True,
            "framework": "react",
            "variant": "nextjs",
            "files": files,
            "project_type": "node"
        }
    
    async def _generate_react_testing_files(
        self,
        description: str,
        options: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """
        Generate React testing files.
        
        Args:
            description: Project description
            options: Additional options
            
        Returns:
            List of file information dictionaries
        """
        # Determine testing framework
        testing_framework = options.get("testing_framework", "jest").lower()
        
        files = []
        file_extension = ".tsx" if options.get("typescript", False) else ".js"
        
        if testing_framework == "jest":
            files = [
                {
                    "path": f"src/App.test{file_extension}",
                    "content": await self._generate_content(f"react/App.test{file_extension}", description, options),
                    "purpose": "App component tests",
                    "language": "typescript" if options.get("typescript", False) else "javascript"
                },
                {
                    "path": "jest.config.js",
                    "content": await self._generate_content("react/jest.config.js", description, options),
                    "purpose": "Jest configuration",
                    "language": "javascript"
                }
            ]
        elif testing_framework == "cypress":
            files = [
                {
                    "path": "cypress/e2e/home.cy.js",
                    "content": await self._generate_content("react/cypress/e2e/home.cy.js", description, options),
                    "purpose": "Home page E2E tests",
                    "language": "javascript"
                },
                {
                    "path": "cypress.config.js",
                    "content": await self._generate_content("react/cypress.config.js", description, options),
                    "purpose": "Cypress configuration",
                    "language": "javascript"
                }
            ]
        elif testing_framework == "testing-library":
            files = [
                {
                    "path": f"src/App.test{file_extension}",
                    "content": await self._generate_content(f"react/App.test-rtl{file_extension}", description, options),
                    "purpose": "App component tests with React Testing Library",
                    "language": "typescript" if options.get("typescript", False) else "javascript"
                }
            ]
        
        return files
    
    async def _generate_django(
        self,
        description: str,
        output_dir: Union[str, Path],
        options: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Generate a Django project structure.
        
        Args:
            description: Description of the project
            output_dir: Output directory
            options: Additional options
            
        Returns:
            Dictionary with generation results
        """
        self._logger.info(f"Generating Django project: {description}")
        
        # Get project name
        project_name = options.get("project_name", "django_project")
        project_name = re.sub(r'[^a-zA-Z0-9_]', '_', project_name)
        
        # Get app name
        app_name = options.get("app_name", "main")
        app_name = re.sub(r'[^a-zA-Z0-9_]', '_', app_name)
        
        files = []
        
        # Define project structure
        structure = [
            {
                "path": f"{project_name}/settings.py",
                "content": await self._generate_content("django/settings.py", description, {"project_name": project_name, "app_name": app_name, **options}),
                "purpose": "Django settings",
                "language": "python"
            },
            {
                "path": f"{project_name}/urls.py",
                "content": await self._generate_content("django/urls.py", description, {"project_name": project_name, "app_name": app_name, **options}),
                "purpose": "URL configuration",
                "language": "python"
            },
            {
                "path": f"{project_name}/wsgi.py",
                "content": await self._generate_content("django/wsgi.py", description, {"project_name": project_name, **options}),
                "purpose": "WSGI configuration",
                "language": "python"
            },
            {
                "path": f"{project_name}/asgi.py",
                "content": await self._generate_content("django/asgi.py", description, {"project_name": project_name, **options}),
                "purpose": "ASGI configuration",
                "language": "python"
            },
            {
                "path": f"{project_name}/__init__.py",
                "content": "",
                "purpose": "Package initialization",
                "language": "python"
            },
            {
                "path": f"{app_name}/models.py",
                "content": await self._generate_content("django/models.py", description, {"app_name": app_name, **options}),
                "purpose": "Data models",
                "language": "python"
            },
            {
                "path": f"{app_name}/views.py",
                "content": await self._generate_content("django/views.py", description, {"app_name": app_name, **options}),
                "purpose": "View functions",
                "language": "python"
            },
            {
                "path": f"{app_name}/urls.py",
                "content": await self._generate_content("django/app_urls.py", description, {"app_name": app_name, **options}),
                "purpose": "App URL configuration",
                "language": "python"
            },
            {
                "path": f"{app_name}/__init__.py",
                "content": "",
                "purpose": "App package initialization",
                "language": "python"
            },
            {
                "path": f"{app_name}/templates/{app_name}/index.html",
                "content": await self._generate_content("django/index.html", description, {"app_name": app_name, **options}),
                "purpose": "Main template",
                "language": "html"
            },
            {
                "path": "manage.py",
                "content": await self._generate_content("django/manage.py", description, {"project_name": project_name, **options}),
                "purpose": "Django management script",
                "language": "python"
            },
            {
                "path": "requirements.txt",
                "content": await self._generate_content("django/requirements.txt", description, options),
                "purpose": "Python dependencies",
                "language": "text"
            },
            {
                "path": "README.md",
                "content": await self._generate_content("django/README.md", description, {"project_name": project_name, "app_name": app_name, **options}),
                "purpose": "Project documentation",
                "language": "markdown"
            }
        ]
        
        # Add tests if requested
        if options.get("tests", True):
            structure.append({
                "path": f"{app_name}/tests.py",
                "content": await self._generate_content("django/tests.py", description, {"app_name": app_name, **options}),
                "purpose": "Test cases",
                "language": "python"
            })
        
        # Add forms if requested
        if options.get("forms", False):
            structure.append({
                "path": f"{app_name}/forms.py",
                "content": await self._generate_content("django/forms.py", description, {"app_name": app_name, **options}),
                "purpose": "Form definitions",
                "language": "python"
            })
        
        # Generate files
        for file_info in structure:
            files.append(CodeFile(
                path=file_info["path"],
                content=file_info["content"],
                purpose=file_info["purpose"],
                dependencies=[],
                language=file_info["language"]
            ))
        
        return {
            "success": True,
            "framework": "django",
            "files": files,
            "project_type": "python",
            "project_name": project_name,
            "app_name": app_name
        }
    
    async def _generate_flask(
        self,
        description: str,
        output_dir: Union[str, Path],
        options: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Generate a Flask project structure.
        
        Args:
            description: Description of the project
            output_dir: Output directory
            options: Additional options
            
        Returns:
            Dictionary with generation results
        """
        self._logger.info(f"Generating Flask project: {description}")
        
        # Get app name
        app_name = options.get("app_name", "app")
        app_name = re.sub(r'[^a-zA-Z0-9_]', '_', app_name)
        
        files = []
        
        # Define project structure
        structure = [
            {
                "path": "app.py",
                "content": await self._generate_content("flask/app.py", description, {"app_name": app_name, **options}),
                "purpose": "Main application",
                "language": "python"
            },
            {
                "path": "config.py",
                "content": await self._generate_content("flask/config.py", description, options),
                "purpose": "Configuration",
                "language": "python"
            },
            {
                "path": f"{app_name}/__init__.py",
                "content": await self._generate_content("flask/init.py", description, {"app_name": app_name, **options}),
                "purpose": "Application initialization",
                "language": "python"
            },
            {
                "path": f"{app_name}/routes.py",
                "content": await self._generate_content("flask/routes.py", description, options),
                "purpose": "Route definitions",
                "language": "python"
            },
            {
                "path": f"{app_name}/models.py",
                "content": await self._generate_content("flask/models.py", description, options),
                "purpose": "Data models",
                "language": "python"
            },
            {
                "path": "templates/index.html",
                "content": await self._generate_content("flask/index.html", description, options),
                "purpose": "Main template",
                "language": "html"
            },
            {
                "path": "templates/layout.html",
                "content": await self._generate_content("flask/layout.html", description, options),
                "purpose": "Base template",
                "language": "html"
            },
            {
                "path": "static/css/style.css",
                "content": await self._generate_content("flask/style.css", description, options),
                "purpose": "Main stylesheet",
                "language": "css"
            },
            {
                "path": "requirements.txt",
                "content": await self._generate_content("flask/requirements.txt", description, options),
                "purpose": "Python dependencies",
                "language": "text"
            },
            {
                "path": "README.md",
                "content": await self._generate_content("flask/README.md", description, {"app_name": app_name, **options}),
                "purpose": "Project documentation",
                "language": "markdown"
            }
        ]
        
        # Add Docker support if requested
        if options.get("docker", False):
            structure.extend([
                {
                    "path": "Dockerfile",
                    "content": await self._generate_content("flask/Dockerfile", description, {"app_name": app_name, **options}),
                    "purpose": "Docker configuration",
                    "language": "dockerfile"
                },
                {
                    "path": "docker-compose.yml",
                    "content": await self._generate_content("flask/docker-compose.yml", description, {"app_name": app_name, **options}),
                    "purpose": "Docker Compose configuration",
                    "language": "yaml"
                }
            ])
        
        # Generate files
        for file_info in structure:
            files.append(CodeFile(
                path=file_info["path"],
                content=file_info["content"],
                purpose=file_info["purpose"],
                dependencies=[],
                language=file_info["language"]
            ))
        
        return {
            "success": True,
            "framework": "flask",
            "files": files,
            "project_type": "python",
            "app_name": app_name
        }
    
    async def _generate_express(
        self,
        description: str,
        output_dir: Union[str, Path],
        options: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Generate an Express.js project structure.
        
        Args:
            description: Description of the project
            output_dir: Output directory
            options: Additional options
            
        Returns:
            Dictionary with generation results
        """
        self._logger.info(f"Generating Express project: {description}")
        
        files = []
        
        # Define project structure
        structure = [
            {
                "path": "app.js",
                "content": await self._generate_content("express/app.js", description, options),
                "purpose": "Main application",
                "language": "javascript"
            },
            {
                "path": "routes/index.js",
                "content": await self._generate_content("express/routes/index.js", description, options),
                "purpose": "Main routes",
                "language": "javascript"
            },
            {
                "path": "routes/users.js",
                "content": await self._generate_content("express/routes/users.js", description, options),
                "purpose": "User routes",
                "language": "javascript"
            },
            {
                "path": "views/index.ejs",
                "content": await self._generate_content("express/views/index.ejs", description, options),
                "purpose": "Main view template",
                "language": "html"
            },
            {
                "path": "views/error.ejs",
                "content": await self._generate_content("express/views/error.ejs", description, options),
                "purpose": "Error view template",
                "language": "html"
            },
            {
                "path": "public/stylesheets/style.css",
                "content": await self._generate_content("express/public/stylesheets/style.css", description, options),
                "purpose": "Main stylesheet",
                "language": "css"
            },
            {
                "path": "package.json",
                "content": await self._generate_content("express/package.json", description, options),
                "purpose": "NPM package configuration",
                "language": "json"
            },
            {
                "path": "README.md",
                "content": await self._generate_content("express/README.md", description, options),
                "purpose": "Project documentation",
                "language": "markdown"
            }
        ]
        
        # Add configuration file
        structure.append({
            "path": "config/config.js",
            "content": await self._generate_content("express/config/config.js", description, options),
            "purpose": "Configuration settings",
            "language": "javascript"
        })
        
        # Add middleware directory
        structure.append({
            "path": "middleware/auth.js",
            "content": await self._generate_content("express/middleware/auth.js", description, options),
            "purpose": "Authentication middleware",
            "language": "javascript"
        })
        
        # TypeScript support
        if options.get("typescript", False):
            # Replace .js files with .ts
            structure = [
                {
                    "path": f.get("path").replace(".js", ".ts") if f.get("path").endswith(".js") else f.get("path"),
                    "content": await self._generate_content(f.get("path").replace(".js", ".ts") if f.get("path").endswith(".js") else f.get("path"), description, options),
                    "purpose": f.get("purpose"),
                    "language": "typescript" if f.get("language") == "javascript" else f.get("language")
                }
                for f in structure
            ]
            
            # Add TypeScript config
            structure.append({
                "path": "tsconfig.json",
                "content": await self._generate_content("express/tsconfig.json", description, options),
                "purpose": "TypeScript configuration",
                "language": "json"
            })
        
        # Generate files
        for file_info in structure:
            files.append(CodeFile(
                path=file_info["path"],
                content=file_info["content"],
                purpose=file_info["purpose"],
                dependencies=[],
                language=file_info["language"]
            ))
        
        return {
            "success": True,
            "framework": "express",
            "files": files,
            "project_type": "node"
        }
    
    async def _generate_fastapi(
        self,
        description: str,
        output_dir: Union[str, Path],
        options: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Generate a FastAPI project structure.
        
        Args:
            description: Description of the project
            output_dir: Output directory
            options: Additional options
            
        Returns:
            Dictionary with generation results
        """
        self._logger.info(f"Generating FastAPI project: {description}")
        
        # Get app name
        app_name = options.get("app_name", "app")
        app_name = re.sub(r'[^a-zA-Z0-9_]', '_', app_name)
        
        files = []
        
        # Define project structure
        structure = [
            {
                "path": "main.py",
                "content": await self._generate_content("fastapi/main.py", description, {"app_name": app_name, **options}),
                "purpose": "Main application",
                "language": "python"
            },
            {
                "path": f"{app_name}/__init__.py",
                "content": "",
                "purpose": "Package initialization",
                "language": "python"
            },
            {
                "path": f"{app_name}/routes.py",
                "content": await self._generate_content("fastapi/routes.py", description, options),
                "purpose": "API routes",
                "language": "python"
            },
            {
                "path": f"{app_name}/models.py",
                "content": await self._generate_content("fastapi/models.py", description, options),
                "purpose": "Data models",
                "language": "python"
            },
            {
                "path": f"{app_name}/schemas.py",
                "content": await self._generate_content("fastapi/schemas.py", description, options),
                "purpose": "Pydantic schemas",
                "language": "python"
            },
            {
                "path": f"{app_name}/database.py",
                "content": await self._generate_content("fastapi/database.py", description, options),
                "purpose": "Database connection",
                "language": "python"
            },
            {
                "path": "requirements.txt",
                "content": await self._generate_content("fastapi/requirements.txt", description, options),
                "purpose": "Python dependencies",
                "language": "text"
            },
            {
                "path": "README.md",
                "content": await self._generate_content("fastapi/README.md", description, {"app_name": app_name, **options}),
                "purpose": "Project documentation",
                "language": "markdown"
            }
        ]
        
        # Add dependencies directory for better organization
        structure.append({
            "path": f"{app_name}/dependencies.py",
            "content": await self._generate_content("fastapi/dependencies.py", description, options),
            "purpose": "Dependency injection functions",
            "language": "python"
        })
        
        # Add config module
        structure.append({
            "path": f"{app_name}/config.py",
            "content": await self._generate_content("fastapi/config.py", description, options),
            "purpose": "Configuration settings",
            "language": "python"
        })
        
        # Add Docker support if requested
        if options.get("docker", True):
            structure.extend([
                {
                    "path": "Dockerfile",
                    "content": await self._generate_content("fastapi/Dockerfile", description, {"app_name": app_name, **options}),
                    "purpose": "Docker configuration",
                    "language": "dockerfile"
                },
                {
                    "path": ".dockerignore",
                    "content": await self._generate_content("fastapi/.dockerignore", description, options),
                    "purpose": "Docker ignore file",
                    "language": "text"
                }
            ])
        
        # Generate files
        for file_info in structure:
            files.append(CodeFile(
                path=file_info["path"],
                content=file_info["content"],
                purpose=file_info["purpose"],
                dependencies=[],
                language=file_info["language"]
            ))
        
        return {
            "success": True,
            "framework": "fastapi",
            "files": files,
            "project_type": "python",
            "app_name": app_name
        }
    
    async def _generate_spring(
        self,
        description: str,
        output_dir: Union[str, Path],
        options: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Generate a Spring Boot project structure.
        
        Args:
            description: Description of the project
            output_dir: Output directory
            options: Additional options
            
        Returns:
            Dictionary with generation results
        """
        self._logger.info(f"Generating Spring Boot project: {description}")
        
        # Get package name
        package_name = options.get("package_name", "com.example.demo")
        package_path = package_name.replace(".", "/")
        
        files = []
        
        # Define project structure
        structure = [
            {
                "path": f"src/main/java/{package_path}/Application.java",
                "content": await self._generate_content("spring/Application.java", description, {"package_name": package_name, **options}),
                "purpose": "Main application class",
                "language": "java"
            },
            {
                "path": f"src/main/java/{package_path}/controller/MainController.java",
                "content": await self._generate_content("spring/MainController.java", description, {"package_name": package_name, **options}),
                "purpose": "Main controller",
                "language": "java"
            },
            {
                "path": f"src/main/java/{package_path}/model/User.java",
                "content": await self._generate_content("spring/User.java", description, {"package_name": package_name, **options}),
                "purpose": "User model",
                "language": "java"
            },
            {
                "path": f"src/main/resources/application.properties",
                "content": await self._generate_content("spring/application.properties", description, options),
                "purpose": "Application properties",
                "language": "properties"
            },
            {
                "path": f"src/main/resources/templates/index.html",
                "content": await self._generate_content("spring/index.html", description, options),
                "purpose": "Main template",
                "language": "html"
            },
            {
                "path": "build.gradle",
                "content": await self._generate_content("spring/build.gradle", description, {"package_name": package_name, **options}),
                "purpose": "Gradle build configuration",
                "language": "gradle"
            },
            {
                "path": "README.md",
                "content": await self._generate_content("spring/README.md", description, {"package_name": package_name, **options}),
                "purpose": "Project documentation",
                "language": "markdown"
            }
        ]
        
        # Add repository and service layers for better organization
        structure.extend([
            {
                "path": f"src/main/java/{package_path}/repository/UserRepository.java",
                "content": await self._generate_content("spring/UserRepository.java", description, {"package_name": package_name, **options}),
                "purpose": "User repository interface",
                "language": "java"
            },
            {
                "path": f"src/main/java/{package_path}/service/UserService.java",
                "content": await self._generate_content("spring/UserService.java", description, {"package_name": package_name, **options}),
                "purpose": "User service interface",
                "language": "java"
            },
            {
                "path": f"src/main/java/{package_path}/service/impl/UserServiceImpl.java",
                "content": await self._generate_content("spring/UserServiceImpl.java", description, {"package_name": package_name, **options}),
                "purpose": "User service implementation",
                "language": "java"
            }
        ])
        
        # Add Maven support
        if options.get("maven", False) or options.get("build_tool", "gradle") == "maven":
            structure.append({
                "path": "pom.xml",
                "content": await self._generate_content("spring/pom.xml", description, {"package_name": package_name, **options}),
                "purpose": "Maven build configuration",
                "language": "xml"
            })
        
        # Generate files
        for file_info in structure:
            files.append(CodeFile(
                path=file_info["path"],
                content=file_info["content"],
                purpose=file_info["purpose"],
                dependencies=[],
                language=file_info["language"]
            ))
        
        return {
            "success": True,
            "framework": "spring",
            "files": files,
            "project_type": "java",
            "package_name": package_name
        }
    
    async def _generate_vue(
        self,
        description: str,
        output_dir: Union[str, Path],
        options: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Generate a Vue.js project structure.
        
        Args:
            description: Description of the project
            output_dir: Output directory
            options: Additional options
            
        Returns:
            Dictionary with generation results
        """
        self._logger.info(f"Generating Vue.js project: {description}")
        
        files = []
        
        # Define project structure
        structure = [
            {
                "path": "src/main.js",
                "content": await self._generate_content("vue/main.js", description, options),
                "purpose": "Application entry point",
                "language": "javascript"
            },
            {
                "path": "src/App.vue",
                "content": await self._generate_content("vue/App.vue", description, options),
                "purpose": "Main application component",
                "language": "vue"
            },
            {
                "path": "src/components/HelloWorld.vue",
                "content": await self._generate_content("vue/HelloWorld.vue", description, options),
                "purpose": "Example component",
                "language": "vue"
            },
            {
                "path": "src/router/index.js",
                "content": await self._generate_content("vue/router.js", description, options),
                "purpose": "Vue Router configuration",
                "language": "javascript"
            },
            {
                "path": "src/views/Home.vue",
                "content": await self._generate_content("vue/Home.vue", description, options),
                "purpose": "Home page component",
                "language": "vue"
            },
            {
                "path": "src/views/About.vue",
                "content": await self._generate_content("vue/About.vue", description, options),
                "purpose": "About page component",
                "language": "vue"
            },
            {
                "path": "public/index.html",
                "content": await self._generate_content("vue/index.html", description, options),
                "purpose": "Main HTML file",
                "language": "html"
            },
            {
                "path": "package.json",
                "content": await self._generate_content("vue/package.json", description, options),
                "purpose": "NPM package configuration",
                "language": "json"
            },
            {
                "path": "vue.config.js",
                "content": await self._generate_content("vue/vue.config.js", description, options),
                "purpose": "Vue CLI configuration",
                "language": "javascript"
            },
            {
                "path": "README.md",
                "content": await self._generate_content("vue/README.md", description, options),
                "purpose": "Project documentation",
                "language": "markdown"
            }
        ]
        
        # Add Vuex store if requested
        if options.get("store", True):
            structure.extend([
                {
                    "path": "src/store/index.js",
                    "content": await self._generate_content("vue/store/index.js", description, options),
                    "purpose": "Vuex store configuration",
                    "language": "javascript"
                },
                {
                    "path": "src/store/modules/auth.js",
                    "content": await self._generate_content("vue/store/modules/auth.js", description, options),
                    "purpose": "Auth store module",
                    "language": "javascript"
                }
            ])
        
        # TypeScript support
        if options.get("typescript", False):
            # Replace .js files with .ts
            structure = [
                {
                    "path": f.get("path").replace(".js", ".ts") if f.get("path").endswith(".js") else f.get("path"),
                    "content": await self._generate_content(f.get("path").replace(".js", ".ts") if f.get("path").endswith(".js") else f.get("path"), description, options),
                    "purpose": f.get("purpose"),
                    "language": "typescript" if f.get("language") == "javascript" else f.get("language")
                }
                for f in structure
            ]
            
            # Add TypeScript config
            structure.append({
                "path": "tsconfig.json",
                "content": await self._generate_content("vue/tsconfig.json", description, options),
                "purpose": "TypeScript configuration",
                "language": "json"
            })
        
        # Generate files
        for file_info in structure:
            files.append(CodeFile(
                path=file_info["path"],
                content=file_info["content"],
                purpose=file_info["purpose"],
                dependencies=[],
                language=file_info["language"]
            ))
        
        return {
            "success": True,
            "framework": "vue",
            "files": files,
            "project_type": "node"
        }
    
    async def _generate_angular(
        self,
        description: str,
        output_dir: Union[str, Path],
        options: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Generate an Angular project structure.
        
        Args:
            description: Description of the project
            output_dir: Output directory
            options: Additional options
            
        Returns:
            Dictionary with generation results
        """
        self._logger.info(f"Generating Angular project: {description}")
        
        files = []
        
        # Define project structure
        structure = [
            {
                "path": "src/main.ts",
                "content": await self._generate_content("angular/main.ts", description, options),
                "purpose": "Application entry point",
                "language": "typescript"
            },
            {
                "path": "src/app/app.module.ts",
                "content": await self._generate_content("angular/app.module.ts", description, options),
                "purpose": "Main application module",
                "language": "typescript"
            },
            {
                "path": "src/app/app.component.ts",
                "content": await self._generate_content("angular/app.component.ts", description, options),
                "purpose": "Main application component",
                "language": "typescript"
            },
            {
                "path": "src/app/app.component.html",
                "content": await self._generate_content("angular/app.component.html", description, options),
                "purpose": "Main component template",
                "language": "html"
            },
            {
                "path": "src/app/app.component.css",
                "content": await self._generate_content("angular/app.component.css", description, options),
                "purpose": "Main component styles",
                "language": "css"
            },
            {
                "path": "src/app/app-routing.module.ts",
                "content": await self._generate_content("angular/app-routing.module.ts", description, options),
                "purpose": "Routing configuration",
                "language": "typescript"
            },
            {
                "path": "src/index.html",
                "content": await self._generate_content("angular/index.html", description, options),
                "purpose": "Main HTML file",
                "language": "html"
            },
            {
                "path": "src/styles.css",
                "content": await self._generate_content("angular/styles.css", description, options),
                "purpose": "Global styles",
                "language": "css"
            },
            {
                "path": "angular.json",
                "content": await self._generate_content("angular/angular.json", description, options),
                "purpose": "Angular CLI configuration",
                "language": "json"
            },
            {
                "path": "package.json",
                "content": await self._generate_content("angular/package.json", description, options),
                "purpose": "NPM package configuration",
                "language": "json"
            },
            {
                "path": "tsconfig.json",
                "content": await self._generate_content("angular/tsconfig.json", description, options),
                "purpose": "TypeScript configuration",
                "language": "json"
            },
            {
                "path": "README.md",
                "content": await self._generate_content("angular/README.md", description, options),
                "purpose": "Project documentation",
                "language": "markdown"
            }
        ]
        
        # Add feature module for better organization
        structure.extend([
            {
                "path": "src/app/features/home/home.component.ts",
                "content": await self._generate_content("angular/features/home/home.component.ts", description, options),
                "purpose": "Home feature component",
                "language": "typescript"
            },
            {
                "path": "src/app/features/home/home.component.html",
                "content": await self._generate_content("angular/features/home/home.component.html", description, options),
                "purpose": "Home feature template",
                "language": "html"
            },
            {
                "path": "src/app/features/home/home.module.ts",
                "content": await self._generate_content("angular/features/home/home.module.ts", description, options),
                "purpose": "Home feature module",
                "language": "typescript"
            }
        ])
        
        # Add shared module
        structure.extend([
            {
                "path": "src/app/shared/shared.module.ts",
                "content": await self._generate_content("angular/shared/shared.module.ts", description, options),
                "purpose": "Shared module",
                "language": "typescript"
            },
            {
                "path": "src/app/shared/components/header/header.component.ts",
                "content": await self._generate_content("angular/shared/components/header/header.component.ts", description, options),
                "purpose": "Header component",
                "language": "typescript"
            },
            {
                "path": "src/app/shared/components/header/header.component.html",
                "content": await self._generate_content("angular/shared/components/header/header.component.html", description, options),
                "purpose": "Header template",
                "language": "html"
            }
        ])
        
        # Generate files
        for file_info in structure:
            files.append(CodeFile(
                path=file_info["path"],
                content=file_info["content"],
                purpose=file_info["purpose"],
                dependencies=[],
                language=file_info["language"]
            ))
        
        return {
            "success": True,
            "framework": "angular",
            "files": files,
            "project_type": "node"
        }
    
    async def _generate_generic(
        self,
        framework: str,
        description: str,
        output_dir: Union[str, Path],
        options: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Generate a generic framework structure using AI.
        
        Args:
            framework: Framework name
            description: Description of the project
            output_dir: Output directory
            options: Additional options
            
        Returns:
            Dictionary with generation results
        """
        self._logger.info(f"Generating generic {framework} project: {description}")
        
        # Use AI to generate a project structure
        prompt = f"""
Generate a typical file structure for a {framework} project that matches this description:
"{description}"

Your response should be a JSON object with this structure:
```json
{{
  "files": [
    {{
      "path": "relative/path/to/file.ext",
      "purpose": "brief description of the file's purpose",
      "language": "programming language/file type"
    }}
  ],
  "project_type": "main programming language (e.g., python, node, java)",
  "description": "brief description of the project structure"
}}
Include all essential files for a working {framework} project, including:

Main entry point file(s)
Configuration files
View/template files
Model definitions
Routing or controller files
Package management files (e.g., package.json, requirements.txt)
Documentation

Keep the structure focused on the core framework files, don't include optional or very specific files.
Ensure the structure follows best practices for {framework} projects.
"""
    try:
        # Call AI service
        api_request = GeminiRequest(
            prompt=prompt,
            max_tokens=4000,
            temperature=0.2
        )   response = await gemini_client.generate_text(api_request)
        
        # Extract JSON from the response
        structure_match = re.search(r'```(?:json)?\s*(.*?)\s*```', response.text, re.DOTALL)
        if structure_match:
            structure_json = structure_match.group(1)
        else:
            structure_json = response.text
        
        structure_data = json.loads(structure_json)
        
        # Generate content for each file
        files = []
        
        for file_info in structure_data.get("files", []):
            # Generate content for the file
            content = await self._generate_file_content(
                framework,
                file_info["path"],
                file_info["purpose"],
                description,
                options
            )
            
            files.append(CodeFile(
                path=file_info["path"],
                content=content,
                purpose=file_info["purpose"],
                dependencies=[],
                language=file_info.get("language")
            ))
        
        return {
            "success": True,
            "framework": framework,
            "files": files,
            "project_type": structure_data.get("project_type", self._infer_project_type(framework))
        }
    
    except json.JSONDecodeError as e:
        self._logger.error(f"Error parsing AI response for {framework} project structure: {e}")
        return {
            "success": False,
            "error": f"Could not generate {framework} project structure: Invalid JSON response",
            "framework": framework
        }
    except Exception as e:
        self._logger.error(f"Error generating {framework} project: {str(e)}", exc_info=True)
        return {
            "success": False,
            "error": f"Could not generate {framework} project structure: {str(e)}",
            "framework": framework
        }

def _infer_project_type(self, framework: str) -> str:
    """
    Infer project type from framework name.
    
    Args:
        framework: Framework name
        
    Returns:
        Inferred project type
    """
    return self._framework_project_types.get(framework.lower(), "unknown")

async def _generate_content(
    self, 
    template_path: str,
    description: str,
    options: Dict[str, Any]
) -> str:
    """
    Generate content for a file based on a template path.
    
    Args:
        template_path: Path to template relative to framework
        description: Project description
        options: Additional options
        
    Returns:
        Generated file content
    """
    self._logger.debug(f"Generating content for template: {template_path}")
    
    # Extract framework and file path
    parts = template_path.split("/", 1)
    if len(parts) < 2:
        # Invalid template path
        framework = "generic"
        file_path = template_path
    else:
        framework = parts[0]
        file_path = parts[1]
    
    return await self._generate_file_content(
        framework,
        file_path,
        "Framework-specific file",
        description,
        options
    )

async def _generate_file_content(
    self, 
    framework: str,
    file_path: str,
    purpose: str,
    description: str,
    options: Dict[str, Any]
) -> str:
    """
    Generate content for a file using AI.
    
    Args:
        framework: Framework name
        file_path: Path to the file
        purpose: Purpose of the file
        description: Project description
        options: Additional options
        
    Returns:
        Generated file content
    """
    # Determine the programming language from the file extension
    ext = Path(file_path).suffix.lower()
    language_map = {
        ".py": "Python",
        ".js": "JavaScript",
        ".ts": "TypeScript",
        ".jsx": "JavaScript (React)",
        ".tsx": "TypeScript (React)",
        ".html": "HTML",
        ".css": "CSS",
        ".json": "JSON",
        ".java": "Java",
        ".go": "Go",
        ".rs": "Rust",
        ".vue": "Vue.js",
        ".md": "Markdown",
        ".yml": "YAML",
        ".yaml": "YAML",
        ".gradle": "Gradle",
        ".properties": "Properties",
        ".xml": "XML",
        ".dockerfile": "Dockerfile",
        ".sh": "Bash",
        ".bat": "Batch",
        ".ejs": "EJS template"
    }
    language = language_map.get(ext, "Unknown")
    
    # Build the prompt
    prompt = f"""
Generate content for a {language} file in a {framework} project.
File path: {file_path}
File purpose: {purpose}
Project description: "{description}"
Requirements:

Generate complete, valid code for a {language} file
Ensure the code follows best practices for {framework} projects
Make the code clean, well-structured, and well-commented
Only include code relevant to the file's purpose and path
Match the style and idioms typically used in {framework} projects

Only respond with the file content, nothing else.
"""
    # Add language-specific instructions
    if language == "Python":
        prompt += "\nInclude appropriate imports and docstrings. Follow PEP 8 guidelines."
    elif language in ["JavaScript", "TypeScript"]:
        prompt += "\nUse modern ES6+ syntax. Include appropriate imports/exports."
    elif language in ["JavaScript (React)", "TypeScript (React)"]:
        prompt += "\nUse functional components with hooks. Include appropriate imports."
    elif language == "Java":
        prompt += "\nInclude appropriate package declaration, imports, and JavaDoc comments."
    # Add framework-specific information
    if framework == "react":
        if "variant" in options and options["variant"] == "nextjs":
            prompt += "\nThis is a Next.js project. Use Next.js-specific patterns and API."
        else:
            prompt += "\nThis is a Create React App project. Use appropriate React patterns."
    elif framework == "django":
        prompt += f"\nProject name: {options.get('project_name', 'django_project')}"
        prompt += f"\nApp name: {options.get('app_name', 'main')}"
    
    try:
        # Call AI service
        api_request = GeminiRequest(
            prompt=prompt,
            max_tokens=4000,
            temperature=0.2
        )
        
        response = await gemini_client.generate_text(api_request)
        
        # Extract code from the response
        code_match = re.search(r'```(?:\w+)?\s*(.*?)\s*```', response.text, re.DOTALL)
        if code_match:
            return code_match.group(1)
        
        # No code block found, use the entire response
        return response.text.strip()
    except Exception as e:
        self._logger.error(f"Error generating content for {file_path}: {str(e)}", exc_info=True)
        return f"# Error generating content: {str(e)}\n# Please regenerate this file"
Global framework generator instance
framework_generator = FrameworkGenerator()
</file>

<file path="angela/intent/enhanced_task_planner.py">
"""
Enhanced execution system for complex task orchestration in Angela CLI.

This module extends the TaskPlanner with robust support for advanced execution steps,
including code execution, API integration, looping constructs, and intelligent
data flow between steps.
"""
import os
import re
import json
import shlex
import asyncio
import tempfile
import subprocess
from pathlib import Path
from typing import Dict, Any, List, Tuple, Optional, Set, Union, Callable
from datetime import datetime
import uuid
import logging
import aiohttp
from enum import Enum

from pydantic import BaseModel, Field, ValidationError, validator

from angela.intent.models import ActionPlan, Intent, IntentType
from angela.ai.client import gemini_client, GeminiRequest
from angela.context import context_manager
from angela.context.file_resolver import file_resolver
from angela.utils.logging import get_logger
from angela.execution.error_recovery import ErrorRecoveryManager
from angela.execution.engine import execution_engine
from angela.safety.validator import validate_command_safety
from angela.safety.classifier import classify_command_risk
from angela.core.registry import registry

# Reuse existing models from angela/intent/planner.py
from angela.intent.planner import (
    PlanStep, TaskPlan, PlanStepType, AdvancedPlanStep, AdvancedTaskPlan,
    task_planner
)

logger = get_logger(__name__)


class StepExecutionContext(BaseModel):
    """Context for step execution with data flow capabilities."""
    step_id: str = Field(..., description="ID of the step being executed")
    plan_id: str = Field(..., description="ID of the plan being executed")
    variables: Dict[str, Any] = Field(default_factory=dict, description="Variables available to the step")
    results: Dict[str, Dict[str, Any]] = Field(default_factory=dict, description="Results of previously executed steps")
    transaction_id: Optional[str] = Field(None, description="Transaction ID for rollback")
    dry_run: bool = Field(False, description="Whether this is a dry run")
    parent_context: Optional[Dict[str, Any]] = Field(None, description="Parent context (e.g., for loops)")
    execution_path: List[str] = Field(default_factory=list, description="Execution path taken so far")

class DataFlowVariable(BaseModel):
    """Model for a variable in the data flow system."""
    name: str = Field(..., description="Name of the variable")
    value: Any = Field(..., description="Value of the variable")
    source_step: Optional[str] = Field(None, description="ID of the step that set this variable")
    timestamp: datetime = Field(default_factory=datetime.now, description="When the variable was set/updated")

class ExecutionResult(BaseModel):
    """Enhanced model for execution results with data flow information."""
    step_id: str = Field(..., description="ID of the executed step")
    type: PlanStepType = Field(..., description="Type of the executed step")
    success: bool = Field(..., description="Whether execution was successful")
    outputs: Dict[str, Any] = Field(default_factory=dict, description="Output values from execution")
    error: Optional[str] = Field(None, description="Error message if execution failed")
    execution_time: float = Field(..., description="Time taken for execution in seconds")
    retried: bool = Field(False, description="Whether the step was retried")
    recovery_applied: bool = Field(False, description="Whether error recovery was applied")
    recovery_strategy: Optional[Dict[str, Any]] = Field(None, description="Recovery strategy that was applied")
    raw_data: Dict[str, Any] = Field(default_factory=dict, description="Raw execution data")

# Data flow operators for variable references
class DataFlowOperator(Enum):
    """Operators for data flow expressions."""
    GET = "get"        # Get a value
    SET = "set"        # Set a value
    CONCAT = "concat"  # Concatenate values
    FORMAT = "format"  # Format a string with values
    JSON = "json"      # Parse or stringify JSON
    REGEX = "regex"    # Apply a regex pattern
    MATH = "math"      # Perform a math operation

# StepStatus enum from the second file - useful for tracking step execution state
class StepStatus(str, Enum):
    """Status of a task step."""
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    SKIPPED = "skipped"

class EnhancedTaskPlanner:
    """
    Enhanced task planner with robust execution capabilities for complex steps.
    
    This class extends the original TaskPlanner with:
    1. Full support for CODE, API, LOOP execution
    2. Formal data flow mechanism between steps
    3. Enhanced error handling with ErrorRecoveryManager integration
    4. Comprehensive logging and debugging
    5. Security measures for code execution
    """
    
    def __init__(self):
        """Initialize the enhanced task planner."""
        self._logger = logger
        self._error_recovery_manager = registry.get("error_recovery_manager")
        if not self._error_recovery_manager:
            self._error_recovery_manager = ErrorRecoveryManager()
        
        # Initialize variable store for data flow
        self._variables: Dict[str, DataFlowVariable] = {}
        
        # Track execution statistics
        self._execution_stats = {
            "executed_plans": 0,
            "executed_steps": 0,
            "errors": 0,
            "recoveries": 0,
            "code_executions": 0,
            "api_calls": 0,
            "loops_executed": 0,
        }
        
        # Set up the sandbox environment for code execution
        self._setup_code_sandbox()
    
    def _setup_code_sandbox(self):
        """Set up the sandbox environment for code execution."""
        # Create a temp directory for code execution if it doesn't exist
        self._sandbox_dir = Path(tempfile.gettempdir()) / "angela_sandbox"
        self._sandbox_dir.mkdir(exist_ok=True)
        
        # Set up allowed imports for code execution
        self._allowed_imports = {
            # Standard library
            "os", "sys", "re", "json", "csv", "datetime", "math", "random",
            "collections", "itertools", "functools", "pathlib", "uuid",
            "time", "tempfile", "shutil", "hashlib", "base64", "hmac",
            "urllib", "http", "typing",
            
            # Common third-party libs (would need to be installed in the sandbox)
            "requests", "aiohttp", "bs4", "pandas", "numpy", "matplotlib",
        }
        
        # Set up banned function patterns
        self._banned_functions = [
            r"__import__\(",
            r"eval\(",
            r"exec\(",
            r"compile\(",
            r"globals\(\)",
            r"locals\(\)",
            r"getattr\(",
            r"setattr\(",
            r"delattr\(",
            r"subprocess\.",
            r"os\.system",
            r"os\.popen",
            r"open\(.+,\s*['\"]w['\"]",  # Writing to files
        ]
        
        self._logger.debug(f"Code sandbox set up at {self._sandbox_dir}")
    
    async def plan_advanced_task(
        self, 
        request: str, 
        context: Dict[str, Any],
        max_steps: int = 20
    ) -> AdvancedTaskPlan:
        """
        Plan a complex task with branching and conditions based on the request.
        
        This method is integrated from the second file to provide a cleaner
        approach to generating advanced task plans directly from natural language.
        
        Args:
            request: Natural language request
            context: Context information
            max_steps: Maximum number of steps to include
            
        Returns:
            Advanced task plan
        """
        self._logger.info(f"Planning advanced task: {request}")
        
        # Generate plan using AI
        plan_data = await self._generate_plan_data(request, context, max_steps)
        
        # Convert to AdvancedTaskPlan model
        try:
            # Create unique ID for the plan
            plan_id = str(uuid.uuid4())
            
            # Create and validate steps
            steps = {}
            for step_id, step_data in plan_data.get("steps", {}).items():
                # Convert the step data to use the AdvancedPlanStep format
                step_type = self._convert_step_type(step_data.get("type", "command"))
                
                # Create a compatible step object that works with our system
                step_params = {
                    "id": step_id,
                    "type": step_type,
                    "description": step_data.get("description", ""),
                    "command": step_data.get("command"),
                    "code": step_data.get("code"),
                    "dependencies": step_data.get("dependencies", []),
                    "estimated_risk": step_data.get("estimated_risk", 0),
                }
                
                # Add condition-specific fields if present
                if "condition" in step_data:
                    step_params["condition"] = step_data["condition"]
                
                if "true_branch" in step_data:
                    step_params["true_branch"] = step_data["true_branch"]
                
                if "false_branch" in step_data:
                    step_params["false_branch"] = step_data["false_branch"]
                
                # Additional parameters
                if "timeout" in step_data:
                    step_params["timeout"] = step_data["timeout"]
                
                if "retry" in step_data:
                    step_params["retry"] = step_data["retry"]
                
                # Add loop-specific fields if present
                if step_type == PlanStepType.LOOP:
                    step_params["loop_items"] = step_data.get("loop_items", "")
                    step_params["loop_body"] = step_data.get("loop_body", [])
                
                # Create the step object
                step = AdvancedPlanStep(**step_params)
                steps[step_id] = step
            
            # Create the plan
            plan = AdvancedTaskPlan(
                id=plan_id,
                goal=plan_data.get("goal", request),
                description=plan_data.get("description", "Advanced task plan"),
                steps=steps,
                entry_points=plan_data.get("entry_points", []),
                created=datetime.now()
            )
            
            return plan
        except Exception as e:
            self._logger.error(f"Error creating advanced plan: {str(e)}")
            # Fall back to simpler plan structure
            return await self._create_fallback_plan(request, context)
    
    def _convert_step_type(self, type_str: str) -> PlanStepType:
        """
        Convert step type string from the plan data to PlanStepType enum.
        
        Args:
            type_str: Step type as string
            
        Returns:
            PlanStepType enum value
        """
        type_mapping = {
            "command": PlanStepType.COMMAND,
            "condition": PlanStepType.DECISION,
            "branch": PlanStepType.DECISION,
            "loop": PlanStepType.LOOP,
            "python_code": PlanStepType.CODE,
            "javascript_code": PlanStepType.CODE,
            "shell_code": PlanStepType.CODE,
            "decision": PlanStepType.DECISION,
            "file": PlanStepType.FILE,
            "api": PlanStepType.API,
            "code": PlanStepType.CODE,
        }
        
        return type_mapping.get(type_str.lower(), PlanStepType.COMMAND)
    
    async def _generate_plan_data(
        self, 
        request: str, 
        context: Dict[str, Any],
        max_steps: int
    ) -> Dict[str, Any]:
        """
        Generate plan data using AI.
        
        Args:
            request: Natural language request
            context: Context information
            max_steps: Maximum number of steps
            
        Returns:
            Dictionary with plan data
        """
        # Build prompt for AI
        prompt = f"""
You are an expert in creating detailed, executable plans for complex tasks. Break down this request into concrete steps that can be executed programmatically:

"{request}"

Create an advanced execution plan with branching logic, conditions, and dynamic paths.

For context, this plan will be executed in a {context.get('os_type', 'Linux')}-based environment with the current directory set to {context.get('cwd', '/home/user')}.

Return a JSON object with this structure:
```json
{{
  "goal": "High-level goal",
  "description": "Detailed description of what this plan will accomplish",
  "steps": {{
    "step1": {{
      "type": "command",
      "description": "Description of this step",
      "command": "shell command to execute",
      "dependencies": [],
      "estimated_risk": 0,
      "timeout": 30,
      "retry": 0
    }},
    "step2": {{
      "type": "condition",
      "description": "Decision point",
      "condition": "command that returns true/false exit code",
      "true_branch": "step3",
      "false_branch": "step4",
      "dependencies": ["step1"],
      "estimated_risk": 0,
      "timeout": 30
    }},
    "step3": {{
      "type": "python_code",
      "description": "Execute Python code",
      "code": "python code to execute",
      "dependencies": ["step2"],
      "estimated_risk": 0,
      "timeout": 30
    }},
    "step4": {{
      "type": "loop",
      "description": "Repeat operation",
      "loop_step": "step5",
      "loop_max": 5,
      "dependencies": ["step2"],
      "estimated_risk": 0
    }},
    "step5": {{
      "type": "command",
      "description": "Command to execute in loop",
      "command": "shell command",
      "dependencies": ["step4"],
      "estimated_risk": 0,
      "timeout": 30
    }}
  }},
  "entry_points": ["step1"]
}}
```

Valid step types: "command", "condition", "branch", "loop", "python_code", "javascript_code", "shell_code".
Risk levels: 0 (safe) to 4 (high risk).
Each step must have a unique ID. Dependencies must reference existing step IDs.
Entry points are step IDs that should be executed first (typically just one).
Create at most {max_steps} steps, but don't add unnecessary steps.

Ensure the plan handles potential errors and provides clear decision branches for different scenarios.
"""
        
        # Call AI service
        api_request = GeminiRequest(
            prompt=prompt,
            max_tokens=4000,
            temperature=0.2
        )
        
        response = await gemini_client.generate_text(api_request)
        
        # Extract JSON data
        try:
            # Look for JSON block in the response
            json_match = re.search(r'```(?:json)?\s*(.*?)\s*```', response.text, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
            else:
                # Try to find JSON without code blocks
                json_match = re.search(r'({.*})', response.text, re.DOTALL)
                if json_match:
                    json_str = json_match.group(1)
                else:
                    # Assume the entire response is JSON
                    json_str = response.text
            
            # Parse JSON
            plan_data = json.loads(json_str)
            return plan_data
        
        except (json.JSONDecodeError, IndexError) as e:
            self._logger.error(f"Error parsing AI response: {str(e)}")
            return {
                "goal": request,
                "description": "Fallback plan due to parsing error",
                "steps": {},
                "entry_points": []
            }
    
    async def _create_fallback_plan(
        self, 
        request: str, 
        context: Dict[str, Any]
    ) -> AdvancedTaskPlan:
        """
        Create a fallback plan when advanced plan generation fails.
        
        Args:
            request: Natural language request
            context: Context information
            
        Returns:
            Simplified advanced task plan
        """
        self._logger.info(f"Creating fallback plan for: {request}")
        
        # Generate a simple command for the request
        from angela.ai.parser import CommandSuggestion
        from angela.ai.prompts import build_prompt
        
        # Build prompt for AI
        prompt = build_prompt(request, context)
        
        # Call AI service
        api_request = GeminiRequest(
            prompt=prompt,
            max_tokens=2000
        )
        
        response = await gemini_client.generate_text(api_request)
        
        # Parse the response to get a command suggestion
        from angela.ai.parser import parse_ai_response
        suggestion = parse_ai_response(response.text)
        
        # Create a simple plan with one command step
        plan_id = str(uuid.uuid4())
        step_id = "step1"
        
        # Get risk level
        risk_level, _ = classify_command_risk(suggestion.command)
        
        # Create the step
        step = AdvancedPlanStep(
            id=step_id,
            type=PlanStepType.COMMAND,
            description=suggestion.explanation or "Execute command",
            command=suggestion.command,
            dependencies=[],
            estimated_risk=risk_level
        )
        
        # Create the plan
        plan = AdvancedTaskPlan(
            id=plan_id,
            goal=request,
            description=f"Execute command: {suggestion.command}",
            steps={step_id: step},
            entry_points=[step_id],
            context={},
            created=datetime.now()
        )
        
        return plan
    
    async def execute_advanced_plan(
        self, 
        plan: AdvancedTaskPlan, 
        dry_run: bool = False,
        transaction_id: Optional[str] = None,
        initial_variables: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Execute an advanced task plan with full support for all step types.
        
        Args:
            plan: The advanced task plan to execute
            dry_run: Whether to simulate execution without making changes
            transaction_id: ID of the transaction this execution belongs to
            initial_variables: Initial variables for data flow
            
        Returns:
            Dictionary with execution results
        """
        self._logger.info(f"Executing advanced plan: {plan.goal} (ID: {plan.id})")
        start_time = datetime.now()
        
        # Reset variable store for this execution
        self._variables = {}
        
        # Set initial variables if provided
        if initial_variables:
            for name, value in initial_variables.items():
                self._set_variable(name, value, "initial")
        
        # Initialize execution context
        context = StepExecutionContext(
            step_id="",
            plan_id=plan.id,
            transaction_id=transaction_id,
            dry_run=dry_run,
            results={},
            variables=self._variables.copy() if self._variables else {}
        )
        
        # Initialize execution state
        results = {}
        completed_steps = set()
        pending_steps = {}
        execution_path = []
        
        # Initialize with entry points
        for entry_point in plan.entry_points:
            if entry_point in plan.steps:
                pending_steps[entry_point] = plan.steps[entry_point]
        
        # Execute steps until all are completed or no more can be executed
        while pending_steps:
            # Find steps that can be executed (all dependencies satisfied)
            executable_steps = {}
            for step_id, step in pending_steps.items():
                if all(dep in completed_steps for dep in step.dependencies):
                    executable_steps[step_id] = step
            
            # If no steps can be executed, we're stuck (circular dependencies or missing steps)
            if not executable_steps:
                self._logger.warning("No executable steps found, possible circular dependencies")
                break
            
            # Execute all executable steps
            newly_completed_steps = []
            
            for step_id, step in executable_steps.items():
                self._logger.info(f"Executing step {step_id}: {step.type} - {step.description}")
                
                # Update execution context for this step
                context.step_id = step_id
                context.execution_path = execution_path.copy()
                
                # Execute the step with enhanced error handling
                try:
                    start_step_time = datetime.now()
                    
                    result = await self._execute_advanced_step(
                        step=step,
                        context=context
                    )
                    
                    # Calculate execution time
                    execution_time = (datetime.now() - start_step_time).total_seconds()
                    
                    # Add execution time to result
                    if isinstance(result, dict) and "execution_time" not in result:
                        result["execution_time"] = execution_time
                    
                    # Store the result
                    results[step_id] = result
                    context.results[step_id] = result
                    
                    # Update execution path
                    execution_path.append(step_id)
                    
                    # Check for next steps based on step type
                    if step.type == PlanStepType.DECISION:
                        # Decision step might have conditional branches
                        condition_result = result.get("condition_result", False)
                        branch_key = "true_branch" if condition_result else "false_branch"
                        next_steps = getattr(step, branch_key, [])
                        
                        self._logger.debug(f"Decision step {step_id} evaluated to {condition_result}, following {branch_key}")
                        
                        if next_steps:
                            for next_step_id in next_steps:
                                if next_step_id in plan.steps and next_step_id not in completed_steps:
                                    pending_steps[next_step_id] = plan.steps[next_step_id]
                    
                    elif step.type == PlanStepType.LOOP:
                        # Loop execution will use recursion
                        loop_result = result.get("loop_results", [])
                        self._logger.debug(f"Loop step {step_id} executed {len(loop_result)} iterations")
                    
                    # Mark step as completed
                    completed_steps.add(step_id)
                    newly_completed_steps.append(step_id)
                    
                    # Update execution stats
                    self._execution_stats["executed_steps"] += 1
                    if step.type == PlanStepType.CODE:
                        self._execution_stats["code_executions"] += 1
                    elif step.type == PlanStepType.API:
                        self._execution_stats["api_calls"] += 1
                    elif step.type == PlanStepType.LOOP:
                        self._execution_stats["loops_executed"] += 1
                    
                    # Check if we need to stop due to an error
                    if not result.get("success", False):
                        self._logger.warning(f"Step {step_id} failed with error: {result.get('error', 'Unknown error')}")
                        
                        # Attempt error recovery
                        if not dry_run and self._error_recovery_manager:
                            recovery_result = await self._attempt_recovery(step, result, context)
                            
                            if recovery_result.get("recovery_success", False):
                                self._logger.info(f"Recovery succeeded for step {step_id}")
                                results[step_id] = recovery_result
                                context.results[step_id] = recovery_result
                                self._execution_stats["recoveries"] += 1
                            else:
                                self._logger.error(f"Recovery failed for step {step_id}")
                                return {
                                    "success": False,
                                    "steps_completed": len(completed_steps),
                                    "steps_total": len(plan.steps),
                                    "failed_step": step_id,
                                    "results": results,
                                    "error": result.get("error", "Unknown error"),
                                    "execution_path": execution_path,
                                    "execution_time": (datetime.now() - start_time).total_seconds()
                                }
                        else:
                            # No recovery attempted, return failure
                            return {
                                "success": False,
                                "steps_completed": len(completed_steps),
                                "steps_total": len(plan.steps),
                                "failed_step": step_id,
                                "results": results,
                                "error": result.get("error", "Unknown error"),
                                "execution_path": execution_path,
                                "execution_time": (datetime.now() - start_time).total_seconds()
                            }
                            
                except Exception as e:
                    self._logger.exception(f"Error executing step {step_id}: {str(e)}")
                    self._execution_stats["errors"] += 1
                    
                    # Record error result
                    error_result = {
                        "step_id": step_id,
                        "type": step.type,
                        "description": step.description,
                        "error": str(e),
                        "success": False,
                        "execution_time": (datetime.now() - start_step_time).total_seconds()
                    }
                    
                    results[step_id] = error_result
                    context.results[step_id] = error_result
                    
                    # Attempt recovery
                    if not dry_run and self._error_recovery_manager:
                        recovery_result = await self._attempt_recovery(step, error_result, context)
                        
                        if recovery_result.get("recovery_success", False):
                            self._logger.info(f"Recovery succeeded for step {step_id}")
                            results[step_id] = recovery_result
                            context.results[step_id] = recovery_result
                            self._execution_stats["recoveries"] += 1
                        else:
                            self._logger.error(f"Recovery failed for step {step_id}")
                            return {
                                "success": False,
                                "steps_completed": len(completed_steps),
                                "steps_total": len(plan.steps),
                                "failed_step": step_id,
                                "results": results,
                                "error": str(e),
                                "execution_path": execution_path,
                                "execution_time": (datetime.now() - start_time).total_seconds()
                            }
                    else:
                        # No recovery attempted, return failure
                        return {
                            "success": False,
                            "steps_completed": len(completed_steps),
                            "steps_total": len(plan.steps),
                            "failed_step": step_id,
                            "results": results,
                            "error": str(e),
                            "execution_path": execution_path,
                            "execution_time": (datetime.now() - start_time).total_seconds()
                        }
            
            # Remove completed steps from pending steps
            for step_id in newly_completed_steps:
                if step_id in pending_steps:
                    del pending_steps[step_id]
            
            # If we're using sequential execution (i.e., no newly completed steps during the last iteration)
            # update pending_steps with steps that depend on the newly completed steps
            if not newly_completed_steps:
                # Find steps that depend on the newly completed steps
                for step_id, step in plan.steps.items():
                    if step_id not in completed_steps and not step_id in pending_steps:
                        # Check if all dependencies are now satisfied
                        if all(dep in completed_steps for dep in step.dependencies):
                            pending_steps[step_id] = step
        
        # Calculate execution time
        execution_time = (datetime.now() - start_time).total_seconds()
        
        # Update execution stats
        self._execution_stats["executed_plans"] += 1
        
        # Check if all steps were completed
        all_completed = len(completed_steps) == len(plan.steps)
        
        return {
            "success": all_completed,
            "steps_completed": len(completed_steps),
            "steps_total": len(plan.steps),
            "results": results,
            "execution_path": execution_path,
            "execution_time": execution_time,
            "variables": {k: v.dict() for k, v in self._variables.items()}
        }
    
    async def _execute_advanced_step(
        self, 
        step: AdvancedPlanStep,
        context: StepExecutionContext
    ) -> Dict[str, Any]:
        """
        Execute a single step of an advanced plan with full support for all step types.
        
        Args:
            step: The step to execute
            context: Execution context with variables and results
            
        Returns:
            Dictionary with execution results
        """
        start_time = datetime.now()
        
        # Prepare common result fields
        result = {
            "step_id": step.id,
            "type": step.type,
            "description": step.description,
            "success": False
        }
        
        try:
            # Process any variable references in parameters
            processed_step = await self._resolve_step_variables(step, context)
            
            # Select appropriate execution method based on step type
            if processed_step.type == PlanStepType.COMMAND:
                step_result = await self._execute_command_step(processed_step, context)
            
            elif processed_step.type == PlanStepType.CODE:
                step_result = await self._execute_code_step(processed_step, context)
            
            elif processed_step.type == PlanStepType.FILE:
                step_result = await self._execute_file_step(processed_step, context)
            
            elif processed_step.type == PlanStepType.DECISION:
                step_result = await self._execute_decision_step(processed_step, context)
            
            elif processed_step.type == PlanStepType.API:
                step_result = await self._execute_api_step(processed_step, context)
            
            elif processed_step.type == PlanStepType.LOOP:
                step_result = await self._execute_loop_step(processed_step, context)
            
            else:
                # Unknown step type
                raise ValueError(f"Unknown step type: {processed_step.type}")
            
            # Merge step-specific results with common fields
            result.update(step_result)
            
            # Extract and store output variables if specified
            if "outputs" in step_result:
                for var_name, var_value in step_result["outputs"].items():
                    self._set_variable(var_name, var_value, step.id)
            
            # Set standard execution time
            result["execution_time"] = (datetime.now() - start_time).total_seconds()
            
            return result
        
        except Exception as e:
            self._logger.exception(f"Error in _execute_advanced_step for {step.id}: {str(e)}")
            
            # Add error information to result
            result["error"] = str(e)
            result["success"] = False
            result["execution_time"] = (datetime.now() - start_time).total_seconds()
            
            # Handle retry if configured
            if step.retry and step.retry > 0:
                result["retry_count"] = 1
                result["retried"] = True
                
                # Attempt retries
                for retry_num in range(1, step.retry + 1):
                    self._logger.info(f"Retrying step {step.id} (attempt {retry_num}/{step.retry})")
                    try:
                        # Wait before retrying with exponential backoff
                        await asyncio.sleep(2 ** retry_num)
                        
                        # Execute retry logic
                        retry_result = await self._execute_advanced_step(step, context)
                        
                        if retry_result.get("success", False):
                            # Retry succeeded
                            retry_result["retry_count"] = retry_num
                            retry_result["retried"] = True
                            return retry_result
                    except Exception as retry_e:
                        self._logger.error(f"Error in retry {retry_num} for step {step.id}: {str(retry_e)}")
                
                # All retries failed
                result["retry_exhausted"] = True
            
            return result
    
    async def _resolve_step_variables(
        self, 
        step: AdvancedPlanStep, 
        context: StepExecutionContext
    ) -> AdvancedPlanStep:
        """
        Resolve variables in step parameters.
        
        Args:
            step: The step with potentially unresolved variables
            context: Execution context with variables
            
        Returns:
            Step with resolved variables
        """
        # Create a copy to avoid modifying the original
        step_dict = step.dict()
        
        # Define a recursive function to process variables in any value
        def process_value(value, path=""):
            if isinstance(value, str):
                # Check for variable references like ${var_name}
                var_pattern = r'\${([^}]+)}'
                matches = re.findall(var_pattern, value)
                
                if matches:
                    result = value
                    for var_name in matches:
                        var_value = self._get_variable_value(var_name, context)
                        if var_value is not None:
                            # Replace the variable reference with its value
                            result = result.replace(f"${{{var_name}}}", str(var_value))
                    return result
                return value
            
            elif isinstance(value, dict):
                return {k: process_value(v, f"{path}.{k}") for k, v in value.items()}
            
            elif isinstance(value, list):
                return [process_value(item, f"{path}[{i}]") for i, item in enumerate(value)]
            
            return value
        
        # Process all fields in the step
        processed_dict = process_value(step_dict)
        
        # Create a new step with processed values
        return AdvancedPlanStep(**processed_dict)
    
    def _get_variable_value(self, var_name: str, context: StepExecutionContext) -> Any:
        """
        Get the value of a variable, supporting both simple names and expressions.
        
        Args:
            var_name: Name of the variable or expression
            context: Execution context
            
        Returns:
            Variable value or None if not found
        """
        # Check for expressions like "result.step1.stdout"
        if "." in var_name:
            parts = var_name.split(".")
            if parts[0] == "result" or parts[0] == "results":
                if len(parts) >= 3:
                    step_id = parts[1]
                    result_field = parts[2]
                    
                    # Get the result for the specified step
                    step_result = context.results.get(step_id)
                    if step_result:
                        # Extract the requested field
                        if result_field in step_result:
                            return step_result[result_field]
                        
                        # Try nested fields
                        if len(parts) > 3:
                            nested_value = step_result
                            for part in parts[2:]:
                                if isinstance(nested_value, dict) and part in nested_value:
                                    nested_value = nested_value[part]
                                else:
                                    return None
                            return nested_value
        
        # Simple variable lookup
        if var_name in self._variables:
            return self._variables[var_name].value
        
        # Check in context variables
        if var_name in context.variables:
            return context.variables[var_name]
        
        return None
    
    def _set_variable(self, name: str, value: Any, source_step: str) -> None:
        """
        Set a variable in the variable store.
        
        Args:
            name: Name of the variable
            value: Value to set
            source_step: ID of the step setting the variable
        """
        self._variables[name] = DataFlowVariable(
            name=name,
            value=value,
            source_step=source_step,
            timestamp=datetime.now()
        )
        self._logger.debug(f"Variable '{name}' set to value from step {source_step}")
    
    # Enhanced variable replacement from the second file
    def _replace_variables(self, text: str, variables: Dict[str, Any]) -> str:
        """
        Replace variables in a text string with a more robust implementation.
        
        This implementation improves handling of both ${var} and $var syntax
        and addresses potential issues with partial matches.
        
        Args:
            text: Text to process
            variables: Dictionary of variables
            
        Returns:
            Text with variables replaced
        """
        if not isinstance(text, str):
            return text
            
        result = text
        
        # Replace ${var} syntax
        for var_name, var_value in variables.items():
            placeholder = f"${{{var_name}}}"
            result = result.replace(placeholder, str(var_value))
        
        # Replace $var syntax
        for var_name, var_value in variables.items():
            placeholder = f"${var_name}"
            
            # Avoid replacing partial matches
            parts = result.split(placeholder)
            if len(parts) > 1:
                new_parts = []
                for i, part in enumerate(parts):
                    new_parts.append(part)
                    if i < len(parts) - 1:
                        # Check if this placeholder is actually part of another variable name
                        if part and part[-1].isalnum() or (i < len(parts) - 1 and parts[i+1] and parts[i+1][0].isalnum()):
                            new_parts.append(placeholder)
                        else:
                            new_parts.append(str(var_value))
                result = "".join(new_parts)
        
        return result
    
    # Enhanced variable extraction from command output
    def _extract_variables_from_output(self, output: str) -> Dict[str, Any]:
        """
        Extract variables from command output with improved pattern detection.
        
        Args:
            output: Command output
            
        Returns:
            Dictionary of extracted variables
        """
        variables = {}
        
        # Look for lines like "VARIABLE=value" or "export VARIABLE=value"
        lines = output.splitlines()
        for line in lines:
            line = line.strip()
            if "=" in line:
                # Check for export pattern
                if line.startswith("export "):
                    line = line[7:]  # Remove "export "
                
                # Split at first equals sign
                parts = line.split("=", 1)
                if len(parts) == 2:
                    var_name = parts[0].strip()
                    var_value = parts[1].strip()
                    
                    # Remove quotes if present
                    if (var_value.startswith('"') and var_value.endswith('"')) or \
                       (var_value.startswith("'") and var_value.endswith("'")):
                        var_value = var_value[1:-1]
                    
                    variables[var_name] = var_value
        
        # Look for JSON output pattern
        if output.strip().startswith("{") and output.strip().endswith("}"):
            try:
                json_data = json.loads(output)
                if isinstance(json_data, dict):
                    for key, value in json_data.items():
                        variables[key] = value
            except json.JSONDecodeError:
                pass
        
        return variables
    
    async def _execute_command_step(
        self, 
        step: AdvancedPlanStep, 
        context: StepExecutionContext
    ) -> Dict[str, Any]:
        """
        Execute a command step.
        
        Args:
            step: The step to execute
            context: Execution context
            
        Returns:
            Dictionary with execution results
        """
        if not step.command:
            return {
                "success": False,
                "error": "Missing command for command step"
            }
        
        self._logger.info(f"Executing command: {step.command}")
        
        if context.dry_run:
            # Simulate command execution
            return {
                "success": True,
                "stdout": f"[DRY RUN] Would execute: {step.command}",
                "stderr": "",
                "return_code": 0,
                "outputs": {
                    f"{step.id}_stdout": f"[DRY RUN] Would execute: {step.command}",
                    f"{step.id}_success": True
                }
            }
        
        # Validate command safety if not specified to skip
        skip_safety = getattr(step, "skip_safety_check", False)
        if not skip_safety:
            # Get validate_command_safety function
            validate_func = registry.get("validate_command_safety")
            if validate_func:
                is_safe, error_message = validate_func(step.command)
                if not is_safe:
                    return {
                        "success": False,
                        "error": f"Command safety validation failed: {error_message}",
                        "command": step.command
                    }
        
        # Execute the command
        try:
            stdout, stderr, return_code = await execution_engine.execute_command(
                command=step.command,
                check_safety=not skip_safety
            )
            
            # Create result
            result = {
                "success": return_code == 0,
                "stdout": stdout,
                "stderr": stderr,
                "return_code": return_code,
                "command": step.command,
                "outputs": {
                    f"{step.id}_stdout": stdout,
                    f"{step.id}_stderr": stderr,
                    f"{step.id}_return_code": return_code,
                    f"{step.id}_success": return_code == 0
                }
            }
            
            # Extract variables from output
            extracted_vars = self._extract_variables_from_output(stdout)
            if extracted_vars:
                for var_name, var_value in extracted_vars.items():
                    result["outputs"][var_name] = var_value
            
            # Record command execution in the transaction if successful
            if context.transaction_id and return_code == 0:
                # Import here to avoid circular imports
                rollback_manager = registry.get("rollback_manager")
                if rollback_manager:
                    await rollback_manager.record_command_execution(
                        command=step.command,
                        return_code=return_code,
                        stdout=stdout,
                        stderr=stderr,
                        transaction_id=context.transaction_id,
                        step_id=step.id
                    )
            
            return result
            
        except Exception as e:
            self._logger.exception(f"Error executing command: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "command": step.command
            }
    
    async def _execute_code_step(
        self, 
        step: AdvancedPlanStep,
        context: StepExecutionContext
    ) -> Dict[str, Any]:
        """
        Execute a code step securely.
        
        Args:
            step: The step to execute
            context: Execution context
            
        Returns:
            Dictionary with execution results
        """
        if not step.code:
            return {
                "success": False,
                "error": "Missing code for code step"
            }
        
        self._logger.info(f"Executing code step: {step.id}")
        
        if context.dry_run:
            # Simulate code execution
            return {
                "success": True,
                "output": f"[DRY RUN] Would execute code: {len(step.code)} characters",
                "outputs": {
                    f"{step.id}_output": f"[DRY RUN] Would execute code: {len(step.code)} characters",
                    f"{step.id}_success": True
                }
            }
        
        try:
            # Validate code for security
            is_safe, validation_error = self._validate_code_security(step.code)
            if not is_safe:
                return {
                    "success": False,
                    "error": f"Code security validation failed: {validation_error}",
                    "code": step.code[:100] + "..." if len(step.code) > 100 else step.code
                }
            
            # Determine code language
            language = getattr(step, "language", "python").lower()
            
            if language == "python":
                # Execute Python code
                code_result = await self._execute_python_code(step.code, context)
            elif language == "javascript" or language == "js":
                # Execute JavaScript code
                code_result = await self._execute_javascript_code(step.code, context)
            elif language == "shell" or language == "bash":
                # Execute shell code
                code_result = await self._execute_shell_code(step.code, context)
            else:
                return {
                    "success": False,
                    "error": f"Unsupported code language: {language}"
                }
            
            # Add step ID to outputs
            if "outputs" in code_result and isinstance(code_result["outputs"], dict):
                prefixed_outputs = {}
                for key, value in code_result["outputs"].items():
                    prefixed_outputs[f"{step.id}_{key}"] = value
                code_result["outputs"] = prefixed_outputs
            
            # Add the code content to result for debugging
            if "code" not in code_result:
                code_short = step.code[:100] + "..." if len(step.code) > 100 else step.code
                code_result["code"] = code_short
            
            return code_result
            
        except Exception as e:
            self._logger.exception(f"Error executing code step: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "code": step.code[:100] + "..." if len(step.code) > 100 else step.code
            }
    
    def _validate_code_security(self, code: str) -> Tuple[bool, Optional[str]]:
        """
        Validate code for security concerns.
        
        Args:
            code: The code to validate
            
        Returns:
            Tuple of (is_safe, error_message)
        """
        # Check for banned function patterns
        for pattern in self._banned_functions:
            if re.search(pattern, code):
                return False, f"Code contains potentially unsafe pattern: {pattern}"
        
        # Check for potentially harmful import statements
        # This is a simplified check; a real implementation might be more sophisticated
        import_pattern = r'^import\s+([a-zA-Z0-9_.,\s]+)$|^from\s+([a-zA-Z0-9_.]+)\s+import'
        for match in re.finditer(import_pattern, code, re.MULTILINE):
            imports = match.group(1) or match.group(2)
            if imports:
                for imp in re.split(r'[\s,]+', imports):
                    # Get the base module (before the first dot)
                    base_module = imp.split('.')[0].strip()
                    if base_module and base_module not in self._allowed_imports:
                        return False, f"Import of module '{base_module}' is not allowed"
        
        return True, None
    
    async def _execute_python_code(
        self, 
        code: str, 
        context: StepExecutionContext
    ) -> Dict[str, Any]:
        """
        Execute Python code securely.
        
        Args:
            code: The Python code to execute
            context: Execution context
            
        Returns:
            Dictionary with execution results
        """
        # Create a unique identifier for this execution
        execution_id = str(uuid.uuid4())
        
        # Create a temporary file to store the code
        temp_dir = self._sandbox_dir / execution_id
        temp_dir.mkdir(exist_ok=True)
        
        temp_file = temp_dir / "code.py"
        
        # Create a file to store the variables
        variables_file = temp_dir / "variables.json"
        
        try:
            # Prepare context variables
            context_vars = {}
            for var_name, var in self._variables.items():
                context_vars[var_name] = var.value
            
            # Write variables to file (serializing complex objects to JSON)
            with open(variables_file, 'w') as f:
                json.dump(context_vars, f)
            
            # Add wrapper code to load variables and capture output
            wrapper_code = f'''
# Generated wrapper for secure code execution
import json
import sys
import io
import traceback

# Redirect stdout and stderr
original_stdout = sys.stdout
original_stderr = sys.stderr
sys.stdout = io.StringIO()
sys.stderr = io.StringIO()

# Output dictionary for capturing results
outputs = {{"success": False}}

try:
    # Load variables from file
    with open("{variables_file}", "r") as var_file:
        variables = json.load(var_file)
    
    # Make variables available in execution context
    globals().update(variables)
    
    # Execute the user code
    {code}
    
    # Capture stdout and stderr
    outputs["stdout"] = sys.stdout.getvalue()
    outputs["stderr"] = sys.stderr.getvalue()
    outputs["success"] = True
    
    # If there's a 'result' or 'output' variable, capture it
    if 'result' in locals():
        outputs["result"] = result
    if 'output' in locals():
        outputs["output"] = output
    
    # Capture all locals that don't start with '_'
    outputs["variables"] = {{
        k: v for k, v in locals().items() 
        if not k.startswith('_') and k not in ['variables', 'var_file']
    }}
    
except Exception as e:
    outputs["error"] = str(e)
    outputs["traceback"] = traceback.format_exc()
    outputs["success"] = False

# Restore stdout and stderr
sys.stdout = original_stdout
sys.stderr = original_stderr

# Write outputs to file
with open("{temp_dir / 'output.json'}", "w") as output_file:
    json.dump(outputs, output_file, default=str)
'''
            
            # Write the wrapper code to the temporary file
            with open(temp_file, 'w') as f:
                f.write(wrapper_code)
            
            timeout = 30
            
            process = await asyncio.create_subprocess_exec(
                sys.executable, str(temp_file),
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            try:
                # Wait for process with timeout
                stdout, stderr = await asyncio.wait_for(process.communicate(), timeout)
                return_code = process.returncode
                
                # Read output file
                output_file = temp_dir / 'output.json'
                if output_file.exists():
                    with open(output_file, 'r') as f:
                        outputs = json.load(f)
                else:
                    outputs = {
                        "success": False,
                        "error": "Output file was not created"
                    }
                
                # Create the result
                result = {
                    "success": outputs.get("success", False),
                    "outputs": outputs.get("variables", {}),
                    "stdout": outputs.get("stdout", ""),
                    "stderr": outputs.get("stderr", "")
                }
                
                if "error" in outputs:
                    result["error"] = outputs["error"]
                    result["traceback"] = outputs.get("traceback", "")
                
                if "result" in outputs:
                    result["result"] = outputs["result"]
                
                if "output" in outputs:
                    result["output"] = outputs["output"]
                
                return result
                
            except asyncio.TimeoutError:
                # Kill the process if it times out
                process.kill()
                return {
                    "success": False,
                    "error": f"Code execution timed out after {timeout} seconds"
                }
                
        except Exception as e:
            self._logger.exception(f"Error in Python code execution: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }
        finally:
            # Clean up temporary files
            try:
                import shutil
                shutil.rmtree(temp_dir)
            except Exception as e:
                self._logger.error(f"Error cleaning up temporary files: {str(e)}")
    
    async def _execute_javascript_code(
        self, 
        code: str, 
        context: StepExecutionContext
    ) -> Dict[str, Any]:
        """
        Execute JavaScript code securely.
        
        Args:
            code: The JavaScript code to execute
            context: Execution context
            
        Returns:
            Dictionary with execution results
        """
        # Create a unique identifier for this execution
        execution_id = str(uuid.uuid4())
        
        # Create a temporary file to store the code
        temp_dir = self._sandbox_dir / execution_id
        temp_dir.mkdir(exist_ok=True)
        
        temp_file = temp_dir / "code.js"
        
        # Create a file to store the variables
        variables_file = temp_dir / "variables.json"
        
        try:
            # Prepare context variables
            context_vars = {}
            for var_name, var in self._variables.items():
                context_vars[var_name] = var.value
            
            # Write variables to file (serializing complex objects to JSON)
            with open(variables_file, 'w') as f:
                json.dump(context_vars, f)
            
            # Add wrapper code to load variables and capture output
            wrapper_code = f'''
// Generated wrapper for secure code execution
const fs = require('fs');

// Load variables from file
const variables = JSON.parse(fs.readFileSync("{variables_file}", "utf8"));

// Make variables available in execution context
Object.assign(global, variables);

// Output object for capturing results
const outputs = {{
    success: false,
    stdout: "",
    stderr: "",
    variables: {{}}
}};

// Capture console.log output
const originalLog = console.log;
const originalError = console.error;
const logs = [];
const errors = [];

console.log = (...args) => {{
    const message = args.map(arg => 
        typeof arg === 'object' ? JSON.stringify(arg) : String(arg)
    ).join(' ');
    logs.push(message);
    outputs.stdout += message + "\\n";
    originalLog.apply(console, args);
}};

console.error = (...args) => {{
    const message = args.map(arg => 
        typeof arg === 'object' ? JSON.stringify(arg) : String(arg)
    ).join(' ');
    errors.push(message);
    outputs.stderr += message + "\\n";
    originalError.apply(console, args);
}};

try {{
    // Execute the user code
    {code}
    
    outputs.success = true;
    
    // If there's a 'result' or 'output' variable, capture it
    if (typeof result !== 'undefined') {{
        outputs.result = result;
    }}
    if (typeof output !== 'undefined') {{
        outputs.output = output;
    }}
    
    // Capture all globals that don't start with '_'
    for (const key in global) {{
        if (!key.startsWith('_') && 
            key !== 'variables' && 
            key !== 'outputs' &&
            key !== 'require' &&
            key !== 'module' &&
            key !== 'exports' &&
            key !== 'Buffer' &&
            key !== 'process' &&
            typeof global[key] !== 'function') {{
            outputs.variables[key] = global[key];
        }}
    }}
    
}} catch (error) {{
    outputs.success = false;
    outputs.error = error.message;
    outputs.stack = error.stack;
}}

// Restore console functions
console.log = originalLog;
console.error = originalError;

// Write outputs to file
fs.writeFileSync("{temp_dir / 'output.json'}", JSON.stringify(outputs, (key, value) => {{
    // Handle circular references
    if (typeof value === 'object' && value !== null) {{
        if (seen.has(value)) {{
            return '[Circular]';
        }}
        seen.add(value);
    }}
    return value;
}}, 2));

function replacer(key, value) {{
    if (typeof value === 'object' && value !== null) {{
        return Object.fromEntries(
            Object.entries(value)
                .filter(([k, v]) => typeof v !== 'function')
        );
    }}
    return value;
}}

fs.writeFileSync("{temp_dir / 'output.json'}", JSON.stringify(outputs, replacer, 2));
'''
            
            # Write the wrapper code to the temporary file
            with open(temp_file, 'w') as f:
                f.write(wrapper_code)
            
            # Check if Node.js is available
            try:
                # Try to run a simple Node.js command
                process = await asyncio.create_subprocess_exec(
                    "node", "--version",
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE
                )
                await process.communicate()
                if process.returncode != 0:
                    return {
                        "success": False,
                        "error": "Node.js is not available for JavaScript execution"
                    }
            except Exception:
                return {
                    "success": False,
                    "error": "Node.js is not available for JavaScript execution"
                }
            
            timeout = 30
            
            process = await asyncio.create_subprocess_exec(
                "node", str(temp_file),
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            try:
                # Wait for process with timeout
                stdout, stderr = await asyncio.wait_for(process.communicate(), timeout)
                return_code = process.returncode
                
                # Read output file
                output_file = temp_dir / 'output.json'
                if output_file.exists():
                    with open(output_file, 'r') as f:
                        outputs = json.load(f)
                else:
                    outputs = {
                        "success": False,
                        "error": "Output file was not created"
                    }
                
                # Create the result
                result = {
                    "success": outputs.get("success", False),
                    "outputs": outputs.get("variables", {}),
                    "stdout": outputs.get("stdout", ""),
                    "stderr": outputs.get("stderr", "")
                }
                
                if "error" in outputs:
                    result["error"] = outputs["error"]
                    result["stack"] = outputs.get("stack", "")
                
                if "result" in outputs:
                    result["result"] = outputs["result"]
                
                if "output" in outputs:
                    result["output"] = outputs["output"]
                
                return result
                
            except asyncio.TimeoutError:
                # Kill the process if it times out
                process.kill()
                return {
                    "success": False,
                    "error": f"Code execution timed out after {timeout} seconds"
                }
                
        except Exception as e:
            self._logger.exception(f"Error in JavaScript code execution: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }
        finally:
            # Clean up temporary files
            try:
                import shutil
                shutil.rmtree(temp_dir)
            except Exception as e:
                self._logger.error(f"Error cleaning up temporary files: {str(e)}")
    
    async def _execute_shell_code(
        self, 
        code: str, 
        context: StepExecutionContext
    ) -> Dict[str, Any]:
        """
        Execute shell code securely.
        
        Args:
            code: The shell code to execute
            context: Execution context
            
        Returns:
            Dictionary with execution results
        """
        # Create a unique identifier for this execution
        execution_id = str(uuid.uuid4())
        
        # Create a temporary file to store the code
        temp_dir = self._sandbox_dir / execution_id
        temp_dir.mkdir(exist_ok=True)
        
        script_file = temp_dir / "script.sh"
        
        try:
            # Write the code to the temporary file
            with open(script_file, 'w') as f:
                f.write("#!/bin/bash\n")
                f.write("set -e\n")  # Exit on error
                
                # Export variables from context
                for var_name, var in self._variables.items():
                    # Only export string variables (shell can't handle complex types)
                    if isinstance(var.value, str) or isinstance(var.value, (int, float, bool)):
                        f.write(f"export {var_name}=\"{str(var.value)}\"\n")
                
                # Add code to capture results
                f.write("OUTPUT_FILE=\"$(mktemp)\"\n")
                f.write("VARS_FILE=\"$(mktemp)\"\n")
                f.write("\n# User code begins\n")
                f.write(code)
                f.write("\n# User code ends\n\n")
                
                # Capture environment variables
                f.write("env > \"$VARS_FILE\"\n")
                
                # Export stdout location
                f.write("echo \"$OUTPUT_FILE\" > " + str(temp_dir / "output_file.txt") + "\n")
                f.write("echo \"$VARS_FILE\" > " + str(temp_dir / "vars_file.txt") + "\n")
            
            # Make the script executable
            script_file.chmod(0o755)
            
            # Execute the script with a timeout
            timeout = 30
            
            process = await asyncio.create_subprocess_exec(
                str(script_file),
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            try:
                # Wait for process with timeout
                stdout, stderr = await asyncio.wait_for(process.communicate(), timeout)
                stdout_str = stdout.decode('utf-8', errors='replace')
                stderr_str = stderr.decode('utf-8', errors='replace')
                return_code = process.returncode
                
                # Read output file location
                output_file_location = temp_dir / "output_file.txt"
                vars_file_location = temp_dir / "vars_file.txt"
                
                outputs = {}
                
                if output_file_location.exists():
                    with open(output_file_location, 'r') as f:
                        output_file = f.read().strip()
                        if os.path.exists(output_file):
                            with open(output_file, 'r') as of:
                                try:
                                    outputs = json.load(of)
                                except json.JSONDecodeError:
                                    # Not JSON, treat as plain text
                                    outputs["output"] = of.read()
                
                # Read captured environment variables
                exported_vars = {}
                if vars_file_location.exists():
                    with open(vars_file_location, 'r') as f:
                        vars_file = f.read().strip()
                        if os.path.exists(vars_file):
                            with open(vars_file, 'r') as vf:
                                for line in vf:
                                    if '=' in line:
                                        key, value = line.split('=', 1)
                                        exported_vars[key] = value.strip()
                
                # Create result
                result = {
                    "success": return_code == 0,
                    "stdout": stdout_str,
                    "stderr": stderr_str,
                    "return_code": return_code,
                    "outputs": exported_vars
                }
                
                if "output" in outputs:
                    result["output"] = outputs["output"]
                
                if return_code != 0:
                    result["error"] = f"Shell script failed with return code {return_code}"
                
                return result
                
            except asyncio.TimeoutError:
                # Kill the process if it times out
                process.kill()
                return {
                    "success": False,
                    "error": f"Shell script execution timed out after {timeout} seconds"
                }
                
        except Exception as e:
            self._logger.exception(f"Error in shell code execution: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }
        finally:
            # Clean up temporary files
            try:
                import shutil
                shutil.rmtree(temp_dir)
            except Exception as e:
                self._logger.error(f"Error cleaning up temporary files: {str(e)}")
    
    async def _execute_file_step(
        self, 
        step: AdvancedPlanStep, 
        context: StepExecutionContext
    ) -> Dict[str, Any]:
        """
        Execute a file operation step.
        
        Args:
            step: The step to execute
            context: Execution context
            
        Returns:
            Dictionary with execution results
        """
        if not step.file_path:
            return {
                "success": False,
                "error": "Missing file path for file step"
            }
        
        self._logger.info(f"Executing file operation on {step.file_path}")
        
        if context.dry_run:
            # Simulate file operation
            operation = "write" if step.file_content else "read"
            return {
                "success": True,
                "message": f"[DRY RUN] Would {operation} file: {step.file_path}",
                "outputs": {
                    f"{step.id}_message": f"[DRY RUN] Would {operation} file: {step.file_path}",
                    f"{step.id}_success": True
                }
            }
        
        try:
            # Determine the operation type
            operation = getattr(step, "operation", "read" if not step.file_content else "write")
            
            # Get filesystem functions
            from angela.execution.filesystem import (
                read_file, write_file, create_directory, delete_file, delete_directory,
                move_file, copy_file
            )
            
            if operation == "read":
                # Read file content
                content = await read_file(step.file_path)
                return {
                    "success": True,
                    "content": content,
                    "outputs": {
                        f"{step.id}_content": content,
                        f"{step.id}_success": True
                    }
                }
                
            elif operation == "write":
                # Create parent directories if needed
                file_path = Path(step.file_path)
                await create_directory(file_path.parent, parents=True)
                
                # Write content to file
                await write_file(step.file_path, step.file_content)
                return {
                    "success": True,
                    "message": f"Content written to {step.file_path}",
                    "outputs": {
                        f"{step.id}_message": f"Content written to {step.file_path}",
                        f"{step.id}_success": True
                    }
                }
                
            elif operation == "delete":
                # Delete file or directory
                if Path(step.file_path).is_dir():
                    await delete_directory(step.file_path)
                    message = f"Directory {step.file_path} deleted"
                else:
                    await delete_file(step.file_path)
                    message = f"File {step.file_path} deleted"
                    
                return {
                    "success": True,
                    "message": message,
                    "outputs": {
                        f"{step.id}_message": message,
                        f"{step.id}_success": True
                    }
                }
                
            elif operation == "copy":
                # Get destination path
                destination = getattr(step, "destination", None)
                if not destination:
                    return {
                        "success": False,
                        "error": "Missing destination for copy operation"
                    }
                
                # Copy file or directory
                await copy_file(step.file_path, destination)
                return {
                    "success": True,
                    "message": f"Copied {step.file_path} to {destination}",
                    "outputs": {
                        f"{step.id}_message": f"Copied {step.file_path} to {destination}",
                        f"{step.id}_source": step.file_path,
                        f"{step.id}_destination": destination,
                        f"{step.id}_success": True
                    }
                }
                
            elif operation == "move":
                # Get destination path
                destination = getattr(step, "destination", None)
                if not destination:
                    return {
                        "success": False,
                        "error": "Missing destination for move operation"
                    }
                
                # Move file or directory
                await move_file(step.file_path, destination)
                return {
                    "success": True,
                    "message": f"Moved {step.file_path} to {destination}",
                    "outputs": {
                        f"{step.id}_message": f"Moved {step.file_path} to {destination}",
                        f"{step.id}_source": step.file_path,
                        f"{step.id}_destination": destination,
                        f"{step.id}_success": True
                    }
                }
                
            else:
                return {
                    "success": False,
                    "error": f"Unsupported file operation: {operation}"
                }
                
        except Exception as e:
            self._logger.exception(f"Error in file operation: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "file_path": step.file_path
            }
    
    async def _execute_decision_step(
        self, 
        step: AdvancedPlanStep, 
        context: StepExecutionContext
    ) -> Dict[str, Any]:
        """
        Execute a decision step.
        
        Args:
            step: The step to execute
            context: Execution context
            
        Returns:
            Dictionary with execution results
        """
        if not step.condition:
            return {
                "success": False,
                "error": "Missing condition for decision step"
            }
        
        self._logger.info(f"Evaluating condition: {step.condition}")
        
        try:
            # Determine condition evaluation method
            condition_type = getattr(step, "condition_type", "expression")
            
            if condition_type == "expression":
                # Evaluate simple expression
                condition_result = await self._evaluate_expression(step.condition, context)
            elif condition_type == "code":
                # Evaluate code for condition
                condition_code = getattr(step, "condition_code", "")
                if not condition_code:
                    return {
                        "success": False,
                        "error": "Missing condition_code for code-based condition"
                    }
                
                # Create a temporary code step
                code_step = AdvancedPlanStep(
                    id=f"{step.id}_condition",
                    type=PlanStepType.CODE,
                    description=f"Condition evaluation for {step.id}",
                    code=condition_code,
                    dependencies=[],
                    estimated_risk=0
                )
                
                # Execute the code
                code_result = await self._execute_code_step(code_step, context)
                
                # Get condition result from code execution
                condition_result = code_result.get("success", False)
                if "result" in code_result:
                    condition_result = bool(code_result["result"])
            else:
                return {
                    "success": False,
                    "error": f"Unsupported condition_type: {condition_type}"
                }
            
            # Create result
            result = {
                "success": True,
                "condition": step.condition,
                "condition_result": condition_result,
                "next_branch": "true_branch" if condition_result else "false_branch",
                "outputs": {
                    f"{step.id}_condition_result": condition_result,
                    f"{step.id}_next_branch": "true_branch" if condition_result else "false_branch",
                    f"{step.id}_success": True
                }
            }
            
            return result
            
        except Exception as e:
            self._logger.exception(f"Error evaluating condition: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "condition": step.condition
            }
    
    async def _evaluate_expression(
        self, 
        expression: str, 
        context: StepExecutionContext
    ) -> bool:
        """
        Evaluate a simple condition expression.
        
        Args:
            expression: The condition expression
            context: Execution context
            
        Returns:
            Boolean result of the condition
        """
        # Check for file existence condition
        file_exists_match = re.search(r'file(?:\s+)exists(?:[:=\s]+)(.+)', expression, re.IGNORECASE)
        if file_exists_match:
            file_path = file_exists_match.group(1).strip()
            # Resolve variables in the file path
            file_path = await self._resolve_variables_in_string(file_path, context)
            return Path(file_path).exists()
        
        # Check for command success condition
        cmd_success_match = re.search(r'command(?:\s+)success(?:[:=\s]+)(.+)', expression, re.IGNORECASE)
        if cmd_success_match:
            step_id = cmd_success_match.group(1).strip()
            return context.results.get(step_id, {}).get("success", False)
        
        # Check for output contains condition
        output_contains_match = re.search(r'output(?:\s+)contains(?:[:=\s]+)(.+?)(?:[:=\s]+)in(?:[:=\s]+)(.+)', expression, re.IGNORECASE)
        if output_contains_match:
            pattern = output_contains_match.group(1).strip()
            step_id = output_contains_match.group(2).strip()
            
            # Resolve variables in the pattern
            pattern = await self._resolve_variables_in_string(pattern, context)
            
            # Get output from the specified step
            step_output = context.results.get(step_id, {}).get("stdout", "")
            return pattern in step_output
        
        # Check for variable condition
        var_match = re.search(r'variable(?:\s+)(.+?)(?:\s*)([=!<>]=|[<>])(?:\s*)(.+)', expression, re.IGNORECASE)
        if var_match:
            var_name = var_match.group(1).strip()
            operator = var_match.group(2).strip()
            value = var_match.group(3).strip()
            
            # Get variable value
            var_value = self._get_variable_value(var_name, context)
            if var_value is None:
                return False
            
            # Evaluate comparison
            try:
                # Convert value to appropriate type
                if value.lower() == "true":
                    compare_value = True
                elif value.lower() == "false":
                    compare_value = False
                elif value.isdigit():
                    compare_value = int(value)
                elif re.match(r'^-?\d+(\.\d+)?$', value):
                    compare_value = float(value)
                else:
                    # Try to resolve variables in the value
                    resolved_value = await self._resolve_variables_in_string(value, context)
                    if resolved_value != value:
                        # Value contained variables, use the resolved value
                        compare_value = resolved_value
                    else:
                        # Treat as a string but strip quotes
                        compare_value = value.strip('\'"')
                
                # Compare based on operator
                if operator == "==":
                    return var_value == compare_value
                elif operator == "!=":
                    return var_value != compare_value
                elif operator == "<":
                    return var_value < compare_value
                elif operator == ">":
                    return var_value > compare_value
                elif operator == "<=":
                    return var_value <= compare_value
                elif operator == ">=":
                    return var_value >= compare_value
                else:
                    return False
            except Exception as e:
                self._logger.error(f"Error comparing variable {var_name} with value {value}: {str(e)}")
                return False
        
        # Simple boolean evaluation for unknown conditions
        return bool(expression and expression.lower() not in ['false', '0', 'no', 'n', ''])
    
    async def _resolve_variables_in_string(
        self, 
        text: str, 
        context: StepExecutionContext
    ) -> str:
        """
        Resolve variables in a string.
        
        Args:
            text: The string with potential variable references
            context: Execution context
            
        Returns:
            String with variables resolved
        """
        if not text or "${" not in text:
            return text
        
        result = text
        var_pattern = r'\${([^}]+)}'
        matches = re.findall(var_pattern, text)
        
        for var_name in matches:
            var_value = self._get_variable_value(var_name, context)
            if var_value is not None:
                # Replace the variable reference with its value
                result = result.replace(f"${{{var_name}}}", str(var_value))
        
        return result
    
    async def _execute_api_step(
        self, 
        step: AdvancedPlanStep, 
        context: StepExecutionContext
    ) -> Dict[str, Any]:
        """
        Execute an API call step.
        
        Args:
            step: The step to execute
            context: Execution context
            
        Returns:
            Dictionary with execution results
        """
        if not step.api_url:
            return {
                "success": False,
                "error": "Missing API URL for API step"
            }
        
        method = getattr(step, "api_method", "GET").upper()
        self._logger.info(f"Executing API call: {method} {step.api_url}")
        
        if context.dry_run:
            # Simulate API call
            return {
                "success": True,
                "message": f"[DRY RUN] Would call API: {method} {step.api_url}",
                "outputs": {
                    f"{step.id}_message": f"[DRY RUN] Would call API: {method} {step.api_url}",
                    f"{step.id}_url": step.api_url,
                    f"{step.id}_method": method,
                    f"{step.id}_success": True
                }
            }
        
        try:
            # Get timeout if specified
            timeout = 30
            
            # Get headers if specified
            headers = getattr(step, "api_headers", {})
            
            # Get query parameters if specified
            params = getattr(step, "api_params", {})
            
            # Get payload if specified
            payload = step.api_payload if hasattr(step, "api_payload") else None
            
            # Create a client session
            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=timeout)) as session:
                # Prepare the request
                request_kwargs = {
                    "headers": headers,
                    "params": params,
                    "ssl": not getattr(step, "insecure_ssl", False)  # Allow insecure SSL as an explicit option
                }
                
                # Add payload for methods that support it
                if method in ["POST", "PUT", "PATCH"] and payload is not None:
                    # Determine content type
                    content_type = headers.get("Content-Type") if headers else None
                    
                    if content_type and "application/json" in content_type:
                        # Send as JSON
                        request_kwargs["json"] = payload
                    elif content_type and "application/x-www-form-urlencoded" in content_type:
                        # Send as form data
                        request_kwargs["data"] = payload
                    elif isinstance(payload, dict):
                        # Default to JSON if payload is a dict
                        request_kwargs["json"] = payload
                    else:
                        # Default to raw data
                        request_kwargs["data"] = payload
                
                # Execute the request
                async with session.request(method, step.api_url, **request_kwargs) as response:
                    # Read response
                    response_text = await response.text()
                    
                    # Try to parse as JSON
                    response_json = None
                    try:
                        response_json = await response.json()
                    except Exception:
                        # Not JSON, leave as None
                        pass
                    
                    # Prepare result
                    result = {
                        "success": 200 <= response.status < 300,
                        "status_code": response.status,
                        "headers": dict(response.headers),
                        "text": response_text,
                        "outputs": {
                            f"{step.id}_status_code": response.status,
                            f"{step.id}_response_text": response_text,
                            f"{step.id}_success": 200 <= response.status < 300
                        }
                    }
                    
                    # Add JSON response if available
                    if response_json is not None:
                        result["json"] = response_json
                        result["outputs"][f"{step.id}_response_json"] = response_json
                    
                    # Add error information for non-success responses
                    if not result["success"]:
                        result["error"] = f"API call failed with status code {response.status}"
                    
                    return result
                    
        except aiohttp.ClientError as e:
            self._logger.exception(f"Error in API call: {str(e)}")
            return {
                "success": False,
                "error": f"API request error: {str(e)}",
                "url": step.api_url,
                "method": method
            }
        except Exception as e:
            self._logger.exception(f"Unexpected error in API call: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "url": step.api_url,
                "method": method
            }
    
    async def _execute_loop_step(
        self, 
        step: AdvancedPlanStep, 
        context: StepExecutionContext
    ) -> Dict[str, Any]:
        """
        Execute a loop step.
        
        Args:
            step: The step to execute
            context: Execution context
            
        Returns:
            Dictionary with execution results
        """
        if not step.loop_items or not step.loop_body:
            return {
                "success": False,
                "error": "Missing loop_items or loop_body for loop step"
            }
        
        self._logger.info(f"Executing loop step: {step.id}")
        
        if context.dry_run:
            # Simulate loop execution
            return {
                "success": True,
                "message": f"[DRY RUN] Would loop over {step.loop_items}",
                "outputs": {
                    f"{step.id}_message": f"[DRY RUN] Would loop over {step.loop_items}",
                    f"{step.id}_success": True
                }
            }
        
        try:
            # Resolve loop items
            loop_items = await self._resolve_loop_items(step.loop_items, context)
            
            if not loop_items:
                return {
                    "success": True,
                    "message": "Loop executed with empty items list",
                    "loop_results": [],
                    "outputs": {
                        f"{step.id}_message": "Loop executed with empty items list",
                        f"{step.id}_success": True,
                        f"{step.id}_iterations": 0
                    }
                }
            
            self._logger.debug(f"Loop will execute over {len(loop_items)} items")
            
            # Execute the loop body for each item
            loop_results = []
            iteration_outputs = {}
            
            for i, item in enumerate(loop_items):
                iteration_key = f"iteration_{i}"
                iteration_id = f"{step.id}_{iteration_key}"
                
                self._logger.debug(f"Executing loop iteration {i} with item: {item}")
                
                # Create a new context for this iteration
                iteration_context = StepExecutionContext(
                    step_id=iteration_id,
                    plan_id=context.plan_id,
                    transaction_id=context.transaction_id,
                    dry_run=context.dry_run,
                    results=context.results.copy(),
                    variables={
                        **context.variables,
                        "loop_item": item,
                        "loop_index": i,
                        "loop_item_index": i,  # Alternative name
                        "loop_first": i == 0,
                        "loop_last": i == len(loop_items) - 1
                    },
                    parent_context=context,
                    execution_path=context.execution_path + [f"{step.id}[{i}]"]
                )
                
                # Execute each step in the loop body
                iteration_results = {}
                
                for step_id in step.loop_body:
                    # For simplicity in this implementation, assume step_id refers to a step in the plan
                    # A more complete implementation would handle nested execution
                    
                    # Record iteration result
                    loop_results.append({
                        "index": i,
                        "item": item,
                        "success": True,  # Simplified for this implementation
                        "results": {}  # Simplified for this implementation
                    })
                    
                    # Extract variables from this iteration to pass back to parent context
                    for var_name, var_value in iteration_context.variables.items():
                        if var_name not in context.variables and not var_name.startswith("loop_"):
                            # Set the variable in the parent context
                            self._set_variable(var_name, var_value, iteration_id)
                
            # Prepare the result
            result = {
                "success": True,  # Simplified; in a complete implementation, we'd check all iterations
                "loop_results": loop_results,
                "iterations": len(loop_results),
                "outputs": {
                    **iteration_outputs,
                    f"{step.id}_success": True,
                    f"{step.id}_iterations": len(loop_results)
                }
            }
            
            return result
            
        except Exception as e:
            self._logger.exception(f"Error in loop execution: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "loop_items": step.loop_items
            }
    
    async def _resolve_loop_items(
        self, 
        loop_items_expr: str, 
        context: StepExecutionContext
    ) -> List[Any]:
        """
        Resolve loop items from various sources.
        
        Args:
            loop_items_expr: Expression for loop items
            context: Execution context
            
        Returns:
            List of items to loop over
        """
        # Check if loop_items is a variable reference
        var_match = re.match(r'\${([^}]+)}$', loop_items_expr)
        if var_match:
            var_name = var_match.group(1)
            var_value = self._get_variable_value(var_name, context)
            
            if var_value is not None:
                if isinstance(var_value, list):
                    return var_value
                elif isinstance(var_value, dict):
                    # For dictionaries, loop over items
                    return list(var_value.items())
                elif isinstance(var_value, str):
                    # For strings, try to parse as JSON
                    try:
                        parsed = json.loads(var_value)
                        if isinstance(parsed, list):
                            return parsed
                    except json.JSONDecodeError:
                        # Not JSON, split by lines
                        return var_value.splitlines()
        
        # Check for range expression: range(start, end, step)
        range_match = re.match(r'range\((\d+)(?:,\s*(\d+))?(?:,\s*(\d+))?\)', loop_items_expr)
        if range_match:
            if range_match.group(2):
                # range(start, end, [step])
                start = int(range_match.group(1))
                end = int(range_match.group(2))
                step = int(range_match.group(3)) if range_match.group(3) else 1
                return list(range(start, end, step))
            else:
                # range(end)
                end = int(range_match.group(1))
                return list(range(end))
        
        # Check for file list: files(pattern)
        files_match = re.match(r'files\(([^)]+)\)', loop_items_expr)
        if files_match:
            pattern = files_match.group(1).strip('"\'')
            
            # Resolve pattern if it contains variables
            resolved_pattern = await self._resolve_variables_in_string(pattern, context)
            
            # Import here to avoid circular imports
            from glob import glob
            
            # Get list of files matching the pattern
            file_list = glob(resolved_pattern)
            return file_list
        
        # Check for JSON array
        if loop_items_expr.startswith('[') and loop_items_expr.endswith(']'):
            try:
                items = json.loads(loop_items_expr)
                if isinstance(items, list):
                    return items
            except json.JSONDecodeError:
                pass
        
        # Check for comma-separated list
        if ',' in loop_items_expr:
            return [item.strip() for item in loop_items_expr.split(',')]
        
        # Default: return as single item
        return [loop_items_expr]
    
    async def _attempt_recovery(
        self, 
        step: AdvancedPlanStep,
        result: Dict[str, Any],
        context: StepExecutionContext
    ) -> Dict[str, Any]:
        """
        Attempt to recover from a failed step.
        
        Args:
            step: The failed step
            result: The failure result
            context: Execution context
            
        Returns:
            Updated result after recovery attempt
        """
        if not self._error_recovery_manager:
            return {
                **result,
                "recovery_attempted": True,
                "recovery_success": False,
                "recovery_error": "Error recovery manager not available"
            }
        
        self._logger.info(f"Attempting recovery for failed step {step.id}")
        
        try:
            # Create a recovery-compatible step dictionary
            step_dict = {
                "id": step.id,
                "command": getattr(step, "command", ""),
                "explanation": step.description
            }
            
            # Call the error recovery manager
            recovery_result = await self._error_recovery_manager.handle_error(
                step_dict, result, {"context": context.dict()}
            )
            
            if recovery_result.get("recovery_success", False):
                self._logger.info(f"Recovery succeeded for step {step.id}")
                
                # Merge success fields
                result["success"] = True
                result["recovery_applied"] = True
                result["recovery_strategy"] = recovery_result.get("recovery_strategy")
                
                    if "outputs" not in result:
                        result["outputs"] = {}
                    result["outputs"].update(recovery_result["outputs"])
                
                return result
            else:
                self._logger.warning(f"Recovery failed for step {step.id}")
                return {
                    **result,
                    "recovery_attempted": True,
                    "recovery_success": False,
                    "recovery_error": recovery_result.get("error", "Unknown recovery error")
                }
            
        except Exception as e:
            self._logger.exception(f"Error in recovery attempt: {str(e)}")
            return {
                **result,
                "recovery_attempted": True,
                "recovery_success": False,
                "recovery_error": str(e)
            }

# Extend the existing TaskPlanner with the enhanced functionality
class EnhancedTaskPlanner(TaskPlanner):
    """
    Enhanced TaskPlanner with support for advanced execution capabilities.
    
    This class extends the original TaskPlanner with the capabilities
    from the EnhancedTaskPlanner.
    """
    
    def __init__(self):
        """Initialize the enhanced task planner."""
        super().__init__()
        self._enhanced_planner = EnhancedTaskPlanner()
    
    async def execute_plan(
        self, 
        plan: Union[TaskPlan, AdvancedTaskPlan], 
        dry_run: bool = False,
        transaction_id: Optional[str] = None,
        initial_variables: Optional[Dict[str, Any]] = None
    ) -> Union[List[Dict[str, Any]], Dict[str, Any]]:
        """
        Execute a task plan with full support for all step types.
        
        Args:
            plan: The plan to execute
            dry_run: Whether to simulate execution without making changes
            transaction_id: ID of the transaction this execution belongs to
            initial_variables: Initial variables for data flow
            
        Returns:
            List of execution results for each step or execution result dict
        """
        if isinstance(plan, AdvancedTaskPlan):
            # Use the enhanced execution for advanced plans
            return await self._enhanced_planner.execute_advanced_plan(
                plan, dry_run, transaction_id, initial_variables
            )
        else:
            # Use the original execution for basic plans
            return await super()._execute_basic_plan(plan, dry_run, transaction_id)
    
    async def plan_task(
        self, 
        request: str, 
        context: Dict[str, Any],
        complexity: str = "auto"
    ) -> Union[TaskPlan, AdvancedTaskPlan]:
        """
        Plan a task by breaking it down into actionable steps.
        
        Enhanced version that can generate advanced task plans directly
        from natural language requests.
        
        Args:
            request: The high-level goal description
            context: Context information
            complexity: Planning complexity level ("simple", "advanced", or "auto")
            
        Returns:
            Either a basic TaskPlan or an advanced AdvancedTaskPlan based on complexity
        """
        self._logger.info(f"Planning task: {request} (complexity: {complexity})")
        
        # Determine planning complexity if auto
        if complexity == "auto":
            complexity = await self._determine_complexity(request)
            self._logger.info(f"Determined complexity: {complexity}")
        
        # Use the appropriate planning strategy
        if complexity == "advanced":
            # Use enhanced advanced planning
            return await self._enhanced_planner.plan_advanced_task(request, context)
        else:
            # Use basic planning for simple tasks
            return await super()._create_basic_plan(request, context)

# Create an instance of the enhanced task planner
enhanced_task_planner = EnhancedTaskPlanner()

# Replace the global task_planner with the enhanced version
task_planner = enhanced_task_planner
</file>

<file path="angela/monitoring/notification_handler.py">
# angela/monitoring/notification_handler.py

"""
Handles notifications from shell hooks for Angela CLI.
"""
import asyncio
import re
from typing import Dict, Any, List, Optional
from pathlib import Path
import logging
import sys

from angela.utils.logging import get_logger
from angela.context import context_manager
from angela.context.session import session_manager
from angela.context.file_activity import file_activity_tracker
from angela.monitoring.background import background_monitor
from angela.shell.inline_feedback import inline_feedback

logger = get_logger(__name__)

class NotificationHandler:
    """
    Handles notifications from shell hooks.
    
    This class processes notifications sent by the shell integration hooks like
    command pre-execution, post-execution, and directory changes.
    """
    
    def __init__(self):
        """Initialize the notification handler."""
        self._logger = logger
        # Store currently running long commands for monitoring
        self._running_commands = {}
        # Track command execution times for performance insights
        self._command_times = {}
        # Track recent directories for context enhancement
        self._recent_directories = []
        # Maximum number of directories to track
        self._max_directories = 10
        # Track commonly failing commands for better suggestions
        self._command_errors = {}
        # Maximum command errors to track
        self._max_errors_per_command = 5
    
    async def handle_notification(self, notification_type: str, *args) -> None:
        """
        Handle a notification from the shell hooks.
        
        Args:
            notification_type: Type of notification (pre_exec, post_exec, dir_change)
            args: Additional arguments for the notification
        """
        self._logger.debug(f"Received notification: {notification_type} with args: {args}")
        
        if notification_type == "pre_exec":
            await self._handle_pre_exec(args[0] if args else "")
        elif notification_type == "post_exec":
            await self._handle_post_exec(
                command=args[0] if len(args) > 0 else "",
                exit_code=int(args[1]) if len(args) > 1 else 0,
                duration=int(args[2]) if len(args) > 2 else 0,
                stderr=args[3] if len(args) > 3 else ""
            )
        elif notification_type == "dir_change":
            await self._handle_dir_change(args[0] if args else "")
    
    async def _handle_pre_exec(self, command: str) -> None:
        """
        Handle command pre-execution notification.
        
        Args:
            command: The command about to be executed
        """
        if not command:
            return
            
        # Update session context
        session_manager.add_entity("current_command", "command", command)
        
        # Record start time for performance tracking
        self._running_commands[command] = {
            "start_time": asyncio.get_event_loop().time(),
            "cwd": str(context_manager.cwd)
        }
        
        # Log the command for later analysis
        self._logger.info(f"Command started: {command}")
        
        # If it's a potentially long-running command, start monitoring
        if _is_long_running_command(command):
            background_monitor.start_command_monitoring(command)
    
    async def _handle_post_exec(self, command: str, exit_code: int, duration: int, stderr: str = "") -> None:
        """
        Handle command post-execution notification.
        
        Args:
            command: The executed command
            exit_code: The command's exit code
            duration: Execution duration in seconds
            stderr: Standard error output (if available)
        """
        if not command:
            return
            
        # Update command statistics
        cmd_base = _extract_base_command(command)
        if cmd_base not in self._command_times:
            self._command_times[cmd_base] = {"count": 0, "total_time": 0, "failures": 0}
        
        self._command_times[cmd_base]["count"] += 1
        self._command_times[cmd_base]["total_time"] += duration
        if exit_code != 0:
            self._command_times[cmd_base]["failures"] += 1
            
            # Track error information for this command
            if cmd_base not in self._command_errors:
                self._command_errors[cmd_base] = []
                
            # Store error information with limited history
            self._command_errors[cmd_base].append({
                "command": command,
                "stderr": stderr,
                "exit_code": exit_code,
                "timestamp": asyncio.get_event_loop().time()
            })
            
            # Trim error history if needed
            if len(self._command_errors[cmd_base]) > self._max_errors_per_command:
                self._command_errors[cmd_base].pop(0)
        
        # Clean up running commands
        if command in self._running_commands:
            del self._running_commands[command]
        
        # Stop monitoring if it was a long-running command
        if _is_long_running_command(command):
            background_monitor.stop_command_monitoring(command)
        
        # Add to session recent commands
        session_manager.add_command(command)
        session_manager.add_entity("last_exit_code", "exit_code", exit_code)
        if stderr:
            session_manager.add_entity("last_stderr", "error_output", stderr)
        
        # If command failed, store it for potential automatic fixes
        if exit_code != 0:
            session_manager.add_entity("last_failed_command", "command", command)
            
            # Analyze the failed command and show proactive suggestions
            fix_suggestion = await self._analyze_failed_command(command, stderr)
            if fix_suggestion:
                # Trigger a proactive suggestion in the terminal
                await inline_feedback.show_message(
                    f"Command failed. Suggestion: {fix_suggestion}",
                    message_type="warning",
                    timeout=15
                )
    
    async def _handle_dir_change(self, new_dir: str) -> None:
        """
        Handle directory change notification.
        
        Args:
            new_dir: The new current directory
        """
        if not new_dir:
            return
            
        # Update context manager with new directory
        context_manager.refresh_context()
        
        # Add to recent directories
        if new_dir not in self._recent_directories:
            self._recent_directories.insert(0, new_dir)
            # Trim to max size
            if len(self._recent_directories) > self._max_directories:
                self._recent_directories = self._recent_directories[:self._max_directories]
        
        # Update session context
        session_manager.add_entity("current_directory", "directory", new_dir)
        session_manager.add_entity("recent_directories", "directories", self._recent_directories)
        
        # If moving to a project directory, refresh project context
        project_root = context_manager.project_root
        if project_root:
            session_manager.add_entity("project_root", "directory", str(project_root))
            
            # If this is a new project, show a helpful message
            if str(project_root) not in self._recent_directories[1:]:
                project_type = context_manager.project_type
                if project_type:
                    await inline_feedback.show_message(
                        f"Detected {project_type.capitalize()} project. Type 'angela help-with {project_type}' for project-specific assistance.",
                        message_type="info",
                        timeout=5
                    )

    async def _analyze_failed_command(self, command: str, stderr: str = "") -> Optional[str]:
        """
        Analyze a failed command to generate a fix suggestion.
        
        Args:
            command: The failed command
            stderr: Standard error output (if available)
            
        Returns:
            A suggestion string or None if no suggestion is available
        """
        # Get exit code from session if stderr not provided
        if not stderr:
            stderr_entity = session_manager.get_entity("last_stderr")
            stderr = stderr_entity.get("value", "") if stderr_entity else ""
        
        # Common error patterns and suggested fixes
        error_patterns = [
            # Git errors
            {
                "pattern": "fatal: could not read Username",
                "command_pattern": "git push",
                "suggestion": "Try setting up SSH keys or use a credential helper: git config --global credential.helper cache"
            },
            {
                "pattern": "fatal: not a git repository",
                "command_pattern": "git",
                "suggestion": "Initialize a git repository first: git init"
            },
            {
                "pattern": "error: failed to push some refs",
                "command_pattern": "git push",
                "suggestion": "Pull changes first: git pull --rebase"
            },
            {
                "pattern": "CONFLICT",
                "command_pattern": "git merge",
                "suggestion": "Resolve merge conflicts and then commit the changes"
            },
            {
                "pattern": "error: Your local changes to the following files would be overwritten by merge",
                "command_pattern": "git pull",
                "suggestion": "Stash your changes first: git stash"
            },
            
            # Python/pip errors
            {
                "pattern": "No module named",
                "command_pattern": "python",
                "suggestion": "Install the missing module with pip: pip install [module_name]"
            },
            {
                "pattern": "ModuleNotFoundError",
                "command_pattern": "python",
                "suggestion": "Install the missing module with pip: pip install [module_name]"
            },
            {
                "pattern": "Could not find a version that satisfies the requirement",
                "command_pattern": "pip install",
                "suggestion": "Check the package name or try with a specific version"
            },
            {
                "pattern": "SyntaxError",
                "command_pattern": "python",
                "suggestion": "Fix the syntax error in your Python file"
            },
            
            # NPM errors
            {
                "pattern": "npm ERR! code ENOENT",
                "command_pattern": "npm",
                "suggestion": "Check if package.json exists in the current directory"
            },
            {
                "pattern": "npm ERR! code E404",
                "command_pattern": "npm install",
                "suggestion": "Package not found. Check the package name and registry"
            },
            {
                "pattern": "Missing script:",
                "command_pattern": "npm run",
                "suggestion": "The script does not exist in package.json. Check available scripts with: npm run"
            },
            
            # Docker errors
            {
                "pattern": "Error response from daemon",
                "command_pattern": "docker",
                "suggestion": "Check if docker daemon is running: systemctl start docker"
            },
            {
                "pattern": "image not found",
                "command_pattern": "docker",
                "suggestion": "Pull the image first: docker pull [image_name]"
            },
            
            # Permission errors
            {
                "pattern": "Permission denied",
                "suggestion": "Try running with sudo or check file permissions"
            },
            
            # Make errors
            {
                "pattern": "No rule to make target",
                "command_pattern": "make",
                "suggestion": "Check your Makefile for the correct target names"
            },
            
            # Generic command not found
            {
                "pattern": "command not found",
                "suggestion": "Install the required package or check the command spelling"
            }
        ]
        
        # Check for specific error patterns in stderr
        for pattern in error_patterns:
            error_pattern = pattern["pattern"]
            cmd_pattern = pattern.get("command_pattern", "")
            
            # Skip if command pattern doesn't match
            if cmd_pattern and cmd_pattern not in command:
                continue
                
            if error_pattern in stderr:
                suggestion = pattern["suggestion"]
                
                # Extract module name if applicable
                if "[module_name]" in suggestion and "No module named " in stderr:
                    module_match = re.search(r"No module named '([^']+)'", stderr)
                    if module_match:
                        module_name = module_match.group(1)
                        suggestion = suggestion.replace("[module_name]", module_name)
                
                # Extract image name if applicable
                if "[image_name]" in suggestion and "image not found" in stderr:
                    image_match = re.search(r"[Ee]rror.*image (.*): not found", stderr)
                    if image_match:
                        image_name = image_match.group(1)
                        suggestion = suggestion.replace("[image_name]", image_name)
                
                return suggestion
        
        # Learning from command history
        cmd_base = _extract_base_command(command)
        
        # Check if we have similar past failures
        if cmd_base in self._command_errors:
            # Look for successful commands that followed the same failed command
            from angela.context.history import history_manager
            
            similar_commands = history_manager.search_similar_command(command)
            if similar_commands and similar_commands.get("success", False):
                return f"Previously successful command: {similar_commands['command']}"
        
        # Fallback suggestions based on command type
        fallback_suggestions = {
            "git": "Check git status and repository configuration",
            "npm": "Verify package.json is valid and node_modules is not corrupted",
            "pip": "Check your Python environment and package requirements",
            "python": "Verify your Python code syntax and imported modules",
            "docker": "Ensure Docker daemon is running and you have sufficient permissions",
            "make": "Check Makefile syntax and required dependencies",
            "yarn": "Verify package.json and yarn.lock files",
            "cargo": "Check your Rust project configuration",
            "mvn": "Verify your Maven configuration and dependencies"
        }
        
        # Return fallback suggestion if available
        if cmd_base in fallback_suggestions:
            return fallback_suggestions[cmd_base]
        
        # No suggestion available
        return None

def _extract_base_command(command: str) -> str:
    """
    Extract the base command from a full command string.
    
    Args:
        command: The full command string
        
    Returns:
        The base command (first word or git subcommand)
    """
    parts = command.strip().split()
    if not parts:
        return ""
    
    # Handle git subcommands as a special case
    if parts[0] == "git" and len(parts) > 1:
        return f"git {parts[1]}"
    
    # Handle npm subcommands
    if parts[0] == "npm" and len(parts) > 1:
        return f"npm {parts[1]}"
    
    # Handle docker subcommands
    if parts[0] == "docker" and len(parts) > 1:
        return f"docker {parts[1]}"
    
    return parts[0]

def _is_long_running_command(command: str) -> bool:
    """
    Check if a command is potentially long-running.
    
    Args:
        command: The command to check
        
    Returns:
        True if the command is potentially long-running
    """
    long_running_patterns = [
        "npm install", "pip install", "apt", "brew", "docker build", 
        "docker-compose up", "make", "cmake", "gcc", "g++", "mvn", "gradle",
        "cargo build", "test", "pytest", "yarn", "sleep", "find", "grep -r",
        "ffmpeg", "convert", "zip", "tar", "unzip", "gunzip", "rsync"
    ]
    
    return any(pattern in command for pattern in long_running_patterns)

def _has_known_fix_pattern(command: str) -> bool:
    """
    Check if a command has a known fix pattern.
    
    Args:
        command: The command to check
        
    Returns:
        True if there's a known fix pattern for this command
    """
    known_patterns = [
        "git push", "git pull", "git commit", "git merge", "git checkout",
        "npm install", "npm run", "npm start", "npm test", "npm build",
        "pip install", "pip uninstall", "python", "pytest", "python -m",
        "docker", "docker-compose", "docker run", "docker build",
        "cargo", "cargo build", "cargo test", "cargo run",
        "make", "make clean", "make install", 
        "mvn", "gradle", "yarn", "bundle"
    ]
    
    return any(pattern in command for pattern in known_patterns)

# Global instance
notification_handler = NotificationHandler()
</file>

<file path="angela/review/__init__.py">
# angela/review/__init__.py
"""
Review components for Angela CLI.
"""
from angela.review.diff_manager import diff_manager
from angela.review.feedback import feedback_manager
</file>

<file path="angela/safety/__init__.py">
async def check_command_safety(command: str, dry_run: bool = False) -> bool:
    """
    Check if a command is safe to execute and obtain user confirmation if needed.
    
    Args:
        command: The shell command to check.
        dry_run: Whether this is a dry run (show preview without executing).
        
    Returns:
        True if the command is safe and confirmed, False otherwise.
    """
    # Step 1: Validate basic safety constraints
    is_valid, error_message = validate_command_safety(command)
    if not is_valid:
        logger.warning(f"Command validation failed: {error_message}")
        return False
    
    # Step 2: Classify the risk level
    risk_level, risk_reason = classify_command_risk(command)
    
    # Step 3: Analyze the command impact
    impact = analyze_command_impact(command)
    
    # Step 4: Generate preview if possible
    preview = await generate_preview(command)
    
    # Step 5: Get user confirmation based on risk level
    confirmed = await get_confirmation(
        command=command,
        risk_level=risk_level,
        risk_reason=risk_reason,
        impact=impact,
        preview=preview,
        dry_run=dry_run
    )
    
    if not confirmed:
        logger.info(f"Command execution cancelled by user: {command}")
        return False
    
    return True

# Register these in the service registry
registry.register("check_command_safety", check_command_safety)
registry.register("validate_command_safety", validate_command_safety)
</file>

<file path="angela/safety/confirmation.py">
"""
User confirmation interface for potentially risky operations.

This module handles presenting command previews and obtaining user confirmation
based on the risk level of operations.
"""
import sys
from typing import Dict, Any, Optional, List, Tuple

from rich.console import Console
from rich.panel import Panel
from rich.syntax import Syntax
from rich.prompt import Confirm
from rich.table import Table
from rich.text import Text

from angela.constants import RISK_LEVELS, DEFAULT_CONFIRMATION_REQUIREMENTS
from angela.config import config_manager
from angela.utils.logging import get_logger

logger = get_logger(__name__)
console = Console()

# Risk level color mapping
RISK_COLORS = {
    RISK_LEVELS["SAFE"]: "green",
    RISK_LEVELS["LOW"]: "blue", 
    RISK_LEVELS["MEDIUM"]: "yellow",
    RISK_LEVELS["HIGH"]: "bright_red",  
    RISK_LEVELS["CRITICAL"]: "red",
}

# Risk level names for display
RISK_LEVEL_NAMES = {v: k for k, v in RISK_LEVELS.items()}


def requires_confirmation(risk_level: int) -> bool:
    """
    Determine if a risk level requires confirmation based on configuration.
    
    Args:
        risk_level: The risk level to check.
        
    Returns:
        True if confirmation is required, False otherwise.
    """
    # If confirm_all_actions is set, always confirm
    if config_manager.config.user.confirm_all_actions:
        return True
    
    # Otherwise, check the default requirements
    return DEFAULT_CONFIRMATION_REQUIREMENTS.get(risk_level, True)


def format_impact_analysis(impact: Dict[str, Any]) -> Table:
    """
    Format the command impact analysis into a rich Table.
    
    Args:
        impact: The impact analysis dictionary.
        
    Returns:
        A rich Table object with the formatted impact analysis.
    """
    table = Table(title="Impact Analysis", expand=True)
    
    table.add_column("Aspect", style="bold cyan")
    table.add_column("Details", style="white")
    
    # Add operation types
    operations = ", ".join(impact.get("operations", ["unknown"]))
    table.add_row("Operations", operations)
    
    # Add destructive warning if applicable
    if impact.get("destructive", False):
        table.add_row("⚠️ Warning", "[bold red]This operation may delete or overwrite files[/bold red]")
    
    # Add file creation info
    if impact.get("creates_files", False):
        table.add_row("Creates Files", "Yes")
    
    # Add file modification info
    if impact.get("modifies_files", False):
        table.add_row("Modifies Files", "Yes")
    
    # Add affected files
    affected_files = impact.get("affected_files", [])
    if affected_files:
        file_list = "\n".join(affected_files[:5])
        if len(affected_files) > 5:
            file_list += f"\n...and {len(affected_files) - 5} more"
        table.add_row("Affected Files", file_list)
    
    # Add affected directories
    affected_dirs = impact.get("affected_dirs", [])
    if affected_dirs:
        dir_list = "\n".join(affected_dirs[:5])
        if len(affected_dirs) > 5:
            dir_list += f"\n...and {len(affected_dirs) - 5} more"
        table.add_row("Affected Directories", dir_list)
    
    return table


async def get_confirmation(
    command: str, 
    risk_level: int, 
    risk_reason: str,
    impact: Dict[str, Any],
    preview: Optional[str] = None,
    dry_run: bool = False
) -> bool:
    """
    Get user confirmation for a command based on its risk level.
    
    Args:
        command: The command to be executed.
        risk_level: The risk level of the command.
        risk_reason: The reason for the risk classification.
        impact: The impact analysis dictionary.
        preview: Optional preview of command results.
        dry_run: Whether this is a dry run.
        
    Returns:
        True if the user confirms, False otherwise.
    """
    # If the risk doesn't require confirmation, return True
    if not requires_confirmation(risk_level) and not dry_run:
        return True
    
    # Get the risk level name and color
    risk_name = RISK_LEVEL_NAMES.get(risk_level, "UNKNOWN")
    risk_color = RISK_COLORS.get(risk_level, "yellow")
    
    # Create panel title based on risk
    if dry_run:
        title = Text("DRY RUN", style=f"bold {risk_color}")
    else:
        title = Text(f"Confirm {risk_name} Risk Operation", style=f"bold {risk_color}")
    
    # Display the command with syntax highlighting
    console.print("\n")
    console.print(Panel(
        Syntax(command, "bash", theme="monokai", word_wrap=True),
        title="Command",
        border_style=risk_color,
        expand=False
    ))
    
    # Display the risk information
    console.print(f"[bold {risk_color}]Risk Level:[/bold {risk_color}] {risk_name}")
    console.print(f"[bold {risk_color}]Reason:[/bold {risk_color}] {risk_reason}")
    
    # Display impact analysis
    console.print(format_impact_analysis(impact))
    
    # Display preview if available
    if preview:
        console.print(Panel(
            preview,
            title="Command Preview",
            border_style=risk_color,
            expand=False
        ))
    
    # For critical operations, use a more prominent warning
    if risk_level == RISK_LEVELS["CRITICAL"]:
        console.print(Panel(
            "⚠️  [bold red]This is a CRITICAL risk operation[/bold red] ⚠️\n"
            "It may cause significant changes to your system or data loss.",
            border_style="red",
            expand=False
        ))
    
    # For dry run, just show the information without asking for confirmation
    if dry_run:
        console.print(Panel(
            "[bold blue]This is a dry run.[/bold blue] No changes will be made.",
            border_style="blue",
            expand=False
        ))
        return False
    
    # Ask for confirmation
    return Confirm.ask("Do you want to proceed?", default=False)
</file>

<file path="angela/safety/preview.py">
"""
Preview generator for command execution.

This module generates previews of what commands will do before they are executed,
helping users make informed decisions about risky operations.
"""
import os
import re
import shlex
import glob
import tempfile
from pathlib import Path
from typing import Dict, Any, Optional, List, Tuple

from angela.execution.engine import execution_engine
from angela.utils.logging import get_logger

logger = get_logger(__name__)

async def preview_mkdir(command: str, tokens: List[str]) -> str:
    """Generate a preview for mkdir command."""
    # Parse flags and paths
    paths = []
    recursive = '-p' in tokens or '--parents' in tokens
    
    for arg in tokens[1:]:
        if not arg.startswith('-'):
            paths.append(arg)
    
    result = []
    for path in paths:
        path_obj = Path(path)
        if path_obj.exists():
            result.append(f"⚠️ Path already exists: {path}")
        elif path_obj.parent.exists() or recursive:
            result.append(f"✓ Will create directory: {path}")
        else:
            result.append(f"❌ Parent directory does not exist: {path.parent}")
    
    if not result:
        return "No directories specified to create."
    
    return "\n".join(result)


async def preview_touch(command: str, tokens: List[str]) -> str:
    """Generate a preview for touch command."""
    # Parse flags and paths
    paths = []
    
    for arg in tokens[1:]:
        if not arg.startswith('-'):
            paths.append(arg)
    
    result = []
    for path in paths:
        path_obj = Path(path)
        if path_obj.exists():
            result.append(f"Will update timestamp: {path}")
        elif path_obj.parent.exists():
            result.append(f"Will create empty file: {path}")
        else:
            result.append(f"❌ Parent directory does not exist: {path_obj.parent}")
    
    if not result:
        return "No files specified to touch."
    
    return "\n".join(result)


async def preview_rm(command: str, tokens: List[str]) -> str:
    """Generate a preview for rm command."""
    # Parse flags and paths
    paths = []
    recursive = '-r' in tokens or '--recursive' in tokens or '-rf' in tokens
    force = '-f' in tokens or '--force' in tokens or '-rf' in tokens
    
    for arg in tokens[1:]:
        if not arg.startswith('-'):
            paths.append(arg)
    
    # Expand any glob patterns
    expanded_paths = []
    for path in paths:
        if '*' in path or '?' in path or '[' in path:
            # Use glob to expand wildcards
            expanded = glob.glob(path)
            if expanded:
                expanded_paths.extend(expanded)
            else:
                expanded_paths.append(f"{path} (no matches)")
        else:
            expanded_paths.append(path)
    
    result = []
    for path in expanded_paths:
        path_obj = Path(path)
        if not path_obj.exists():
            if force:
                continue  # With force flag, non-existent files are silently ignored
            else:
                result.append(f"❌ Not found: {path}")
        elif path_obj.is_dir() and not recursive:
            result.append(f"❌ Cannot remove directory without -r flag: {path}")
        elif path_obj.is_dir():
            file_count = sum(1 for _ in path_obj.glob('**/*'))
            result.append(f"⚠️ Will remove directory containing {file_count} files: {path}")
        else:
            result.append(f"Will remove file: {path}")
    
    if not result:
        return "No files specified to remove or all paths are invalid."
    
    return "\n".join(result)


async def preview_cp(command: str, tokens: List[str]) -> str:
    """Generate a preview for cp command."""
    # This is a simplified preview that doesn't handle all cp options
    
    # Need at least 3 tokens: cp source dest
    if len(tokens) < 3:
        return "Invalid cp command: missing source or destination"
    
    # Last argument is the destination
    destination = tokens[-1]
    # All arguments except the command and destination are sources
    sources = [arg for arg in tokens[1:-1] if not arg.startswith('-')]
    
    recursive = '-r' in tokens or '--recursive' in tokens
    
    result = []
    for source in sources:
        source_path = Path(source)
        
        if not source_path.exists():
            result.append(f"❌ Source does not exist: {source}")
            continue
        
        if source_path.is_dir() and not recursive:
            result.append(f"❌ Cannot copy directory without -r flag: {source}")
            continue
        
        # Determine the destination path
        dest_path = Path(destination)
        if len(sources) > 1 or dest_path.is_dir():
            # Multiple sources or destination is a directory
            if not dest_path.exists():
                if dest_path.name.endswith('/'):  # Explicitly specified as directory
                    result.append(f"Will create directory: {destination}")
                else:
                    result.append(f"Will copy {source} to {destination}")
            else:
                if dest_path.is_dir():
                    result.append(f"Will copy {source} to {destination}/{source_path.name}")
                else:
                    result.append(f"⚠️ Cannot copy multiple sources to a single file: {destination}")
        else:
            # Single source to destination
            if dest_path.exists() and dest_path.is_file():
                result.append(f"⚠️ Will overwrite: {destination}")
            else:
                result.append(f"Will copy {source} to {destination}")
    
    if not result:
        return "No files specified to copy."
    
    return "\n".join(result)


async def preview_mv(command: str, tokens: List[str]) -> str:
    """Generate a preview for mv command."""
    # This is a simplified preview that doesn't handle all mv options
    
    # Need at least 3 tokens: mv source dest
    if len(tokens) < 3:
        return "Invalid mv command: missing source or destination"
    
    # Last argument is the destination
    destination = tokens[-1]
    # All arguments except the command and destination are sources
    sources = [arg for arg in tokens[1:-1] if not arg.startswith('-')]
    
    result = []
    for source in sources:
        source_path = Path(source)
        
        if not source_path.exists():
            result.append(f"❌ Source does not exist: {source}")
            continue
        
        # Determine the destination path
        dest_path = Path(destination)
        if len(sources) > 1 or dest_path.is_dir():
            # Multiple sources or destination is a directory
            if not dest_path.exists():
                if dest_path.name.endswith('/'):  # Explicitly specified as directory
                    result.append(f"Will create directory: {destination}")
                else:
                    result.append(f"Will move {source} to {destination}")
            else:
                if dest_path.is_dir():
                    result.append(f"Will move {source} to {destination}/{source_path.name}")
                else:
                    result.append(f"⚠️ Cannot move multiple sources to a single file: {destination}")
        else:
            # Single source to destination
            if dest_path.exists() and dest_path.is_file():
                result.append(f"⚠️ Will overwrite: {destination}")
            else:
                result.append(f"Will move {source} to {destination}")
    
    if not result:
        return "No files specified to move."
    
    return "\n".join(result)


async def preview_ls(command: str, tokens: List[str]) -> str:
    """Generate a preview for ls command."""
    # Extract the paths from the command
    paths = []
    for arg in tokens[1:]:
        if not arg.startswith('-'):
            paths.append(arg)
    
    # If no paths specified, use current directory
    if not paths:
        paths = ['.']
    
    result = []
    for path in paths:
        try:
            path_obj = Path(path)
            if not path_obj.exists():
                result.append(f"❌ Path does not exist: {path}")
                continue
            
            if path_obj.is_dir():
                # Just count files rather than listing them all
                file_count = sum(1 for _ in path_obj.iterdir())
                result.append(f"Will list directory: {path} (contains {file_count} entries)")
            else:
                result.append(f"Will show file information: {path}")
        except Exception as e:
            result.append(f"Error analyzing {path}: {str(e)}")
    
    return "\n".join(result)


async def preview_cat(command: str, tokens: List[str]) -> str:
    """Generate a preview for cat command."""
    # Extract the paths from the command
    paths = []
    for arg in tokens[1:]:
        if not arg.startswith('-'):
            paths.append(arg)
    
    if not paths:
        return "No files specified to display."
    
    result = []
    for path in paths:
        path_obj = Path(path)
        if not path_obj.exists():
            result.append(f"❌ File does not exist: {path}")
        elif path_obj.is_dir():
            result.append(f"❌ Cannot display directory content: {path}")
        else:
            # Get file size
            size = path_obj.stat().st_size
            size_str = f"{size} bytes"
            if size > 1024:
                size_str = f"{size/1024:.1f} KB"
            if size > 1024 * 1024:
                size_str = f"{size/(1024*1024):.1f} MB"
            
            # Try to determine if it's a text file
            try:
                with open(path_obj, 'rb') as f:
                    is_text = True
                    for block in iter(lambda: f.read(1024), b''):
                        if b'\0' in block:
                            is_text = False
                            break
                
                if is_text:
                    # Count lines
                    with open(path_obj, 'r', errors='replace') as f:
                        line_count = sum(1 for _ in f)
                    result.append(f"Will display text file: {path} ({size_str}, {line_count} lines)")
                else:
                    result.append(f"⚠️ Will display binary file: {path} ({size_str})")
            except Exception as e:
                result.append(f"Error analyzing {path}: {str(e)}")
    
    return "\n".join(result)


async def preview_grep(command: str, tokens: List[str]) -> str:
    """Generate a preview for grep command."""
    # This is a simplified preview that doesn't handle all grep options
    
    # Need at least 3 tokens: grep pattern file
    if len(tokens) < 3:
        return "Invalid grep command: missing pattern or file"
    
    pattern = None
    files = []
    recursive = '-r' in tokens or '--recursive' in tokens
    
    # Simple parsing to extract pattern and files
    pattern_found = False
    for arg in tokens[1:]:
        if arg.startswith('-'):
            continue
        
        if not pattern_found:
            pattern = arg
            pattern_found = True
        else:
            files.append(arg)
    
    if not pattern:
        return "No pattern specified for grep."
    
    if not files:
        if recursive:
            files = ['.']
        else:
            return "No files specified for grep."
    
    result = []
    for file_path in files:
        path_obj = Path(file_path)
        if not path_obj.exists():
            result.append(f"❌ Path does not exist: {file_path}")
        elif path_obj.is_dir() and not recursive:
            result.append(f"❌ Cannot grep directory without -r flag: {file_path}")
        elif path_obj.is_dir() and recursive:
            # Count files in directory
            file_count = sum(1 for _ in path_obj.glob('**/*') if Path(_).is_file())
            result.append(f"Will search for '{pattern}' in directory: {file_path} "
                         f"(contains {file_count} files)")
        else:
            # Try to count occurrences in file
            try:
                with open(path_obj, 'r', errors='replace') as f:
                    content = f.read()
                    count = len(re.findall(pattern, content))
                    result.append(f"Will search for '{pattern}' in {file_path} "
                                 f"(potentially {count} matches)")
            except Exception as e:
                result.append(f"Will search in {file_path}, but preview failed: {str(e)}")
    
    return "\n".join(result)


async def preview_find(command: str, tokens: List[str]) -> str:
    """Generate a preview for find command."""
    # Extract directories to search from the command
    # This is a simple implementation that doesn't handle all find options
    
    dirs = []
    name_pattern = None
    type_filter = None
    
    # Find the directories (arguments before the first option)
    for i, arg in enumerate(tokens[1:], 1):
        if arg.startswith('-'):
            break
        dirs.append(arg)
    
    # If no directories specified, use current directory
    if not dirs:
        dirs = ['.']
    
    # Try to extract name pattern if present
    for i, arg in enumerate(tokens):
        if arg == '-name' and i + 1 < len(tokens):
            name_pattern = tokens[i + 1]
        elif arg == '-type' and i + 1 < len(tokens):
            type_filter = tokens[i + 1]
    
    result = []
    for directory in dirs:
        dir_path = Path(directory)
        if not dir_path.exists():
            result.append(f"❌ Directory does not exist: {directory}")
            continue
        
        if not dir_path.is_dir():
            result.append(f"❌ Not a directory: {directory}")
            continue
        
        # Count files and directories in the search path
        file_count = sum(1 for _ in dir_path.glob('**/*') if Path(_).is_file())
        dir_count = sum(1 for _ in dir_path.glob('**/*') if Path(_).is_dir())
        
        search_desc = f"Will search in: {directory} ({file_count} files, {dir_count} directories)"
        
        if name_pattern:
            search_desc += f"\nLooking for files matching: {name_pattern}"
        
        if type_filter:
            type_desc = {'f': 'files', 'd': 'directories', 'l': 'symbolic links'}.get(type_filter, type_filter)
            search_desc += f"\nFiltering by type: {type_desc}"
        
        result.append(search_desc)
    
    return "\n".join(result)

# Commands that can be simulated with more specific previews
PREVIEWABLE_COMMANDS = {
    'mkdir': preview_mkdir,
    'touch': preview_touch,
    'rm': preview_rm,
    'cp': preview_cp,
    'mv': preview_mv,
    'ls': preview_ls,
    'cat': preview_cat,
    'grep': preview_grep,
    'find': preview_find,
}

async def generate_preview(command: str) -> Optional[str]:
    """
    Generate a preview of what a command will do.
    
    Args:
        command: The shell command to preview.
        
    Returns:
        A string containing the preview, or None if preview is not available.
    """
    try:
        # Parse the command
        tokens = shlex.split(command)
        if not tokens:
            return None
        
        base_cmd = tokens[0]
        
        # Check if we have a specific preview function for this command
        if base_cmd in PREVIEWABLE_COMMANDS:
            return await PREVIEWABLE_COMMANDS[base_cmd](command, tokens)
        
        # For other commands, try to use --dry-run or similar flags if available
        return await generic_preview(command)
    
    except Exception as e:
        logger.exception(f"Error generating preview for '{command}': {str(e)}")
        return f"Preview generation failed: {str(e)}"


async def generic_preview(command: str) -> Optional[str]:
    """
    Generate a generic preview for commands without specific implementations.
    Attempts to use --dry-run flags when available.
    
    Args:
        command: The shell command to preview.
        
    Returns:
        A string containing the preview, or None if preview is not available.
    """
    # List of commands that support --dry-run or similar
    dry_run_commands = {
        'rsync': '--dry-run',
        'apt': '--dry-run',
        'apt-get': '--dry-run',
        'dnf': '--dry-run',
        'yum': '--dry-run',
        'pacman': '--print',
    }
    
    tokens = shlex.split(command)
    base_cmd = tokens[0]
    
    if base_cmd in dry_run_commands:
        # Add the dry run flag
        dry_run_flag = dry_run_commands[base_cmd]
        
        # Check if the flag is already in the command
        if dry_run_flag not in command:
            modified_command = f"{command} {dry_run_flag}"
        else:
            modified_command = command
        
        # Execute the command with the dry run flag
        stdout, stderr, return_code = await execution_engine.execute_command(modified_command)
        
        if return_code == 0:
            return f"Dry run output:\n{stdout}"
        else:
            return f"Dry run failed with error:\n{stderr}"
    
    # For commands without dry run support, return a generic message
    return "Preview not available for this command type. Use --dry-run to simulate."
</file>

<file path="angela/safety/validator.py">
"""
Safety validation for operations.

This module validates operations against safety policies and constraints
before they are executed.
"""
import os
import re
import shlex
from pathlib import Path
from typing import Dict, Any, Optional, List, Tuple

from angela.constants import RISK_LEVELS
from angela.utils.logging import get_logger

logger = get_logger(__name__)

# Define dangerous patterns that should be blocked
DANGEROUS_PATTERNS = [
    # Remove critical system directories
    (r"rm\s+(-r|-f|--recursive|--force)\s+(/|/boot|/etc|/bin|/sbin|/lib|/usr|/var|~)",
     "Removing critical system directories is not allowed"),
    
    # Format disk operations
    (r"(mkfs|fdisk|dd|shred)\s+.*(/dev/sd[a-z]|/dev/nvme[0-9])",
     "Disk formatting operations are not allowed"),
    
    # Critical system commands
    (r"(shutdown|reboot|halt|poweroff|init\s+0|init\s+6)",
     "System power commands are not allowed"),
    
    # Chmod 777 recursively
    (r"chmod\s+(-R|--recursive)\s+777",
     "Setting recursive 777 permissions is not allowed"),
    
    # Network disruption
    (r"(ifconfig|ip)\s+.*down",
     "Network interface disabling is not allowed"),
    
    # Dangerous redirects
    (r">\s*(/etc/passwd|/etc/shadow|/etc/sudoers)",
     "Writing directly to critical system files is not allowed"),
    
    # Hidden command execution
    (r";\s*rm\s+",
     "Hidden deletion commands are not allowed"),
    
    # Web download + execute
    (r"(curl|wget).*\|\s*(bash|sh)",
     "Downloading and executing scripts is not allowed"),
    
    # Disk full attack
    (r"(dd|fallocate)\s+.*if=/dev/zero",
     "Creating large files that may fill disk space is not allowed"),
    
    # Dangerous shell loops
    (r"for\s+.*\s+in\s+.*;.*rm\s+",
     "Shell loops with file deletion are not allowed"),
]

# Define patterns that would require root/sudo access
ROOT_PATTERNS = [
    r"^sudo\s+",
    r"^pkexec\s+",
    r"^su\s+(-|--|-c|\w+)\s+",
    r"(chmod|chown|chgrp)\s+.*(/usr/|/etc/|/bin/|/sbin/|/lib/|/var/)",
    r"(touch|rm|mv|cp)\s+.*(/usr/|/etc/|/bin/|/sbin/|/lib/|/var/)",
    r">\s*(/usr/|/etc/|/bin/|/sbin/|/lib/|/var/)",
]

class ValidationError(Exception):
    """Exception raised when a command fails validation."""
    pass


def validate_command_safety(command: str) -> Tuple[bool, Optional[str]]:
    """
    Validate a command against safety rules.
    
    Args:
        command: The shell command to validate.
        
    Returns:
        A tuple of (is_valid, error_message). If is_valid is False,
        error_message will contain the reason.
    """
    if not command.strip():
        return True, None
    
    # Check against dangerous patterns
    for pattern, message in DANGEROUS_PATTERNS:
        if re.search(pattern, command):
            logger.warning(f"Command '{command}' blocked: {message}")
            return False, message
    
    # Check permission requirements
    if not is_superuser() and requires_superuser(command):
        logger.warning(f"Command '{command}' requires superuser privileges")
        return False, "This command requires superuser privileges, which Angela CLI doesn't have."
    
    return True, None


def requires_superuser(command: str) -> bool:
    """
    Check if a command requires superuser privileges.
    
    Args:
        command: The shell command to check.
        
    Returns:
        True if the command requires superuser privileges, False otherwise.
    """
    for pattern in ROOT_PATTERNS:
        if re.search(pattern, command):
            return True
    
    return False


def is_superuser() -> bool:
    """
    Check if the current process has superuser privileges.
    
    Returns:
        True if running as superuser, False otherwise.
    """
    return os.geteuid() == 0 if hasattr(os, 'geteuid') else False


def check_file_permission(path: Path, require_write: bool = False) -> Tuple[bool, Optional[str]]:
    """
    Check if a file has the required permissions.
    
    Args:
        path: The path to check.
        require_write: Whether write permission is required.
        
    Returns:
        A tuple of (has_permission, error_message). If has_permission is False,
        error_message will contain the reason.
    """
    try:
        if not path.exists():
            # If the file doesn't exist, check if the parent directory is writable
            if require_write:
                parent = path.parent
                if not parent.exists():
                    return False, f"Parent directory {parent} does not exist"
                if not os.access(parent, os.W_OK):
                    return False, f"No write permission for directory {parent}"
            return True, None
        
        if not os.access(path, os.R_OK):
            return False, f"No read permission for {path}"
        
        if require_write and not os.access(path, os.W_OK):
            return False, f"No write permission for {path}"
        
        return True, None
    
    except Exception as e:
        logger.exception(f"Error checking permissions for {path}: {str(e)}")
        return False, f"Permission check failed: {str(e)}"


def validate_operation(operation_type: str, params: Dict[str, Any]) -> Tuple[bool, Optional[str]]:
    """
    Validate a high-level operation against safety rules.
    
    Args:
        operation_type: The type of operation (e.g., 'create_file', 'delete_file').
        params: Parameters for the operation.
        
    Returns:
        A tuple of (is_valid, error_message). If is_valid is False,
        error_message will contain the reason.
    """
    try:
        if operation_type == 'create_file':
            path = Path(params.get('path', ''))
            return check_file_permission(path, require_write=True)
        
        elif operation_type == 'write_file':
            path = Path(params.get('path', ''))
            return check_file_permission(path, require_write=True)
        
        elif operation_type == 'read_file':  # Add this handler
            path = Path(params.get('path', ''))
            return check_file_permission(path, require_write=False)
            
        elif operation_type == 'delete_file':
            path = Path(params.get('path', ''))
            # Check if this is a system file
            system_dirs = ['/bin', '/sbin', '/lib', '/usr', '/etc', '/var']
            if any(str(path).startswith(dir) for dir in system_dirs):
                return False, f"Deleting system files is not allowed: {path}"
            
            return check_file_permission(path, require_write=True)
        
        elif operation_type == 'create_directory':
            path = Path(params.get('path', ''))
            if path.exists():
                return False, f"Path already exists: {path}"
            return check_file_permission(path.parent, require_write=True)
        
        elif operation_type == 'delete_directory':
            path = Path(params.get('path', ''))
            # Check if this is a system directory
            system_dirs = ['/bin', '/sbin', '/lib', '/usr', '/etc', '/var']
            if any(str(path).startswith(dir) for dir in system_dirs):
                return False, f"Deleting system directories is not allowed: {path}"
            
            return check_file_permission(path, require_write=True)
        
        elif operation_type == 'copy_file':  # Add this handler
            source = Path(params.get('source', ''))
            destination = Path(params.get('destination', ''))
            
            # Check if source exists
            if not source.exists():
                return False, f"Source file does not exist: {source}"
                
            # Check destination permissions
            return check_file_permission(destination.parent, require_write=True)
            
        elif operation_type == 'move_file':  # Add this handler
            source = Path(params.get('source', ''))
            destination = Path(params.get('destination', ''))
            
            # Check if source exists
            if not source.exists():
                return False, f"Source file does not exist: {source}"
                
            # Check permissions for both source and destination
            source_ok, source_err = check_file_permission(source, require_write=True)
            if not source_ok:
                return False, source_err
                
            return check_file_permission(destination.parent, require_write=True)
            
        elif operation_type == 'execute_command':
            command = params.get('command', '')
            return validate_command_safety(command)
        
        # Unknown operation type
        logger.warning(f"Unknown operation type: {operation_type}")
        return False, f"Unknown operation type: {operation_type}"
    
    except Exception as e:
        logger.exception(f"Error validating operation {operation_type}: {str(e)}")
        return False, f"Validation failed: {str(e)}"
</file>

<file path="angela/shell/angela.zsh">
#!/bin/zsh
# Angela CLI Zsh Integration

# Function to handle Angela CLI requests
angela() {
    # Check if arguments were provided
    if [ $# -eq 0 ]; then
        # No arguments, show help
        python -m angela --help
    else
        # Capture the current working directory
        local current_dir=$(pwd)
        
        # Process the request
        python -m angela request "$@"
        
        # Note: In future phases, we'll add support for command execution,
        # directory changing, etc. For now, this is just a simple pass-through.
    fi
}

# Enable command completion for angela function
# This will be implemented in a future phase
</file>

<file path="angela/shell/completion.py">
"""
AI-powered contextual auto-completion for Angela CLI.
"""
import asyncio
from typing import List, Dict, Any, Optional, Set
import os
from pathlib import Path
import re

from angela.utils.logging import get_logger
from angela.context import context_manager
from angela.context.file_activity import file_activity_tracker
from angela.context.session import session_manager
from angela.context.history import history_manager
from angela.ai.client import gemini_client, GeminiRequest

logger = get_logger(__name__)

class CompletionHandler:
    """
    Provides contextually relevant completions for the Angela CLI.
    
    This class generates completions based on command history, project context,
    recent file activity, and current input state.
    """
    
    def __init__(self):
        """Initialize the completion handler."""
        self._logger = logger
        
        # Cache common completions to avoid repeated calculation
        self._completion_cache = {}
        self._cache_ttl = 300  # Cache lifetime in seconds
        self._cache_last_update = {}
        
        # Static completions for common commands
        self._static_completions = {
            "init": [],
            "status": [],
            "shell": [],
            "files": ["ls", "mkdir", "rm", "cat", "write", "find", "info", "rollback"],
            "workflows": ["list", "create", "run", "delete", "show", "export", "import"],
            "generate": ["create-project", "add-feature", "refine-code", "refine-project", "generate-ci", "generate-tests"],
            "rollback": ["list", "operation", "transaction", "last"],
        }
        
        # Common file extensions for different contexts
        self._file_extensions = {
            "python": [".py", ".json", ".yml", ".yaml", ".txt", ".md"],
            "javascript": [".js", ".json", ".ts", ".jsx", ".tsx", ".html", ".css"],
            "web": [".html", ".css", ".js", ".svg", ".png", ".jpg"],
            "data": [".csv", ".json", ".xml", ".yaml", ".sql"],
            "docs": [".md", ".txt", ".pdf", ".docx"],
        }
    
    async def get_completions(self, args: List[str]) -> List[str]:
        """
        Get completions for the current command line.
        
        Args:
            args: The current command line arguments
            
        Returns:
            List of completions
        """
        self._logger.debug(f"Generating completions for args: {args}")
        
        if not args:
            # No args yet, return top-level commands
            return self._get_top_level_completions()
        
        # Handle subcommand completions
        main_command = args[0]
        
        # Check static completions first
        if main_command in self._static_completions and len(args) == 1:
            return self._static_completions[main_command]
        
        # Handle specific completion contexts
        if main_command == "files":
            return await self._get_files_completions(args[1:] if len(args) > 1 else [])
        elif main_command == "workflows":
            return await self._get_workflow_completions(args[1:] if len(args) > 1 else [])
        elif main_command == "generate":
            return await self._get_generate_completions(args[1:] if len(args) > 1 else [])
        elif main_command == "rollback":
            return await self._get_rollback_completions(args[1:] if len(args) > 1 else [])
        elif main_command in ["fix", "explain", "help-with"]:
            # Natural language commands get context-aware completions
            return await self._get_contextual_completions(main_command, args[1:] if len(args) > 1 else [])
        
        # Default to empty list for unknown commands
        return []
    
    def _get_top_level_completions(self) -> List[str]:
        """
        Get top-level command completions.
        
        Returns:
            List of top-level commands
        """
        # Standard commands
        commands = list(self._static_completions.keys())
        
        # Add natural language command prefixes
        commands.extend(["fix", "explain", "help-with"])
        
        # Sort and return
        return sorted(commands)
    
    async def _get_files_completions(self, args: List[str]) -> List[str]:
        """
        Get completions for file-related commands.
        
        Args:
            args: The command arguments after 'files'
            
        Returns:
            List of completions
        """
        if not args:
            # No subcommand yet, return available subcommands
            return self._static_completions["files"]
        
        subcommand = args[0]
        
        # For commands that take file paths, provide file path completions
        if subcommand in ["ls", "cat", "rm", "find", "info"] and len(args) <= 2:
            return await self._get_file_path_completions(args[1] if len(args) > 1 else "")
        
        return []
    
    async def _get_file_path_completions(self, partial_path: str) -> List[str]:
        """
        Get completions for file paths.
        
        Args:
            partial_path: The partial file path to complete
            
        Returns:
            List of matching file paths
        """
        # Convert to Path object for easier handling
        path = Path(partial_path) if partial_path else Path(".")
        
        # Check if it's a directory prefix
        if not partial_path.endswith("/") and path.is_dir():
            # Return the directory with a trailing slash
            return [f"{partial_path}/"]
        
        # Get the directory to search in
        directory = path.parent if partial_path and not partial_path.endswith("/") else path
        prefix = path.name if partial_path and not partial_path.endswith("/") else ""
        
        try:
            # List directory contents matching the prefix
            if not directory.exists():
                return []
                
            completions = []
            for item in directory.iterdir():
                if prefix and not item.name.startswith(prefix):
                    continue
                    
                # Handle directories
                if item.is_dir():
                    completions.append(f"{item.name}/")
                else:
                    completions.append(item.name)
            
            # Return with proper prefix
            prefix_dir = str(directory) if str(directory) != "." else ""
            if prefix_dir and not prefix_dir.endswith("/"):
                prefix_dir += "/"
                
            return [f"{prefix_dir}{c}" for c in completions]
            
        except Exception as e:
            self._logger.error(f"Error getting file path completions: {str(e)}")
            return []
    
    async def _get_workflow_completions(self, args: List[str]) -> List[str]:
        """
        Get completions for workflow-related commands.
        
        Args:
            args: The command arguments after 'workflows'
            
        Returns:
            List of completions
        """
        if not args:
            # No subcommand yet, return available subcommands
            return self._static_completions["workflows"]
        
        subcommand = args[0]
        
        # For commands that take workflow names, provide workflow name completions
        if subcommand in ["run", "delete", "show", "export"] and len(args) <= 2:
            # This would be replaced with actual workflow names from the workflow manager
            return ["workflow1", "workflow2", "backup", "deploy"]
        
        return []
    
    async def _get_generate_completions(self, args: List[str]) -> List[str]:
        """
        Get completions for code generation commands.
        
        Args:
            args: The command arguments after 'generate'
            
        Returns:
            List of completions
        """
        if not args:
            # No subcommand yet, return available subcommands
            return self._static_completions["generate"]
        
        subcommand = args[0]
        
        # Handle specific generate subcommands
        if subcommand == "generate-ci" and len(args) <= 2:
            return ["github_actions", "gitlab_ci", "jenkins", "travis", "circle_ci"]
        
        return []
    

    
    async def _get_rollback_completions(self, args: List[str]) -> List[str]:
        """
        Get completions for rollback commands.
        
        Args:
            args: The command arguments after 'rollback'
            
        Returns:
            List of completions
        """
        if not args:
            # No subcommand yet, return available subcommands
            return self._static_completions["rollback"]
        
        subcommand = args[0]
        
        # For commands that take operation or transaction IDs
        if subcommand in ["operation", "transaction"] and len(args) <= 2:
            # Get IDs from rollback manager
            try:
                # Import here to avoid circular imports
                from angela.execution.rollback import rollback_manager
                
                if subcommand == "operation":
                    # Get recent operations
                    operations = await rollback_manager.get_recent_operations(limit=10)
                    return [str(op["id"]) for op in operations if op.get("can_rollback", False)]
                else:  # transaction
                    # Get recent transactions
                    transactions = await rollback_manager.get_recent_transactions(limit=10)
                    return [str(tx["id"]) for tx in transactions if tx.get("can_rollback", False)]
            except Exception as e:
                self._logger.error(f"Error fetching rollback IDs: {str(e)}")
                return []
        
        # For the "list" command with options
        elif subcommand == "list" and len(args) <= 2:
            return ["--transactions", "--operations", "--limit"]
        
        # For the "last" command with options
        elif subcommand == "last" and len(args) <= 2:
            return ["--transaction", "--force"]
        
        return []
    
    def _get_fix_completions(self, context: Dict[str, Any]) -> List[str]:
        """
        Get completions for the 'fix' command.
        
        Args:
            context: The completion context
            
        Returns:
            List of completions
        """
        completions = []
        
        # Add completions based on last failed command
        last_failed = context.get("last_failed_command")
        if last_failed:
            base_command = last_failed.split()[0] if last_failed.strip() else ""
            completions.append(f"last {base_command} command")
            completions.append(f"last command")
        
        # Add project-specific fix suggestions
        project_type = context.get("project_type")
        if project_type == "python":
            completions.extend([
                "import errors",
                "python syntax",
                "pip dependencies",
                "missing module"
            ])
        elif project_type == "node":
            completions.extend([
                "npm dependencies",
                "webpack config",
                "typescript errors",
                "node version"
            ])
        
        # Add general fix suggestions
        completions.extend([
            "git conflicts",
            "git merge issues",
            "build errors",
            "path issues"
        ])
        
        return completions
    
    def _get_explain_completions(self, context: Dict[str, Any]) -> List[str]:
        """
        Get completions for the 'explain' command.
        
        Args:
            context: The completion context
            
        Returns:
            List of completions
        """
        completions = []
        
        # Add completions for recent files
        recent_files = context.get("recent_files", [])
        for file in recent_files[:3]:  # Limit to 3 recent files
            completions.append(f"file {file}")
        
        # Add completions for recent commands
        recent_commands = context.get("recent_commands", [])
        for cmd in recent_commands[:3]:  # Limit to 3 recent commands
            # Extract base command
            base_cmd = cmd.split()[0] if cmd.strip() else ""
            if base_cmd:
                completions.append(f"command {base_cmd}")
        
        # Add project-specific explain suggestions
        project_type = context.get("project_type")
        if project_type == "python":
            completions.extend([
                "virtual environments",
                "python packaging",
                "project structure"
            ])
        elif project_type == "node":
            completions.extend([
                "package.json",
                "nodejs modules",
                "npm scripts"
            ])
        
        return completions
    
    def _get_help_completions(self, context: Dict[str, Any]) -> List[str]:
        """
        Get completions for the 'help-with' command.
        
        Args:
            context: The completion context
            
        Returns:
            List of completions
        """
        completions = []
        
        # Add project-specific help suggestions
        project_type = context.get("project_type")
        if project_type == "python":
            completions.extend([
                "setting up pytest",
                "creating a Python package",
                "using virtual environments",
                "debugging Python code"
            ])
        elif project_type == "node":
            completions.extend([
                "creating a React component",
                "setting up webpack",
                "optimizing npm builds",
                "debugging JavaScript"
            ])
        
        # Add general help suggestions
        completions.extend([
            "git workflow",
            "project structure",
            "optimizing performance",
            "writing documentation"
        ])
        
        return completions
    
    async def _get_ai_completions(
        self,
        command: str,
        partial: str,
        context: Dict[str, Any]
    ) -> List[str]:
        """
        Get AI-powered completions for natural language commands.
        
        Args:
            command: The main command (fix, explain, help-with)
            partial: The partial natural language input
            context: The completion context
            
        Returns:
            List of AI-suggested completions
        """
        try:
            # Build a prompt for the AI
            prompt = f"""
You are suggesting auto-completions for the Angela CLI's "{command}" command. 
The user has typed: "{command} {partial}"

Context information:
- Project type: {context.get('project_type', 'unknown')}
- Recent files: {', '.join(context.get('recent_files', [])[:3])}
- Recent commands: {', '.join(context.get('recent_commands', [])[:3])}
- Last failed command: {context.get('last_failed_command', 'none')}

Suggest 3-5 natural language completions that would be helpful continuations of what the user is typing.
Each completion should be the FULL text that would follow "{command} ", not just the part after "{partial}".
Completions should be relevant to the current context and project type.

Respond with ONLY a JSON array of strings, like:
["completion 1", "completion 2", "completion 3"]
"""
            
            # Call the AI
            api_request = GeminiRequest(
                prompt=prompt,
                max_tokens=200,
                temperature=0.1  # Low temperature for more deterministic completions
            )
            
            response = await gemini_client.generate_text(api_request)
            
            # Parse the response to extract completions
            import json
            import re
            
            # Try to find JSON in the response
            json_match = re.search(r'\[.*\]', response.text, re.DOTALL)
            if json_match:
                completions = json.loads(json_match.group(0))
                return completions
            
            # If we couldn't parse JSON, return empty list
            return []
            
        except Exception as e:
            self._logger.error(f"Error getting AI completions: {str(e)}")
            return []
    
    def _build_completion_context(self) -> Dict[str, Any]:
        """
        Build a context dictionary for completions.
        
        Returns:
            Context dictionary
        """
        context = {}
        
        # Add project information
        context["project_type"] = context_manager.project_type
        
        # Add recent files
        recent_activities = file_activity_tracker.get_recent_activities(max_count=5)
        context["recent_files"] = [str(activity.file_path) for activity in recent_activities 
                                  if activity.file_path is not None]
        
        # Add recent commands from session
        session_context = session_manager.get_context()
        context["recent_commands"] = session_context.get("recent_commands", [])
        
        # Add last failed command if available
        last_failed = session_manager.get_entity("last_failed_command")
        if last_failed:
            context["last_failed_command"] = last_failed.get("value", "")
        
        return context

# Global instance
completion_handler = CompletionHandler()
</file>

<file path="angela/shell/inline_feedback.py">
# angela/shell/inline_feedback.py

"""
Inline feedback and interaction system for Angela CLI.
"""
import sys
import os
import asyncio
from typing import Dict, Any, List, Optional, Callable, Awaitable
import time
import threading

from angela.utils.logging import get_logger
from angela.context.session import session_manager

logger = get_logger(__name__)

class InlineFeedback:
    """
    Provides inline feedback and interaction capabilities.
    
    This class allows Angela to display feedback, ask questions, and
    interact with the user directly within the terminal session.
    """
    
    def __init__(self):
        """Initialize the inline feedback system."""
        self._logger = logger
        self._active_prompts = {}
        self._last_message_time = 0
        self._message_cooldown = 5  # Seconds between automatic messages
        self._prompt_id_counter = 0
        self._active_threads = {}
        self._active_messages = {}  # Track messages that might need to be cleared
    
    async def show_message(
        self, 
        message: str, 
        message_type: str = "info",
        timeout: float = 0
    ) -> None:
        """
        Display a message inline in the terminal.
        
        Args:
            message: The message to display
            message_type: Type of message (info, warning, error, success)
            timeout: Auto-clear message after this many seconds (0 = no auto-clear)
        """
        # Respect cooldown for automatic messages
        current_time = time.time()
        if current_time - self._last_message_time < self._message_cooldown:
            self._logger.debug(f"Skipping message due to cooldown: {message}")
            return
        
        self._last_message_time = current_time
        
        # Determine color based on message type
        color_code = {
            "info": "\033[34m",     # Blue
            "warning": "\033[33m",  # Yellow
            "error": "\033[31m",    # Red
            "success": "\033[32m",  # Green
        }.get(message_type, "\033[34m")  # Default to blue
        
        reset_code = "\033[0m"
        
        # Format the message
        formatted_message = f"\n{color_code}[Angela] {message}{reset_code}"
        
        # Generate a unique message ID
        message_id = str(time.time())
        self._active_messages[message_id] = formatted_message
        
        # Print the message
        print(formatted_message, file=sys.stderr)
        
        # Set up auto-clear if timeout is specified
        if timeout > 0:
            # Schedule message clear after timeout
            asyncio.create_task(self._clear_message_after_timeout(message_id, timeout))
    
    async def ask_question(
        self, 
        question: str,
        options: List[str],
        default_option: Optional[str] = None,
        timeout: int = 30,
        callback: Optional[Callable[[str], Awaitable[None]]] = None
    ) -> str:
        """
        Ask a question inline and wait for response.
        
        Args:
            question: The question to ask
            options: List of possible answers
            default_option: Default option to use if user doesn't respond
            timeout: Timeout in seconds before using default
            callback: Optional callback to call with the selected option
            
        Returns:
            The selected option
        """
        prompt_id = self._get_next_prompt_id()
        
        # Format options display
        options_display = "/".join(options)
        if default_option and default_option in options:
            # Highlight default option
            options_display = options_display.replace(
                default_option, 
                f"[{default_option}]"
            )
        
        # Format the question
        formatted_question = f"\n\033[35m[Angela] {question} ({options_display})\033[0m "
        
        # Store active prompt
        self._active_prompts[prompt_id] = {
            "question": question,
            "options": options,
            "default": default_option,
            "result": asyncio.Future(),
            "formatted_question": formatted_question
        }
        
        # Start a thread to handle user input
        thread = threading.Thread(
            target=self._input_thread,
            args=(prompt_id, formatted_question, options, default_option, timeout)
        )
        thread.daemon = True
        thread.start()
        
        self._active_threads[prompt_id] = thread
        
        try:
            # Wait for the result
            result = await self._active_prompts[prompt_id]["result"]
            
            # Call the callback if provided
            if callback and result:
                await callback(result)
            
            return result
        finally:
            # Clean up
            if prompt_id in self._active_prompts:
                del self._active_prompts[prompt_id]
            if prompt_id in self._active_threads:
                del self._active_threads[prompt_id]
    
    async def suggest_command(
        self, 
        command: str,
        explanation: str,
        confidence: float = 0.8,
        execute_callback: Optional[Callable[[], Awaitable[None]]] = None
    ) -> bool:
        """
        Suggest a command and offer to execute it.
        
        Args:
            command: The command to suggest
            explanation: Explanation for the suggestion
            confidence: Confidence level (0.0-1.0)
            execute_callback: Callback to execute if accepted
            
        Returns:
            True if the suggestion was accepted, False otherwise
        """
        # Format confidence indicator
        confidence_stars = int(confidence * 5)
        confidence_display = "★" * confidence_stars + "☆" * (5 - confidence_stars)
        
        # Format the message
        message = (
            f"I suggest this command: \033[1m{command}\033[0m\n"
            f"Confidence: {confidence_display} ({confidence:.2f})\n"
            f"{explanation}\n"
            f"Execute? (y/n/e - where 'e' will edit before executing)"
        )
        
        # Ask the question
        response = await self.ask_question(
            message,
            ["y", "n", "e"],
            default_option="n",
            timeout=30
        )
        
        if response == "y":
            # User accepted the suggestion
            if execute_callback:
                await execute_callback()
            return True
        elif response == "e":
            # User wants to edit before executing
            edited_command = await self._get_edited_command(command)
            if edited_command and execute_callback:
                # Store the edited command for execution
                session_manager.add_entity("edited_command", "command", edited_command)
                await execute_callback()
                return True
        
        # User declined or edited but didn't execute
        return False
    
    async def _get_edited_command(self, original_command: str) -> Optional[str]:
        """
        Allow the user to edit a command using prompt_toolkit.
        
        Args:
            original_command: The original command
            
        Returns:
            The edited command or None if cancelled
        """
        try:
            # Try to import prompt_toolkit for enhanced editing
            try:
                from prompt_toolkit import prompt
                from prompt_toolkit.history import InMemoryHistory
                from prompt_toolkit.auto_suggest import AutoSuggestFromHistory
                from prompt_toolkit.formatted_text import HTML
                from prompt_toolkit.key_binding import KeyBindings
                
                # Create key bindings for special keys
                kb = KeyBindings()
                
                @kb.add('escape')
                def _(event):
                    """Exit on Escape key."""
                    event.app.exit(result=None)
                
                # Create history and add the original command
                history = InMemoryHistory()
                history.append_string(original_command)
                
                # Create a future for the result
                input_future = asyncio.Future()
                
                def get_input():
                    try:
                        # Use prompt_toolkit for enhanced editing
                        result = prompt(
                            HTML("<ansiblue>Edit the command: </ansiblue>"),
                            default=original_command,
                            history=history,
                            auto_suggest=AutoSuggestFromHistory(),
                            key_bindings=kb,
                            enable_history_search=True,
                            enable_system_prompt=True,
                            enable_suspend=True,
                            mouse_support=True
                        )
                        # Set the future result
                        asyncio.run(self._set_future_result(input_future, result))
                    except (KeyboardInterrupt, EOFError):
                        # Cancel on Ctrl+C or Ctrl+D
                        asyncio.run(self._set_future_result(input_future, None))
                
                # Run the prompt in a separate thread to avoid blocking
                thread = threading.Thread(target=get_input)
                thread.daemon = True
                thread.start()
                
                # Wait for input with a timeout
                return await asyncio.wait_for(input_future, timeout=60)
                
            except ImportError:
                # Fall back to basic input if prompt_toolkit is not available
                self._logger.warning("prompt_toolkit not available, using basic input")
                raise ImportError("prompt_toolkit not available")
                
        except ImportError:
            # Use basic input as fallback
            print(f"\n\033[36m[Angela] Edit the command (Ctrl+C to cancel):\033[0m", file=sys.stderr)
            print(f"\033[36m> \033[1m{original_command}\033[0m", file=sys.stderr)
            
            try:
                # Start a thread to get user input
                input_future = asyncio.Future()
                
                def get_basic_input():
                    try:
                        user_input = input("\033[36m> \033[0m")
                        asyncio.run(self._set_future_result(input_future, user_input))
                    except (KeyboardInterrupt, EOFError):
                        asyncio.run(self._set_future_result(input_future, None))
                
                thread = threading.Thread(target=get_basic_input)
                thread.daemon = True
                thread.start()
                
                # Wait for input with a timeout
                return await asyncio.wait_for(input_future, timeout=60)
                
            except asyncio.TimeoutError:
                print("\n\033[33m[Angela] Edit timed out\033[0m", file=sys.stderr)
                return None
        except Exception as e:
            self._logger.error(f"Error in command editor: {str(e)}")
            return None
    
    async def _set_future_result(self, future, result):
        """Set the result of a future, handling event loop issues."""
        if not future.done():
            future.set_result(result)
    
    def _input_thread(
        self, 
        prompt_id: int,
        formatted_question: str,
        options: List[str],
        default_option: Optional[str],
        timeout: int
    ) -> None:
        """
        Thread function to handle user input for a prompt.
        
        Args:
            prompt_id: ID of the prompt
            formatted_question: Formatted question to display
            options: Valid response options
            default_option: Default option
            timeout: Timeout in seconds
        """
        print(formatted_question, end="", file=sys.stderr)
        sys.stderr.flush()
        
        result = default_option
        
        try:
            # Use select to implement timeout on Unix systems
            if os.name == "posix":
                import select
                
                # Check if input is available
                i, o, e = select.select([sys.stdin], [], [], timeout)
                
                if i:
                    # Input is available
                    user_input = sys.stdin.readline().strip().lower()
                    
                    if user_input in options:
                        result = user_input
                    elif user_input == "" and default_option:
                        result = default_option
            else:
                # Fallback for non-Unix systems
                user_input = input().strip().lower()
                
                if user_input in options:
                    result = user_input
                elif user_input == "" and default_option:
                    result = default_option
                
        except (KeyboardInterrupt, EOFError):
            # User cancelled, use default
            pass
        except Exception as e:
            self._logger.error(f"Error in input thread: {str(e)}")
        
        # Set the result in the future
        if prompt_id in self._active_prompts:
            future = self._active_prompts[prompt_id]["result"]
            if not future.done():
                asyncio.run(self._set_future_result(future, result))
    
    async def _clear_message_after_timeout(self, message_id: str, timeout: float) -> None:
        """
        Clear a message after a timeout.
        
        Args:
            message_id: ID of the message to clear
            timeout: Timeout in seconds
        """
        await asyncio.sleep(timeout)
        
        if message_id not in self._active_messages:
            return
            
        message = self._active_messages[message_id]
        
        try:
            # Calculate the number of lines in the message
            lines = message.count('\n') + 1
            
            # ANSI escape sequence to move cursor up and clear lines
            up_sequence = f"\033[{lines}A"  # Move cursor up
            clear_sequence = "\033[K"  # Clear to end of line
            
            # Move up and clear each line
            clear_command = up_sequence
            for _ in range(lines):
                clear_command += clear_sequence + "\033[1B"  # Clear line and move down
            
            # Move back up after clearing
            clear_command += f"\033[{lines}A"
            
            # Write the clear sequence to stderr (where we wrote the message)
            sys.stderr.write(clear_command)
            sys.stderr.flush()
            
            # Remove from active messages
            del self._active_messages[message_id]
            
            self._logger.debug(f"Cleared message after timeout: {message_id}")
            
        except Exception as e:
            self._logger.error(f"Error clearing message: {str(e)}")
    
    def _get_next_prompt_id(self) -> int:
        """
        Get the next prompt ID.
        
        Returns:
            A unique prompt ID
        """
        self._prompt_id_counter += 1
        return self._prompt_id_counter

# Global instance
inline_feedback = InlineFeedback()
</file>

<file path="angela/toolchain/__init__.py">
# angela/toolchain/__init__.py
"""
Toolchain components for Angela CLI.
"""
</file>

<file path="angela/utils/enhanced_logging.py">
# angela/utils/enhanced_logging.py
import json
import inspect
import logging
import traceback
from datetime import datetime
from typing import Dict, Any, Optional, Union

class EnhancedLogger:
    """Enhanced logger with context tracking and structured output."""
    
    def __init__(self, name: str):
        self._logger = logging.getLogger(name)
        self._context: Dict[str, Any] = {}
    
    def add_context(self, key: str, value: Any) -> None:
        """Add context information for subsequent log messages."""
        self._context[key] = value
    
    def remove_context(self, key: str) -> None:
        """Remove context information."""
        if key in self._context:
            del self._context[key]
    
    def clear_context(self) -> None:
        """Clear all context information."""
        self._context.clear()
    
    def with_context(self, **context) -> 'EnhancedLogger':
        """Create a new logger with added context."""
        new_logger = EnhancedLogger(self._logger.name)
        new_logger._context = {**self._context, **context}
        return new_logger
    
    def _format_message(self, msg: str, extra: Optional[Dict[str, Any]] = None) -> str:
        """Format message with context information."""
        # Get caller info
        frame = inspect.currentframe().f_back.f_back
        func_name = frame.f_code.co_name
        filename = frame.f_code.co_filename.split('/')[-1]
        lineno = frame.f_lineno
        
        # Combine contexts
        context = {**self._context}
        if extra:
            context.update(extra)
        
        # Create structured log
        log_data = {
            "timestamp": datetime.now().isoformat(),
            "message": msg,
            "context": context,
            "caller": f"{filename}:{func_name}:{lineno}"
        }
        
        return json.dumps(log_data)
    
    def debug(self, msg: str, *args, **kwargs) -> None:
        """Log a debug message with context."""
        extra = kwargs.pop("extra", {})
        self._logger.debug(self._format_message(msg, extra), *args, **kwargs)
    
    def info(self, msg: str, *args, **kwargs) -> None:
        """Log an info message with context."""
        extra = kwargs.pop("extra", {})
        self._logger.info(self._format_message(msg, extra), *args, **kwargs)
    
    def warning(self, msg: str, *args, **kwargs) -> None:
        """Log a warning message with context."""
        extra = kwargs.pop("extra", {})
        self._logger.warning(self._format_message(msg, extra), *args, **kwargs)
    
    def error(self, msg: str, *args, **kwargs) -> None:
        """Log an error message with context."""
        extra = kwargs.pop("extra", {})
        self._logger.error(self._format_message(msg, extra), *args, **kwargs)
    
    def critical(self, msg: str, *args, **kwargs) -> None:
        """Log a critical message with context."""
        extra = kwargs.pop("extra", {})
        self._logger.critical(self._format_message(msg, extra), *args, **kwargs)
    
    def exception(self, msg: str, exc_info: Union[bool, BaseException] = True, 
                 *args, **kwargs) -> None:
        """Log an exception with context."""
        extra = kwargs.pop("extra", {})
        # Add exception info to context
        if exc_info:
            if isinstance(exc_info, BaseException):
                exc_type = type(exc_info).__name__
                exc_message = str(exc_info)
            else:
                exc_info = sys.exc_info()
                exc_type = exc_info[0].__name__ if exc_info[0] else "Unknown"
                exc_message = str(exc_info[1]) if exc_info[1] else ""
            
            exception_context = {
                "exception_type": exc_type,
                "exception_message": exc_message,
                "traceback": traceback.format_exc()
            }
            if not extra:
                extra = {}
            extra["exception"] = exception_context
            
        self._logger.exception(self._format_message(msg, extra), *args, **kwargs)
    
    def log(self, level: int, msg: str, *args, **kwargs) -> None:
        """Log a message with the specified level."""
        extra = kwargs.pop("extra", {})
        self._logger.log(level, self._format_message(msg, extra), *args, **kwargs)

    @property
    def name(self) -> str:
        """Get the logger name."""
        return self._logger.name
    
    @property
    def level(self) -> int:
        """Get the logger level."""
        return self._logger.level
    
    @level.setter
    def level(self, level: int) -> None:
        """Set the logger level."""
        self._logger.setLevel(level)
</file>

<file path="angela/utils/logging.py">
# angela/utils/logging.py
"""
Logging configuration for Angela CLI.
"""
import sys
import logging
from pathlib import Path

from loguru import logger
from angela.constants import LOG_DIR, LOG_FORMAT, LOG_ROTATION, LOG_RETENTION
from angela.utils.enhanced_logging import EnhancedLogger

# Dictionary to store enhanced logger instances
_enhanced_loggers = {}

def setup_logging(debug: bool = False) -> None:
    """
    Configure the application logging.
    
    Args:
        debug: Whether to enable debug logging.
    """
    # Ensure log directory exists
    LOG_DIR.mkdir(parents=True, exist_ok=True)
    
    # Remove default handlers
    logger.remove()
    
    # Add console handler with appropriate level
    log_level = "DEBUG" if debug else "INFO"
    logger.add(
        sys.stderr,
        format=LOG_FORMAT,
        level=log_level,
        diagnose=debug,  # Include variable values in traceback if debug is True
    )
    
    # Add file handler
    log_file = LOG_DIR / "angela.log"
    logger.add(
        log_file,
        format=LOG_FORMAT,
        level="INFO",
        rotation=LOG_ROTATION,
        retention=LOG_RETENTION,
        compression="zip",
    )
    
    # Add structured JSON log file
    json_log_file = LOG_DIR / "angela_structured.log"
    logger.add(
        json_log_file,
        serialize=True,  # Output as JSON
        level="INFO",
        rotation=LOG_ROTATION,
        retention=LOG_RETENTION,
        compression="zip",
    )
    
    logger.debug(f"Logging initialized. Log files: {log_file}, {json_log_file}")


def get_logger(name: str = "angela") -> EnhancedLogger:
    """
    Get a logger instance with the given name.
    
    Args:
        name: The name for the logger.
        
    Returns:
        An enhanced logger instance.
    """
    # Check if we already have an enhanced logger for this name
    if name in _enhanced_loggers:
        return _enhanced_loggers[name]
    
    # Create a new enhanced logger
    enhanced_logger = EnhancedLogger(name)
    _enhanced_loggers[name] = enhanced_logger
    
    return enhanced_logger
</file>

<file path="angela/__main__.py">
# angela/__main__.py 
"""
Entry point for Angela CLI.
"""
from angela.cli import app
from angela import init_application

if __name__ == "__main__":
    # Initialize all application components
    init_application()
    
    # Start the CLI application
    app()
</file>

<file path="angela/config.py">
"""
Configuration management for Angela CLI.
Uses TOML format for configuration files.
"""
import os
import json # Keep json import for potential debugging or other uses if needed
from pathlib import Path
from typing import Dict, Any, Optional
import sys

# --- TOML Library Handling ---

# Reader (tomllib for >= 3.11, tomli for < 3.11)
if sys.version_info >= (3, 11):
    import tomllib
    _TOML_LOAD_AVAILABLE = True
    _TOML_READ_ERROR_TYPE = tomllib.TOMLDecodeError
else:
    try:
        import tomli as tomllib # Alias tomli as tomllib
        _TOML_LOAD_AVAILABLE = True
        _TOML_READ_ERROR_TYPE = tomllib.TOMLDecodeError
    except ImportError:
        tomllib = None
        _TOML_LOAD_AVAILABLE = False
        _TOML_READ_ERROR_TYPE = Exception # Fallback

# Writer (tomli-w)
try:
    import tomli_w
    _TOML_WRITE_AVAILABLE = True
except ImportError:
    tomli_w = None
    _TOML_WRITE_AVAILABLE = False

# --- Pydantic and Environment Handling ---
from pydantic import BaseModel, Field
from dotenv import load_dotenv

from angela.constants import CONFIG_DIR, CONFIG_FILE


# --- Configuration Models ---

class ApiConfig(BaseModel):
    """API configuration settings."""
    gemini_api_key: Optional[str] = Field(None, description="Google Gemini API Key")


class UserConfig(BaseModel):
    """User-specific configuration settings."""
    default_project_root: Optional[Path] = Field(None, description="Default project root directory")
    confirm_all_actions: bool = Field(False, description="Whether to confirm all actions regardless of risk level")


class AppConfig(BaseModel):
    """Application configuration settings."""
    api: ApiConfig = Field(default_factory=ApiConfig, description="API configuration")
    user: UserConfig = Field(default_factory=UserConfig, description="User configuration")
    debug: bool = Field(False, description="Enable debug mode")


# --- Configuration Manager ---

class ConfigManager:
    """Manages the configuration for the Angela CLI application using TOML."""

    def __init__(self):
        """Initializes the ConfigManager with default settings."""
        self._config: AppConfig = AppConfig()
        self._load_environment()
        self._ensure_config_dir()
        # Note: Loading from file happens via the global instance later

    def _load_environment(self) -> None:
        """Loads API keys from environment variables and .env file."""
        load_dotenv() # Load .env file if present
        gemini_api_key = os.getenv("GEMINI_API_KEY")
        if gemini_api_key:
            self._config.api.gemini_api_key = gemini_api_key
            # Add other environment variable loadings here if needed

    def _ensure_config_dir(self) -> None:
        """Ensures the application's configuration directory exists."""
        try:
            CONFIG_DIR.mkdir(parents=True, exist_ok=True)
        except OSError as e:
            print(f"Error creating configuration directory {CONFIG_DIR}: {e}")
            # Depending on severity, might want to raise or exit here

    def load_config(self) -> None:
        """Loads configuration from the TOML config file."""
        if not CONFIG_FILE.exists():
            print(f"Configuration file not found at '{CONFIG_FILE}'. Saving default configuration.")
            self.save_config() # Save default TOML config
            return

        if not _TOML_LOAD_AVAILABLE:
            print(f"Warning: Cannot load TOML config file '{CONFIG_FILE}'.")
            if sys.version_info < (3, 11):
                print("       Reason: 'tomli' package is not installed for this Python version.")
                print("       To fix, ensure 'tomli; python_version < \"3.11\"' is in your dependencies.")
            else:
                 print("       Reason: Could not import the built-in 'tomllib' module.") # Should be unlikely
            print("       Using default configuration and environment variables.")
            return

        try:
            print(f"Loading configuration from: {CONFIG_FILE}") # Debugging info
            with open(CONFIG_FILE, "rb") as f: # TOML requires binary read mode
                config_data = tomllib.load(f)

            # Update configuration with loaded data, using Pydantic validation
            if "api" in config_data and isinstance(config_data["api"], dict):
                self._config.api = ApiConfig(**config_data["api"])

            if "user" in config_data and isinstance(config_data["user"], dict):
                 # Pydantic will handle Path conversion from string during validation
                 self._config.user = UserConfig(**config_data["user"])

            if "debug" in config_data:
                # Explicitly check type for robustness
                if isinstance(config_data["debug"], bool):
                     self._config.debug = config_data["debug"]
                else:
                     print(f"Warning: Invalid type for 'debug' in {CONFIG_FILE}. Expected boolean, got {type(config_data['debug'])}. Ignoring.")

        except _TOML_READ_ERROR_TYPE as e:
             print(f"Error decoding TOML configuration file ({CONFIG_FILE}): {e}")
             print("       Please check the file syntax. Using default configuration and environment variables.")
             print("       Resetting configuration to default.")
             self._config = AppConfig()
             self._load_environment()
        except Exception as e:
            print(f"Unexpected error loading configuration from {CONFIG_FILE}: {e}")
            print("       Using default configuration and environment variables.")
            print("       Resetting configuration to default.")
            self._config = AppConfig()
            self._load_environment()


    def save_config(self) -> None:
        """Saves the current configuration to the config file (as TOML)."""
        if not _TOML_WRITE_AVAILABLE:
             print(f"Error: Cannot save TOML config. 'tomli-w' package not installed.")
             print(f"       To fix, add 'tomli-w' to your dependencies and reinstall.")
             print(f"       Skipping save to {CONFIG_FILE}.")
             return

        try:
            # Convert Pydantic model to dict.
            # Need to handle Path object manually for TOML serialization.
            config_dict = self._config.model_dump()
            if config_dict.get("user", {}).get("default_project_root"):
               # Convert Path to string if it exists
               config_dict["user"]["default_project_root"] = str(config_dict["user"]["default_project_root"])

            # Ensure parent directory exists (usually handled by _ensure_config_dir)
            CONFIG_FILE.parent.mkdir(parents=True, exist_ok=True)

            # Write to file using tomli_w in binary write mode
            with open(CONFIG_FILE, "wb") as f:
                tomli_w.dump(config_dict, f)
            print(f"Configuration saved successfully to {CONFIG_FILE}") # Confirmation message

        except Exception as e:
            print(f"Error saving TOML configuration to {CONFIG_FILE}: {e}")
            # Consider more specific error handling if needed


    @property
    def config(self) -> AppConfig:
        """Provides read-only access to the current application configuration."""
        return self._config


# --- Global Instance ---

# Create a single, globally accessible instance of the ConfigManager
config_manager = ConfigManager()

# Load the configuration from file immediately when this module is imported.
# This makes the loaded config available to other modules that import config_manager.
config_manager.load_config()
</file>

<file path="angela/constants.py">
"""
Constants for the Angela CLI application.
"""
from pathlib import Path
import os

# Application information
APP_NAME = "angela-cli"
APP_VERSION = "0.1.0"
APP_DESCRIPTION = "AI-powered command-line assistant integrated into your terminal shell"

# Paths
BASE_DIR = Path(__file__).parent.parent.absolute()
CONFIG_DIR = Path(os.path.expanduser("~/.config/angela"))
CONFIG_FILE = CONFIG_DIR / "config.toml"
LOG_DIR = CONFIG_DIR / "logs"
HISTORY_FILE = CONFIG_DIR / "history.json"

# Shell integration
SHELL_INVOKE_COMMAND = "angela"
BASH_INTEGRATION_PATH = BASE_DIR / "shell" / "angela.bash"
ZSH_INTEGRATION_PATH = BASE_DIR / "shell" / "angela.zsh"

# Project markers for detection
PROJECT_MARKERS = [
    ".git",               # Git repository
    "package.json",       # Node.js project
    "requirements.txt",   # Python project
    "Cargo.toml",         # Rust project
    "pom.xml",            # Maven project
    "build.gradle",       # Gradle project
    "Dockerfile",         # Docker project
    "docker-compose.yml", # Docker Compose project
    "CMakeLists.txt",     # CMake project
    "Makefile",           # Make project
]

# Logging
LOG_FORMAT = "{time:YYYY-MM-DD HH:mm:ss} | {level} | {message}"
LOG_ROTATION = "100 MB"
LOG_RETENTION = "10 days"

# API
GEMINI_MODEL = "gemini-2.5-pro-exp-03-25"
GEMINI_MAX_TOKENS = 4000
GEMINI_TEMPERATURE = 0.2
REQUEST_TIMEOUT = 45  # seconds

# Safety
RISK_LEVELS = {
    "SAFE": 0,            # Reading operations, info commands
    "LOW": 1,             # Directory creation, simple file operations
    "MEDIUM": 2,          # File content changes, non-critical configurations
    "HIGH": 3,            # System configuration, package installation
    "CRITICAL": 4,        # Destructive operations, security-sensitive changes
}

# Default confirmation requirements by risk level
DEFAULT_CONFIRMATION_REQUIREMENTS = {
    0: False,  # SAFE: No confirmation needed
    1: False,  # LOW: No confirmation needed
    2: True,   # MEDIUM: Confirmation needed
    3: True,   # HIGH: Confirmation needed
    4: True,   # CRITICAL: Confirmation needed with warning
}
</file>

<file path="MD/Next-Steps.md">
**Phase 8: Seamless Shell Integration & Enhanced Interaction**

*   **Goal:** Make Angela feel like an intrinsic part of the shell, blurring the lines between standard commands and AI interactions. Improve the core user experience for invoking and interacting with Angela.
*   **Key Objectives:**
    *   **Advanced Shell Hooking:** Investigate and implement deeper shell integration beyond simple aliases. Explore options like:
        *   Zsh/Bash plugins for more sophisticated input interception or pre-command hooks.
        *   Potential integration with terminal multiplexers (like tmux or Zellij) if feasible.
        *   Using `PROMPT_COMMAND` (Bash) or `precmd`/`preexec` (Zsh) hooks for contextual awareness *before* a command is run or *after* it finishes.
    *   **Natural Invocation:** Design mechanisms where Angela can be invoked more naturally, perhaps even implicitly based on command patterns or specific keywords within a command line, rather than always requiring the `angela` prefix. (e.g., detecting `git commit -m "refactor login logic based on ticket #123"` and offering AI assistance).
    *   **Inline Feedback & Interaction:** Enhance `shell/formatter.py` to allow Angela to provide feedback or ask clarifying questions *inline* within the terminal session, potentially modifying the current command line or presenting interactive prompts without breaking the user's flow entirely.
    *   **Contextual Auto-Completion:** Develop AI-powered auto-completion suggestions that leverage Angela's understanding of the project context, recent files, and user intent.

**Phase 9: Deep Contextual Understanding & Semantic Awareness**

*   **Goal:** Elevate Angela's understanding from file paths and types to the *semantic meaning* of code, project state, and complex user intentions.
*   **Key Objectives:**
    *   **Code Semantic Analysis:** Integrate more advanced static analysis tools (like tree-sitter or language servers) or leverage the LLM's code understanding capabilities more deeply to parse functions, classes, dependencies within code files.
    *   **Project State Inference:** Move beyond basic type detection. Infer the *state* of the project (e.g., current Git branch status, pending migrations, test coverage status, build health).
    *   **Fine-Grained Activity Tracking:** Enhance `context/file_activity.py` to track not just file access, but potentially specific function/class modifications (might require IDE integration or file watching with parsing).
    *   **Advanced Intent Decomposition:** Improve `intent/enhanced_task_planner.py` to handle more ambiguous, multi-stage goals. Develop strategies for the LLM to ask clarifying questions when decomposition is uncertain.
    *   **Contextual Prompting V2:** Refine `ai/prompts.py` to feed semantic code information, detailed project state, and nuanced user history to the LLM for significantly more informed responses.

**Phase 10: Expanded Ecosystem Integration (Core Developer Tools)**

*   **Goal:** Enable Angela to understand and interact with a wider range of essential developer tools beyond basic Git and package managers.
*   **Key Objectives:**
    *   **Docker Integration:** Implement understanding and execution of common Docker commands (`build`, `run`, `ps`, `logs`, `stop`, `rm`). Allow requests like "Angela, show me the logs for the webserver container" or "Rebuild the backend Docker image". Requires specific command generation logic and potentially parsing Docker output.
  
    *   **Toolchain Module Enhancement:** Refactor and expand `angela/toolchain/` to include dedicated modules for Docker, abstracting the interaction logic.

**Phase 11: Autonomous Multi-File Code Generation & Refinement**

*   **Goal:** Enable Angela to generate and modify entire multi-file codebases based on high-level descriptions, including interactive refinement.
*   **Key Objectives:**
    *   **Multi-File Planning:** Enhance `generation/planner.py` and `generation/architecture.py` to plan complex directory structures and inter-file dependencies for larger projects (e.g., full web applications).
    *   **Coherent Code Generation:** Improve `generation/engine.py` to generate consistent code across multiple files, ensuring imports, function calls, and data structures align. This likely involves iterative generation and passing context between file generation steps.
    *   **Massive Context Handling:** Implement strategies (e.g., RAG with code context, summarization, iterative prompting) to manage the large context required for generating substantial codebases with the LLM.
    *   **Interactive Refinement Loop:** Integrate `review/feedback.py` and `review/diff_manager.py` more deeply. After generation, present a summary/diff to the user and allow natural language feedback (e.g., "Change the database model to include an email field", "Use functional components instead of class components in React") to trigger regeneration/modification cycles.
    *   **Framework Specialization:** Enhance `generation/frameworks.py` to support generating more complete and idiomatic code for the specific frameworks detected in Phase 9/10.

**Phase 12: Advanced Orchestration & Universal Tool Translation**

*   **Goal:** Achieve near-AGI capability within the terminal by enabling complex task orchestration across *any* CLI tool and automating full CI/CD pipelines.
*   **Key Objectives:**
    *   **Universal CLI Translator:** Develop a robust mechanism (likely LLM-driven with sophisticated prompting and validation) to translate natural language requests into commands for *arbitrary* CLI tools, leveraging `--help` output, man pages, or general knowledge. This requires strong safety validation (`safety/validator.py`).
    *   **Complex Workflow Orchestration:** Enhance the `Orchestrator` and `EnhancedTaskPlanner` to handle workflows involving sequences of commands across different tools (e.g., Git -> Docker -> Cloud CLI -> kubectl).
    *   **Automated CI/CD Pipeline Execution:** Integrate `toolchain/ci_cd.py` fully. Allow requests like "Set up a full CI/CD pipeline for this Node.js project on GitHub Actions, including build, test, lint, and deploy to staging". This involves generating complex configuration *and* potentially triggering initial pipeline runs or setup commands.
    *   **Self-Correction & Learning:** Implement mechanisms for Angela to learn from failed commands or workflows, potentially attempting self-correction or refining its understanding of specific tools based on error messages and successful outcomes.
    *   **Proactive Assistance V2:** Enhance `monitoring/background.py` to offer more complex suggestions based on combined context (e.g., "Your tests failed after the last commit, want me to try reverting and rerunning?", "Your cloud deployment seems to be unhealthy, want me to check the logs?").

These 5 phases provide a structured approach to tackling the remaining challenges, moving from foundational UX improvements and deeper understanding towards complex actions and broad tool integration, culminating in the advanced orchestration required for the AGI-like vision.
</file>

<file path="scripts/install.sh">
#!/bin/bash
# Angela CLI Installation Script



# Check if we're running as root
if [ "$(id -u)" -eq 0 ]; then
    echo "Warning: Running as root. Installing system-wide."
    INSTALL_DIR="/usr/local/lib/angela"
    CONFIG_DIR="/etc/angela"
else
    echo "Installing for current user."
    INSTALL_DIR="$HOME/.local/lib/angela"
    CONFIG_DIR="$HOME/.config/angela"
fi

# Create directories
mkdir -p "$INSTALL_DIR"
mkdir -p "$CONFIG_DIR"
mkdir -p "$CONFIG_DIR/logs"

# Install Python package
echo "Installing Python package..."
pip install -e .

# Determine shell
current_shell="$(basename "$SHELL")"
echo "Detected shell: $current_shell"

# Enhanced integration for Bash
setup_bash() {
    echo "Setting up enhanced Bash integration..."
    
    bashrc="$HOME/.bashrc"
    
    # Check if angela is already in .bashrc
    if grep -q "angela_enhanced.bash" "$bashrc"; then
        echo "Enhanced Bash integration already installed."
    else
        # Remove old integration if present
        sed -i '/angela.bash/d' "$bashrc"
        
        # Add the enhanced integration
        cat << 'EOF' >> "$bashrc"

# Angela CLI Enhanced Integration
if [ -f "$HOME/.local/lib/angela/shell/angela_enhanced.bash" ]; then
    source "$HOME/.local/lib/angela/shell/angela_enhanced.bash"
fi
EOF
        echo "Enhanced Bash integration added to $bashrc"
    fi
    
    # Copy the enhanced shell script
    cp angela/shell/angela_enhanced.bash "$INSTALL_DIR/shell/"
    chmod +x "$INSTALL_DIR/shell/angela_enhanced.bash"
}

# Enhanced integration for Zsh
setup_zsh() {
    echo "Setting up enhanced Zsh integration..."
    
    zshrc="$HOME/.zshrc"
    
    # Check if angela is already in .zshrc
    if grep -q "angela_enhanced.zsh" "$zshrc"; then
        echo "Enhanced Zsh integration already installed."
    else
        # Remove old integration if present
        sed -i '/angela.zsh/d' "$zshrc"
        
        # Add the enhanced integration
        cat << 'EOF' >> "$zshrc"

# Angela CLI Enhanced Integration
if [ -f "$HOME/.local/lib/angela/shell/angela_enhanced.zsh" ]; then
    source "$HOME/.local/lib/angela/shell/angela_enhanced.zsh"
fi
EOF
        echo "Enhanced Zsh integration added to $zshrc"
    fi
    
    # Copy the enhanced shell script
    cp angela/shell/angela_enhanced.zsh "$INSTALL_DIR/shell/"
    chmod +x "$INSTALL_DIR/shell/angela_enhanced.zsh"
}

# Set up based on shell
case "$current_shell" in
    bash)
        setup_bash
        ;;
    zsh)
        setup_zsh
        ;;
    *)
        echo "Unsupported shell: $current_shell"
        echo "Only Bash and Zsh are currently supported."
        echo "Manual installation required."
        exit 1
        ;;
esac

# Copy shell scripts
echo "Setting up shell scripts..."
mkdir -p "$INSTALL_DIR/shell"
cp angela/shell/angela.bash "$INSTALL_DIR/shell/"
cp angela/shell/angela.zsh "$INSTALL_DIR/shell/"
chmod +x "$INSTALL_DIR/shell/angela.bash"
chmod +x "$INSTALL_DIR/shell/angela.zsh"

# Initialize Angela CLI
echo -e "${YELLOW}Initializing Angela CLI...${NC}"


echo
echo -e "${GREEN}╔════════════════════════════════════════╗${NC}"
echo -e "${GREEN}║    Angela CLI installed successfully!  ║${NC}"
echo -e "${GREEN}╚════════════════════════════════════════╝${NC}"
echo "Please restart your shell or run 'source ~/.${current_shell}rc' to complete the installation."
echo -e "You can now use Angela CLI by typing: ${BLUE}angela <your request>${NC}"
</file>

<file path="pyproject.toml">
[build-system]
requires = ["setuptools>=42", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "angela-cli"
version = "0.1.0"
description = "AI-powered command-line assistant integrated into your terminal shell"
readme = "README.md"
requires-python = ">=3.9"
license = {text = "MIT"}
authors = [
    {name = "Angela CLI Team"}
]
classifiers = [
    "Development Status :: 3 - Alpha",
    "Environment :: Console",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Topic :: Software Development :: Libraries :: Python Modules",
    "Topic :: Utilities",
]
dependencies = [
    "typer>=0.9.0",
    "rich>=13.4.2",
    "pydantic>=2.0.0",
    "click>=8.1.3",
    "pexpect>=4.8.0",
    "prompt_toolkit>=3.0.38",
    "python-dotenv>=1.0.0",
    "aiohttp>=3.8.5",
    "google-generativeai>=0.1.0",
    "loguru>=0.7.0",
    "tomli>=2.0.1; python_version < '3.11'",
    "tomli-w",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.3.1",
    "pytest-asyncio>=0.21.0",
    "black>=23.3.0",
    "isort>=5.12.0",
    "mypy>=1.3.0",
]

[project.scripts]
angela = "angela.__main__:app"

[tool.setuptools]
packages = ["angela"]

[tool.black]
line-length = 88
target-version = ["py39"]

[tool.isort]
profile = "black"
line_length = 88

[tool.mypy]
python_version = "3.9"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
disallow_incomplete_defs = true

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = "test_*.py"
</file>

<file path="angela/ai/client.py">
# angela/ai/client.py
import asyncio
from typing import Dict, Any, Optional

import google.generativeai as genai
from pydantic import BaseModel

from angela.config import config_manager
from angela.constants import GEMINI_MODEL, GEMINI_MAX_TOKENS, GEMINI_TEMPERATURE
from angela.utils.logging import get_logger

logger = get_logger(__name__)

class GeminiRequest(BaseModel):
    """Model for a request to the Gemini API."""
    prompt: str
    temperature: float = GEMINI_TEMPERATURE
    max_tokens: int = GEMINI_MAX_TOKENS
    
class GeminiResponse(BaseModel):
    """Model for a response from the Gemini API."""
    text: str
    generated_text: str
    raw_response: Dict[str, Any]

class GeminiClient:
    """Client for interacting with the Google Gemini API."""
    
    def __init__(self):
        """Initialize the Gemini API client."""
        self._setup_client()
        
    def _setup_client(self):
        """Set up the Gemini API client."""
        api_key = config_manager.config.api.gemini_api_key
        if not api_key:
            logger.error("Gemini API key is not configured.")
            raise ValueError("Gemini API key is not configured. Run 'angela init' to set it up.")
        
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel(GEMINI_MODEL)
        logger.debug(f"Gemini API client initialized with model: {GEMINI_MODEL}")
        
    # Update angela/ai/client.py
    async def generate_text(self, request: GeminiRequest) -> GeminiResponse:
        """Generate text using the Gemini API."""
        try:
            # Configure the generation configuration
            generation_config = genai.types.GenerationConfig(
                temperature=request.temperature,
                max_output_tokens=request.max_tokens,
            )
            
            # Call the Gemini API
            response = await asyncio.to_thread(
                self.model.generate_content,
                request.prompt,
                generation_config=generation_config,
            )
            
            # Process the response
            if not response.text:
                # Don't wrap this in a try/except - let it propagate directly
                raise ValueError("Empty response from Gemini API.")
            
            # Create a structured response - handle different response structures
            try:
                # Try to adapt to different response formats
                if hasattr(response, 'candidates') and response.candidates:
                    # Convert candidate to dict if possible
                    if hasattr(response.candidates[0], '__dict__'):
                        raw_response = response.candidates[0].__dict__
                    elif hasattr(response.candidates[0], 'to_dict'):
                        raw_response = response.candidates[0].to_dict()
                    else:
                        # Fallback - create a simple dict with text
                        raw_response = {"text": response.text}
                else:
                    # Fallback to a simpler format if candidates not available
                    raw_response = {"text": response.text}
                    
                result = GeminiResponse(
                    text=response.text,
                    generated_text=response.text,
                    raw_response=raw_response,
                )
            except Exception as format_error:
                logger.exception(f"Error formatting Gemini response: {str(format_error)}")
                # Even if formatting fails, still provide a valid response
                result = GeminiResponse(
                    text=response.text,
                    generated_text=response.text,
                    raw_response={"text": response.text},
                )
            
            logger.debug(f"Gemini API response received. Length: {len(result.text)}")
            return result
        
        except ValueError as ve:
            # Let ValueError propagate directly
            logger.exception(f"Gemini API returned empty response: {str(ve)}")
            raise
        except Exception as e:
            # Wrap other exceptions
            logger.exception(f"Error calling Gemini API: {str(e)}")
            raise RuntimeError(f"Failed to generate text with Gemini API: {str(e)}")

# Global client instance
gemini_client = GeminiClient()
</file>

<file path="angela/cli/generation.py">
# angela/cli/generation.py
"""
CLI interface for code generation features in Angela CLI.
"""
import os
import asyncio
from pathlib import Path
from typing import List, Optional, Tuple, Dict, Any
import typer
from rich.console import Console
from rich.panel import Panel
from rich.syntax import Syntax
from rich.table import Table
from rich import print as rich_print

from angela.utils.logging import get_logger
from angela.generation.engine import code_generation_engine
from angela.toolchain.git import git_integration
from angela.toolchain.package_managers import package_manager_integration
from angela.toolchain.test_frameworks import test_framework_integration
from angela.toolchain.ci_cd import ci_cd_integration
from angela.review.diff_manager import diff_manager
from angela.review.feedback import feedback_manager
from angela.context import context_manager

app = typer.Typer(help="Code generation commands")
console = Console()
logger = get_logger(__name__)

@app.command("create-project")
def create_project(
    description: str = typer.Argument(..., help="Description of the project to generate"),
    output_dir: str = typer.Option(".", help="Directory where the project should be generated"),
    project_type: Optional[str] = typer.Option(None, help="Project type (python, node, etc.)"),
    git_init: bool = typer.Option(True, help="Initialize Git repository"),
    install_deps: bool = typer.Option(False, help="Install dependencies"),
    generate_tests: bool = typer.Option(False, help="Generate test files"),
    ci_platform: Optional[str] = typer.Option(None, help="Generate CI configuration (github, gitlab, etc.)"),
    dry_run: bool = typer.Option(False, help="Preview without creating files")
):
    """
    Generate a complete project from a description.
    """
    console.print(Panel(
        f"[bold green]Generating project from description:[/bold green]\n{description}",
        title="Project Generation",
        expand=False
    ))
    
    try:
        # Get current context
        context = context_manager.get_context_dict()
        
        # Generate project plan
        project_plan = asyncio.run(code_generation_engine.generate_project(
            description=description,
            output_dir=output_dir,
            project_type=project_type,
            context=context
        ))
        
        # Display project plan
        console.print("\n[bold blue]Project Plan:[/bold blue]")
        console.print(f"Name: [bold]{project_plan.name}[/bold]")
        console.print(f"Type: [bold]{project_plan.project_type}[/bold]")
        console.print(f"Files: [bold]{len(project_plan.files)}[/bold]")
        
        # Show the list of files
        table = Table(title="Files to Generate")
        table.add_column("Path", style="cyan")
        table.add_column("Purpose", style="green")
        
        for file in project_plan.files:
            table.add_row(file.path, file.purpose)
        
        console.print(table)
        
        # Create the files if not dry run
        if not dry_run:
            console.print("\n[bold]Creating project files...[/bold]")
            
            with console.status("[bold green]Creating files...[/bold green]"):
                result = asyncio.run(code_generation_engine.create_project_files(project_plan))
            
            console.print(f"[green]Created {result['file_count']} files[/green]")
            
            # Initialize Git repository if requested
            if git_init:
                console.print("\n[bold]Initializing Git repository...[/bold]")
                
                with console.status("[bold green]Initializing Git...[/bold green]"):
                    git_result = asyncio.run(git_integration.init_repository(
                        path=output_dir,
                        initial_branch="main",
                        gitignore_template=project_plan.project_type
                    ))
                
                if git_result["success"]:
                    console.print("[green]Git repository initialized successfully[/green]")
                else:
                    console.print(f"[yellow]Failed to initialize Git repository: {git_result.get('error', 'Unknown error')}[/yellow]")
            
            # Install dependencies if requested
            if install_deps:
                console.print("\n[bold]Installing dependencies...[/bold]")
                
                with console.status("[bold green]Installing dependencies...[/bold green]"):
                    deps_result = asyncio.run(package_manager_integration.install_dependencies(
                        path=output_dir,
                        dependencies=project_plan.dependencies.get("runtime", []),
                        dev_dependencies=project_plan.dependencies.get("development", []),
                        project_type=project_plan.project_type
                    ))
                
                if deps_result["success"]:
                    console.print("[green]Dependencies installed successfully[/green]")
                else:
                    console.print(f"[yellow]Failed to install dependencies: {deps_result.get('error', 'Unknown error')}[/yellow]")
            
            # Generate test files if requested
            if generate_tests:
                console.print("\n[bold]Generating test files...[/bold]")
                
                with console.status("[bold green]Generating tests...[/bold green]"):
                    test_result = asyncio.run(test_framework_integration.generate_test_files(
                        src_files=project_plan.files,
                        project_type=project_plan.project_type,
                        root_dir=output_dir
                    ))
                
                if test_result["success"]:
                    console.print(f"[green]Generated {test_result['file_count']} test files[/green]")
                else:
                    console.print(f"[yellow]Failed to generate test files: {test_result.get('error', 'Unknown error')}[/yellow]")
            
            # Generate CI/CD configuration if requested
            if ci_platform:
                console.print("\n[bold]Generating CI/CD configuration...[/bold]")
                
                with console.status(f"[bold green]Generating {ci_platform} configuration...[/bold green]"):
                    ci_result = asyncio.run(ci_cd_integration.generate_ci_configuration(
                        path=output_dir,
                        platform=ci_platform,
                        project_type=project_plan.project_type
                    ))
                
                if ci_result["success"]:
                    console.print(f"[green]Generated {ci_platform} configuration successfully[/green]")
                else:
                    console.print(f"[yellow]Failed to generate CI/CD configuration: {ci_result.get('error', 'Unknown error')}[/yellow]")
            
            # Create initial commit if Git was initialized
            if git_init:
                console.print("\n[bold]Creating initial commit...[/bold]")
                
                with console.status("[bold green]Creating commit...[/bold green]"):
                    commit_result = asyncio.run(git_integration.commit_changes(
                        path=output_dir,
                        message="Initial project generation",
                        auto_stage=True
                    ))
                
                if commit_result["success"]:
                    console.print("[green]Created initial commit successfully[/green]")
                else:
                    console.print(f"[yellow]Failed to create initial commit: {commit_result.get('error', 'Unknown error')}[/yellow]")
            
            console.print(f"\n[bold green]Project generated successfully in: {output_dir}[/bold green]")
        else:
            console.print("\n[bold yellow]Dry run - no files were created[/bold yellow]")
    
    except Exception as e:
        logger.exception("Error generating project")
        console.print(f"[bold red]Error generating project:[/bold red] {str(e)}")

@app.command("add-feature")
def add_feature(
    description: str = typer.Argument(..., help="Description of the feature to add"),
    project_dir: str = typer.Option(".", help="Project directory"),
    branch: Optional[str] = typer.Option(None, help="Create a feature branch"),
    generate_tests: bool = typer.Option(False, help="Generate test files"),
    install_deps: bool = typer.Option(False, help="Install new dependencies"),
    dry_run: bool = typer.Option(False, help="Preview without creating files"),
    auto_commit: bool = typer.Option(False, help="Commit changes automatically")
):
    """
    Add a new feature to an existing project.
    """
    console.print(Panel(
        f"[bold green]Adding feature to project:[/bold green]\n{description}",
        title="Feature Addition",
        expand=False
    ))
    
    try:
        # Get current context
        context = context_manager.get_context_dict()
        context = asyncio.run(context_enhancer.enrich_context(context))
        
        # Check if project directory exists
        project_path = Path(project_dir)
        if not project_path.exists() or not project_path.is_dir():
            console.print(f"[bold red]Project directory does not exist: {project_dir}[/bold red]")
            return
        
        # Create a feature branch if requested
        if branch:
            console.print(f"\n[bold]Creating feature branch: {branch}[/bold]")
            
            if not dry_run:
                with console.status("[bold green]Creating branch...[/bold green]"):
                    branch_result = asyncio.run(git_integration.create_branch(
                        path=project_dir,
                        branch_name=branch,
                        checkout=True
                    ))
                
                if branch_result["success"]:
                    console.print(f"[green]Created and checked out branch: {branch}[/green]")
                else:
                    console.print(f"[yellow]Failed to create branch: {branch_result.get('error', 'Unknown error')}[/yellow]")
        
        # Get project info
        with console.status("[bold green]Analyzing project...[/bold green]"):
            # Detect project type
            project_type_result = asyncio.run(ci_cd_integration.detect_project_type(project_dir))
            project_type = project_type_result.get("project_type")
            
            if not project_type:
                console.print("[yellow]Could not detect project type. Proceeding anyway...[/yellow]")
            else:
                console.print(f"[green]Detected project type: {project_type}[/green]")
        
        # Generate feature implementation
        console.print("\n[bold]Generating feature implementation...[/bold]")
        
        with console.status("[bold green]Generating feature implementation...[/bold green]"):
            # Use the new feature addition method
            result = asyncio.run(code_generation_engine.add_feature_to_project(
                description=description,
                project_dir=project_dir,
                context=context
            ))
        
        if result["success"]:
            # Display results
            console.print(f"[green]Successfully added feature to project![/green]")
            
            if result.get("new_files"):
                console.print("\n[bold]Created Files:[/bold]")
                for file_path in result["new_files"]:
                    console.print(f"  ✅ {file_path}")
            
            if result.get("modified_files"):
                console.print("\n[bold]Modified Files:[/bold]")
                for file_path in result["modified_files"]:
                    console.print(f"  ✏️ {file_path}")
            
            # Generate tests if requested
            if generate_tests and not dry_run:
                console.print("\n[bold]Generating tests for new feature...[/bold]")
                
                with console.status("[bold green]Generating tests...[/bold green]"):
                    # Create a list of new files with CodeFile objects
                    src_files = []
                    for file_path in result.get("new_files", []):
                        try:
                            with open(file_path, 'r', encoding='utf-8', errors='replace') as f:
                                content = f.read()
                                
                            rel_path = str(Path(file_path).relative_to(project_dir))
                            src_files.append(CodeFile(
                                path=rel_path,
                                content=content,
                                purpose=f"New feature: {description}",
                                dependencies=[],
                                language=project_type
                            ))
                        except Exception as e:
                            console.print(f"[yellow]Error reading file {file_path}: {str(e)}[/yellow]")
                    
                    if src_files:
                        test_result = asyncio.run(test_framework_integration.generate_test_files(
                            src_files=src_files,
                            project_type=project_type,
                            root_dir=project_dir
                        ))
                        
                        if test_result["success"]:
                            console.print(f"[green]Generated {test_result['file_count']} test files[/green]")
                        else:
                            console.print(f"[yellow]Failed to generate test files: {test_result.get('error', 'Unknown error')}[/yellow]")
                    else:
                        console.print("[yellow]No source files available for test generation[/yellow]")
            
            # Install dependencies if requested
            if install_deps and not dry_run:
                console.print("\n[bold]Installing dependencies...[/bold]")
                
                with console.status("[bold green]Extracting and installing dependencies...[/bold green]"):
                    # Extract dependencies from the feature files
                    dependencies = await code_generation_engine._extract_dependencies_from_feature(
                        feature_files={
                            "new_files": [{"path": path, "content": open(path, 'r', encoding='utf-8', errors='replace').read()} 
                                          for path in result.get("new_files", []) if Path(path).exists()],
                            "modified_files": [{"path": path, 
                                               "original_content": "", # We don't need original content for dependency extraction
                                               "modified_content": open(path, 'r', encoding='utf-8', errors='replace').read()} 
                                              for path in result.get("modified_files", []) if Path(path).exists()]
                        },
                        project_type=project_type
                    )
                    
                    if not dependencies["runtime"] and not dependencies["development"]:
                        console.print("[yellow]No new dependencies detected in the feature.[/yellow]")
                    else:
                        # Install the detected dependencies
                        runtime_deps = dependencies.get("runtime", [])
                        dev_deps = dependencies.get("development", [])
                        
                        if runtime_deps:
                            console.print(f"[bold]Runtime dependencies to install:[/bold] {', '.join(runtime_deps)}")
                            install_result = await package_manager_integration.install_dependencies(
                                path=project_dir,
                                dependencies=runtime_deps,
                                project_type=project_type
                            )
                            
                            if install_result["success"]:
                                console.print(f"[green]Successfully installed runtime dependencies[/green]")
                            else:
                                console.print(f"[yellow]Failed to install runtime dependencies: {install_result.get('error', 'Unknown error')}[/yellow]")
                        
                        if dev_deps:
                            console.print(f"[bold]Development dependencies to install:[/bold] {', '.join(dev_deps)}")
                            dev_install_result = await package_manager_integration.install_dependencies(
                                path=project_dir,
                                dependencies=[],
                                dev_dependencies=dev_deps,
                                project_type=project_type
                            )
                            
                            if dev_install_result["success"]:
                                console.print(f"[green]Successfully installed development dependencies[/green]")
                            else:
                                console.print(f"[yellow]Failed to install development dependencies: {dev_install_result.get('error', 'Unknown error')}[/yellow]")
    
    except Exception as e:
        logger.exception("Error adding feature")
        console.print(f"[bold red]Error adding feature:[/bold red] {str(e)}")

@app.command("refine-code")
def refine_code(
    feedback: str = typer.Argument(..., help="Feedback for code improvement"),
    file_path: str = typer.Argument(..., help="Path to the file to refine"),
    apply: bool = typer.Option(False, help="Apply the changes"),
    backup: bool = typer.Option(True, help="Create backup before applying changes")
):
    """
    Refine code based on feedback.
    """
    console.print(Panel(
        f"[bold green]Refining code based on feedback:[/bold green]\n{feedback}",
        title="Code Refinement",
        expand=False
    ))
    
    try:
        # Get current context
        context = context_manager.get_context_dict()
        
        # Check if file exists
        file = Path(file_path)
        if not file.exists() or not file.is_file():
            console.print(f"[bold red]File does not exist: {file_path}[/bold red]")
            return
        
        # Read file content
        with open(file, 'r', encoding='utf-8', errors='replace') as f:
            original_code = f.read()
        
        # Process feedback
        console.print("\n[bold]Processing feedback...[/bold]")
        
        with console.status("[bold green]Generating improvements...[/bold green]"):
            result = asyncio.run(feedback_manager.process_feedback(
                feedback=feedback,
                original_code=original_code,
                file_path=str(file),
                context=context
            ))
        
        # Display diff
        console.print("\n[bold blue]Code changes:[/bold blue]")
        
        syntax = Syntax(
            result["diff"],
            "diff",
            theme="monokai",
            line_numbers=True,
            word_wrap=True
        )
        console.print(syntax)
        
        # Display explanation
        console.print("\n[bold blue]Explanation:[/bold blue]")
        console.print(result["explanation"])
        
        # Apply changes if requested
        if apply:
            console.print("\n[bold]Applying changes...[/bold]")
            
            refinements = {
                "project_dir": str(file.parent),
                "results": [
                    {
                        "file_path": file.name,
                        "has_changes": original_code != result["improved_code"],
                        "diff": result["diff"],
                        "explanation": result["explanation"]
                    }
                ]
            }
            
            with console.status("[bold green]Applying changes...[/bold green]"):
                apply_result = asyncio.run(feedback_manager.apply_refinements(
                    refinements=refinements,
                    backup=backup
                ))
            
            if apply_result["files_changed"] > 0:
                console.print("[green]Changes applied successfully[/green]")
                if backup:
                    backup_file = apply_result["results"][0].get("backup")
                    if backup_file:
                        console.print(f"[blue]Backup created: {backup_file}[/blue]")
            else:
                console.print("[yellow]No changes were applied[/yellow]")
        else:
            console.print("\n[bold yellow]Changes were not applied. Use --apply to apply changes.[/bold yellow]")
    
    except Exception as e:
        logger.exception("Error refining code")
        console.print(f"[bold red]Error refining code:[/bold red] {str(e)}")

@app.command("refine-project")
def refine_project(
    feedback: str = typer.Argument(..., help="Feedback for project improvement"),
    project_dir: str = typer.Option(".", help="Project directory"),
    focus: Optional[List[str]] = typer.Option(None, help="Files to focus on (glob patterns supported)"),
    apply: bool = typer.Option(False, help="Apply the changes"),
    backup: bool = typer.Option(True, help="Create backup before applying changes")
):
    """
    Refine an entire project based on feedback.
    """
    console.print(Panel(
        f"[bold green]Refining project based on feedback:[/bold green]\n{feedback}",
        title="Project Refinement",
        expand=False
    ))
    
    try:
        # Get current context
        context = context_manager.get_context_dict()
        
        # Check if project directory exists
        project_path = Path(project_dir)
        if not project_path.exists() or not project_path.is_dir():
            console.print(f"[bold red]Project directory does not exist: {project_dir}[/bold red]")
            return
        
        # Process feedback
        console.print("\n[bold]Processing feedback...[/bold]")
        
        with console.status("[bold green]Analyzing project and generating improvements...[/bold green]"):
            result = asyncio.run(feedback_manager.refine_project(
                project_dir=project_path,
                feedback=feedback,
                focus_files=focus,
                context=context
            ))
        
        # Display results
        console.print(f"\n[bold blue]Files analyzed: {len(result['results'])}[/bold blue]")
        
        # Create a table to show the changes
        table = Table(title="Refinement Results")
        table.add_column("File", style="cyan")
        table.add_column("Status", style="green")
        table.add_column("Changes", style="yellow")
        
        for file_result in result["results"]:
            file_path = file_result["file_path"]
            
            if "error" in file_result:
                status = "[red]Error[/red]"
                changes = file_result["error"]
            elif not file_result.get("has_changes", False):
                status = "[blue]No changes[/blue]"
                changes = "No changes needed"
            else:
                status = "[green]Changes pending[/green]"
                diff_lines = file_result["diff"].splitlines()
                additions = sum(1 for line in diff_lines if line.startswith('+') and not line.startswith('+++'))
                deletions = sum(1 for line in diff_lines if line.startswith('-') and not line.startswith('---'))
                changes = f"+{additions} -{deletions}"
            
            table.add_row(file_path, status, changes)
        
        console.print(table)
        
        # Show details for files with changes
        changed_files = [r for r in result["results"] if r.get("has_changes", False)]
        if changed_files:
            console.print(f"\n[bold blue]Files with changes ({len(changed_files)}):[/bold blue]")
            
            for file_result in changed_files:
                console.print(f"\n[bold cyan]File: {file_result['file_path']}[/bold cyan]")
                
                # Display diff
                syntax = Syntax(
                    file_result["diff"],
                    "diff",
                    theme="monokai",
                    line_numbers=True,
                    word_wrap=True
                )
                console.print(syntax)
                
                # Display explanation
                if "explanation" in file_result:
                    console.print(f"[italic]{file_result['explanation']}[/italic]")
        
        # Apply changes if requested
        if apply:
            console.print("\n[bold]Applying changes...[/bold]")
            
            with console.status("[bold green]Applying changes...[/bold green]"):
                apply_result = asyncio.run(feedback_manager.apply_refinements(
                    refinements=result,
                    backup=backup
                ))
            
            if apply_result["files_changed"] > 0:
                console.print(f"[green]Changes applied to {apply_result['files_changed']} files[/green]")
                if backup:
                    console.print("[blue]Backups created for modified files[/blue]")
            else:
                console.print("[yellow]No changes were applied[/yellow]")
        else:
            console.print("\n[bold yellow]Changes were not applied. Use --apply to apply changes.[/bold yellow]")
    
    except Exception as e:
        logger.exception("Error refining project")
        console.print(f"[bold red]Error refining project:[/bold red] {str(e)}")

@app.command("generate-ci")
def generate_ci(
    platform: str = typer.Argument(..., help="CI platform (github_actions, gitlab_ci, jenkins, travis, circle_ci)"),
    project_dir: str = typer.Option(".", help="Project directory"),
    project_type: Optional[str] = typer.Option(None, help="Project type (python, node, etc.)")
):
    """
    Generate CI/CD configuration for a project.
    """
    console.print(Panel(
        f"[bold green]Generating CI/CD configuration for platform:[/bold green] {platform}",
        title="CI/CD Configuration",
        expand=False
    ))
    
    try:
        # Check if project directory exists
        project_path = Path(project_dir)
        if not project_path.exists() or not project_path.is_dir():
            console.print(f"[bold red]Project directory does not exist: {project_dir}[/bold red]")
            return
        
        # Detect project type if not provided
        if not project_type:
            console.print("\n[bold]Detecting project type...[/bold]")
            
            with console.status("[bold green]Analyzing project...[/bold green]"):
                detection_result = asyncio.run(ci_cd_integration.detect_project_type(project_dir))
                project_type = detection_result.get("project_type")
            
            if project_type:
                console.print(f"[green]Detected project type: {project_type}[/green]")
            else:
                console.print("[red]Could not detect project type[/red]")
                return
        
        # Generate CI configuration
        console.print(f"\n[bold]Generating {platform} configuration...[/bold]")
        
        with console.status(f"[bold green]Generating configuration...[/bold green]"):
            result = asyncio.run(ci_cd_integration.generate_ci_configuration(
                path=project_dir,
                platform=platform,
                project_type=project_type
            ))
        
        if result["success"]:
            console.print(f"[green]Generated {platform} configuration successfully[/green]")
            console.print(f"Configuration file: [bold]{result['config_file']}[/bold]")
        else:
            console.print(f"[red]Failed to generate configuration: {result.get('error', 'Unknown error')}[/red]")
    
    except Exception as e:
        logger.exception("Error generating CI/CD configuration")
        console.print(f"[bold red]Error generating CI/CD configuration:[/bold red] {str(e)}")

@app.command("generate-tests")
def generate_tests(
    project_dir: str = typer.Option(".", help="Project directory"),
    test_framework: Optional[str] = typer.Option(None, help="Test framework to use"),
    focus: Optional[List[str]] = typer.Option(None, help="Files to focus on (glob patterns supported)")
):
    """
    Generate test files for a project.
    """
    console.print(Panel(
        "[bold green]Generating test files for project[/bold green]",
        title="Test Generation",
        expand=False
    ))
    
    try:
        # Check if project directory exists
        project_path = Path(project_dir)
        if not project_path.exists() or not project_path.is_dir():
            console.print(f"[bold red]Project directory does not exist: {project_dir}[/bold red]")
            return
        
        # Detect test framework if not provided
        if not test_framework:
            console.print("\n[bold]Detecting test framework...[/bold]")
            
            with console.status("[bold green]Analyzing project...[/bold green]"):
                detection_result = asyncio.run(test_framework_integration.detect_test_framework(project_dir))
                test_framework = detection_result.get("test_framework")
            
            if test_framework:
                console.print(f"[green]Detected test framework: {test_framework}[/green]")
            else:
                console.print("[yellow]Could not detect test framework. Using default for project type...[/yellow]")
        
        # Find source files
        console.print("\n[bold]Finding source files...[/bold]")
        
        src_files = []
        with console.status("[bold green]Scanning project...[/bold green]"):
            # Get project type
            project_type_result = asyncio.run(ci_cd_integration.detect_project_type(project_dir))
            project_type = project_type_result.get("project_type")
            
            # Map of project types to file extensions
            extensions = {
                "python": [".py"],
                "node": [".js", ".jsx", ".ts", ".tsx"],
                "java": [".java"],
                "go": [".go"],
                "rust": [".rs"],
                "ruby": [".rb"]
            }
            
            # Get relevant file extensions
            file_exts = extensions.get(project_type, [".py", ".js", ".java", ".go", ".rs", ".rb"])
            
            # Find all source files
            for root, _, files in os.walk(project_path):
                # Skip common test directories and non-source directories
                if any(excluded in root for excluded in ["test", "tests", "__pycache__", "node_modules", ".git"]):
                    continue
                
                for file in files:
                    _, ext = os.path.splitext(file)
                    if ext in file_exts:
                        # If focus is specified, check if file matches any pattern
                        if focus:
                            file_path = Path(root) / file
                            rel_path = file_path.relative_to(project_path)
                            
                            matched = False
                            for pattern in focus:
                                if Path(pattern).name == file or rel_path.match(pattern):
                                    matched = True
                                    break
                            
                            if not matched:
                                continue
                        
                        # Read file content
                        try:
                            with open(Path(root) / file, 'r', encoding='utf-8', errors='replace') as f:
                                content = f.read()
                            
                            # Create CodeFile object
                            from angela.generation.engine import CodeFile
                            file_path = Path(root) / file
                            rel_path = file_path.relative_to(project_path)
                            
                            src_files.append(CodeFile(
                                path=str(rel_path),
                                content=content,
                                purpose=f"Source file: {file}",
                                dependencies=[],
                                language=project_type
                            ))
                        except Exception as e:
                            console.print(f"[yellow]Error reading file {file}: {str(e)}[/yellow]")
        
        console.print(f"[green]Found {len(src_files)} source files[/green]")
        
        # Generate test files
        console.print("\n[bold]Generating test files...[/bold]")
        
        with console.status("[bold green]Generating tests...[/bold green]"):
            result = asyncio.run(test_framework_integration.generate_test_files(
                src_files=src_files,
                test_framework=test_framework,
                project_type=project_type,
                root_dir=project_dir
            ))
        
        if result["success"]:
            console.print(f"[green]Generated {result['file_count']} test files[/green]")
            
            # Show generated files
            if result["generated_files"]:
                console.print("\n[bold blue]Generated test files:[/bold blue]")
                for file in result["generated_files"]:
                    console.print(f"- {file}")
        else:
            console.print(f"[red]Failed to generate test files: {result.get('error', 'Unknown error')}[/red]")
    
    except Exception as e:
        logger.exception("Error generating test files")
        console.print(f"[bold red]Error generating test files:[/bold red] {str(e)}")

if __name__ == "__main__":
    app()
</file>

<file path="angela/cli/workflows.py">
"""
Workflow management commands for Angela CLI.

This module provides CLI commands for creating, running, and managing workflows.
"""
import sys
import asyncio
from pathlib import Path
from typing import List, Optional, Dict, Any

import typer
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.syntax import Syntax
from rich.prompt import Prompt, Confirm

from angela.workflows.manager import workflow_manager
from angela.context import context_manager
from angela.shell.formatter import terminal_formatter
from angela.utils.logging import get_logger

logger = get_logger(__name__)
console = Console()

# Create the workflow commands app
app = typer.Typer(help="Manage Angela workflows")


# Define this at module level to replace await_func
def run_async(coro):
    """Run an async function from a synchronous context.
    
    This function handles getting the appropriate event loop
    rather than creating a new one with asyncio.run(), which causes
    problems when called from an async context.
    """
    try:
        loop = asyncio.get_event_loop()
    except RuntimeError:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
    return loop.run_until_complete(coro)


@app.command("list")
def list_workflows(
    tag: Optional[str] = typer.Option(
        None, "--tag", "-t", help="Filter workflows by tag"
    ),
    verbose: bool = typer.Option(
        False, "--verbose", "-v", help="Show detailed information"
    ),
):
    """List available workflows."""
    try:
        # Get workflows
        workflows = workflow_manager.list_workflows(tag)
        
        if not workflows:
            if tag:
                console.print(f"No workflows found with tag: {tag}")
            else:
                console.print("No workflows defined yet. Use 'angela workflows create' to define one.")
            return
        
        # Create table for workflows
        table = Table(title="Available Workflows")
        table.add_column("Name", style="cyan")
        table.add_column("Description", style="white")
        table.add_column("Steps", style="magenta", justify="right")
        
        if verbose:
            table.add_column("Tags", style="blue")
            table.add_column("Created", style="green")
        
        # Add workflows to table
        for workflow in workflows:
            if verbose:
                tags = ", ".join(workflow.tags) if workflow.tags else ""
                created = workflow.created.strftime("%Y-%m-%d %H:%M")
                table.add_row(
                    workflow.name,
                    workflow.description,
                    str(len(workflow.steps)),
                    tags,
                    created
                )
            else:
                table.add_row(
                    workflow.name,
                    workflow.description,
                    str(len(workflow.steps))
                )
        
        # Display the table
        console.print(table)
        
    except Exception as e:
        logger.exception(f"Error listing workflows: {str(e)}")
        console.print(f"[bold red]Error:[/bold red] {str(e)}")
        sys.exit(1)


@app.command("export")
def export_workflow(
    name: str = typer.Argument(
        ..., help="Name of the workflow to export"
    ),
    output: Optional[Path] = typer.Option(
        None, "--output", "-o", help="Output path for the exported workflow"
    ),
):
    """Export a workflow to a shareable package."""
    try:
        # Get the workflow sharing manager
        from angela.workflows.sharing import workflow_sharing_manager
        
        # Export the workflow using run_async instead of asyncio.run()
        result = run_async(workflow_sharing_manager.export_workflow(
            workflow_name=name,
            output_path=output
        ))
        
        if result["success"]:
            console.print(f"[bold green]Workflow '{name}' exported successfully![/bold green]")
            console.print(f"Output path: {result['output_path']}")
        else:
            console.print(f"[bold red]Error:[/bold red] {result.get('error', 'Unknown error')}")
            sys.exit(1)
        
    except Exception as e:
        logger.exception(f"Error exporting workflow: {str(e)}")
        console.print(f"[bold red]Error:[/bold red] {str(e)}")
        sys.exit(1)


@app.command("import")
def import_workflow(
    path: Path = typer.Argument(
        ..., help="Path to the workflow package to import"
    ),
    rename: Optional[str] = typer.Option(
        None, "--rename", "-r", help="New name for the imported workflow"
    ),
    replace: bool = typer.Option(
        False, "--replace", help="Replace existing workflow with same name"
    ),
):
    """Import a workflow from a package."""
    try:
        # Get the workflow sharing manager
        from angela.workflows.sharing import workflow_sharing_manager
        
        # Import the workflow using run_async instead of asyncio.run()
        result = run_async(workflow_sharing_manager.import_workflow(
            workflow_path=path,
            rename=rename,
            replace_existing=replace
        ))
        
        if result["success"]:
            console.print(f"[bold green]Workflow imported successfully as '{result['workflow']}'![/bold green]")
        else:
            console.print(f"[bold red]Error:[/bold red] {result.get('error', 'Unknown error')}")
            sys.exit(1)
        
    except Exception as e:
        logger.exception(f"Error importing workflow: {str(e)}")
        console.print(f"[bold red]Error:[/bold red] {str(e)}")
        sys.exit(1)


@app.command("create")
def create_workflow(
    name: str = typer.Argument(..., help="Name for the workflow"),
    description: Optional[str] = typer.Option(
        None, "--description", "-d", help="Description of the workflow"
    ),
    from_file: Optional[Path] = typer.Option(
        None, "--file", "-f", help="Load workflow definition from a file"
    ),
):
    """Create a new workflow."""
    try:
        # Get description if not provided
        if not description:
            description = Prompt.ask("Enter workflow description")
        
        steps = []
        
        if from_file:
            # Load workflow definition from file
            if not from_file.exists():
                console.print(f"[bold red]Error:[/bold red] File not found: {from_file}")
                sys.exit(1)
            
            # Read the file
            with open(from_file, "r") as f:
                workflow_text = f.read()
            
            # Get context
            context = context_manager.get_context_dict()
            
            # Define workflow from file content using run_async instead of asyncio.run()
            workflow = run_async(workflow_manager.define_workflow_from_natural_language(
                name=name,
                description=description,
                natural_language=workflow_text,
                context=context
            ))
        else:
            # Interactive workflow creation
            console.print("Enter the steps for your workflow. Each step should be a shell command.")
            console.print("Press [bold cyan]Enter[/bold cyan] on an empty line when finished.")
            
            step_num = 1
            while True:
                command = Prompt.ask(f"Step {step_num} command", default="")
                if not command:
                    break
                
                explanation = Prompt.ask(f"Step {step_num} explanation", default="")
                optional = Confirm.ask(f"Is step {step_num} optional?", default=False)
                requires_confirmation = Confirm.ask(f"Does step {step_num} require confirmation?", default=False)
                
                steps.append({
                    "command": command,
                    "explanation": explanation,
                    "optional": optional,
                    "requires_confirmation": requires_confirmation
                })
                
                step_num += 1
            
            # Need at least one step
            if not steps:
                console.print("[bold red]Error:[/bold red] Workflow must have at least one step.")
                sys.exit(1)
            
            # Define the workflow using run_async instead of asyncio.run()
            workflow = run_async(workflow_manager.define_workflow(
                name=name,
                description=description,
                steps=steps
            ))
        
        # Display the created workflow using run_async instead of await_func
        run_async(terminal_formatter.display_workflow(workflow))
        
        console.print(f"[bold green]Workflow '{name}' created successfully![/bold green]")
        console.print(f"Run it with: [bold cyan]angela workflows run {name}[/bold cyan]")
        
    except Exception as e:
        logger.exception(f"Error creating workflow: {str(e)}")
        console.print(f"[bold red]Error:[/bold red] {str(e)}")
        sys.exit(1)


@app.command("run")
def run_workflow(
    name: str = typer.Argument(..., help="Name of the workflow to run"),
    variable: List[str] = typer.Option(
        [], "--var", "-v", help="Variable value in format NAME=VALUE"
    ),
    dry_run: bool = typer.Option(
        False, "--dry-run", help="Show what would happen without executing"
    ),
):
    """Run a workflow."""
    try:
        # Check if workflow exists
        workflow = workflow_manager.get_workflow(name)
        if not workflow:
            console.print(f"[bold red]Error:[/bold red] Workflow '{name}' not found.")
            
            # Show available workflows
            available = workflow_manager.list_workflows()
            if available:
                console.print("\nAvailable workflows:")
                for w in available:
                    console.print(f"  - {w.name}")
            else:
                console.print("\nNo workflows defined yet. Use 'angela workflows create' to define one.")
                
            sys.exit(1)
        
        # Parse variables
        variables = {}
        for var in variable:
            if "=" in var:
                key, value = var.split("=", 1)
                variables[key] = value
            else:
                console.print(f"[bold yellow]Warning:[/bold yellow] Ignoring invalid variable format: {var}")
        
        # Get context
        context = context_manager.get_context_dict()
        
        # Display the workflow using run_async instead of await_func
        run_async(terminal_formatter.display_workflow(workflow, variables))
        
        # Confirm execution
        if not dry_run:
            if not Confirm.ask("Execute this workflow?", default=True):
                console.print("Workflow execution cancelled.")
                return
        
        # Execute the workflow using run_async instead of asyncio.run()
        result = run_async(workflow_manager.execute_workflow(
            workflow_name=name,
            variables=variables,
            context=context,
            dry_run=dry_run
        ))
        
        # Display results
        if result["success"]:
            status = "[bold green]Workflow executed successfully![/bold green]"
            if dry_run:
                status = "[bold blue]Dry run completed successfully![/bold blue]"
            console.print(status)
        else:
            console.print("[bold red]Workflow execution failed.[/bold red]")
            
            if result.get("error"):
                console.print(f"Error: {result['error']}")
        
    except Exception as e:
        logger.exception(f"Error running workflow: {str(e)}")
        console.print(f"[bold red]Error:[/bold red] {str(e)}")
        sys.exit(1)


@app.command("delete")
def delete_workflow(
    name: str = typer.Argument(..., help="Name of the workflow to delete"),
    force: bool = typer.Option(
        False, "--force", "-f", help="Delete without confirmation"
    ),
):
    """Delete a workflow."""
    try:
        # Check if workflow exists
        workflow = workflow_manager.get_workflow(name)
        if not workflow:
            console.print(f"[bold red]Error:[/bold red] Workflow '{name}' not found.")
            sys.exit(1)
        
        # Confirm deletion
        if not force:
            if not Confirm.ask(f"Are you sure you want to delete workflow '{name}'?", default=False):
                console.print("Deletion cancelled.")
                return
        
        # Delete the workflow
        workflow_manager.delete_workflow(name)
        
        console.print(f"[bold green]Workflow '{name}' deleted successfully.[/bold green]")
        
    except Exception as e:
        logger.exception(f"Error deleting workflow: {str(e)}")
        console.print(f"[bold red]Error:[/bold red] {str(e)}")
        sys.exit(1)


@app.command("show")
def show_workflow(
    name: str = typer.Argument(..., help="Name of the workflow to show"),
    verbose: bool = typer.Option(
        False, "--verbose", "-v", help="Show detailed information"
    ),
):
    """Show details of a workflow."""
    try:
        # Get the workflow
        workflow = workflow_manager.get_workflow(name)
        if not workflow:
            console.print(f"[bold red]Error:[/bold red] Workflow '{name}' not found.")
            sys.exit(1)
        
        # Display the workflow using run_async instead of await_func
        run_async(terminal_formatter.display_workflow(workflow))
        
        # Show additional details if verbose
        if verbose:
            console.print("\n[bold]Additional Details:[/bold]")
            console.print(f"Created: {workflow.created.strftime('%Y-%m-%d %H:%M:%S')}")
            console.print(f"Last Modified: {workflow.modified.strftime('%Y-%m-%d %H:%M:%S')}")
            
            if workflow.tags:
                console.print(f"Tags: {', '.join(workflow.tags)}")
            
            if workflow.author:
                console.print(f"Author: {workflow.author}")
            
            if workflow.variables:
                console.print("\n[bold]Variables:[/bold]")
                for var_name, var_desc in workflow.variables.items():
                    console.print(f"  {var_name}: {var_desc}")
        
    except Exception as e:
        logger.exception(f"Error showing workflow: {str(e)}")
        console.print(f"[bold red]Error:[/bold red] {str(e)}")
        sys.exit(1)
</file>

<file path="angela/context/__init__.py">
"""Context management package for Angela CLI."""

from .manager import context_manager
from .session import session_manager
from .history import history_manager
from .preferences import preferences_manager
from .file_detector import detect_file_type, get_content_preview
from .file_resolver import file_resolver
from .file_activity import file_activity_tracker, ActivityType
from .enhancer import context_enhancer

# Initialize project inference in the background when importing this package
import asyncio
from .project_inference import project_inference

def initialize_project_inference():
    """Initialize project inference for the current project in background."""
    from .manager import context_manager
    if context_manager.project_root:
        asyncio.create_task(
            project_inference.infer_project_info(context_manager.project_root)
        )

# Schedule initialization to run soon but not block import
asyncio.get_event_loop().call_soon(initialize_project_inference)
</file>

<file path="angela/execution/engine.py">
# angela/execution/engine.py (modified)
"""
Engine for safely executing commands.
"""
import asyncio
import shlex
import subprocess
from typing import Dict, Any, List, Tuple, Optional

from angela.utils.logging import get_logger
from angela.intent.models import ActionPlan
from angela.core.registry import registry

logger = get_logger(__name__)

class ExecutionEngine:
    """Engine for safely executing commands."""
    
    def __init__(self):
        """Initialize the execution engine."""
        self._logger = logger
    
    async def execute_command(
        self, 
        command: str,
        check_safety: bool = True,
        dry_run: bool = False
    ) -> Tuple[str, str, int]:
        """
        Execute a shell command and return its output.
        
        Args:
            command: The shell command to execute.
            check_safety: Whether to perform safety checks before execution.
            dry_run: Whether to simulate the command without actual execution.
            
        Returns:
            A tuple of (stdout, stderr, return_code).
        """
        self._logger.info(f"Preparing to execute command: {command}")
        
        # If safety checks are requested, perform them
        if check_safety:
            # Get check_command_safety function from registry to avoid circular import
            check_command_safety = registry.get("check_command_safety")
            
            # Check if the command is safe to execute
            is_safe = await check_command_safety(command, dry_run)
            if not is_safe:
                self._logger.warning(f"Command execution cancelled due to safety concerns: {command}")
                return "", "Command execution cancelled due to safety concerns", 1
            
            # For dry runs, return simulated results
            if dry_run:
                self._logger.info(f"DRY RUN: Would execute command: {command}")
                return f"[DRY RUN] Would execute: {command}", "", 0
        
        # Execute the command
        try:
            # Split the command properly using shlex
            args = shlex.split(command)
            
            # Execute the command and capture output
            process = await asyncio.create_subprocess_exec(
                *args,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
            )
            
            # Wait for the command to complete
            stdout_bytes, stderr_bytes = await process.communicate()
            stdout = stdout_bytes.decode('utf-8', errors='replace')
            stderr = stderr_bytes.decode('utf-8', errors='replace')
            
            self._logger.debug(f"Command completed with return code: {process.returncode}")
            self._logger.debug(f"stdout: {stdout[:100]}{'...' if len(stdout) > 100 else ''}")
            if stderr:
                self._logger.debug(f"stderr: {stderr}")
            
            # Record the operation for potential rollback
            if not dry_run and process.returncode == 0:
                # Get rollback_manager from registry to avoid circular import
                rollback_manager = registry.get("rollback_manager")
                if rollback_manager:
                    await rollback_manager.record_operation(
                        operation_type="execute_command",
                        params={"command": command},
                        backup_path=None  # Commands don't have direct file backups
                    )
            
            return stdout, stderr, process.returncode
        
        except Exception as e:
            self._logger.exception(f"Error executing command '{command}': {str(e)}")
            return "", str(e), -1

# Global execution engine instance
execution_engine = ExecutionEngine()
</file>

<file path="angela/intent/planner.py">
"""
Task planning and goal decomposition for Angela CLI.

This module handles breaking down complex high-level goals into
executable action plans with dependencies and execution flow.
It provides two levels of planning capability:
1. Basic planning - For straightforward sequential tasks
2. Advanced planning - For complex tasks with branching, conditionals, and various step types
"""
import os
import re
import json
import shlex
import asyncio
from pathlib import Path
from typing import Dict, Any, List, Tuple, Optional, Set, Union
from enum import Enum
from datetime import datetime

from pydantic import BaseModel, Field

from angela.intent.models import ActionPlan, Intent, IntentType
from angela.ai.client import gemini_client, GeminiRequest
from angela.context import context_manager
from angela.utils.logging import get_logger

logger = get_logger(__name__)

#######################
# Basic Planning Models
#######################

class PlanStep(BaseModel):
    """Model for a single step in a basic plan."""
    command: str = Field(..., description="The command to execute")
    explanation: str = Field(..., description="Explanation of the command")
    dependencies: List[int] = Field(default_factory=list, description="Indices of steps this step depends on")
    estimated_risk: int = Field(0, description="Estimated risk level (0-4)")


class TaskPlan(BaseModel):
    """Model for a complete basic task plan."""
    goal: str = Field(..., description="The original high-level goal")
    steps: List[PlanStep] = Field(..., description="Steps to achieve the goal")
    context: Dict[str, Any] = Field(default_factory=dict, description="Context information")

#######################
# Advanced Planning Models
#######################

class PlanStepType(str, Enum):
    """Types of plan steps for advanced planning."""
    COMMAND = "command"  # Shell command
    CODE = "code"        # Code to execute or save
    FILE = "file"        # File operation
    DECISION = "decision"  # Decision point, may branch execution
    API = "api"          # API call
    LOOP = "loop"        # Looping construct


class AdvancedPlanStep(BaseModel):
    """Model for an advanced plan step with additional capabilities."""
    id: str = Field(..., description="Unique identifier for this step")
    type: PlanStepType = Field(..., description="Type of step")
    description: str = Field(..., description="Human-readable description")
    command: Optional[str] = Field(None, description="Command to execute (for command type)")
    code: Optional[str] = Field(None, description="Code to execute or save (for code type)")
    file_path: Optional[str] = Field(None, description="Path for file operations (for file type)")
    file_content: Optional[str] = Field(None, description="Content for file operations (for file type)")
    condition: Optional[str] = Field(None, description="Condition for decision steps (for decision type)")
    true_branch: Optional[List[str]] = Field(None, description="Steps to execute if condition is true")
    false_branch: Optional[List[str]] = Field(None, description="Steps to execute if condition is false")
    api_url: Optional[str] = Field(None, description="URL for API calls (for api type)")
    api_method: Optional[str] = Field(None, description="HTTP method for API calls (for api type)")
    api_payload: Optional[Dict[str, Any]] = Field(None, description="Payload for API calls (for api type)")
    loop_items: Optional[str] = Field(None, description="Items to loop over (for loop type)")
    loop_body: Optional[List[str]] = Field(None, description="Steps to execute in loop (for loop type)")
    dependencies: List[str] = Field(default_factory=list, description="IDs of steps this step depends on")
    estimated_risk: int = Field(0, description="Estimated risk level (0-4)")
    timeout: Optional[int] = Field(None, description="Timeout in seconds")
    retry: Optional[int] = Field(None, description="Number of retries on failure")
    tags: List[str] = Field(default_factory=list, description="Tags for categorization")


class AdvancedTaskPlan(BaseModel):
    """Model for an advanced task plan with branching and complex steps."""
    id: str = Field(..., description="Unique identifier for this plan")
    goal: str = Field(..., description="The original high-level goal")
    description: str = Field(..., description="Detailed description of the plan")
    steps: Dict[str, AdvancedPlanStep] = Field(..., description="Steps to achieve the goal, indexed by ID")
    entry_points: List[str] = Field(..., description="Step IDs to start execution with")
    context: Dict[str, Any] = Field(default_factory=dict, description="Context information")
    created: datetime = Field(default_factory=datetime.now, description="When the plan was created")


#######################
# Unified Task Planner
#######################

class TaskPlanner:
    """
    Task planner for breaking down complex goals into actionable steps.
    
    This planner can generate two types of plans:
    1. Basic plans (TaskPlan) - For simple sequential tasks
    2. Advanced plans (AdvancedTaskPlan) - For complex tasks with branching execution
    
    The planner automatically determines the appropriate plan type based on the
    complexity of the goal and request context.
    """
    
    def __init__(self):
        """Initialize the task planner."""
        self._logger = logger
    
    async def plan_task(
        self, 
        goal: str, 
        context: Dict[str, Any],
        complexity: str = "auto"
    ) -> Union[TaskPlan, AdvancedTaskPlan]:
        """
        Plan a task by breaking it down into actionable steps.
        
        Args:
            goal: The high-level goal description
            context: Context information
            complexity: Planning complexity level ("simple", "advanced", or "auto")
            
        Returns:
            Either a basic TaskPlan or an advanced AdvancedTaskPlan based on complexity
        """
        self._logger.info(f"Planning task: {goal} (complexity: {complexity})")
        
        # Determine planning complexity if auto
        if complexity == "auto":
            complexity = await self._determine_complexity(goal)
            self._logger.info(f"Determined complexity: {complexity}")
        
        # Use the appropriate planning strategy
        if complexity == "simple":
            # Use basic planning for simple tasks
            return await self._create_basic_plan(goal, context)
        else:
            # Use advanced planning for complex tasks
            return await self._generate_advanced_plan(goal, context)
    
    async def _determine_complexity(self, goal: str) -> str:
        """
        Determine the appropriate planning complexity for a goal.
        
        Args:
            goal: The high-level goal
            
        Returns:
            Complexity level ("simple" or "advanced")
        """
        # Simple heuristics based on goal text
        complexity_indicators = [
            "if", "when", "based on", "for each", "foreach", "loop", "iterate",
            "depending on", "decision", "alternative", "otherwise", "create file",
            "write to file", "dynamic", "api", "request", "conditionally",
            "advanced", "complex", "multiple steps", "error handling"
        ]
        
        # Count indicators
        indicator_count = sum(1 for indicator in complexity_indicators 
                              if indicator in goal.lower())
        
        # Check goal length and complexity indicators
        if len(goal.split()) > 20 or indicator_count >= 2:
            return "advanced"
        else:
            return "simple"
    
    #######################
    # Basic Planning Methods
    #######################
    
    async def _create_basic_plan(
        self, 
        goal: str, 
        context: Dict[str, Any]
    ) -> TaskPlan:
        """
        Create a basic plan for a task.
        
        Args:
            goal: The high-level goal description
            context: Context information
            
        Returns:
            A TaskPlan with steps to achieve the goal
        """
        self._logger.info(f"Creating basic plan for task: {goal}")
        
        # Generate a plan using the AI
        prompt = self._build_planning_prompt(goal, context)
        
        # Call AI service
        api_request = GeminiRequest(
            prompt=prompt,
            max_tokens=4000
        )
        
        response = await gemini_client.generate_text(api_request)
        
        # Parse the plan from the response
        plan = self._parse_plan_response(response.text, goal, context)
        
        return plan
    
    def _build_planning_prompt(
        self, 
        goal: str,
        context: Dict[str, Any]
    ) -> str:
        """
        Build a prompt for basic planning.
        
        Args:
            goal: The high-level goal
            context: Context information
            
        Returns:
            A prompt string for the AI service
        """
        # Create context string
        context_str = "Current context:\n"
        
        if context.get("cwd"):
            context_str += f"- Current working directory: {context['cwd']}\n"
        if context.get("project_root"):
            context_str += f"- Project root: {context['project_root']}\n"
        if context.get("project_type"):
            context_str += f"- Project type: {context['project_type']}\n"
        
        # Add files in current directory for context
        if context.get("cwd"):
            try:
                dir_contents = context_manager.get_directory_contents(Path(context["cwd"]))
                files_str = "\n".join([f"- {item['name']}" for item in dir_contents])
                context_str += f"\nFiles in current directory:\n{files_str}\n"
            except Exception as e:
                self._logger.error(f"Error getting directory contents: {str(e)}")
        
        # Build the prompt
        prompt = f"""
You are Angela, an AI terminal assistant. Your task is to create a detailed plan for achieving the following goal:

GOAL: {goal}

{context_str}

Break down this goal into a sequence of shell commands that would accomplish it.
For each command, provide:
1. The exact command to run
2. A brief explanation of what the command does
3. Any dependencies (which previous steps must complete first)
4. An estimated risk level (0: SAFE, 1: LOW, 2: MEDIUM, 3: HIGH, 4: CRITICAL)

Format your response as JSON:
{{
  "steps": [
    {{
      "command": "command_1",
      "explanation": "Explanation of command 1",
      "dependencies": [],
      "estimated_risk": 1
    }},
    {{
      "command": "command_2",
      "explanation": "Explanation of command 2",
      "dependencies": [0],
      "estimated_risk": 2
    }},
    ...
  ]
}}

Ensure each command is valid and appropriate for a Linux/Unix shell environment.
Use the most efficient and standard commands to accomplish the task.
Include error handling where appropriate.
"""
        
        return prompt
    
    def _parse_plan_response(self, response: str, goal: str, context: Dict[str, Any]) -> TaskPlan:
        """
        Parse the AI response to extract the basic plan.
        
        Args:
            response: The AI response text
            goal: The original high-level goal
            context: Context information
            
        Returns:
            A TaskPlan object
        """
        try:
            # Extract JSON from the response
            json_match = re.search(r'```(?:json)?\s*(.*?)\s*```', response, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
            else:
                # Try to find JSON without code blocks
                json_match = re.search(r'({.*})', response, re.DOTALL)
                if json_match:
                    json_str = json_match.group(1)
                else:
                    # Assume the entire response is JSON
                    json_str = response
            
            # Parse the JSON
            plan_data = json.loads(json_str)
            
            # Create a TaskPlan object
            steps = []
            for step_data in plan_data.get("steps", []):
                step = PlanStep(
                    command=step_data["command"],
                    explanation=step_data["explanation"],
                    dependencies=step_data.get("dependencies", []),
                    estimated_risk=step_data.get("estimated_risk", 0)
                )
                steps.append(step)
            
            return TaskPlan(
                goal=goal,
                steps=steps,
                context=context
            )
        
        except Exception as e:
            self._logger.exception(f"Error parsing plan response: {str(e)}")
            # Create a fallback single-step plan
            return TaskPlan(
                goal=goal,
                steps=[
                    PlanStep(
                        command=f"echo 'Unable to create detailed plan for: {goal}'",
                        explanation="Fallback step due to planning error",
                        dependencies=[],
                        estimated_risk=0
                    )
                ],
                context=context
            )
    
    def create_action_plan(self, task_plan: TaskPlan) -> ActionPlan:
        """
        Convert a TaskPlan to an executable ActionPlan.
        
        Args:
            task_plan: The task plan to convert
            
        Returns:
            An ActionPlan ready for execution
        """
        # Create an intent for the action plan
        intent = Intent(
            type=IntentType.UNKNOWN,
            original_request=task_plan.goal
        )
        
        # Extract commands and explanations preserving the order
        commands = []
        explanations = []
        
        # For now, we'll execute steps in the order they appear
        # In the future, we could use the dependencies to create a proper execution order
        for step in task_plan.steps:
            commands.append(step.command)
            explanations.append(step.explanation)
        
        # Determine the overall risk level (maximum of all steps)
        risk_level = max([step.estimated_risk for step in task_plan.steps], default=0)
        
        return ActionPlan(
            intent=intent,
            commands=commands,
            explanations=explanations,
            risk_level=risk_level
        )
    

    async def execute_plan(
        self, 
        plan: Union[TaskPlan, AdvancedTaskPlan], 
        dry_run: bool = False,
        transaction_id: Optional[str] = None
    ) -> Union[List[Dict[str, Any]], Dict[str, Any]]:
        """
        Execute a task plan with transaction support.
        
        Args:
            plan: The plan to execute
            dry_run: Whether to simulate execution without making changes
            transaction_id: ID of the transaction this execution belongs to
            
        Returns:
            List of execution results for each step
        """
        self._logger.info(f"Executing plan: {plan.goal}")
        
        # Handle different plan types
        if isinstance(plan, AdvancedTaskPlan):
            return await self._execute_advanced_plan(plan, dry_run, transaction_id)
        else:
            return await self._execute_basic_plan(plan, dry_run, transaction_id)
    
    async def _execute_basic_plan(
        self, 
        plan: TaskPlan, 
        dry_run: bool = False,
        transaction_id: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """
        Execute a basic task plan with transaction support.
        
        Args:
            plan: The plan to execute
            dry_run: Whether to simulate execution without making changes
            transaction_id: ID of the transaction this execution belongs to
            
        Returns:
            List of execution results for each step
        """
        results = []
        
        # Execute each step in sequence
        for i, step in enumerate(plan.steps):
            self._logger.info(f"Executing step {i+1}/{len(plan.steps)}: {step.command}")
            
            # Generate a step_id for tracking
            step_id = f"step_{i+1}"
            
            try:
                # Execute the command
                result = await execution_engine.execute_command(
                    command=step.command,
                    check_safety=True,
                    dry_run=dry_run
                )
                
                # Record command execution in the transaction if successful
                if not dry_run and transaction_id and result[2] == 0:  # return_code == 0
                    # Import here to avoid circular imports
                    from angela.execution.rollback import rollback_manager
                    
                    await rollback_manager.record_command_execution(
                        command=step.command,
                        return_code=result[2],
                        stdout=result[0],
                        stderr=result[1],
                        transaction_id=transaction_id,
                        step_id=step_id
                    )
                
                # Format the result
                execution_result = {
                    "step": i + 1,
                    "command": step.command,
                    "explanation": step.explanation,
                    "stdout": result[0],
                    "stderr": result[1],
                    "return_code": result[2],
                    "success": result[2] == 0
                }
                
                results.append(execution_result)
                
                # Stop execution if a step fails
                if result[2] != 0:
                    self._logger.warning(f"Step {i+1} failed with return code {result[2]}")
                    break
                    
            except Exception as e:
                self._logger.exception(f"Error executing step {i+1}: {str(e)}")
                
                # Record the error
                results.append({
                    "step": i + 1,
                    "command": step.command,
                    "explanation": step.explanation,
                    "error": str(e),
                    "success": False
                })
                
                # Stop execution on error
                break
        
        return results
    

    #######################
    # Advanced Planning Methods
    #######################
    
    async def _generate_advanced_plan(
        self, 
        goal: str, 
        context: Dict[str, Any]
    ) -> AdvancedTaskPlan:
        """
        Generate an advanced plan using the AI service.
        
        Args:
            goal: The high-level goal
            context: Context information
            
        Returns:
            An AdvancedTaskPlan with steps to achieve the goal
        """
        # Build a planning prompt for advanced planning
        prompt = self._build_advanced_planning_prompt(goal, context)
        
        # Call the AI service
        api_request = GeminiRequest(
            prompt=prompt,
            max_tokens=4000
        )
        
        self._logger.debug("Sending advanced planning request to AI service")
        api_response = await gemini_client.generate_text(api_request)
        
        # Parse the plan from the response
        plan = self._parse_advanced_plan_response(api_response.text, goal, context)
        
        return plan
    
    def _build_advanced_planning_prompt(
        self, 
        goal: str, 
        context: Dict[str, Any]
    ) -> str:
        """
        Build a prompt for generating an advanced plan.
        
        Args:
            goal: The high-level goal
            context: Context information
            
        Returns:
            A prompt string for the AI service
        """
        # Create context string
        context_str = "Current context:\n"
        
        if context.get("cwd"):
            context_str += f"- Current working directory: {context['cwd']}\n"
        if context.get("project_root"):
            context_str += f"- Project root: {context['project_root']}\n"
        if context.get("project_type"):
            context_str += f"- Project type: {context['project_type']}\n"
        
        # Add files in current directory for context
        if context.get("cwd"):
            try:
                dir_contents = context_manager.get_directory_contents(Path(context["cwd"]))
                files_str = "\n".join([f"- {item['name']}" for item in dir_contents])
                context_str += f"\nFiles in current directory:\n{files_str}\n"
            except Exception as e:
                self._logger.error(f"Error getting directory contents: {str(e)}")
        
        # Build the prompt
        prompt = f"""
You are Angela, an AI terminal assistant with advanced planning capabilities. Your task is to create a detailed, sophisticated plan for achieving the following complex goal:

GOAL: {goal}

{context_str}

This is a complex goal that may require branching, conditions, loops, or other advanced constructs.

Break down this goal into a comprehensive plan with these advanced features:
1. Different types of steps (commands, code, file operations, API calls, decisions, loops)
2. Branching execution paths based on conditions
3. Dependencies between steps
4. Error recovery strategies
5. Risk assessment for each step

Format your response as JSON:
{{
  "id": "generate a unique plan ID",
  "goal": "the original goal",
  "description": "detailed plan description",
  "steps": {{
    "step1": {{
      "id": "step1",
      "type": "command",
      "description": "Description of step 1",
      "command": "command to execute",
      "dependencies": [],
      "estimated_risk": 1
    }},
    "step2": {{
      "id": "step2",
      "type": "file",
      "description": "Create a file",
      "file_path": "/path/to/file",
      "file_content": "content to write",
      "dependencies": ["step1"],
      "estimated_risk": 2
    }},
    "step3": {{
      "id": "step3",
      "type": "decision",
      "description": "Check if a condition is met",
      "condition": "test condition",
      "true_branch": ["step4a"],
      "false_branch": ["step4b"],
      "dependencies": ["step2"],
      "estimated_risk": 0
    }},
    "step4a": {{
      "id": "step4a",
      "type": "command",
      "description": "Executed if condition is true",
      "command": "command to execute",
      "dependencies": ["step3"],
      "estimated_risk": 1
    }},
    "step4b": {{
      "id": "step4b",
      "type": "command",
      "description": "Executed if condition is false",
      "command": "command to execute",
      "dependencies": ["step3"],
      "estimated_risk": 1
    }},
    "step5": {{
      "id": "step5",
      "type": "loop",
      "description": "Process each item",
      "loop_items": "items to process",
      "loop_body": ["step6"],
      "dependencies": ["step4a", "step4b"],
      "estimated_risk": 2
    }},
    "step6": {{
      "id": "step6",
      "type": "code",
      "description": "Execute some code",
      "code": "code to execute",
      "dependencies": [],
      "estimated_risk": 1
    }}
  }},
  "entry_points": ["step1"]
}}

Ensure each step has a unique ID and clear dependencies. Entry points are the steps that should be executed first.
"""
        
        return prompt
    
    def _parse_advanced_plan_response(
        self, 
        response: str, 
        goal: str, 
        context: Dict[str, Any]
    ) -> AdvancedTaskPlan:
        """
        Parse the AI response into an AdvancedTaskPlan.
        
        Args:
            response: The AI response text
            goal: The original high-level goal
            context: Context information
            
        Returns:
            An AdvancedTaskPlan object
        """
        try:
            # Extract JSON from the response
            json_match = re.search(r'```(?:json)?\s*(.*?)\s*```', response, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
            else:
                # Try to find JSON without code blocks
                json_match = re.search(r'({.*})', response, re.DOTALL)
                if json_match:
                    json_str = json_match.group(1)
                else:
                    # Assume the entire response is JSON
                    json_str = response
            
            # Parse the JSON
            plan_data = json.loads(json_str)
            
            # Create an AdvancedTaskPlan object
            return AdvancedTaskPlan(
                id=plan_data.get("id", f"plan_{datetime.now().strftime('%Y%m%d%H%M%S')}"),
                goal=goal,
                description=plan_data.get("description", "Advanced plan for " + goal),
                steps=plan_data["steps"],
                entry_points=plan_data.get("entry_points", [next(iter(plan_data["steps"].keys()))]),
                context=context,
                created=datetime.now()
            )
        
        except Exception as e:
            self._logger.exception(f"Error parsing advanced plan response: {str(e)}")
            # Create a fallback plan
            fallback_step_id = "fallback_step"
            return AdvancedTaskPlan(
                id=f"fallback_plan_{datetime.now().strftime('%Y%m%d%H%M%S')}",
                goal=goal,
                description=f"Fallback plan for: {goal}",
                steps={
                    fallback_step_id: AdvancedPlanStep(
                        id=fallback_step_id,
                        type=PlanStepType.COMMAND,
                        description="Fallback step due to planning error",
                        command=f"echo 'Unable to create detailed plan for: {goal}'",
                        dependencies=[],
                        estimated_risk=0
                    )
                },
                entry_points=[fallback_step_id],
                context=context
            )
    
    async def _execute_advanced_plan(
        self, 
        plan: AdvancedTaskPlan, 
        dry_run: bool = False,
        transaction_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Execute an advanced task plan with transaction support.
        
        Args:
            plan: The plan to execute
            dry_run: Whether to simulate execution without making changes
            transaction_id: ID of the transaction this execution belongs to
            
        Returns:
            Dictionary with execution results
        """
        self._logger.info(f"Executing advanced plan: {plan.goal}")
        
        # Initialize execution state
        results = {}
        completed_steps = set()
        pending_steps = {}
        
        # Initialize with entry points
        for entry_point in plan.entry_points:
            if entry_point in plan.steps:
                pending_steps[entry_point] = plan.steps[entry_point]
        
        # Execute steps until all are completed or no more can be executed
        while pending_steps:
            # Find steps that can be executed (all dependencies satisfied)
            executable_steps = {}
            for step_id, step in pending_steps.items():
                if all(dep in completed_steps for dep in step.dependencies):
                    executable_steps[step_id] = step
            
            # If no steps can be executed, we're stuck (circular dependencies or missing steps)
            if not executable_steps:
                self._logger.warning("No executable steps found, possible circular dependencies")
                break
            
            # Execute all executable steps
            for step_id, step in executable_steps.items():
                self._logger.info(f"Executing step {step_id}: {step.command}")
                
                try:
                    # Handle different step types
                    if step.type == "command":
                        # Execute shell command
                        result = await execution_engine.execute_command(
                            command=step.command,
                            check_safety=True,
                            dry_run=dry_run
                        )
                        
                        # Record command execution in the transaction if successful
                        if not dry_run and transaction_id and result[2] == 0:  # return_code == 0
                            # Import here to avoid circular imports
                            from angela.execution.rollback import rollback_manager
                            
                            await rollback_manager.record_command_execution(
                                command=step.command,
                                return_code=result[2],
                                stdout=result[0],
                                stderr=result[1],
                                transaction_id=transaction_id,
                                step_id=step_id
                            )
                        
                        # Format the result
                        execution_result = {
                            "step_id": step_id,
                            "type": step.type,
                            "command": step.command,
                            "description": step.description,
                            "stdout": result[0],
                            "stderr": result[1],
                            "return_code": result[2],
                            "success": result[2] == 0
                        }
                        
                    else:
                        # Unsupported step type, mark as failure
                        execution_result = {
                            "step_id": step_id,
                            "type": step.type,
                            "description": step.description,
                            "error": f"Unsupported step type: {step.type}",
                            "success": False
                        }
                    
                    results[step_id] = execution_result
                    
                    # Mark step as completed if successful, otherwise the plan failed
                    if execution_result["success"]:
                        completed_steps.add(step_id)
                    else:
                        self._logger.warning(f"Step {step_id} failed")
                        return {
                            "success": False,
                            "steps_completed": len(completed_steps),
                            "steps_total": len(plan.steps),
                            "failed_step": step_id,
                            "results": results
                        }
                        
                except Exception as e:
                    self._logger.exception(f"Error executing step {step_id}: {str(e)}")
                    
                    # Record the error
                    results[step_id] = {
                        "step_id": step_id,
                        "type": step.type,
                        "description": step.description,
                        "error": str(e),
                        "success": False
                    }
                    
                    # Plan failed
                    return {
                        "success": False,
                        "steps_completed": len(completed_steps),
                        "steps_total": len(plan.steps),
                        "failed_step": step_id,
                        "results": results
                    }
                
                # Remove from pending steps
                del pending_steps[step_id]
        
        # Check if all steps were completed
        all_completed = len(completed_steps) == len(plan.steps)
        
        return {
            "success": all_completed,
            "steps_completed": len(completed_steps),
            "steps_total": len(plan.steps),
            "results": results
        }
    
    
    def _select_next_step(
        self, 
        plan: AdvancedTaskPlan,
        pending_steps: Set[str],
        executed_steps: Set[str]
    ) -> Optional[str]:
        """
        Select the next step to execute in an advanced plan.
        
        Args:
            plan: The plan
            pending_steps: Set of pending step IDs
            executed_steps: Set of executed step IDs
            
        Returns:
            ID of the next step to execute, or None if no steps are ready
        """
        for step_id in pending_steps:
            step = plan.steps[step_id]
            
            # Check if all dependencies are satisfied
            if all(dep in executed_steps for dep in step.dependencies):
                return step_id
        
        return None
    
    async def _execute_step(
        self, 
        step: AdvancedPlanStep,
        previous_results: Dict[str, Dict[str, Any]],
        dry_run: bool
    ) -> Dict[str, Any]:
        """
        Execute a single step of the advanced plan.
        
        Args:
            step: The step to execute
            previous_results: Results of previously executed steps
            dry_run: Whether to simulate execution
            
        Returns:
            Dictionary with step execution results
        """
        # Import here to avoid circular imports
        from angela.execution.engine import execution_engine
        
        # Prepare base result
        result = {
            "step_id": step.id,
            "type": step.type,
            "description": step.description,
            "dry_run": dry_run
        }
        
        try:
            # Execute based on step type
            if step.type == PlanStepType.COMMAND:
                if step.command:
                    if dry_run:
                        # Simulate command execution
                        result["stdout"] = f"[DRY RUN] Would execute: {step.command}"
                        result["stderr"] = ""
                        result["return_code"] = 0
                        result["success"] = True
                    else:
                        # Execute the command
                        stdout, stderr, return_code = await execution_engine.execute_command(
                            step.command,
                            check_safety=True
                        )
                        result["stdout"] = stdout
                        result["stderr"] = stderr
                        result["return_code"] = return_code
                        result["success"] = return_code == 0
                else:
                    result["error"] = "Missing command for command step"
                    result["success"] = False
            
            elif step.type == PlanStepType.FILE:
                if step.file_path:
                    if dry_run:
                        # Simulate file operation
                        operation = "write" if step.file_content else "read"
                        result["message"] = f"[DRY RUN] Would {operation} file: {step.file_path}"
                        result["success"] = True
                    else:
                        # Execute file operation
                        if step.file_content:
                            # Write to file
                            await self._write_file(step.file_path, step.file_content)
                            result["message"] = f"Wrote content to {step.file_path}"
                            result["success"] = True
                        else:
                            # Read from file
                            content = await self._read_file(step.file_path)
                            result["content"] = content
                            result["success"] = True
                else:
                    result["error"] = "Missing file path for file step"
                    result["success"] = False
            
            elif step.type == PlanStepType.CODE:
                if step.code:
                    if dry_run:
                        # Simulate code execution
                        result["message"] = f"[DRY RUN] Would execute code: {len(step.code)} characters"
                        result["success"] = True
                    else:
                        # Execute the code
                        # This is a simplified implementation - in a real system,
                        # this would use a sandboxed execution environment
                        code_result = await self._execute_code(step.code)
                        result.update(code_result)
                else:
                    result["error"] = "Missing code for code step"
                    result["success"] = False
            
            elif step.type == PlanStepType.DECISION:
                if step.condition:
                    # Evaluate the condition
                    # This is a simplified implementation - in a real system,
                    # this would use a more sophisticated condition evaluation
                    condition_result = await self._evaluate_condition(
                        step.condition, previous_results, dry_run
                    )
                    result["condition"] = step.condition
                    result["condition_result"] = condition_result
                    result["next_branch"] = "true_branch" if condition_result else "false_branch"
                    result["success"] = True
                else:
                    result["error"] = "Missing condition for decision step"
                    result["success"] = False
            
            elif step.type == PlanStepType.API:
                if step.api_url and step.api_method:
                    if dry_run:
                        # Simulate API call
                        result["message"] = f"[DRY RUN] Would call API: {step.api_method} {step.api_url}"
                        result["success"] = True
                    else:
                        # Execute API call
                        api_result = await self._execute_api_call(
                            step.api_url, step.api_method, step.api_payload
                        )
                        result.update(api_result)
                else:
                    result["error"] = "Missing URL or method for API step"
                    result["success"] = False
            
            elif step.type == PlanStepType.LOOP:
                if step.loop_items and step.loop_body:
                    if dry_run:
                        # Simulate loop execution
                        result["message"] = f"[DRY RUN] Would loop over {step.loop_items}"
                        result["success"] = True
                    else:
                        # This is a placeholder for loop execution
                        # In a real system, this would execute the loop body for each item
                        result["message"] = f"Loop execution not implemented: {step.loop_items}"
                        result["success"] = True
                else:
                    result["error"] = "Missing items or body for loop step"
                    result["success"] = False
            
            else:
                result["error"] = f"Unknown step type: {step.type}"
                result["success"] = False
            
        except Exception as e:
            self._logger.exception(f"Error executing step {step.id}: {str(e)}")
            result["error"] = str(e)
            result["success"] = False
            
            # Handle retry if configured
            if step.retry and step.retry > 0:
                result["retry_count"] = 1
                result["retried"] = True
                
                # Attempt retries (simplified)
                for retry_num in range(1, step.retry + 1):
                    self._logger.info(f"Retrying step {step.id} (attempt {retry_num}/{step.retry})")
                    try:
                        # Wait before retrying
                        await asyncio.sleep(1)
                        
                        # Execute retry logic based on step type
                        # This is a simplified implementation
                        retry_result = await self._execute_step(step, previous_results, dry_run)
                        
                        if retry_result.get("success", False):
                            # Retry succeeded
                            retry_result["retry_count"] = retry_num
                            retry_result["retried"] = True
                            return retry_result
                    except Exception as retry_e:
                        self._logger.error(f"Error in retry {retry_num} for step {step.id}: {str(retry_e)}")
                
                # All retries failed
                result["retry_exhausted"] = True
        
        return result
    
    def _update_pending_steps(
        self, 
        plan: AdvancedTaskPlan,
        executed_step: AdvancedPlanStep,
        result: Dict[str, Any],
        pending_steps: Set[str],
        executed_steps: Set[str]
    ) -> None:
        """
        Update the set of pending steps based on execution result.
        
        Args:
            plan: The plan
            executed_step: The step that was just executed
            result: The execution result
            pending_steps: Set of pending step IDs to update
            executed_steps: Set of executed step IDs
        """
        # For decision steps, add the appropriate branch
        if executed_step.type == PlanStepType.DECISION:
            condition_result = result.get("condition_result", False)
            if condition_result and executed_step.true_branch:
                # Add steps from true branch
                for step_id in executed_step.true_branch:
                    if step_id not in executed_steps and step_id in plan.steps:
                        pending_steps.add(step_id)
            elif not condition_result and executed_step.false_branch:
                # Add steps from false branch
                for step_id in executed_step.false_branch:
                    if step_id not in executed_steps and step_id in plan.steps:
                        pending_steps.add(step_id)
        
        # For normal steps, add all steps that depend on this one
        for step_id, step in plan.steps.items():
            if executed_step.id in step.dependencies and step_id not in executed_steps:
                # Check if all dependencies are satisfied
                if all(dep in executed_steps for dep in step.dependencies):
                    pending_steps.add(step_id)
    
    async def _read_file(self, path: str) -> str:
        """Read content from a file."""
        from angela.execution.filesystem import read_file
        return await read_file(path)
    
    async def _write_file(self, path: str, content: str) -> bool:
        """Write content to a file."""
        from angela.execution.filesystem import write_file
        return await write_file(path, content)
    
    async def _execute_code(self, code: str) -> Dict[str, Any]:
        """
        Execute code (placeholder implementation).
        
        In a real system, this would use a sandboxed execution environment.
        """
        return {
            "message": f"Code execution not implemented: {len(code)} characters",
            "success": True
        }
    
    async def _evaluate_condition(
        self, 
        condition: str,
        previous_results: Dict[str, Dict[str, Any]],
        dry_run: bool
    ) -> bool:
        """
        Evaluate a condition (placeholder implementation).
        
        In a real system, this would use a more sophisticated condition evaluation.
        """
        import re
        
        # Look for simple patterns
        if re.search(r'file exists', condition, re.IGNORECASE):
            # Extract file path
            match = re.search(r'file exists[:\s]+([^\s]+)', condition, re.IGNORECASE)
            if match:
                file_path = match.group(1)
                return Path(file_path).exists()
        
        if re.search(r'command success', condition, re.IGNORECASE):
            # Extract step ID
            match = re.search(r'step[:\s]+([^\s]+)', condition, re.IGNORECASE)
            if match:
                step_id = match.group(1)
                return previous_results.get(step_id, {}).get("success", False)
        
        # Default behavior for dry run
        if dry_run:
            return True
        
        # Default for unknown conditions
        return False
    
    async def _execute_api_call(
        self, 
        url: str,
        method: str,
        payload: Optional[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        Execute an API call (placeholder implementation).
        
        In a real system, this would use a proper HTTP client.
        """
        return {
            "message": f"API call not implemented: {method} {url}",
            "success": True
        }


# Global instance
task_planner = TaskPlanner()
</file>

<file path="angela/monitoring/background.py">
"""
Background monitoring and proactive suggestions for Angela CLI.

This module provides background monitoring of system state and user activities
to offer proactive assistance and suggestions.
"""
import os
import sys
import asyncio
import time
import re
import signal
import subprocess
from pathlib import Path
from typing import Dict, Any, Optional, List, Set, Callable, Awaitable
from datetime import datetime, timedelta

from angela.ai.client import GeminiRequest
from angela.context import context_manager
from angela.utils.logging import get_logger
from angela.shell.formatter import terminal_formatter
from angela.core.events import event_bus

logger = get_logger(__name__)

class BackgroundMonitor:
    """
    Background monitor for detecting potential issues and offering proactive assistance.
    
    Monitors:
    1. Git status changes
    2. Syntax errors in recently modified files
    3. System resource usage
    4. Process failures
    5. Common error patterns
    """
    
    def __init__(self):
        """Initialize the background monitor."""
        self._logger = logger
        self._monitoring_tasks = set()
        self._monitoring_active = False
        self._suggestions = set()  # To avoid repeating the same suggestions
        self._last_suggestion_time = datetime.now() - timedelta(hours=1)  # Ensure initial delay has passed
        self._suggestion_cooldown = timedelta(minutes=5)  # Minimum time between suggestions
    
    def start_monitoring(self):
        """Start background monitoring tasks."""
        if self._monitoring_active:
            return
            
        self._monitoring_active = True
        
        # Create and start monitoring tasks
        self._create_monitoring_task(self._monitor_git_status(), "git_status")
        self._create_monitoring_task(self._monitor_file_changes(), "file_changes")
        self._create_monitoring_task(self._monitor_system_resources(), "system_resources")
        
        self._logger.info("Background monitoring started")
    
    def stop_monitoring(self):
        """Stop all background monitoring tasks."""
        if not self._monitoring_active:
            return
            
        self._monitoring_active = False
        
        # Cancel all running tasks
        for task in self._monitoring_tasks:
            if not task.done():
                task.cancel()
                
        self._monitoring_tasks.clear()
        self._logger.info("Background monitoring stopped")
    
    def _create_monitoring_task(self, coro: Awaitable, name: str) -> None:
        """
        Create and start a monitoring task.
        
        Args:
            coro: The coroutine to run as a task
            name: A name for the task (for logging)
        """
        task = asyncio.create_task(self._run_monitoring_task(coro, name))
        self._monitoring_tasks.add(task)
        task.add_done_callback(self._monitoring_tasks.discard)
    
    async def _run_monitoring_task(self, coro: Awaitable, name: str) -> None:
        """
        Run a monitoring task with error handling.
        
        Args:
            coro: The coroutine to run
            name: The task name
        """
        try:
            await coro
        except asyncio.CancelledError:
            self._logger.debug(f"Monitoring task {name} cancelled")
        except Exception as e:
            self._logger.exception(f"Error in monitoring task {name}: {str(e)}")
            
            # Restart the task after a delay
            await asyncio.sleep(30)
            if self._monitoring_active:
                self._logger.info(f"Restarting monitoring task {name}")
                if name == "git_status":
                    self._create_monitoring_task(self._monitor_git_status(), name)
                elif name == "file_changes":
                    self._create_monitoring_task(self._monitor_file_changes(), name)
                elif name == "system_resources":
                    self._create_monitoring_task(self._monitor_system_resources(), name)
    
    async def _monitor_git_status(self) -> None:
        """Monitor Git status in the current project."""
        self._logger.debug("Starting Git status monitoring")
        
        while self._monitoring_active:
            try:
                # Check if the current directory is a Git repository
                context = context_manager.get_context_dict()
                if not context.get("project_root"):
                    # No project detected, sleep and try again later
                    await asyncio.sleep(60)
                    continue
                
                project_root = Path(context["project_root"])
                git_dir = project_root / ".git"
                
                if not git_dir.exists():
                    # Not a Git repository, sleep and try again later
                    await asyncio.sleep(60)
                    continue
                
                # Check Git status
                result = await self._run_command("git status -s", cwd=str(project_root))
                
                if result["success"] and result["stdout"].strip():
                    # Check if this is different from the last status we saw
                    status_text = result["stdout"].strip()
                    
                    # Count changes
                    modified_count = status_text.count(" M ")
                    untracked_count = status_text.count("?? ")
                    deleted_count = status_text.count(" D ")
                    
                    # Analyze the status and suggest actions
                    if modified_count > 0 or untracked_count > 0 or deleted_count > 0:
                        suggestion_key = f"git_status:{modified_count}:{untracked_count}:{deleted_count}"
                        
                        if suggestion_key not in self._suggestions:
                            # Create a suggestion based on the status
                            suggestion = await self._generate_git_suggestion(
                                modified_count, 
                                untracked_count, 
                                deleted_count
                            )
                            
                            # Display the suggestion if possible
                            if suggestion and self._can_show_suggestion():
                                terminal_formatter.print_proactive_suggestion(suggestion, "Git Monitor")
                                self._suggestions.add(suggestion_key)
                                self._last_suggestion_time = datetime.now()
                                
                                await event_bus.publish("monitoring:git_status", {
                                    "suggestion": suggestion,
                                    "modified_count": modified_count,
                                    "untracked_count": untracked_count,
                                    "deleted_count": deleted_count,
                                    "timestamp": datetime.now().isoformat()
                                })                               
                                
                                
                
                # Wait before checking again
                await asyncio.sleep(60)
                
            except Exception as e:
                self._logger.exception(f"Error in Git status monitoring: {str(e)}")
                await asyncio.sleep(60)  # Wait before retrying
    
    async def _monitor_file_changes(self) -> None:
        """Monitor file changes for syntax errors and linting issues."""
        self._logger.debug("Starting file changes monitoring")
        
        # Track the last modified time of each file
        last_modified_times = {}
        
        while self._monitoring_active:
            try:
                # Get current project context
                context = context_manager.get_context_dict()
                if not context.get("project_root"):
                    # No project detected, sleep and try again later
                    await asyncio.sleep(30)
                    continue
                
                project_root = Path(context["project_root"])
                
                # Scan for files that have changed
                changed_files = []
                
                for file_path in self._find_source_files(project_root):
                    try:
                        mtime = file_path.stat().st_mtime
                        
                        # Check if this file is newly modified
                        if file_path in last_modified_times:
                            if mtime > last_modified_times[file_path]:
                                changed_files.append(file_path)
                                last_modified_times[file_path] = mtime
                        else:
                            # New file we haven't seen before
                            last_modified_times[file_path] = mtime
                    except (FileNotFoundError, PermissionError):
                        # File may have been deleted or is inaccessible
                        if file_path in last_modified_times:
                            del last_modified_times[file_path]
                
                # Check changed files for issues
                for file_path in changed_files:
                    # Get file info
                    file_info = context_manager.get_file_info(file_path)
                    
                    # Check file based on language
                    if file_info.get("language") == "Python":
                        await self._check_python_file(file_path)
                    elif file_info.get("language") == "JavaScript":
                        await self._check_javascript_file(file_path)
                    # Add more language checks as needed
                
                # Wait before checking again
                await asyncio.sleep(10)
                
            except Exception as e:
                self._logger.exception(f"Error in file changes monitoring: {str(e)}")
                await asyncio.sleep(30)  # Wait before retrying
    
    async def _monitor_system_resources(self) -> None:
        """Monitor system resources for potential issues."""
        self._logger.debug("Starting system resources monitoring")
        
        # Last values for comparison
        last_values = {
            "disk_usage": 0,
            "memory_usage": 0,
            "cpu_usage": 0
        }
        
        while self._monitoring_active:
            try:
                # Check disk space
                disk_usage = await self._get_disk_usage()
                if disk_usage > 90 and disk_usage > last_values["disk_usage"] + 5:
                    # Disk usage above 90% and increased by 5%
                    if self._can_show_suggestion():
                        suggestion = f"Your disk space is running low ({disk_usage}% used). Consider cleaning up unused files or moving data to free up space."
                        terminal_formatter.print_proactive_suggestion(suggestion, "System Monitor")
                        self._last_suggestion_time = datetime.now()
                        
                        # Publish as an event
                        await event_bus.publish("monitoring:disk_space_low", {
                            "suggestion": suggestion,
                            "disk_usage": disk_usage,
                            "timestamp": datetime.now().isoformat()
                        })
                        
                last_values["disk_usage"] = disk_usage
                
                # Wait before checking again
                await asyncio.sleep(300)  # Check every 5 minutes
                
            except Exception as e:
                self._logger.exception(f"Error in system resources monitoring: {str(e)}")
                await asyncio.sleep(60)  # Wait before retrying
    
    async def _run_command(self, command: str, cwd: Optional[str] = None) -> Dict[str, Any]:
        """
        Run a shell command and return its output.
        
        Args:
            command: The command to run
            cwd: Optional working directory
            
        Returns:
            Dictionary with command results
        """
        try:
            process = await asyncio.create_subprocess_shell(
                command,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
                cwd=cwd
            )
            
            stdout, stderr = await process.communicate()
            
            return {
                "command": command,
                "stdout": stdout.decode('utf-8', errors='replace'),
                "stderr": stderr.decode('utf-8', errors='replace'),
                "return_code": process.returncode,
                "success": process.returncode == 0
            }
        except Exception as e:
            self._logger.error(f"Error running command '{command}': {str(e)}")
            return {
                "command": command,
                "stdout": "",
                "stderr": str(e),
                "return_code": -1,
                "success": False
            }
    
    def _find_source_files(self, base_dir: Path) -> List[Path]:
        """
        Find source code files in a directory.
        
        Args:
            base_dir: The base directory to search
            
        Returns:
            List of file paths
        """
        source_files = []
        
        # File extensions to look for
        extensions = {
            ".py", ".js", ".ts", ".java", ".c", ".cpp", ".h", ".hpp",
            ".rs", ".go", ".rb", ".php", ".html", ".css", ".jsx", ".tsx"
        }
        
        # Directories to ignore
        ignore_dirs = {
            "__pycache__", "node_modules", ".git", "venv", "env",
            "build", "dist", "target", ".idea", ".vscode"
        }
        
        try:
            for root, dirs, files in os.walk(base_dir):
                # Skip ignored directories
                dirs[:] = [d for d in dirs if d not in ignore_dirs]
                
                for file in files:
                    file_ext = os.path.splitext(file)[1]
                    if file_ext in extensions:
                        source_files.append(Path(os.path.join(root, file)))
        except Exception as e:
            self._logger.error(f"Error finding source files: {str(e)}")
        
        return source_files
    
    async def _check_python_file(self, file_path: Path) -> None:
        """
        Check a Python file for syntax errors or linting issues.
        
        Args:
            file_path: Path to the Python file
        """
        # Check for syntax errors
        result = await self._run_command(f"python -m py_compile {file_path}")
        
        if not result["success"]:
            # Found a syntax error, generate a suggestion
            error_text = result["stderr"]
            suggestion_key = f"python_syntax:{file_path}"
            
            if suggestion_key not in self._suggestions and self._can_show_suggestion():
                # Extract the error message
                match = re.search(r"SyntaxError: (.*)", error_text)
                error_msg = match.group(1) if match else "syntax error"
                
                suggestion = f"Syntax error detected in {file_path.name}: {error_msg}"
                terminal_formatter.print_proactive_suggestion(suggestion, "File Monitor")
                self._suggestions.add(suggestion_key)
                self._last_suggestion_time = datetime.now()
                
                # Publish as an event
                await event_bus.publish("monitoring:python_syntax_error", {
                    "suggestion": suggestion,
                    "file_path": str(file_path),
                    "error_message": error_msg,
                    "timestamp": datetime.now().isoformat()
                })
        
        # Check with flake8 if available
        flake8_result = await self._run_command(f"flake8 {file_path}")
        
        if flake8_result["success"] and flake8_result["stdout"].strip():
            # Found linting issues
            suggestion_key = f"python_lint:{file_path}"
            
            if suggestion_key not in self._suggestions and self._can_show_suggestion():
                lint_issues = flake8_result["stdout"].strip().count('\n') + 1
                suggestion = f"Found {lint_issues} linting issues in {file_path.name}"
                terminal_formatter.print_proactive_suggestion(suggestion, "File Monitor")
                self._suggestions.add(suggestion_key)
                self._last_suggestion_time = datetime.now()
                
                # Publish as an event
                await event_bus.publish("monitoring:python_lint_issue", {
                    "suggestion": suggestion,
                    "file_path": str(file_path),
                    "lint_issues": lint_issues,
                    "timestamp": datetime.now().isoformat()
                })
    
    async def _check_javascript_file(self, file_path: Path) -> None:
        """
        Check a JavaScript file for syntax errors or linting issues.
        
        Args:
            file_path: Path to the JavaScript file
        """
        # Check for syntax errors with Node.js
        result = await self._run_command(f"node --check {file_path}")
        
        if not result["success"]:
            # Found a syntax error, generate a suggestion
            error_text = result["stderr"]
            suggestion_key = f"js_syntax:{file_path}"
            
            if suggestion_key not in self._suggestions and self._can_show_suggestion():
                suggestion = f"Syntax error detected in {file_path.name}"
                terminal_formatter.print_proactive_suggestion(suggestion, "File Monitor")
                self._suggestions.add(suggestion_key)
                self._last_suggestion_time = datetime.now()
                
                # Publish as an event
                await event_bus.publish("monitoring:javascript_syntax_error", {
                    "suggestion": suggestion,
                    "file_path": str(file_path),
                    "error_text": error_text,
                    "timestamp": datetime.now().isoformat()
                })
        
        # Check with ESLint if available
        eslint_result = await self._run_command(f"eslint {file_path}")
        
        if eslint_result["success"] and eslint_result["stdout"].strip():
            # Found linting issues
            suggestion_key = f"js_lint:{file_path}"
            
            if suggestion_key not in self._suggestions and self._can_show_suggestion():
                lint_issues = eslint_result["stdout"].strip().count('\n') + 1
                suggestion = f"Found {lint_issues} linting issues in {file_path.name}"
                terminal_formatter.print_proactive_suggestion(suggestion, "File Monitor")
                self._suggestions.add(suggestion_key)
                self._last_suggestion_time = datetime.now()
                
                # Publish as an event
                await event_bus.publish("monitoring:javascript_lint_issue", {
                    "suggestion": suggestion,
                    "file_path": str(file_path),
                    "lint_issues": lint_issues,
                    "timestamp": datetime.now().isoformat()
                })
    
    async def _get_disk_usage(self) -> float:
        """
        Get disk usage percentage for the current directory.
        
        Returns:
            Disk usage percentage (0-100)
        """
        if sys.platform == "win32":
            # Windows
            result = await self._run_command("wmic logicaldisk get freespace,size")
            if result["success"]:
                lines = result["stdout"].strip().split('\n')
                if len(lines) >= 2:
                    values = lines[1].split()
                    if len(values) >= 2:
                        try:
                            free_space = int(values[0])
                            total_size = int(values[1])
                            return 100 - (free_space / total_size * 100)
                        except (ValueError, IndexError):
                            pass
            return 0
        else:
            # Unix-like
            result = await self._run_command("df -h .")
            if result["success"]:
                lines = result["stdout"].strip().split('\n')
                if len(lines) >= 2:
                    values = lines[1].split()
                    if len(values) >= 5:
                        try:
                            usage = values[4].rstrip('%')
                            return float(usage)
                        except (ValueError, IndexError):
                            pass
            return 0
    
    async def _generate_git_suggestion(
        self, 
        modified_count: int, 
        untracked_count: int, 
        deleted_count: int
    ) -> Optional[str]:
        """
        Generate a suggestion based on Git status.
        
        Args:
            modified_count: Number of modified files
            untracked_count: Number of untracked files
            deleted_count: Number of deleted files
            
        Returns:
            A suggestion string, or None if no suggestion is needed
        """
        total_changes = modified_count + untracked_count + deleted_count
        
        if total_changes <= 0:
            return None
            
        if total_changes > 10:
            return f"You have {total_changes} uncommitted changes in your Git repository. Consider committing your changes to avoid losing work."
            
        if modified_count > 0 and untracked_count > 0:
            return f"You have {modified_count} modified files and {untracked_count} untracked files. Consider using 'git add' to stage changes and 'git commit' to save your work."
            
        if modified_count > 0:
            return f"You have {modified_count} modified files that aren't committed. Use 'git commit' to save your changes."
            
        if untracked_count > 0:
            return f"You have {untracked_count} untracked files. Use 'git add' to begin tracking them."
            
        if deleted_count > 0:
            return f"You have {deleted_count} deleted files that haven't been committed. Use 'git commit' to record these deletions."
            
        return None
    
    def _can_show_suggestion(self) -> bool:
        """
        Check if we can show a suggestion now (respecting cooldown period).
        
        Returns:
            True if a suggestion can be shown, False otherwise
        """
        now = datetime.now()
        return (now - self._last_suggestion_time) >= self._suggestion_cooldown

# Global background monitor instance
background_monitor = BackgroundMonitor()
</file>

<file path="angela/shell/angela.bash">
#!/bin/bash
# Angela CLI Bash Integration

# Function to handle Angela CLI requests
angela() {
    # Check if no arguments or help requested
    if [ $# -eq 0 ] || [ "$1" = "--help" ] || [ "$1" = "-h" ]; then
        python -m angela --help
        return
    fi

    # Handle version flag
    if [ "$1" = "--version" ] || [ "$1" = "-v" ]; then
        python -m angela --version
        return
    fi

    # Handle debug flag
    if [ "$1" = "--debug" ] || [ "$1" = "-d" ]; then
        DEBUG_FLAG="--debug"
        shift  # Remove the debug flag from arguments
    else
        DEBUG_FLAG=""
    fi

    # Handle specific command (init, etc.)
    if [ "$1" = "init" ]; then
        python -m angela $DEBUG_FLAG init
        return
    fi

    # Process as a request for anything else
    python -m angela $DEBUG_FLAG request "$@"
}

# Enable command completion for angela function
# This will be implemented in a future phase
</file>

<file path="angela/shell/formatter.py">
"""
Rich terminal formatting for Angela CLI.

This module provides enhanced terminal output formatting with
support for async operations and interactive elements.
"""
import asyncio
import sys
from typing import Optional, List, Dict, Any, Callable, Awaitable, Tuple
from enum import Enum
from pathlib import Path

from rich.console import Console
from rich.panel import Panel
from rich.syntax import Syntax
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TimeElapsedColumn
from rich.table import Table
from rich.live import Live
from rich.text import Text
from rich.layout import Layout
from rich.tree import Tree
from rich import box

terminal_formatter.display_advanced_plan = display_advanced_plan
terminal_formatter.display_execution_results = display_execution_results
terminal_formatter.display_step_details = display_step_details
terminal_formatter.display_step_error = display_step_error

from angela.utils.logging import get_logger

logger = get_logger(__name__)

class OutputType(Enum):
    """Types of command output."""
    STDOUT = "stdout"
    STDERR = "stderr"
    INFO = "info"
    SUCCESS = "success"
    WARNING = "warning"
    ERROR = "error"
    PROGRESS = "progress"

class TerminalFormatter:
    """
    Rich terminal formatter with support for asynchronous output
    and interactive elements.
    """
    
    def __init__(self):
        """Initialize the terminal formatter."""
        self._console = Console()
        self._logger = logger
    
    def print_command(self, command: str, title: Optional[str] = None) -> None:
        """
        Display a command with syntax highlighting.
        
        Args:
            command: The command to display
            title: Optional title for the panel
        """
        title = title or "Command"
        syntax = Syntax(command, "bash", theme="monokai", word_wrap=True)
        self._console.print(Panel(syntax, title=title, expand=False))
    
    def print_output(
        self, 
        output: str, 
        output_type: OutputType = OutputType.STDOUT,
        title: Optional[str] = None
    ) -> None:
        """
        Display command output with appropriate formatting.
        
        Args:
            output: The output text
            output_type: Type of output
            title: Optional title for the panel
        """
        if not output:
            return
            
        # Set styling based on output type
        if output_type == OutputType.STDERR or output_type == OutputType.ERROR:
            style = "bold red"
            title = title or "Error"
            border_style = "red"
        elif output_type == OutputType.WARNING:
            style = "yellow"
            title = title or "Warning"
            border_style = "yellow"
        elif output_type == OutputType.SUCCESS:
            style = "green"
            title = title or "Success"
            border_style = "green"
        elif output_type == OutputType.INFO:
            style = "blue"
            title = title or "Info"
            border_style = "blue"
        else:  # Default for STDOUT
            style = "white"
            title = title or "Output"
            border_style = "white"
        
        # Create panel with output
        panel = Panel(output, title=title, border_style=border_style, expand=False)
        self._console.print(panel)
    
    def print_error_analysis(self, analysis: Dict[str, Any]) -> None:
        """
        Display error analysis with fix suggestions.
        
        Args:
            analysis: The error analysis dictionary
        """
        # Create a table for the error analysis
        table = Table(title="Error Analysis", expand=False)
        table.add_column("Aspect", style="bold cyan")
        table.add_column("Details", style="white")
        
        # Add error summary
        table.add_row("Error", Text(analysis.get("error_summary", "Unknown error"), style="bold red"))
        
        # Add possible cause
        table.add_row("Possible Cause", analysis.get("possible_cause", "Unknown"))
        
        # Add command issues
        if analysis.get("command_issues"):
            issues = "\n".join(f"• {issue}" for issue in analysis["command_issues"])
            table.add_row("Command Issues", issues)
        
        # Add file issues
        if analysis.get("file_issues"):
            file_issues = []
            for issue in analysis["file_issues"]:
                path = issue.get("path", "unknown")
                if "suggestion" in issue:
                    file_issues.append(f"• {path}: {issue['suggestion']}")
                if "similar_files" in issue:
                    similar = ", ".join(issue["similar_files"])
                    file_issues.append(f"  Did you mean: {similar}?")
            
            if file_issues:
                table.add_row("File Issues", "\n".join(file_issues))
        
        # Display the table
        self._console.print(table)
        
        # Display fix suggestions if available
        if analysis.get("fix_suggestions"):
            suggestions = analysis["fix_suggestions"]
            if suggestions:
                self._console.print(Panel(
                    "\n".join(f"• {suggestion}" for suggestion in suggestions),
                    title="Fix Suggestions",
                    border_style="green",
                    expand=False
                ))
    
    async def stream_output(
        self,
        command: str,
        show_spinner: bool = True,
        show_output: bool = True,
        callback: Optional[Callable[[str, OutputType], Awaitable[None]]] = None
    ) -> Tuple[str, str, int]:
        """
        Stream command output asynchronously with rich formatting.
        
        Args:
            command: The command to execute
            show_spinner: Whether to show a spinner
            show_output: Whether to display output
            callback: Optional callback for when output is received
            
        Returns:
            Tuple of (stdout, stderr, return_code)
        """
        # Import here to avoid circular imports
        from angela.execution.engine import execution_engine
        
        stdout_chunks = []
        stderr_chunks = []
        return_code = None
        
        # Set up progress display if requested
        if show_spinner:
            progress = Progress(
                SpinnerColumn(),
                TextColumn("[bold blue]Executing command...[/bold blue]"),
                TimeElapsedColumn(),
                console=self._console
            )
        else:
            progress = None
        
        try:
            # Start progress if requested
            if progress:
                progress.start()
                task = progress.add_task("Executing", total=None)
            
            # Create the process
            proc = await asyncio.create_subprocess_shell(
                command,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            # Set up tasks to read output
            async def read_stream(stream, output_type: OutputType):
                while True:
                    line = await stream.readline()
                    if not line:
                        break
                        
                    try:
                        line_str = line.decode('utf-8', errors='replace')
                        
                        # Store the output
                        if output_type == OutputType.STDOUT:
                            stdout_chunks.append(line_str)
                        else:
                            stderr_chunks.append(line_str)
                        
                        # Display if requested
                        if show_output:
                            if output_type == OutputType.STDOUT:
                                self._console.print(line_str, end="")
                            else:
                                self._console.print(f"[bold red]{line_str}[/bold red]", end="")
                        
                        # Call callback if provided
                        if callback:
                            await callback(line_str, output_type)
                            
                    except Exception as e:
                        self._logger.error(f"Error processing output: {str(e)}")
            
            # Create tasks for stdout and stderr
            stdout_task = asyncio.create_task(read_stream(proc.stdout, OutputType.STDOUT))
            stderr_task = asyncio.create_task(read_stream(proc.stderr, OutputType.STDERR))
            
            # Wait for the process to complete
            return_code = await proc.wait()
            
            # Wait for the streams to complete
            await stdout_task
            await stderr_task
            
            # Update progress
            if progress:
                progress.update(task, completed=True)
        
        finally:
            # Clean up progress
            if progress:
                progress.stop()
        
        # Return the collected output
        return "".join(stdout_chunks), "".join(stderr_chunks), return_code
    
    def create_table(
        self, 
        title: str, 
        columns: List[Tuple[str, Optional[str]]]
    ) -> Table:
        """
        Create a rich table.
        
        Args:
            title: The table title
            columns: List of (column_name, style) tuples
            
        Returns:
            A Rich Table object
        """
        table = Table(title=title, expand=False)
        
        for name, style in columns:
            table.add_column(name, style=style)
            
        return table
    
    async def display_task_plan(self, plan: Any) -> None:
        """
        Display a task plan with rich interactive visualization.
        
        Args:
            plan: The task plan to display
        """
        # Create a table for the plan steps
        table = Table(title=f"Plan for: {plan.goal}", box=box.ROUNDED)
        table.add_column("#", style="cyan", no_wrap=True)
        table.add_column("Command", style="green")
        table.add_column("Explanation", style="white")
        table.add_column("Risk", style="yellow", no_wrap=True)
        table.add_column("Dependencies", style="magenta", no_wrap=True)
        
        # Risk level names
        risk_names = ["SAFE", "LOW", "MEDIUM", "HIGH", "CRITICAL"]
        risk_styles = ["green", "blue", "yellow", "red", "bold red"]
        
        # Add steps to the table
        for i, step in enumerate(plan.steps):
            risk_idx = step.estimated_risk if 0 <= step.estimated_risk < len(risk_names) else 0
            risk_name = risk_names[risk_idx]
            risk_style = risk_styles[risk_idx]
            
            # Format dependencies
            deps = ", ".join([str(d+1) for d in step.dependencies]) if step.dependencies else "None"
            
            table.add_row(
                str(i + 1),
                Syntax(step.command, "bash", theme="monokai", word_wrap=True).markup,
                step.explanation,
                f"[{risk_style}]{risk_name}[/{risk_style}]",
                deps
            )
        
        # Display the table
        self._console.print("\n")
        self._console.print(Panel(
            "I've created a plan to accomplish your goal. Here are the steps I'll take:",
            title="Task Plan",
            border_style="blue"
        ))
        self._console.print(table)
        
        # Create a dependency visualization if there are non-trivial dependencies
        has_dependencies = any(step.dependencies for step in plan.steps)
        if has_dependencies:
            await self._display_dependency_graph(plan)
    
    async def _display_dependency_graph(self, plan: Any) -> None:
        """
        Display a visual representation of the dependency graph.
        
        Args:
            plan: The task plan with dependencies
        """
        # Create a dependency tree
        tree = Tree("Execution Flow", guide_style="bold blue")
        
        # Track processed steps
        processed = set()
        
        # Add steps with no dependencies first (roots)
        roots = []
        for i, step in enumerate(plan.steps):
            if not step.dependencies:
                roots.append(i)
                node = tree.add(f"Step {i+1}: {step.command[:30]}..." if len(step.command) > 30 else step.command)
                processed.add(i)
                
                # Add children recursively
                self._add_dependency_children(node, i, plan, processed)
        
        # Check if any steps were not processed (in case of circular dependencies)
        if len(processed) < len(plan.steps):
            for i, step in enumerate(plan.steps):
                if i not in processed:
                    node = tree.add(f"Step {i+1}: {step.command[:30]}..." if len(step.command) > 30 else step.command)
                    processed.add(i)
                    
                    # Add children recursively
                    self._add_dependency_children(node, i, plan, processed)
        
        # Display the tree
        self._console.print("\n[bold blue]Dependency Graph:[/bold blue]")
        self._console.print(tree)
    
    def _add_dependency_children(
        self, 
        parent_node: Any, 
        step_idx: int, 
        plan: Any, 
        processed: Set[int]
    ) -> None:
        """
        Recursively add children to a dependency node.
        
        Args:
            parent_node: The parent tree node
            step_idx: The index of the current step
            plan: The task plan
            processed: Set of already processed steps
        """
        # Find steps that depend on this one
        for i, step in enumerate(plan.steps):
            if step_idx in step.dependencies and i not in processed:
                node = parent_node.add(f"Step {i+1}: {step.command[:30]}..." 
                                       if len(step.command) > 30 else step.command)
                processed.add(i)
                
                # Recurse
                self._add_dependency_children(node, i, plan, processed)
    
    async def display_multi_step_execution(
        self, 
        plan: Any, 
        results: List[Dict[str, Any]]
    ) -> None:
        """
        Display the results of a multi-step execution.
        
        Args:
            plan: The task plan that was executed
            results: The execution results for each step
        """
        # Create a table for the execution results
        table = Table(title="Execution Results", box=box.ROUNDED)
        table.add_column("#", style="cyan", no_wrap=True)
        table.add_column("Command", style="green")
        table.add_column("Status", style="white", no_wrap=True)
        table.add_column("Output", style="white")
        
        # Add results to the table
        for i, result in enumerate(results):
            # Get the command
            command = result.get("command", plan.steps[i].command if i < len(plan.steps) else "Unknown")
            
            # Get status
            status = "[green]Success[/green]" if result.get("success", False) else "[red]Failed[/red]"
            
            # Get output (combine stdout and stderr)
            stdout = result.get("stdout", "").strip()
            stderr = result.get("stderr", "").strip()
            
            # Truncate output if too long
            output = stdout
            if stderr:
                if output:
                    output += "\n"
                output += f"[red]{stderr}[/red]"
            
            if len(output) > 100:
                output = output[:97] + "..."
            
            table.add_row(
                str(i + 1),
                Syntax(command, "bash", theme="monokai", word_wrap=True).markup,
                status,
                output
            )
        
        # Display the table
        self._console.print("\n")
        self._console.print(Panel(
            "Execution results for your multi-step task:",
            title="Multi-Step Execution",
            border_style="blue"
        ))
        self._console.print(table)
        
        # Display summary
        success_count = sum(1 for r in results if r.get("success", False))
        total_count = len(results)
        
        if success_count == total_count:
            self._console.print(f"[bold green]All {total_count} steps completed successfully![/bold green]")
        else:
            self._console.print(f"[bold yellow]{success_count} of {total_count} steps completed successfully[/bold yellow]")
            
            # Show which steps failed
            failed_steps = [i+1 for i, r in enumerate(results) if not r.get("success", False)]
            if failed_steps:
                self._console.print(f"[bold red]Failed steps: {', '.join(map(str, failed_steps))}[/bold red]")
    
    async def display_workflow(self, workflow: Any, variables: Dict[str, Any] = None) -> None:
        """
        Display a workflow with rich formatting.
        
        Args:
            workflow: The workflow to display
            variables: Optional variables for the workflow
        """
        # Create a table for the workflow steps
        table = Table(title=f"Workflow: {workflow.name}", box=box.ROUNDED)
        table.add_column("#", style="cyan", no_wrap=True)
        table.add_column("Command", style="green")
        table.add_column("Explanation", style="white")
        table.add_column("Options", style="yellow")
        
        # Add steps to the table
        for i, step in enumerate(workflow.steps):
            # Apply variable substitution if variables provided
            command = step.command
            if variables:
                for var_name, var_value in variables.items():
                    # Remove leading $ if present
                    clean_name = var_name[1:] if var_name.startswith('$') else var_name
                    
                    # Substitute ${VAR} syntax
                    command = command.replace(f"${{{clean_name}}}", str(var_value))
                    
                    # Substitute $VAR syntax
                    command = command.replace(f"${clean_name}", str(var_value))
            
            options = []
            if step.optional:
                options.append("Optional")
            if step.requires_confirmation:
                options.append("Requires Confirmation")
            
            table.add_row(
                str(i + 1),
                Syntax(command, "bash", theme="monokai", word_wrap=True).markup,
                step.explanation,
                ", ".join(options) if options else ""
            )
        
        # Display the table
        self._console.print("\n")
        self._console.print(Panel(
            workflow.description,
            title=f"Workflow: {workflow.name}",
            border_style="blue"
        ))
        self._console.print(table)
        
        # Display variables if provided
        if variables:
            var_table = Table(title="Variables", box=box.SIMPLE)
            var_table.add_column("Name", style="cyan")
            var_table.add_column("Value", style="green")
            
            for var_name, var_value in variables.items():
                var_table.add_row(var_name, str(var_value))
            
            self._console.print(var_table)
    
    async def display_file_analysis(self, analysis: Dict[str, Any]) -> None:
        """
        Display file content analysis results.
        
        Args:
            analysis: The analysis results
        """
        self._console.print("\n")
        self._console.print(Panel(
            f"Analysis of {analysis.get('path', 'file')}",
            title="File Analysis",
            border_style="blue"
        ))
        
        # Display language and type info
        file_type = analysis.get("type", "unknown")
        language = analysis.get("language")
        
        if language:
            self._console.print(f"[bold]File type:[/bold] {file_type} ({language})")
        else:
            self._console.print(f"[bold]File type:[/bold] {file_type}")
        
        # Display the analysis text
        self._console.print("\n[bold]Analysis:[/bold]")
        self._console.print(analysis.get("analysis", "No analysis available"))
    
    async def display_file_manipulation(self, manipulation: Dict[str, Any]) -> None:
        """
        Display file manipulation results with diff.
        
        Args:
            manipulation: The manipulation results
        """
        self._console.print("\n")
        self._console.print(Panel(
            f"Changes to {manipulation.get('path', 'file')}",
            title="File Manipulation",
            border_style="blue"
        ))
        
        # Display the instruction
        self._console.print(f"[bold]Instruction:[/bold] {manipulation.get('instruction', 'Unknown')}")
        
        # Display the diff
        self._console.print("\n[bold]Changes:[/bold]")
        syntax = Syntax(manipulation.get("diff", "No changes"), "diff", theme="monokai")
        self._console.print(syntax)
        
        # Show whether changes were applied
        if manipulation.get("changes_applied", False):
            self._console.print("[bold green]Changes have been applied to the file.[/bold green]")
        elif manipulation.get("dry_run", False):
            self._console.print("[bold blue]Dry run: Changes were not applied to the file.[/bold blue]")
        else:
            self._console.print("[bold yellow]Changes were not applied to the file.[/bold yellow]")
    
    async def display_file_search_results(self, search_results: Dict[str, Any]) -> None:
        """
        Display file search results.
        
        Args:
            search_results: The search results
        """
        self._console.print("\n")
        self._console.print(Panel(
            f"Search results in {search_results.get('path', 'file')}",
            title="File Search",
            border_style="blue"
        ))
        
        # Display the query
        self._console.print(f"[bold]Query:[/bold] {search_results.get('query', 'Unknown')}")
        
        # Display match count
        match_count = search_results.get("match_count", 0)
        self._console.print(f"[bold]Found {match_count} matches[/bold]")
        
        # Display matches
        if match_count > 0:
            matches = search_results.get("matches", [])
            
            for i, match in enumerate(matches, 1):
                self._console.print(f"\n[bold cyan]Match #{i}[/bold cyan] (Lines {match.get('line_start', '?')}-{match.get('line_end', '?')})")
                
                # Display the content with context
                syntax = Syntax(match.get("content", ""), search_results.get("language", "text"), theme="monokai", line_numbers=True)
                self._console.print(syntax)
                
                # Display explanation
                if "explanation" in match:
                    self._console.print(f"[italic]{match['explanation']}[/italic]")
    
    def print_suggestion(self, suggestion: Dict[str, Any], with_confidence: bool = True) -> None:
        """
        Print a command suggestion with rich formatting.
        
        Args:
            suggestion: The command suggestion
            with_confidence: Whether to show confidence score
        """
        self._console.print("\n")
        
        # Extract suggestion components
        command = suggestion.get("command", "")
        explanation = suggestion.get("explanation", "")
        confidence = suggestion.get("confidence", 0.0)
        
        # Display the command
        self.print_command(command)
        
        # Show confidence if requested
        if with_confidence:
            confidence_color = "green" if confidence > 0.8 else "yellow" if confidence > 0.6 else "red"
            self._console.print(f"[bold]Confidence:[/bold] [{confidence_color}]{confidence:.2f}[/{confidence_color}]")
        
        # Show explanation
        self._console.print("\n[bold]Explanation:[/bold]")
        self._console.print(explanation)
    
    def print_proactive_suggestion(self, suggestion: str, source: str = "AI") -> None:
        """
        Print a proactive suggestion.
        
        Args:
            suggestion: The suggestion text
            source: The source of the suggestion
        """
        self._console.print("\n")
        self._console.print(Panel(
            suggestion,
            title=f"Suggestion from {source}",
            border_style="green",
            expand=False
        ))



# Global formatter instance
terminal_formatter = TerminalFormatter()
</file>

<file path="angela/ai/content_analyzer.py">
"""
File content analysis and manipulation for Angela CLI.

This module provides AI-powered capabilities for understanding and
manipulating file contents based on natural language requests.
"""
import os
import re
import difflib
from pathlib import Path
from typing import Dict, Any, List, Tuple, Optional, Union, List

from angela.review.diff_manager import diff_manager
from angela.ai.client import gemini_client, GeminiRequest
from angela.context import context_manager
from angela.context.file_detector import detect_file_type
from angela.utils.logging import get_logger

logger = get_logger(__name__)

class ContentAnalyzer:
    """
    Analyzer for file content with AI-powered understanding and manipulation.
    
    This class provides:
    1. Content understanding - extract meaning from code or text
    2. Content summarization - generate concise summaries
    3. Content manipulation - make targeted changes based on natural language requests
    4. Content search - find relevant sections or patterns
    """
    
    def __init__(self):
        """Initialize the content analyzer."""
        self._logger = logger
    
    async def analyze_content(
        self, 
        file_path: Union[str, Path], 
        request: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Analyze file content to extract meaningful information.
        
        Args:
            file_path: Path to the file to analyze
            request: Optional specific analysis request
            
        Returns:
            Dictionary with analysis results
        """
        path_obj = Path(file_path)
        
        # Check if file exists
        if not path_obj.exists():
            return {"error": f"File not found: {path_obj}"}
        
        # Get file info to determine type and appropriate analysis
        file_info = detect_file_type(path_obj)
        
        # Read file content
        try:
            with open(path_obj, 'r', encoding='utf-8', errors='replace') as f:
                content = f.read()
        except Exception as e:
            self._logger.error(f"Error reading file: {str(e)}")
            return {"error": f"Error reading file: {str(e)}"}
        
        # Generate analysis prompt based on file type and request
        prompt = self._build_analysis_prompt(content, file_info, request)
        
        # Call AI service
        api_request = GeminiRequest(
            prompt=prompt,
            max_tokens=4000
        )
        
        response = await gemini_client.generate_text(api_request)
        
        # Structure the analysis results
        result = {
            "path": str(path_obj),
            "type": file_info.get("type", "unknown"),
            "language": file_info.get("language"),
            "analysis": response.text,
            "request": request
        }
        
        return result
    
    async def summarize_content(
        self, 
        file_path: Union[str, Path], 
        max_length: int = 500
    ) -> Dict[str, Any]:
        """
        Generate a concise summary of file content.
        
        Args:
            file_path: Path to the file to summarize
            max_length: Maximum length of the summary in characters
            
        Returns:
            Dictionary with summary results
        """
        path_obj = Path(file_path)
        
        # Check if file exists
        if not path_obj.exists():
            return {"error": f"File not found: {path_obj}"}
        
        # Get file info
        file_info = detect_file_type(path_obj)
        
        # Read file content
        try:
            with open(path_obj, 'r', encoding='utf-8', errors='replace') as f:
                content = f.read()
        except Exception as e:
            self._logger.error(f"Error reading file: {str(e)}")
            return {"error": f"Error reading file: {str(e)}"}
        
        # Generate summarization prompt
        prompt = f"""
Provide a concise summary of the following {file_info.get('language', 'text')} file. 
Focus on the main purpose, structure, and key components.
Keep the summary under {max_length} characters.

```
{content[:20000]}  # Limit to first 20K chars for very large files
```

Summary:
"""
        
        # Call AI service
        api_request = GeminiRequest(
            prompt=prompt,
            max_tokens=1000
        )
        
        response = await gemini_client.generate_text(api_request)
        
        # Return the summary
        return {
            "path": str(path_obj),
            "type": file_info.get("type", "unknown"),
            "language": file_info.get("language"),
            "summary": response.text,
            "content_length": len(content)
        }
    

    
    async def manipulate_content(
        self, 
        file_path: Union[str, Path], 
        instruction: str,
        transaction_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Manipulate file content based on a natural language instruction with rollback support.
        
        Args:
            file_path: Path to the file to manipulate
            instruction: Natural language instruction for the manipulation
            transaction_id: Optional transaction ID for rollback tracking
            
        Returns:
            Dictionary with manipulation results including old and new content
        """
        path_obj = Path(file_path)
        
        # Check if file exists
        if not path_obj.exists():
            return {"error": f"File not found: {path_obj}"}
        
        # Get file info
        file_info = detect_file_type(path_obj)
        
        # Check if this is a text file that can be manipulated
        if file_info.get("binary", False):
            return {"error": f"Cannot manipulate binary file: {path_obj}"}
        
        # Read current content
        try:
            with open(path_obj, 'r', encoding='utf-8', errors='replace') as f:
                original_content = f.read()
        except Exception as e:
            self._logger.error(f"Error reading file: {str(e)}")
            return {"error": f"Error reading file: {str(e)}"}
        
        # Generate manipulation prompt
        prompt = self._build_manipulation_prompt(original_content, file_info, instruction)
        
        # Call AI service
        api_request = GeminiRequest(
            prompt=prompt,
            max_tokens=20000  # Large token limit for returning the full modified content
        )
        
        response = await gemini_client.generate_text(api_request)
        
        # Extract the modified content from the response
        modified_content = self._extract_modified_content(response.text, original_content)
        
        # Generate diff
        diff = diff_manager.generate_diff(original_content, modified_content)
        
        # Return the results
        result = {
            "path": str(path_obj),
            "type": file_info.get("type", "unknown"),
            "language": file_info.get("language"),
            "instruction": instruction,
            "original_content": original_content,
            "modified_content": modified_content,
            "diff": diff,
            "has_changes": original_content != modified_content
        }
        
        return result
    
    async def search_content(
        self,
        file_path: Union[str, Path],
        query: str,
        context_lines: int = 2
    ) -> Dict[str, Any]:
        """
        Search for relevant sections in a file based on a query.
        
        Args:
            file_path: Path to the file to search
            query: Natural language search query
            context_lines: Number of context lines to include around matches
            
        Returns:
            Dictionary with search results
        """
        path_obj = Path(file_path)
        
        # Check if file exists
        if not path_obj.exists():
            return {"error": f"File not found: {path_obj}"}
        
        # Get file info
        file_info = detect_file_type(path_obj)
        
        # Check if this is a text file that can be searched
        if file_info.get("binary", False):
            return {"error": f"Cannot search binary file: {path_obj}"}
        
        # Read content
        try:
            with open(path_obj, 'r', encoding='utf-8', errors='replace') as f:
                content = f.read()
        except Exception as e:
            self._logger.error(f"Error reading file: {str(e)}")
            return {"error": f"Error reading file: {str(e)}"}
        
        # Generate search prompt
        prompt = f"""
Search the following {file_info.get('language', 'text')} file for sections that match this query: "{query}"

For each matching section, provide:
1. Line numbers (approximate)
2. The relevant code/text section
3. A brief explanation of why it matches the query

```
{content[:50000]}  # Limit to first 50K chars for very large files
```

Search results:
"""
        
        # Call AI service
        api_request = GeminiRequest(
            prompt=prompt,
            max_tokens=4000
        )
        
        response = await gemini_client.generate_text(api_request)
        
        # Parse the search results to extract matches
        matches = self._parse_search_results(response.text, content, context_lines)
        
        # Return the results
        return {
            "path": str(path_obj),
            "type": file_info.get("type", "unknown"),
            "language": file_info.get("language"),
            "query": query,
            "matches": matches,
            "match_count": len(matches)
        }
    
    def _build_analysis_prompt(
        self, 
        content: str, 
        file_info: Dict[str, Any], 
        request: Optional[str]
    ) -> str:
        """
        Build a prompt for content analysis.
        
        Args:
            content: The file content
            file_info: Information about the file
            request: Specific analysis request
            
        Returns:
            A prompt string for the AI service
        """
        file_type = file_info.get("type", "unknown")
        language = file_info.get("language", "unknown")
        
        # Adjust analysis based on file type and language
        analysis_focus = ""
        if language == "Python":
            analysis_focus = """
- Identify main functions and classes
- Describe the overall code structure
- Note any imports and dependencies
- Identify potential bugs or code issues
- Suggest improvements or best practices
"""
        elif language == "JavaScript" or language == "TypeScript":
            analysis_focus = """
- Identify key functions and modules
- Note any imports, frameworks, or libraries used
- Analyze the code structure and patterns
- Identify potential bugs or code issues
- Suggest improvements or best practices
"""
        elif language == "HTML" or language == "CSS":
            analysis_focus = """
- Describe the document structure
- Identify key components or sections
- Note any external resources or dependencies
- Analyze accessibility and best practices
- Suggest improvements
"""
        elif file_type == "document" or language == "Markdown":
            analysis_focus = """
- Summarize the main topics and sections
- Identify key points and arguments
- Note the document structure and organization
- Analyze clarity and coherence
- Suggest improvements
"""
        elif "config" in file_type.lower() or file_type in ["JSON", "YAML", "TOML"]:
            analysis_focus = """
- Identify key configuration settings
- Explain the purpose of important parameters
- Note any environment-specific settings
- Identify potential issues or missing values
- Suggest improvements or best practices
"""
        
        # Create prompt based on request and file type
        if request:
            prompt = f"""
Analyze the following {language} file with this specific request: "{request}"

```
{content[:50000]}  # Limit to first 50K chars for very large files
```

Analysis:
"""
        else:
            prompt = f"""
Analyze the following {language} file.

{analysis_focus}

```
{content[:50000]}  # Limit to first 50K chars for very large files
```

Analysis:
"""
        
        return prompt
    
    def _build_manipulation_prompt(
        self, 
        content: str, 
        file_info: Dict[str, Any], 
        instruction: str
    ) -> str:
        """
        Build a prompt for content manipulation.
        
        Args:
            content: The original file content
            file_info: Information about the file
            instruction: Manipulation instruction
            
        Returns:
            A prompt string for the AI service
        """
        language = file_info.get("language", "unknown")
        
        prompt = f"""
You are given a {language} file and a request to modify it.

File content:
```
{content}
```

Request: {instruction}

Your task is to modify the file according to the request, maintaining the integrity, style, and purpose of the original file.
Return the ENTIRE modified content, not just the changed parts.
Only make changes that directly address the request.

Modified file content:
```
"""
        
        return prompt
    
    def _extract_modified_content(self, response: str, original_content: str) -> str:
        """
        Extract the modified content from the AI response.
        
        Args:
            response: The AI service response
            original_content: The original file content
            
        Returns:
            The modified content
        """
        # Try to extract content between ```
        match = re.search(r'```(?:.*?)\n(.*?)```', response, re.DOTALL)
        if match:
            return match.group(1)
        
        # If no code block, look for specific patterns indicating the start of content
        patterns = [
            r'Modified file content:\n(.*)',
            r'MODIFIED CONTENT:\n(.*)',
            r'Here\'s the modified content:\n(.*)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, response, re.DOTALL)
            if match:
                return match.group(1).strip()
        
        # If no clear content found, return the full response
        # (or the original content if response clearly isn't just content)
        if len(response.splitlines()) < 5 or len(response) > len(original_content) * 1.5:
            self._logger.warning("Could not clearly identify modified content, using original")
            return original_content
        
        return response.strip()
    
    
    def _parse_search_results(
        self, 
        response: str, 
        content: str, 
        context_lines: int
    ) -> List[Dict[str, Any]]:
        """
        Parse search results from the AI response.
        
        Args:
            response: The AI service response
            content: The original file content
            context_lines: Number of context lines to include
            
        Returns:
            A list of match dictionaries
        """
        # Split content into lines for context
        content_lines = content.splitlines()
        
        # Look for patterns like "Lines 10-15" or "Line 20"
        line_patterns = [
            r'Lines? (\d+)(?:-(\d+))?',  # Standard "Line X" or "Lines X-Y"
            r'L(\d+)(?:-L(\d+))?',       # Shortened "LX" or "LX-LY"
            r'(\d+)(?:-(\d+))?\s*:',     # Line numbers with colon "X:" or "X-Y:"
        ]
        
        # Matches to return
        matches = []
        
        # Process multi-line response sections separately
        sections = re.split(r'\n\s*\n', response)
        
        for section in sections:
            # Skip empty sections
            if not section.strip():
                continue
                
            # Look for line number patterns
            line_start = None
            line_end = None
            
            for pattern in line_patterns:
                line_match = re.search(pattern, section)
                if line_match:
                    line_start = int(line_match.group(1))
                    if line_match.group(2):
                        line_end = int(line_match.group(2))
                    else:
                        line_end = line_start
                    break
            
            # If no line numbers found, continue to next section
            if line_start is None:
                continue
            
            # Extract code block if present
            code_block = None
            code_match = re.search(r'```(?:.*?)\n(.*?)```', section, re.DOTALL)
            if code_match:
                code_block = code_match.group(1)
            
            # Extract explanation
            explanation = section
            if code_block:
                explanation = re.sub(r'```(?:.*?)\n.*?```', '', explanation, flags=re.DOTALL)
            explanation = re.sub(r'Lines? \d+(?:-\d+)?:?', '', explanation, flags=re.DOTALL)
            explanation = explanation.strip()
            
            # Get context lines
            context_start = max(0, line_start - 1 - context_lines)
            context_end = min(len(content_lines) - 1, line_end - 1 + context_lines)
            
            # Get the actual content with context
            match_content = '\n'.join(content_lines[context_start:context_end + 1])
            
            # Create match entry
            match = {
                "line_start": line_start,
                "line_end": line_end,
                "context_start": context_start + 1,  # 1-indexed for display
                "context_end": context_end + 1,      # 1-indexed for display
                "content": match_content,
                "explanation": explanation
            }
            
            matches.append(match)
        
        return matches

# Global content analyzer instance
content_analyzer = ContentAnalyzer()
</file>

<file path="MD/MDHelpers/context.md">
# I couldnt give you all teh files i have currently in repository so i haev thsi file to provide you some conetxxt regaridng teh files you may not be able to directly see. Aswell as a directopry tree/structure/hiererechy
## heres a breif description of each .py file you cannot directly see / see the code in them
---
**File: `angela/workflows/sharing.py`**
`angela/workflows/sharing.py` facilitates sharing workflows by enabling their export into packaged `.angela-workflow` zip files and subsequent import into the Angela system. It defines a `WorkflowExportMetadata` Pydantic model to structure package information, including ID, name, version, author, timestamps, and a SHA-256 checksum generated by `hashlib` for data integrity. The `WorkflowSharingManager` class orchestrates the export process by packaging `workflow.json` (workflow data), `metadata.json`, and a `README.md` into a zip archive, and the import process by extracting, validating the checksum, and adding the workflow via `WorkflowManager`. Export functionality can optionally detect external dependencies like Python or Node.js versions by asynchronously running shell commands (e.g., `python --version`) and includes this in the metadata. The module robustly utilizes `tempfile` for temporary directories, `datetime` for timestamps, `uuid` for unique package IDs, and `pathlib` for filesystem path manipulations.
---
**File: `angela/workflows/manager.py` (inferred from context)**
The file `angela/workflows/manager.py` provides the core `WorkflowManager` class for defining, storing, retrieving, and executing reusable command sequences, known as workflows, within the Angela CLI. It utilizes Pydantic models, `WorkflowStep` (detailing command, explanation, optionality, confirmation needs) and `Workflow` (encompassing name, description, steps, variables, timestamps, tags, author), to structure workflow data. Workflows are persisted in a `workflows.json` file within the application's configuration directory (`CONFIG_DIR`), with the manager handling loading at startup and saving upon modification, including `datetime` to ISO format serialization. A key feature is the `define_workflow_from_natural_language` async method, which leverages an AI (Gemini client) and a `TaskPlanner` to convert user descriptions into structured workflow steps and identify potential variables. Workflow execution involves substituting provided variable values into command templates, converting the workflow into a `TaskPlan`, and then running this plan via the `task_planner`, supporting both regular execution and dry runs.
---
**File: `angela/ai/content_analyzer_extensions.py`**
The `angela/ai/content_analyzer_extensions.py` file introduces `EnhancedContentAnalyzer`, a class that extends the base `ContentAnalyzer` to provide specialized analysis for a wider range of file types and programming languages. It employs a `LANGUAGE_HANDLERS` dictionary to route file analysis requests to language-specific async methods, such as `_analyze_typescript` or `_analyze_json`, based on detected file information from `_get_file_info`. For instance, `_analyze_typescript` uses custom AI prompts for TypeScript code analysis via `_get_ai_analysis` (calling Gemini) and regex patterns (in `_extract_typescript_types`) to identify types and interfaces. Similarly, `_analyze_json` validates JSON content using `json.loads`, infers a basic schema through `_infer_json_schema` by recursively examining data types, and leverages AI for a human-readable structural analysis. If no specific handler is found for a language, the `EnhancedContentAnalyzer` falls back to the `analyze_content` method of its parent class, ensuring general analysis capabilities remain.
---
**File: `angela/ai/parser.py`**
The `angela/ai/parser.py` file is responsible for parsing responses from an AI model, aiming to convert potentially unstructured text into a structured `CommandSuggestion` object. It defines the `CommandSuggestion` Pydantic model, which specifies the expected fields: `intent`, `command`, `explanation`, and optional `additional_info`, ensuring data integrity and providing typed access. The core `parse_ai_response` function intelligently attempts to locate and extract JSON data from the AI's output, specifically looking for JSON within markdown code blocks (e.g., ```json ... ```) or assuming the entire response is JSON. After extracting the JSON string, it uses `json.loads` for parsing and then Pydantic for validation against the `CommandSuggestion` model, logging success or errors. In cases of `json.JSONDecodeError` or Pydantic `ValidationError`, a fallback mechanism employs regular expressions (`re.search`) to try and salvage at least the `command` string, enhancing the parser's resilience to malformed AI responses.
---
**File: `angela/ai/confidence.py`**
`angela/ai/confidence.py` introduces the `ConfidenceScorer` class, designed to evaluate and assign a numerical confidence score (ranging from 0.0 to 1.0) to AI-generated command suggestions. The primary method, `score_command_confidence`, aggregates scores from multiple weighted heuristics: `_check_history` (queries `history_manager` for command frequency and success rate), `_check_complexity` (compares token counts of request and command), `_check_entities` (basic check for entity type matches like files/dirs), and `_check_command_flags` (looks for unusual/conflicting flags). Each heuristic function, like `_check_complexity` which compares request and command token lengths, contributes a value that is then weighted into the final score. The entity check (`_check_entities`) uses simple string matching for terms like "file" or "directory" and `re.findall` for path patterns. The module ensures the final confidence score remains within the 0.0 to 1.0 range and logs the breakdown of contributing factors for debuggability.
---
**File: `angela/config.py` (inferred from content)**
This configuration management file, `angela/config.py`, establishes a `ConfigManager` class to handle application settings using TOML for file-based configuration and environment variables for sensitive data like API keys. It employs Pydantic models (`ApiConfig`, `UserConfig`, `AppConfig`) to define a clear structure for settings such as Gemini API keys, default project root (`Path`), `confirm_all_actions` (bool), and `debug` mode, ensuring type validation. The manager dynamically selects TOML parsing libraries (`tomllib` for Python 3.11+ or `tomli` for older versions, and `tomli-w` for writing), loading from a predefined `CONFIG_FILE` path and `.env` files via `python-dotenv`. `load_config` reads the TOML file, populates the Pydantic models, and gracefully handles potential `TOMLDecodeError` or missing files by falling back to defaults or saving a new default configuration. The `save_config` method serializes the current `AppConfig` model (converting `Path` objects to strings for TOML compatibility) back to the configuration file, while a global `config_manager` instance ensures the loaded configuration is immediately available upon module import.
---
**File: `angela/cli/files.py` (inferred from content)**
This file, `angela/cli/files.py`, defines a Typer-based command-line interface application for managing file and directory operations within the Angela CLI, offering an enhanced user experience through the `rich` library. It implements common filesystem commands such as `ls` (with detailed table views via `rich.Table` and color-coding), `mkdir`, `rmdir`, `touch`, `cat` (with syntax highlighting using `rich.Syntax` based on `context_manager.get_file_info`), `rm`, `cp`, `mv`, and `write` (with interactive content input via `rich.Prompt`). These commands primarily delegate their core logic to async functions from `angela.execution.filesystem` (e.g., `create_directory`, `read_file`) and use `angela.context.context_manager` for path resolution and file metadata. Advanced commands include `find` for pattern-based file searching via `context_manager.find_files` and `info` for displaying detailed file/directory information using `rich.Panel` and content previews. A crucial feature is the `rollback` command, which interacts with `angela.execution.rollback.rollback_manager` to list recent operations and allow users to undo them if backups are available, confirming actions with `rich.Confirm`.
---
**File: `angela/cli/workflows.py`**
This file, `angela/cli/workflows.py`, implements a Typer-based command-line interface for managing Angela workflows, allowing users to list, create, run, delete, show, export, and import these reusable command sequences. It relies on `angela.workflows.manager.workflow_manager` for core operations like defining workflows (interactively via `rich.Prompt` or from natural language in a file via `create`), executing them with variable substitution (`run`), and managing their lifecycle (`list`, `delete`, `show`). The `export` and `import` commands interface with `angela.workflows.sharing.workflow_sharing_manager` to package workflows into shareable `.angela-workflow` archives and to integrate received packages into the system, handling potential renames or replacements. User interaction is enhanced using the `rich` library, providing formatted tables for listing workflows (`rich.Table`), detailed panels for showing workflow steps via `terminal_formatter.display_workflow`, and interactive prompts/confirmations (`rich.Prompt`, `rich.Confirm`). The `run` command supports dry-run mode for previewing execution and accepts variables via command-line options (`--var NAME=VALUE`), which are then passed to the `workflow_manager` for execution within the current `context_manager` context.
---
**File: `angela/context/history.py`**
`angela/context/history.py` implements the `HistoryManager` class to record and analyze user command execution history, persisting data in `command_history.json` (for `CommandRecord`s) and `command_patterns.json` (for `CommandPattern`s) within the `CONFIG_DIR`. It uses a `CommandRecord` class to store detailed information about each command execution, including the command string, natural language request, success status, ISO-formatted timestamp, output, error, and risk level. The `CommandPattern` class tracks metrics like execution count, success rate, and last used timestamp for base commands (e.g., "git commit", extracted by `_extract_base_command`), which are updated via `_update_patterns` if `auto_learn_patterns` preference is enabled. `HistoryManager` loads history and patterns upon initialization, trims history based on `preferences_manager.preferences.context.max_history_items`, and provides methods to retrieve recent commands, query command frequency/success rates, and search for similar past commands using Jaccard similarity on tokenized natural requests. This historical data is crucial for features like adaptive confirmation scoring, command suggestions, and potentially for AI fine-tuning or error recovery within the Angela CLI.
---
**File: `angela/execution/rollback.py`**
This file, `angela/execution/rollback.py`, implements a `RollbackManager` to provide undo functionality for file and directory operations performed by the Angela CLI, storing its state in `operation_history.json`. It defines an `OperationRecord` class to store details of each recorded action, including its type (e.g., "create_file", "delete_directory"), parameters, ISO-formatted timestamp, and the path to any created backup within the `BACKUP_DIR`. The manager loads this history on initialization and saves updates when `record_operation` is called after a filesystem action. The `rollback_operation` async method is central to the undo logic: based on the `operation_type` and `backup_path` from the selected `OperationRecord`, it reverses the original action, such as deleting a created file or restoring a deleted file/directory from its backup using `shutil` functions like `copy2` or `copytree`. Users can view recent undoable operations (formatted by `_get_operation_description`) via `get_recent_operations`, and upon successful rollback, the manager truncates the history to reflect the undone state.
---
---
**File: `angela/safety/adaptive_confirmation.py`**
`angela/safety/adaptive_confirmation.py` implements an intelligent user confirmation system that adapts its prompting behavior based on command risk, execution history, and user preferences. It leverages `prompt_toolkit`'s `yes_no_dialog` for interactive user consent and `rich` library components (`Console`, `Panel`, `Syntax`, `Table`) for presenting detailed, styled information, including command syntax, risk levels (using `CONFIRMATION_STYLES`), impact analysis, and previews. The core async function `get_adaptive_confirmation` determines whether to auto-execute a command by consulting `preferences_manager` (for trusted commands) and `history_manager` (for frequency/success rate), or to proceed with explicit user prompting. It tailors the confirmation UI: `_get_detailed_confirmation` is used for high/critical risk operations showing comprehensive details and impact tables, while `_get_simple_confirmation` provides a more concise prompt for lower risks; dry runs (`_show_dry_run_preview`) bypass confirmation entirely. After a successful execution of certain commands, `offer_command_learning` may prompt the user to add the command to their trusted list, further personalizing the safety behavior.
---
**File: `angela/safety/classifier.py`**
`angela/safety/classifier.py` is responsible for assessing the potential danger of shell commands by classifying their risk level and analyzing their likely impact on the system. The `classify_command_risk` function determines a command's risk by matching it against a predefined dictionary of regular expressions, `RISK_PATTERNS` (mapping risk levels to regexes and reasons, e.g., `rm -rf` as CRITICAL) and `OVERRIDE_PATTERNS` (for special cases), categorizing it from "SAFE" to "CRITICAL" as defined in `angela.constants.RISK_LEVELS`. These patterns are designed to identify operations like file deletion, package management, privileged execution (`sudo`), or disk formatting, assigning appropriate risk scores. The `analyze_command_impact` function performs a lexical analysis of the command using `shlex.split` to tokenize it, then heuristically identifies potential operations (e.g., delete, create, read), affected files/directories, and flags if the command is destructive or modifies/creates files. This classification and impact analysis data is then consumed by other safety modules to determine the appropriate level of user confirmation and the details to display.
---
**File: `angela/safety/confirmation.py`**
`angela/safety/confirmation.py` manages the user interaction phase of the safety workflow, presenting detailed information about a command and prompting for explicit user approval before execution. The `requires_confirmation` function determines if a prompt is necessary by checking the command's risk level against `DEFAULT_CONFIRMATION_REQUIREMENTS` and global user settings like `config_manager.config.user.confirm_all_actions`. The `get_confirmation` async function orchestrates the display using the `rich` library, showing the command with `Syntax` highlighting, its `risk_level` (colored using `RISK_COLORS` and named via `RISK_LEVEL_NAMES`), the `risk_reason`, an impact analysis table generated by `format_impact_analysis`, and any available `preview`. It utilizes `rich.Panel` for structuring information clearly and `rich.Confirm.ask` to get a boolean (yes/no) response from the user regarding whether to proceed with the command. For "CRITICAL" risk operations or if `dry_run` is true, additional specific warnings or informational messages are displayed to ensure the user is fully aware of the context and potential consequences.
---
**File: `angela/safety/preview.py`**
`angela/safety/preview.py` is dedicated to generating predictive textual summaries of what shell commands are expected to do, without actually executing them, to aid user decision-making during safety checks. It features a main `generate_preview` async function that dispatches to command-specific async handlers (e.g., `preview_mkdir`, `preview_rm`, `preview_ls`) listed in the `PREVIEWABLE_COMMANDS` dictionary, based on the parsed command (tokenized using `shlex.split`). These specific preview functions, like `preview_rm` or `preview_cp`, analyze command arguments, check file/directory existence and types using `pathlib.Path`, expand glob patterns using `glob.glob`, and then construct a human-readable summary of intended actions, including warnings for overwrites or non-existent paths. For example, `preview_cat` estimates file size and line count for text files or warns about displaying binary content, while `preview_find` describes the search scope and criteria. If no specialized previewer exists for a command, `generic_preview` attempts to execute it with common dry-run flags (e.g., `--dry-run`, `--print`) using `execution_engine.execute_command`, capturing its output as the preview.
---
**File: `angela/safety/validator.py`**
`angela/safety/validator.py` enforces safety policies by validating commands and operations against a set of predefined rules and system constraints before they can proceed to execution. The `validate_command_safety` function scrutinizes raw shell commands, checking them against `DANGEROUS_PATTERNS` (a list of regexes for forbidden actions like `rm -rf /` or `mkfs /dev/sda`) and ensuring necessary superuser privileges (checked via `is_superuser` which uses `os.geteuid`, and `ROOT_PATTERNS` regex list) are met if the current user is not root. The `validate_operation` function handles abstracted operations (e.g., 'create_file', 'delete_directory'), leveraging `check_file_permission` (which employs `os.access`) to verify read/write permissions for specified `Path` objects and checking against deletion of system directories. It defines a custom `ValidationError` exception, although it is not explicitly raised in the provided snippet, it's implied for severe validation failures not handled by returning a boolean and message. This module acts as a critical first line of defense, aiming to prevent overtly harmful or permission-violating operations from even being considered for execution by the Angela CLI.
---
**File: `angela/execution/error_recovery.py`:**
The `angela/execution/error_recovery.py` file implements the `ErrorRecoveryManager` class, a sophisticated system designed to intelligently handle and attempt recovery from errors encountered during multi-step command executions within the Angela CLI. Its primary entry point, the async `handle_error` method, orchestrates a sequence involving error information extraction (command, stderr), detailed analysis via `_analyze_error` which uses an external `error_analyzer` and internal regex patterns from `_get_common_error_patterns`, and generation of potential `RecoveryStrategy` enums (like `RETRY`, `MODIFY_COMMAND`, `PREPARE_ENV`) through `_generate_recovery_strategies`. Strategy generation is multi-faceted: `_generate_recovery_strategies` first attempts to derive actions by parsing fix suggestions from the error analysis using regex in `_parse_fix_suggestion` and `_create_strategy_from_pattern_fix`, and if these heuristic methods yield insufficient results, it queries the `gemini_client` via `_generate_ai_recovery_strategies` with a structured JSON-expecting prompt for AI-driven solutions. These strategies, which are standard Python dictionaries adhering to a defined structure including type, command, description, and confidence, are then sorted by their confidence score, always including fallback options like simple retry or skipping the problematic step.
Automatic recovery, determined by `_can_auto_recover`, is attempted for high-confidence strategies or those with a proven success record tracked in the internal `_recovery_history` dictionary (which logs successful strategy applications like `{ "type:command": {"success_count": N}}`). The `_execute_recovery_strategy` async method performs the actual recovery by dispatching actions based on the strategy type, often involving command execution via the `angela.execution.engine.execution_engine`, where safety checks might be selectively skipped for retries or enforced for newly generated commands. Notably, strategies such as `PREPARE_ENV` can execute a preparatory command (e.g., `mkdir` for a missing directory, or `apt-get install` for a missing package) and, if successful and indicated by a `retry_original` flag within the strategy dictionary, will subsequently re-attempt the original failed command. If automatic recovery isn't viable or fails, `_guided_recovery` presents the generated strategies to the user via `terminal_formatter` for display and uses `prompt_toolkit.input_dialog` to capture their choice, subsequently executing the selected strategy. The system thus combines heuristic rule-based error matching, AI-powered suggestion generation, a learning mechanism from past successful recoveries, and user-guided intervention to maximize the chances of successful task completion.
----------
**Summary for `BackgroundMonitor.py`:**
This Python module implements an asynchronous `BackgroundMonitor` class for the Angela CLI, designed to proactively assist users by observing system state and activities through concurrent, restartable `asyncio` tasks. It actively monitors Git repository status by periodically running `git status -s`, analyzing changes like modified, untracked, or deleted files, and then generating contextual suggestions for commits or additions if significant activity is detected, subject to a cooldown period and repetition avoidance. The monitor also tracks file modifications within the project, identified by `_find_source_files`, and upon detecting changes, it invokes language-specific checkers such as `python -m py_compile` and `flake8` for Python or `node --check` and `eslint` for JavaScript to report syntax errors and linting issues. System resource monitoring is partially implemented, focusing on disk usage by executing platform-specific commands (`wmic` or `df`) via an asynchronous `_run_command` utility, and it alerts the user if usage exceeds a threshold and has significantly increased. All suggestions are managed to prevent repetition using a set of seen suggestions and are displayed via `terminal_formatter`, with overall monitoring controlled by `start_monitoring` and `stop_monitoring` methods that manage the lifecycle of the underlying `asyncio` tasks.
**Summary for `ProjectInference.py`**
The `ProjectInference` Python module provides advanced, asynchronous capabilities to analyze a given project directory, aiming to deduce its primary type, technological stack, dependencies, and structural characteristics using file system inspection and pattern matching. It determines the project type (e.g., Python, Node, Java) by scoring matches against predefined `PROJECT_SIGNATURES` that include characteristic files (like `requirements.txt` or `package.json`), directories (e.g., `venv`, `node_modules`), and common file extensions, capable of identifying mixed-type projects by combining high-scoring candidates. Framework detection is achieved by cross-referencing project files and contents against `FRAMEWORK_SIGNATURES` (e.g., identifying Django via `manage.py` or React via `package.json` dependencies) and by directly parsing dependency lists from files like `requirements.txt` or `package.json` using dedicated analyzer methods. The module meticulously extracts project dependencies by parsing specific manifest files corresponding to the detected project type, such as `requirements.txt`, `setup.py`, and `pyproject.toml` for Python projects, or `package.json` for Node.js projects, detailing dependency names, version specifiers, and source files. It identifies and lists important project files, including signature files that confirmed the project type, common documentation like READMEs and LICENSEs, and attempts to locate potential entry point files (e.g., `main.py`, `index.js`) based on conventional naming within the project structure. Project structure analysis involves counting files by extension, identifying prominent subdirectories (ignoring common ones like `.git` or `node_modules`), and generating a hierarchical, depth-limited tree representation of the directory layout using the recursive `_generate_directory_structure` method. All inferred information, including project root, type, detected files, frameworks, dependencies, and structural details, is compiled into a comprehensive dictionary, with results cached per project root path to optimize subsequent analyses of the same project.
**`angela/cli/file_extensions.py`**
This module extends Angela's command-line interface (CLI) with advanced file-related functionalities, operating within the broader "Angela" application by interfacing with its context management, file resolution, and activity tracking systems. Its primary purpose is to empower users with sophisticated commands for resolving ambiguous file references, extracting file paths from text, viewing recently or frequently accessed files, and inspecting detailed project information. Technically, it leverages `typer` for command-line argument parsing and command definition, and `rich` for creating user-friendly, formatted console output like tables and panels, while also using `asyncio` to run asynchronous operations provided by other Angela modules. Key commands include `resolve` which uses `file_resolver.resolve_reference` and logs views with `file_activity_tracker`, and `extract` which processes text to find and display file references. The `recent` and `active` commands query the `file_activity_tracker` to present historical file interaction data in structured tables. Finally, the `project` command utilizes `context_manager` and `context_enhancer` to gather and present a rich summary of the current project's attributes, dependencies, and structure.
**`angela/cli/files.py`**
This file defines core file and directory manipulation commands for the Angela CLI, offering an enhanced, context-aware alternative to standard shell utilities by integrating with Angela's `context_manager` and `rollback_manager`. It aims to provide a comprehensive suite of operations such as listing (`ls`), creating (`mkdir`, `touch`), deleting (`rmdir`, `rm`), copying (`cp`), moving (`mv`), reading (`cat`), and writing (`write`) files, all augmented with rich console output and Angela's operational oversight. The module heavily relies on `typer` for its command structure and `rich` for visually appealing outputs, including tables, syntax-highlighted file previews, and interactive prompts; asynchronous filesystem operations are imported from `angela.execution.filesystem`. Commands like `ls` offer detailed views with file types and sizes, while `cat` provides syntax highlighting based on language detection from `context_manager`. Operations such as `mkdir` or `rm` include safety features like `--dry-run` and interact with `rollback_manager` to allow for undoing actions. Furthermore, it includes a `find` command for pattern-based file searching and an `info` command to display detailed metadata and previews for specified files or directories.
**`angela/context/history.py`**
The `angela/context/history.py` module provides the `HistoryManager` class, a crucial component for logging and analyzing user command interactions within the Angela ecosystem, supporting features like command suggestions and usage pattern identification. Its purpose is to persistently record details of each executed command—including the raw command, natural language query, success status, output, and risk level—and to derive actionable insights from this historical data. Technical implementation involves `CommandRecord` and `CommandPattern` data classes, with history and learned patterns stored in JSON files (`command_history.json`, `command_patterns.json`) managed by `config_manager` and influenced by `preferences_manager`. The `add_command` method logs new entries and triggers `_update_patterns` which uses `_extract_base_command` to intelligently group commands (e.g., "git commit") and update their frequency and success rates. Retrieval methods like `get_recent_commands`, `get_command_frequency`, and `get_command_success_rate` allow access to this data. Advanced analysis functions include `search_similar_command` using Jaccard similarity on natural language requests and `get_common_command_contexts` to identify typical command sequences.
**`angela/context/file_activity.py`**
This module, `angela/context/file_activity.py`, implements the `FileActivityTracker` to monitor and log interactions with files and directories within the Angela environment, providing a basis for features like "recently used files" and project activity analysis. Its core purpose is to capture various file events such as creations, modifications, deletions, and views, associating them with metadata like timestamps, the triggering command, and custom details for later retrieval and analysis. The system uses an `ActivityType` enum to classify events and a `FileActivity` class to structure logged data, which is maintained in an in-memory list with a configurable maximum size and integrated with `session_manager` to enrich Angela's session context. The `track_activity` method and its specialized wrappers (e.g., `track_file_creation`) are central to logging, appending new `FileActivity` objects and updating the session. Users can query this log via methods like `get_recent_activities`, which returns time-sorted activities filterable by type, and `get_most_active_files`, which aggregates data to highlight frequently accessed files. The `FileActivity` class supports dictionary conversion for serialization, although the primary activity list is currently managed in memory.
---
**`angela/context/preferences.py`**
This module provides a `PreferencesManager` class to handle user-configurable settings for the Angela application, influencing behavior related to command trust, UI presentation, and context management. It utilizes Pydantic `BaseModel`s (`TrustPreferences`, `UIPreferences`, `ContextPreferences`, nested under `UserPreferences`) to define a structured, validated schema for all preferences, which are persistently stored and retrieved from a `preferences.json` file located via `config_manager`. The `PreferencesManager` loads these settings upon initialization, creates a default file if one doesn't exist, and provides methods to update and save any changes back to the JSON file. Key functionalities include the `should_auto_execute` method, which determines if a command requires user confirmation based on its risk level (from `angela.constants.RISK_LEVELS`) and the user's `TrustPreferences`, including lists of explicitly trusted or untrusted commands. Users can dynamically modify these trusted/untrusted command lists through dedicated methods like `add_trusted_command`. A global instance, `preferences_manager`, makes these settings readily accessible throughout the Angela application, allowing other components to adapt their behavior accordingly.
---
**1. `angela/ai/analyzer.py`**
This module implements an `ErrorAnalyzer` class within Angela's AI capabilities, tasked with diagnosing command-line execution errors to offer users insightful feedback and potential solutions. It operates by matching error messages against a predefined list of `ERROR_PATTERNS` (regex, explanations, suggestions), analyzing command syntax with `shlex`, and checking for issues related to file references like non-existence or permission problems. The analyzer also consults the `history_manager` to find previously successful fixes for similar errors, enabling a degree of learning. Key methods like `_extract_key_error` simplify verbose errors, while `_check_file_references` intelligently suggests corrections for mistyped paths by looking for similar filenames in the parent directory. The `_analyze_command_structure` method identifies common syntactic pitfalls, such as missing arguments or malformed flags. Finally, `generate_fix_suggestions` consolidates all findings into a de-duplicated list of actionable advice for the user.
-----
**`angela/ai/content_analyzer.py` (ContentAnalyzer)**
The `angela/ai/content_analyzer.py` module provides the `ContentAnalyzer` class, empowering Angela with AI-driven functionalities to understand, summarize, manipulate, and search within file contents based on natural language instructions. It interfaces with an AI service (`gemini_client`), constructing detailed, asynchronous prompts that incorporate file content (truncated for token limits), detected file type (via `detect_file_type`), and the user's specific request. Core asynchronous methods include `analyze_content` for deep understanding, `summarize_content` for brevity, `manipulate_content` which attempts to apply changes and generates a `difflib` diff, and `search_content` for natural language querying of file text. Private methods like `_build_analysis_prompt` tailor AI requests for different file types and tasks, while `_extract_modified_content` and `_parse_search_results` robustly handle parsing the AI's textual output, often looking for markdown code blocks or specific line number patterns. This system allows Angela to offer intelligent assistance directly related to the substance of user files.
----
**`angela/ai/intent_analyzer.py` (IntentAnalyzer)**
This module defines the `IntentAnalyzer` for Angela's natural language understanding, designed to interpret user requests, identify the core intent (e.g., "file_search", "git_operation"), extract relevant entities, and manage ambiguity, potentially through interactive clarification. It employs request normalization by correcting common misspellings defined in `SPELLING_VARIATIONS` and then uses `difflib.SequenceMatcher` for fuzzy matching against predefined `INTENT_PATTERNS` to determine the most likely intent and a confidence score, outputting an `IntentAnalysisResult` Pydantic model. Entity extraction, performed by `_extract_entities`, uses intent-specific regular expressions to capture parameters like file paths or search terms from the normalized input. If ambiguity arises (e.g., multiple intents with close scores), the `get_interactive_disambiguation` method can leverage `prompt_toolkit.radiolist_dialog` to ask the user for clarification, refining the analysis. This system aims for robust interpretation of user commands, accommodating variations and offering a mechanism for resolving uncertainty.
----
**`angela/execution/hooks.py` (ExecutionHooks)**
The `angela/execution/hooks.py` module introduces the `ExecutionHooks` class, which integrates into Angela's command execution pipeline to automatically track file activities and enrich contextual understanding without explicit logging at every interaction point. It provides asynchronous `pre_execute_command` and `post_execute_command` methods that analyze command strings and their output for file paths using string parsing and regex, subsequently logging interactions like views, creations, or modifications with the `file_activity_tracker` using appropriate `ActivityType` enums. Specific common commands (e.g., `cat`, `rm`, `cp`, `echo >`) are explicitly handled in `post_execute_command` to infer the correct activity type, resolving paths against the current working directory from the provided context. Furthermore, `post_execute_file_operation` is tailored for Angela's internal filesystem calls, ensuring actions like `create_file` or `write_file` are accurately logged, thus building a comprehensive history of file interactions.
----
**`angela/context/file_detector.py`**
This module is crucial for Angela's contextual awareness, providing the `detect_file_type` function to identify file characteristics such as general type (e.g., image, text, source_code), specific programming language, MIME type, and binary status. It employs a multi-layered detection strategy, using Python's `mimetypes` library, extensive predefined dictionaries like `LANGUAGE_EXTENSIONS` (e.g., `.py` to Python) and `FILENAME_MAPPING` (e.g., `Dockerfile` to Docker), and checking for common `SHEBANG_PATTERNS` in the first line of text files. A binary check is performed by searching for null bytes in an initial chunk of the file, and the module also offers a `get_content_preview` function to display the beginning of text files. This detailed file information is then used by other Angela components for tasks like syntax highlighting, forming appropriate AI prompts, or deciding on safe file handling procedures.
----
Okay, here are the high-level, contextual explanations for the requested files, adhering to the sentence limits.
**File: `angela/intent/enhanced_task_planner.py` (10 Sentences)**
This file, located at `angela/intent/enhanced_task_planner.py`, defines the core logic for executing complex, multi-step tasks within the Angela CLI. Its primary purpose is to orchestrate advanced plans generated by the AI, going beyond simple command sequences. It introduces robust support for diverse step types including shell commands (`COMMAND`), sandboxed code execution (`CODE` - Python, JS, Shell), file manipulations (`FILE`), API calls (`API`), conditional branching (`DECISION`), and loops (`LOOP`). Key classes like `StepExecutionContext`, `DataFlowVariable`, and `ExecutionResult` manage state and data flow between these varied steps. The `EnhancedTaskPlanner` class contains the main execution loop (`execute_advanced_plan`) which handles dependency resolution, step execution via specific methods like `_execute_code_step` or `_execute_api_step`, and variable passing using `${variable}` syntax. Security for code execution is addressed via validation (`_validate_code_security`) and a sandboxing setup (`_setup_code_sandbox`). It integrates with the `ErrorRecoveryManager` (`_attempt_recovery`) for resilience against step failures. It also connects with the `RollbackManager` to record actions within transactions. Ultimately, this module enables Angela to autonomously handle sophisticated user requests requiring intricate sequences of actions and dynamic control flow. The global `task_planner` instance is replaced by this enhanced version to integrate these capabilities seamlessly.
--------
**File: `angela/toolchain/package_managers.py` (8 Sentences)**
Located at `angela/toolchain/package_managers.py`, this file provides integration with various software package managers. Its main purpose is to allow Angela to detect the appropriate package manager for a project (like pip, npm, yarn, poetry, cargo) and use it to install necessary dependencies, often as part of automated project scaffolding or feature addition. The central class, `PackageManagerIntegration`, contains methods like `detect_package_manager` which checks for indicator files (e.g., `requirements.txt`, `package.json`, `Cargo.toml`) and `install_dependencies` which orchestrates the installation process. Specific internal methods like `_install_pip_dependencies`, `_install_npm_dependencies`, etc., handle the nuances of each manager. It interacts with the `execution_engine` to run the actual installation commands (e.g., `pip install <package>`, `npm install <package>`). It also includes logic to infer the project type if not explicitly provided, ensuring the correct manager is invoked. This module automates a crucial part of the development setup process.
----------
**File: `angela/cli/rollback_commands.py` (8 Sentences)**
This file, `angela/cli/rollback_commands.py`, defines the command-line interface for Angela's enhanced rollback system. Its purpose is to expose the functionality of the `RollbackManager` (`angela/execution/rollback.py`) directly to the user via `typer` commands. It includes commands like `list` (to view recent operations or transactions), `operation <ID>` (to roll back a single specific action), `transaction <ID>` (to roll back a group of related actions), and `last` (as a shortcut for the most recent operation or transaction). These commands interact asynchronously with the `rollback_manager` to fetch history and trigger rollback actions. The file uses the `rich` library to display tables and panels for presenting rollback information clearly. It also incorporates confirmation prompts (`rich.prompt.Confirm`) before executing potentially irreversible rollbacks, ensuring user control over the undo process.
------
**File: `angela/execution/filesystem.py` (8 Sentences)**
Located at `angela/execution/filesystem.py`, this module offers a safe and reliable abstraction layer for performing common file system operations within Angela. It provides asynchronous functions like `create_directory`, `delete_directory`, `create_file`, `read_file`, `write_file`, `delete_file`, `copy_file`, and `move_file`. A key feature is its integration with the safety system (`check_operation_safety`) to validate operations before execution and prevent unintended dangerous actions. It defines a custom `FileSystemError` for specific error handling. Crucially, for potentially destructive operations (delete, write, move), it interacts with the `RollbackManager` by creating backups (`_backup_file`, `_backup_directory`) in a temporary location (`BACKUP_DIR`), enabling these operations to be undone. It leverages Python's standard `pathlib`, `os`, and `shutil` modules for the underlying file manipulations.
------
**File: `angela/review/feedback.py` (8 Sentences)**
This file, `angela/review/feedback.py`, manages the processing of user feedback to iteratively refine generated code or modify existing project files. Its central component is the `FeedbackManager` class. The core function `process_feedback` takes user feedback text and original code, constructs a detailed prompt using `_build_improvement_prompt`, and leverages the AI client (`ai/client.py`) to generate an improved code version along with an explanation. It utilizes the `DiffManager` (`review/diff_manager.py`) to compute and present the differences between the original and improved code. The module also supports project-wide refinement (`refine_project`), optionally focusing on specific files, and applying these generated changes back to the filesystem (`apply_refinements`), potentially creating backups. It includes helper functions for language detection (`_get_language_from_extension`) and identifying relevant files based on feedback (`_find_relevant_files`).
-------
**File: `angela/review/diff_manager.py` (8 Sentences)**
Located at `angela/review/diff_manager.py`, this module is responsible for generating and applying differences (diffs) between text strings or file contents. The main class `DiffManager` uses Python's built-in `difflib` module to perform these comparisons. Its primary function, `generate_diff`, creates a standard unified diff output showing additions and deletions between two versions of text. It also provides methods for generating diffs directly between files (`generate_file_diff`), comparing entire directories (`generate_directory_diff`), and creating HTML-formatted diffs (`generate_html_diff`). Additionally, it includes an `apply_diff` method (though noted as potentially simplified) to patch original content using a provided diff string. This manager is primarily used by the `FeedbackManager` to visualize code changes suggested by the AI.
--------
**File: `angela/generation/documentation.py` (8 Sentences)**
This file, `angela/generation/documentation.py`, houses the `DocumentationGenerator` class, responsible for automatically creating various documentation files for software projects using AI. It offers functions like `generate_readme`, `generate_api_docs`, `generate_user_guide`, and `generate_contributing_guide`. The process typically involves analyzing the target project (`_analyze_project`) to gather context (like project type, files, dependencies), constructing specific prompts (`_build_readme_prompt`, etc.), and then querying the Gemini AI (`ai/client.py`) to generate the content in Markdown format. For API documentation, it includes basic code parsing helpers (`_parse_python_file`, `_parse_js_file`, `_parse_java_file`) to extract information about classes and functions to feed into the AI prompt. It uses `_extract_markdown_content` to clean up the AI's response, ensuring well-formatted documentation output.
------
**File: `angela/generation/frameworks.py` (8 Sentences)**
Located at `angela/generation/frameworks.py`, this file provides specialized generators for creating boilerplate project structures tailored to popular software frameworks like React, Django, Flask, Spring, etc. The core `FrameworkGenerator` class uses a dictionary (`_framework_generators`) to map framework names to specific generation methods (e.g., `_generate_react`, `_generate_django`). These methods define a standard file layout for the framework and typically use AI calls via `_generate_content` or `_generate_file_content` to populate these files with appropriate starter code and configuration. For frameworks without a dedicated generator, it falls back to a generic AI-driven approach (`_generate_generic`) to plan the structure. This module allows Angela to quickly scaffold new projects with conventional layouts, interacting closely with the main `CodeGenerationEngine`.
----------
**File: `angela/intent/planner.py`**
Located at `angela/intent/planner.py`, this module serves as the core task planning engine for the Angela CLI, responsible for decomposing high-level user goals into structured, executable plans. It defines Pydantic models for both basic sequential plans (`TaskPlan`, `PlanStep`) and more complex, potentially non-linear plans (`AdvancedTaskPlan`, `AdvancedPlanStep`) supporting various action types like commands, code execution, file operations, API calls, decisions, and loops (`PlanStepType`). The central `TaskPlanner` class determines the required plan complexity (`_determine_complexity`) and orchestrates the plan generation by interacting with the AI model (`ai/client.py`). It builds specific prompts (`_build_planning_prompt`, `_build_advanced_planning_prompt`) incorporating user context and parses the AI's JSON response (`_parse_plan_response`, `_parse_advanced_plan_response`) into the corresponding plan model. While the execution of *advanced* plans is delegated (primarily to `enhanced_task_planner.py`), this module contains the logic for generating both basic and advanced plans and executing basic sequential plans (`_execute_basic_plan`). It is invoked by the `Orchestrator` for requests identified as needing multi-step execution. This file essentially translates abstract user goals into concrete, step-by-step instructions for Angela to follow.
-----
# Current Project Tree/Structure
```bash
.
.
├── MD
│   ├── ImplemenationsMD
│   │   ├── Phase_5_implementation.md
│   │   ├── Phase_6_implementation.md
│   │   ├── planner_implementation.md
│   │   ├── rollback_implementation.md
│   │   └── shell_enhancement.md
│   ├── MDHelpers
│   │   ├── Files.md
│   │   ├── Info.md
│   │   ├── context.md
│   │   └── tree.md
│   ├── Next-Steps.md
│   └── PhasesMD
│       ├── Phase1.md
│       ├── Phase2.md
│       ├── Phase3.md
│       ├── Phase4.md
│       ├── Phase5.md
│       ├── Phase6.md
│       └── Phase7.md
├── Makefile
├── README.md
├── angela
│   ├── __init__.py
│   ├── __main__.py
│   ├── ai
│   │   ├── __init__.py
│   │   ├── analyzer.py
│   │   ├── client.py
│   │   ├── confidence.py
│   │   ├── content_analyzer.py
│   │   ├── content_analyzer_extensions.py
│   │   ├── enhanced_prompts.py
│   │   ├── file_integration.py
│   │   ├── intent_analyzer.py
│   │   ├── parser.py
│   │   ├── prompts.py
│   │   └── semantic_analyzer.py
│   ├── cli
│   │   ├── __init__.py
│   │   ├── docker.py
│   │   ├── files.py
│   │   ├── files_extensions.py
│   │   ├── generation.py
│   │   ├── main.py
│   │   └── workflows.py
│   ├── config.py
│   ├── constants.py
│   ├── context
│   │   ├── __init__.py
│   │   ├── enhanced_file_activity.py
│   │   ├── enhancer.py
│   │   ├── file_activity.py
│   │   ├── file_detector.py
│   │   ├── file_resolver.py
│   │   ├── history.py
│   │   ├── manager.py
│   │   ├── preferences.py
│   │   ├── project_inference.py
│   │   ├── project_state_analyzer.py
│   │   ├── semantic_context_manager.py
│   │   └── session.py
│   ├── core
│   │   ├── __init__.py
│   │   ├── events.py
│   │   └── registry.py
│   ├── execution
│   │   ├── __init__.py
│   │   ├── adaptive_engine.py
│   │   ├── engine.py
│   │   ├── error_recovery.py
│   │   ├── filesystem.py
│   │   ├── hooks.py
│   │   ├── rollback.py
│   │   └── rollback_commands.py
│   ├── generation
│   │   ├── __init__.py
│   │   ├── architecture.py
│   │   ├── documentation.py
│   │   ├── engine.py
│   │   ├── frameworks.py
│   │   ├── planner.py
│   │   └── validators.py
│   ├── integrations
│   │   ├── __init__.py
│   │   ├── enhanced_planner_integration.py
│   │   └── semantic_integration.py
│   ├── intent
│   │   ├── __init__.py
│   │   ├── enhanced_task_planner.py
│   │   ├── models.py
│   │   ├── planner.py
│   │   └── semantic_task_planner.py
│   ├── interfaces
│   │   ├── __init__.py
│   │   ├── execution.py
│   │   └── safety.py
│   ├── monitoring
│   │   ├── __init__.py
│   │   ├── background.py
│   │   ├── network_monitor.py
│   │   └── notification_handler.py
│   ├── orchestrator.py
│   ├── review
│   │   ├── __init__.py
│   │   ├── diff_manager.py
│   │   └── feedback.py
│   ├── safety
│   │   ├── __init__.py
│   │   ├── adaptive_confirmation.py
│   │   ├── classifier.py
│   │   ├── confirmation.py
│   │   ├── preview.py
│   │   └── validator.py
│   ├── shell
│   │   ├── __init__.py
│   │   ├── advanced_formatter.py
│   │   ├── angela.bash
│   │   ├── angela.tmux
│   │   ├── angela.zsh
│   │   ├── angela_enhanced.bash
│   │   ├── angela_enhanced.zsh
│   │   ├── completion.py
│   │   ├── formatter.py
│   │   └── inline_feedback.py
│   ├── toolchain
│   │   ├── __init__.py
│   │   ├── ci_cd.py
│   │   ├── docker.py
│   │   ├── git.py
│   │   └── package_managers.py
│   ├── utils
│   │   ├── __init__.py
│   │   ├── enhanced_logging.py
│   │   └── logging.py
│   └── workflows
│       ├── __init__.py
│       ├── manager.py
│       └── sharing.py
├── pyproject.toml
├── pytest.ini
├── requirements.txt
├── scripts
│   ├── install.sh
│   └── uninstall.sh
├── setup.py

```
</file>

<file path="angela/ai/prompts.py">
"""
Prompt engineering for Angela CLI.

This module provides a comprehensive collection of prompts and templates for the Gemini API
with enhanced context information about the current environment, project structure, file activities,
and resolved references. All prompt building functionality is centralized in this file.

The module offers various specialized prompt templates for different use cases, including:
- Command generation with rich context awareness
- File operation prompts with project-specific knowledge
- Multi-step operation planning
- Error analysis and recovery suggestions
- Code generation and manipulation prompts
"""
from typing import Dict, Any, Optional, List, Tuple, Union
from pathlib import Path
import logging

from angela.utils.logging import get_logger

logger = get_logger(__name__)

# Base system instructions
SYSTEM_INSTRUCTIONS = """
You are Angela, an AI-powered command-line assistant integrated into the user's terminal shell.
Your goal is to help users by interpreting their natural language requests and translating them into appropriate shell commands or file operations.

Follow these guidelines:
1. Prioritize standard Linux shell commands that work across different distributions.
2. Focus on practical and efficient solutions that work in a terminal environment.
3. Be clear and direct about what suggested commands will do.
4. For file operations, prefer using built-in commands like mkdir, touch, rm, etc.
5. Format your responses in a structured JSON format for consistent parsing.
6. Consider the user's context, history, and project environment in your suggestions.
7. Offer informative explanations that help users learn terminal skills over time.
"""

# Examples for few-shot learning
EXAMPLES = [
    {
        "request": "Find all Python files in this project",
        "context": {"project_root": "/home/user/project", "project_type": "python"},
        "response": {
            "intent": "search_files",
            "command": "find . -name '*.py'",
            "explanation": "This command searches for files with the .py extension in the current directory and all subdirectories."
        }
    },
    {
        "request": "Show me disk usage for the current directory",
        "context": {"cwd": "/home/user/project"},
        "response": {
            "intent": "disk_usage",
            "command": "du -sh .",
            "explanation": "This command shows the disk usage (-s) in a human-readable format (-h) for the current directory."
        }
    },
    {
        "request": "Create a directory called 'test' and a file inside it",
        "context": {"cwd": "/home/user/project"},
        "response": {
            "intent": "file_creation",
            "command": "mkdir -p test && touch test/example.txt",
            "explanation": "This command creates a directory named 'test' and an empty file named 'example.txt' inside it. The -p flag ensures parent directories are created if needed."
        }
    },
    {
        "request": "Delete all temporary files in the current directory",
        "context": {"cwd": "/home/user/project"},
        "response": {
            "intent": "file_deletion",
            "command": "find . -name '*.tmp' -type f -delete",
            "explanation": "This command finds and deletes all files with the .tmp extension in the current directory and its subdirectories. Be careful as this will permanently delete matching files."
        }
    },
    {
        "request": "Move all JavaScript files to the src directory",
        "context": {"cwd": "/home/user/project", "project_type": "node"},
        "response": {
            "intent": "file_movement",
            "command": "mkdir -p src && find . -maxdepth 1 -name '*.js' -type f -exec mv {} src/ \\;",
            "explanation": "This command creates the src directory if it doesn't exist, then finds all JavaScript files in the current directory and moves them to the src directory."
        }
    }
]

# Additional examples for file operations
FILE_OPERATION_EXAMPLES = [
    {
        "request": "Edit a file and change all instances of 'old' to 'new'",
        "context": {"cwd": "/home/user/project"},
        "response": {
            "intent": "file_edit",
            "command": "sed -i 's/old/new/g' filename.txt",
            "explanation": "This command uses sed to replace all occurrences of 'old' with 'new' in the file. The -i flag makes the changes in-place."
        }
    },
    {
        "request": "Display the first 10 lines of a log file",
        "context": {"cwd": "/home/user/project"},
        "response": {
            "intent": "file_view",
            "command": "head -n 10 logfile.log",
            "explanation": "This command displays the first 10 lines of the specified log file."
        }
    },
    {
        "request": "Create a backup of my configuration file",
        "context": {"cwd": "/home/user"},
        "response": {
            "intent": "file_backup",
            "command": "cp ~/.config/app/config.yaml ~/.config/app/config.yaml.bak",
            "explanation": "This command creates a backup copy of the configuration file by appending .bak to the filename."
        }
    }
]

# Enhanced project context template
ENHANCED_PROJECT_CONTEXT = """
## Enhanced Project Information
Project Type: {project_type}
Frameworks: {frameworks}
Main Dependencies: {dependencies}
Important Files: {important_files}
Project Structure:
- Main Directories: {main_directories}
- Total Files: {total_files}
"""

# Error analysis prompts - for generating error explanations and fixes
ERROR_ANALYSIS_PROMPT = """
Analyze the following command error and provide helpful debugging information:

Command: {command}
Error Output:
{error_output}

Consider:
1. Common syntax errors or misused flags
2. Missing dependencies or prerequisites
3. Permission issues or path problems
4. Similar commands that might work instead
5. Step-by-step debugging approach

Provide a concise explanation of the error and actionable suggestions to fix it.
"""

# Multi-step operation prompt - for complex tasks requiring multiple commands
MULTI_STEP_OPERATION_PROMPT = """
Your task is to create a sequence of commands to accomplish this goal:
{goal}

Project context:
{project_context}

Consider creating a plan that:
1. Breaks down the task into clear sequential steps
2. Handles potential errors or edge cases
3. Uses variables or temporary files when needed
4. Incorporates proper checks between steps
5. Follows best practices for the user's environment

Return a JSON object with an array of command objects, each having:
- command: the shell command to execute
- purpose: brief explanation of this step
- dependencies: list of previous step indices this depends on
- estimated_risk: number from 0-4 indicating risk level
"""

# Code generation prompt - for creating code files or snippets
CODE_GENERATION_PROMPT = """
Create code for the following purpose:
{purpose}

Language: {language}
Project Type: {project_type}
File Path: {file_path}

Requirements:
{requirements}

Include:
- Appropriate imports and dependencies
- Clear documentation and comments
- Error handling and input validation
- Best practices for {language}
- Consistency with the project's coding style

The code should be production-ready, following modern standards and design patterns.
"""

# Workflow automation prompt - for creating sequences of reusable operations
WORKFLOW_AUTOMATION_PROMPT = """
Create a reusable workflow for this scenario:
{scenario}

User's environment:
{environment}

The workflow should:
1. Be parameterizable with variables like ${FILE} or ${DIR}
2. Include appropriate error handling
3. Be efficient and avoid unnecessary steps
4. Follow best practices for shell scripting
5. Include clear documentation for each step

Format the workflow as a sequence of commands with explanations.
"""

# Recent file activity template 
RECENT_FILES_CONTEXT = """
## Recent File Activity
Recently Accessed Files:
{recent_files}

Most Active Files:
{active_files}
"""

# Resolved file references template
RESOLVED_FILES_CONTEXT = """
## Resolved File References
The following file references were resolved from your request:
{resolved_files}
"""

# Enhanced file operation prompt template
FILE_OPERATION_PROMPT_TEMPLATE = """
You are asked to perform an operation on a file with enhanced context awareness.

## File Information
Path: {file_path}
Type: {file_type}
Language: {language}
Size: {size}

## Project Context
Project Type: {project_type}
Project Root: {project_root}

## Request
{request}

Consider all this context when generating your response. If the file is part of a project,
consider how this operation might affect the project as a whole.
"""

# Advanced debugging prompt - for complex system troubleshooting
ADVANCED_DEBUGGING_PROMPT = """
Help debug this complex system issue:
{issue_description}

System Information:
- OS: {os_info}
- Environment: {environment}
- Related Components: {components}

Error logs:
{error_logs}

Recent system changes:
{recent_changes}

Provide a comprehensive debugging approach including:
1. Root cause analysis with multiple potential explanations
2. Diagnostic commands to gather more information
3. Potential solutions ranked by likelihood of success
4. Prevention strategies for future occurrences
5. Explanation of the underlying system mechanisms
"""

# Data transformation prompt - for processing and converting data
DATA_TRANSFORMATION_PROMPT = """
Transform the data according to these requirements:
{requirements}

Source data format: {source_format}
Target data format: {target_format}

Sample data:
{sample_data}

Generate a command or script that will:
1. Handle the full data set efficiently
2. Validate input and provide error handling
3. Produce the output in exactly the specified format
4. Preserve data integrity and type safety
5. Include appropriate logging or progress indication
"""

# Security audit prompt - for analyzing security implications
SECURITY_AUDIT_PROMPT = """
Perform a security audit of this command or script:
{command_or_script}

Context:
{context}

In your audit, consider:
1. Potential injection vulnerabilities or escape issues
2. Permissions and privilege escalation risks
3. Data exposure or leakage concerns
4. Resource exhaustion possibilities
5. Best practice recommendations for secure usage

Provide a security risk assessment and suggested improvements.
"""

def build_prompt(
    request: str, 
    context: Dict[str, Any],
    similar_command: Optional[str] = None,
    intent_result: Optional[Dict[str, Any]] = None
) -> str:
    """
    Build a prompt for the Gemini API with enhanced context information.
    
    Args:
        request: The user request
        context: Context information about the current environment
        similar_command: Optional similar command from history
        intent_result: Optional intent analysis result
        
    Returns:
        A prompt string for the AI service
    """
    # Create a context description
    context_str = "Current context:\n"
    if context.get("cwd"):
        context_str += f"- Current working directory: {context['cwd']}\n"
    if context.get("project_root"):
        context_str += f"- Project root: {context['project_root']}\n"
    if context.get("project_type"):
        context_str += f"- Project type: {context['project_type']}\n"
    if context.get("relative_path"):
        context_str += f"- Path relative to project root: {context['relative_path']}\n"
    
    # Add information about the current file if available
    if context.get("current_file"):
        file_info = context["current_file"]
        context_str += f"- Current file: {file_info.get('path')}\n"
        if file_info.get("language"):
            context_str += f"- File language: {file_info.get('language')}\n"
        if file_info.get("type"):
            context_str += f"- File type: {file_info.get('type')}\n"
    
    # Add enhanced project information if available
    if context.get("enhanced_project"):
        project_info = context["enhanced_project"]
        
        # Format frameworks information
        frameworks_str = "None detected"
        if project_info.get("frameworks"):
            framework_names = list(project_info["frameworks"].keys())
            frameworks_str = ", ".join(framework_names[:5])
            if len(framework_names) > 5:
                frameworks_str += f" and {len(framework_names) - 5} more"
        
        # Format dependencies information
        dependencies_str = "None detected"
        if project_info.get("dependencies") and project_info["dependencies"].get("top_dependencies"):
            dependencies_str = ", ".join(project_info["dependencies"]["top_dependencies"][:5])
            if len(project_info["dependencies"]["top_dependencies"]) > 5:
                dependencies_str += f" and {len(project_info['dependencies']['top_dependencies']) - 5} more"
            
            # Add counts information
            if project_info["dependencies"].get("counts"):
                dependencies_str += f" (Total: {project_info['dependencies'].get('total', 0)})"
        
        # Format important files information
        important_files_str = "None detected"
        if project_info.get("important_files") and project_info["important_files"].get("paths"):
            important_files_str = ", ".join(project_info["important_files"]["paths"][:5])
            if len(project_info["important_files"]["paths"]) > 5:
                important_files_str += f" and {len(project_info['important_files']['paths']) - 5} more"
        
        # Format main directories information
        main_directories_str = "None detected"
        if project_info.get("structure") and project_info["structure"].get("main_directories"):
            main_directories_str = ", ".join(project_info["structure"]["main_directories"])
        
        # Format total files information
        total_files_str = "Unknown"
        if project_info.get("structure") and "total_files" in project_info["structure"]:
            total_files_str = str(project_info["structure"]["total_files"])
        
        # Add to context string
        context_str += ENHANCED_PROJECT_CONTEXT.format(
            project_type=project_info.get("type", "Unknown"),
            frameworks=frameworks_str,
            dependencies=dependencies_str,
            important_files=important_files_str,
            main_directories=main_directories_str,
            total_files=total_files_str
        )
    
    # Add recent file activity if available
    if context.get("recent_files"):
        recent_files = context["recent_files"]
        
        # Format recent files information
        recent_files_str = "None"
        if recent_files.get("accessed"):
            # Extract filenames only for brevity
            recent_filenames = [Path(path).name for path in recent_files["accessed"][:5]]
            recent_files_str = ", ".join(recent_filenames)
            if len(recent_files["accessed"]) > 5:
                recent_files_str += f" and {len(recent_files['accessed']) - 5} more"
        
        # Format active files information
        active_files_str = "None"
        if recent_files.get("activities"):
            active_files_str = ", ".join([a.get("name", "unknown") for a in recent_files["activities"][:3]])
            if len(recent_files["activities"]) > 3:
                active_files_str += f" and {len(recent_files['activities']) - 3} more"
        
        # Add to context string
        context_str += RECENT_FILES_CONTEXT.format(
            recent_files=recent_files_str,
            active_files=active_files_str
        )
    
    # Add resolved file references if available
    if context.get("resolved_files"):
        resolved_files = context["resolved_files"]
        
        # Format resolved files information
        resolved_files_str = ""
        for ref_info in resolved_files:
            reference = ref_info.get("reference", "")
            path = ref_info.get("path", "Not found")
            resolved_files_str += f"- '{reference}' → {path}\n"
        
        # Add to context string
        if resolved_files_str:
            context_str += RESOLVED_FILES_CONTEXT.format(
                resolved_files=resolved_files_str
            )
    
    # Add conversation context
    if "session" in context:
        session = context["session"]
        
        # Add recent commands for continuity
        if session.get("recent_commands"):
            context_str += "Recent commands:\n"
            for i, cmd in enumerate(session.get("recent_commands", []), 1):
                context_str += f"- Command {i}: {cmd}\n"
        
        # Add recent results for reference
        if session.get("recent_results"):
            context_str += "Recent command results:\n"
            for i, result in enumerate(session.get("recent_results", []), 1):
                # Truncate long results
                if len(result) > 200:
                    result = result[:200] + "..."
                context_str += f"- Result {i}: {result}\n"
        
        # Add entities for reference resolution
        if session.get("entities"):
            context_str += "Referenced entities:\n"
            for name, entity in session.get("entities", {}).items():
                context_str += f"- {name}: {entity.get('type')} - {entity.get('value')}\n"
    
    # Add intent analysis if available
    if intent_result:
        context_str += "\nIntent analysis:\n"
        context_str += f"- Intent type: {intent_result.get('intent_type', 'unknown')}\n"
        context_str += f"- Confidence: {intent_result.get('confidence', 0.0):.2f}\n"
        
        # Add extracted entities
        if intent_result.get("entities"):
            context_str += "- Extracted entities:\n"
            for key, value in intent_result.get("entities", {}).items():
                context_str += f"  - {key}: {value}\n"
    
    # Add similar command suggestion if available
    if similar_command:
        context_str += f"\nYou previously suggested this similar command: {similar_command}\n"
    
    # Add examples for few-shot learning
    examples_str = "Examples:\n"
    
    # Add standard examples
    for example in EXAMPLES:
        examples_str += f"\nUser request: {example['request']}\n"
        examples_str += f"Context: {example['context']}\n"
        examples_str += f"Response: {example['response']}\n"
    
    # Add file operation examples
    for example in FILE_OPERATION_EXAMPLES:
        examples_str += f"\nUser request: {example['request']}\n"
        examples_str += f"Context: {example['context']}\n"
        examples_str += f"Response: {example['response']}\n"
    
    # Define the expected response format - now with confidence indicator
    response_format = """
Expected response format (valid JSON):
{
    "intent": "the_classified_intent",
    "command": "the_suggested_command",
    "explanation": "explanation of what the command does",
    "confidence": 0.85, /* Optional confidence score from 0.0 to 1.0 */
    "additional_info": "any additional information (optional)"
}
"""
    
    # Build the complete prompt
    prompt = f"{SYSTEM_INSTRUCTIONS}\n\n{context_str}\n\n{examples_str}\n\n{response_format}\n\nUser request: {request}\n\nResponse:"
    
    logger.debug(f"Built prompt with length: {len(prompt)}")
    return prompt


# Terminal customization prompt - for personalized environment setup
TERMINAL_CUSTOMIZATION_PROMPT = """
Create a customization plan for the user's terminal environment:

Current setup:
{current_setup}

User preferences:
{preferences}

Usage patterns:
{usage_patterns}

The customization should include:
1. Shell configuration recommendations (.bashrc, .zshrc, etc.)
2. Prompt styling and information display
3. Aliases and functions for common operations
4. Productivity tools and utilities
5. Performance optimization settings

Provide detailed implementation instructions with code snippets.
"""

# System administration prompt - for advanced system tasks
SYSTEM_ADMINISTRATION_PROMPT = """
Provide a solution for this system administration task:
{task_description}

System details:
{system_details}

Requirements:
{requirements}

The solution should:
1. Be robust and handle edge cases
2. Include appropriate logging and monitoring
3. Consider security implications
4. Be efficient and scalable
5. Follow system administration best practices

Provide detailed implementation steps with commands and configuration.
"""

# Project analysis prompt - for codebase understanding
PROJECT_ANALYSIS_PROMPT = """
Analyze this software project:
{project_summary}

Key files:
{key_files}

Key questions:
{questions}

Provide an in-depth analysis covering:
1. Architecture and design patterns
2. Component relationships and dependencies
3. Potential technical debt or improvement areas
4. Performance and scalability considerations
5. Security posture and risk assessment

The analysis should be actionable and prioritized by impact.
"""

def build_file_operation_prompt(
    operation: str, 
    parameters: Dict[str, Any], 
    context: Dict[str, Any]
) -> str:
    """
    Build a prompt for generating a file operation command.
    
    Args:
        operation: The type of file operation (e.g., 'create_file', 'delete_directory').
        parameters: Parameters for the operation.
        context: Context information about the current environment.
        
    Returns:
        A prompt string for the Gemini API.
    """
    # Create file information
    file_path = parameters.get("path", "Unknown")
    
    # Get file info if available
    file_info = {}
    if file_path != "Unknown":
        try:
            from angela.context.manager import context_manager
            file_info = context_manager.get_file_info(Path(file_path))
        except Exception as e:
            logger.debug(f"Error getting file info: {str(e)}")
    
    file_info_str = f"""
File: {file_path}
Type: {file_info.get('type', 'Unknown')}
Language: {file_info.get('language', 'Unknown')}
"""
    
    # Create a description of the requested operation
    operation_str = f"""
Requested file operation: {operation}
Parameters:
"""
    for key, value in parameters.items():
        operation_str += f"- {key}: {value}\n"
    
    # Create enhanced project context
    project_context_str = "Project Context:\n"
    
    if context.get("enhanced_project"):
        project_info = context["enhanced_project"]
        project_context_str += f"- Project Type: {project_info.get('type', 'Unknown')}\n"
        
        # Add frameworks if available
        if project_info.get("frameworks"):
            frameworks = list(project_info["frameworks"].keys())
            project_context_str += f"- Frameworks: {', '.join(frameworks[:3])}"
            if len(frameworks) > 3:
                project_context_str += f" and {len(frameworks) - 3} more"
            project_context_str += "\n"
        
        # Add file's relationship to project
        if file_path != "Unknown" and context.get("project_root"):
            try:
                rel_path = Path(file_path).relative_to(Path(context["project_root"]))
                project_context_str += f"- Relative Path: {rel_path}\n"
            except ValueError:
                # File is not within project root
                project_context_str += f"- Note: File is outside project root\n"
    
    # Define the task
    task_str = f"""
Your task is to generate a shell command that will perform the requested file operation.
The command should be safe, efficient, and follow best practices for Linux/Unix shell environments.
Consider the file type, language, and project context when generating the command.
"""
    
    # Define the expected response format
    response_format = """
Expected response format (valid JSON):
{
    "command": "the_shell_command",
    "explanation": "explanation of what the command does",
    "risk_level": "SAFE|LOW|MEDIUM|HIGH|CRITICAL",
    "destructive": true|false
}
"""
    
    # Build the complete prompt
    prompt = f"{SYSTEM_INSTRUCTIONS}\n\n{operation_str}\n\n{file_info_str}\n\n{project_context_str}\n\n{task_str}\n\n{response_format}\n\nResponse:"
    
    logger.debug(f"Built file operation prompt with length: {len(prompt)}")
    return prompt
</file>

<file path="angela/cli/__init__.py">
# angela/cli/__init__.py
"""
CLI components for Angela CLI.
"""
from angela.cli.main import app as main_app
from angela.cli.files import app as files_app
from angela.cli.workflows import app as workflows_app
from angela.cli.generation import app as generation_app
from angela.cli.rollback_commands import app as rollback_app
from angela.cli.docker import app as docker_app

# Add subcommands to the main app
main_app.add_typer(files_app, name="files", help="File and directory operations")
main_app.add_typer(workflows_app, name="workflows", help="Workflow management")
main_app.add_typer(generation_app, name="generate", help="Code generation")
main_app.add_typer(rollback_app, name="rollback", help="Rollback operations and transactions")
main_app.add_typer(docker_app, name="docker", help="Docker and Docker Compose operations")

# Export the main app
app = main_app
</file>

<file path="angela/generation/engine.py">
# angela/generation/engine.py
"""
Advanced code generation engine for Angela CLI.

This module provides capabilities for generating entire directory structures
and multiple code files based on high-level natural language descriptions.
"""
import os
import asyncio
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple, Union, Set
import json
import re

from pydantic import BaseModel, Field

from angela.ai.client import gemini_client, GeminiRequest
from angela.context import context_manager
from angela.context.enhancer import context_enhancer
from angela.utils.logging import get_logger
from angela.execution.filesystem import create_directory, create_file, write_file
from angela.generation.validators import validate_code

logger = get_logger(__name__)

class CodeFile(BaseModel):
    """Model for a code file to be generated."""
    path: str = Field(..., description="Relative path to the file")
    content: str = Field(..., description="Content of the file")
    purpose: str = Field(..., description="Purpose/description of the file")
    dependencies: List[str] = Field(default_factory=list, description="Paths of files this depends on")
    language: Optional[str] = Field(None, description="Programming language of the file")

class CodeProject(BaseModel):
    """Model for a complete code project to be generated."""
    name: str = Field(..., description="Name of the project")
    description: str = Field(..., description="Description of the project")
    root_dir: str = Field(..., description="Root directory for the project")
    files: List[CodeFile] = Field(..., description="List of files to generate")
    dependencies: Dict[str, List[str]] = Field(default_factory=dict, description="External dependencies")
    project_type: str = Field(..., description="Type of project (e.g., python, node)")
    structure_explanation: str = Field(..., description="Explanation of the project structure")

class CodeGenerationEngine:
    """
    Advanced code generation engine that can create entire projects
    based on natural language descriptions.
    """
    
    def __init__(self):
        """Initialize the code generation engine."""
        self._logger = logger
    
    async def generate_project(
        self, 
        description: str, 
        output_dir: Optional[str] = None,
        project_type: Optional[str] = None,
        context: Optional[Dict[str, Any]] = None
    ) -> CodeProject:
        """
        Generate a complete project from a description.
        
        Args:
            description: Natural language description of the project
            output_dir: Directory where the project should be generated (defaults to cwd)
            project_type: Optional type of project to generate (auto-detected if None)
            context: Additional context information
            
        Returns:
            CodeProject object representing the generated project
        """
        self._logger.info(f"Generating project from description: {description}")
        
        # Get current context if not provided
        if context is None:
            context = context_manager.get_context_dict()
            context = await context_enhancer.enrich_context(context)
        
        # Determine output directory
        if output_dir is None:
            output_dir = context.get("cwd", os.getcwd())
        
        # Create project plan
        project_plan = await self._create_project_plan(description, output_dir, project_type, context)
        self._logger.info(f"Created project plan with {len(project_plan.files)} files")
        
        # Validate the project plan
        is_valid, validation_errors = await self._validate_project_plan(project_plan)
        
        if not is_valid:
            self._logger.error(f"Project plan validation failed: {validation_errors}")
            # Try to fix validation errors
            project_plan = await self._fix_validation_errors(project_plan, validation_errors)
        
        return project_plan
    
    async def create_project_files(
        self, 
        project: CodeProject,
        dry_run: bool = False
    ) -> Dict[str, Any]:
        """
        Create the actual files for a project.
        
        Args:
            project: CodeProject to generate
            dry_run: Whether to simulate file creation without making changes
            
        Returns:
            Dictionary with creation results
        """
        self._logger.info(f"Creating project files for: {project.name}")
        
        # Create the root directory if it doesn't exist
        root_path = Path(project.root_dir)
        if not root_path.exists() and not dry_run:
            await create_directory(root_path, parents=True)
        
        # Create files in dependency order
        created_files = []
        file_errors = []
        dependency_graph = self._build_dependency_graph(project.files)
        
        # Process files in dependency order
        for file in self._get_ordered_files(project.files, dependency_graph):
            file_path = root_path / file.path
            
            # Create parent directories if needed
            if not dry_run:
                await create_directory(file_path.parent, parents=True)
            
            # Write file content
            try:
                if not dry_run:
                    await write_file(file_path, file.content)
                created_files.append(str(file_path))
                self._logger.debug(f"Created file: {file_path}")
            except Exception as e:
                self._logger.error(f"Error creating file {file_path}: {str(e)}")
                file_errors.append({"path": str(file_path), "error": str(e)})
        
        return {
            "project_name": project.name,
            "root_dir": str(root_path),
            "created_files": created_files,
            "file_errors": file_errors,
            "file_count": len(created_files),
            "success": len(file_errors) == 0,
            "dry_run": dry_run
        }
    
    async def _create_project_plan(
        self, 
        description: str, 
        output_dir: str,
        project_type: Optional[str],
        context: Dict[str, Any]
    ) -> CodeProject:
        """
        Create a plan for a project based on the description.
        
        Args:
            description: Natural language description of the project
            output_dir: Directory where the project should be generated
            project_type: Optional type of project to generate
            context: Additional context information
            
        Returns:
            CodeProject object with the plan
        """
        # Determine project type if not specified
        if project_type is None:
            project_type = await self._infer_project_type(description, context)
            self._logger.debug(f"Inferred project type: {project_type}")
        
        # Build prompt for project planning
        prompt = self._build_project_planning_prompt(description, project_type, context)
        
        # Call AI service to generate project plan
        api_request = GeminiRequest(
            prompt=prompt,
            max_tokens=8000,  # Large token limit for complex project plans
            temperature=0.2   # Low temperature for more deterministic output
        )
        
        self._logger.debug("Sending project planning request to AI service")
        response = await gemini_client.generate_text(api_request)
        
        # Parse the response to extract the project plan
        project_plan = await self._parse_project_plan(response.text, output_dir, project_type)
        
        # Generate detailed content for each file
        project_plan = await self._generate_file_contents(project_plan, context)
        
        return project_plan
    
    async def _infer_project_type(
        self, 
        description: str, 
        context: Dict[str, Any]
    ) -> str:
        """
        Infer the project type from the description.
        
        Args:
            description: Natural language description of the project
            context: Additional context information
            
        Returns:
            String indicating the project type
        """
        # Check for explicit mentions of languages/frameworks
        tech_indicators = {
            "python": ["python", "flask", "django", "fastapi", "sqlalchemy", "pytest"],
            "node": ["node", "javascript", "express", "react", "vue", "angular", "npm"],
            "java": ["java", "spring", "maven", "gradle", "junit"],
            "go": ["go", "golang", "gin", "echo"],
            "ruby": ["ruby", "rails", "sinatra", "rspec"],
            "rust": ["rust", "cargo", "actix", "rocket"],
        }
        
        # Lowercase description for easier matching
        description_lower = description.lower()
        
        # Count mentions of each technology
        tech_counts = {}
        for tech, indicators in tech_indicators.items():
            count = sum(indicator in description_lower for indicator in indicators)
            if count > 0:
                tech_counts[tech] = count
        
        # If we found clear indicators, return the most mentioned
        if tech_counts:
            return max(tech_counts.items(), key=lambda x: x[1])[0]
        
        # No clear indicators, use AI to infer
        prompt = f"""
Determine the most suitable programming language/framework for this project:

"{description}"

Return only the project type as a single word, using one of these options:
python, node, java, go, ruby, rust, or other.
"""
        
        api_request = GeminiRequest(prompt=prompt, max_tokens=10)
        response = await gemini_client.generate_text(api_request)
        
        # Extract the project type from the response
        project_type = response.text.strip().lower()
        
        # Default to python if we couldn't determine
        if project_type not in {"python", "node", "java", "go", "ruby", "rust"}:
            return "python"
        
        return project_type
    
    def _build_project_planning_prompt(
        self, 
        description: str,
        project_type: str,
        context: Dict[str, Any]
    ) -> str:
        """
        Build a prompt for project planning.
        
        Args:
            description: Natural language description of the project
            project_type: Type of project to generate
            context: Additional context information
            
        Returns:
            Prompt string for the AI service
        """
        prompt = f"""
You are an expert software architect tasked with planning a {project_type} project based on this description:

"{description}"

First, analyze the requirements and identify:
1. Core components needed
2. Data models and their relationships
3. Key functionality to be implemented
4. External dependencies required

Then, create a detailed project structure plan in JSON format, including:

```json
{{
  "name": "project_name",
  "description": "brief project description",
  "project_type": "{project_type}",
  "dependencies": {{
    "runtime": ["list", "of", "dependencies"],
    "development": ["test", "frameworks", "etc"]
  }},
  "files": [
    {{
      "path": "relative/path/to/file.ext",
      "purpose": "description of the file's purpose",
      "dependencies": ["other/files/this/depends/on"],
      "language": "programming language"
    }}
  ],
  "structure_explanation": "explanation of why this structure was chosen"
}}
Focus on creating a well-structured, maintainable project following best practices for {project_type} projects. Include appropriate configuration files, tests, documentation, and proper project organization.
The project should be modular, follow SOLID principles, and be easy to extend.
"""
    return prompt

async def _parse_project_plan(
    self, 
    response: str, 
    output_dir: str,
    project_type: str
) -> CodeProject:
    """
    Parse the AI response to extract the project plan.
    
    Args:
        response: AI response text
        output_dir: Directory where the project should be generated
        project_type: Type of project to generate
        
    Returns:
        CodeProject object with the plan
    """
    try:
        # Look for JSON block in the response
        json_match = re.search(r'```(?:json)?\s*(.*?)\s*```', response, re.DOTALL)
        if json_match:
            json_str = json_match.group(1)
        else:
            # Try to find JSON without code blocks
            json_match = re.search(r'({.*})', response, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
            else:
                # Assume the entire response is JSON
                json_str = response
        
        # Parse the JSON
        plan_data = json.loads(json_str)
        
        # Create CodeFile objects
        files = []
        for file_data in plan_data.get("files", []):
            files.append(CodeFile(
                path=file_data["path"],
                content="",  # Content will be generated later
                purpose=file_data["purpose"],
                dependencies=file_data.get("dependencies", []),
                language=file_data.get("language")
            ))
        
        # Create CodeProject object
        project = CodeProject(
            name=plan_data.get("name", f"new_{project_type}_project"),
            description=plan_data.get("description", "Generated project"),
            root_dir=output_dir,
            files=files,
            dependencies=plan_data.get("dependencies", {}),
            project_type=project_type,
            structure_explanation=plan_data.get("structure_explanation", "")
        )
        
        return project
        
    except Exception as e:
        self._logger.exception(f"Error parsing project plan: {str(e)}")
        
        # Create a minimal fallback project
        fallback_file = CodeFile(
            path="main.py" if project_type == "python" else "index.js",
            content="",
            purpose="Main entry point",
            dependencies=[],
            language=project_type
        )
        
        return CodeProject(
            name=f"new_{project_type}_project",
            description="Generated project (fallback)",
            root_dir=output_dir,
            files=[fallback_file],
            dependencies={},
            project_type=project_type,
            structure_explanation="Fallback project structure due to parsing error."
        )

async def _generate_file_contents(
    self, 
    project: CodeProject,
    context: Dict[str, Any]
) -> CodeProject:
    """
    Generate content for each file in the project.
    
    Args:
        project: CodeProject with file information
        context: Additional context information
        
    Returns:
        Updated CodeProject with file contents
    """
    self._logger.info(f"Generating content for {len(project.files)} files")
    
    # Process files in dependency order
    dependency_graph = self._build_dependency_graph(project.files)
    
    # Prepare batches of files to generate (to avoid too many concurrent requests)
    batches = self._create_file_batches(project.files, dependency_graph)
    
    # Generate content for each batch
    for batch_idx, batch in enumerate(batches):
        self._logger.debug(f"Processing batch {batch_idx+1}/{len(batches)} with {len(batch)} files")
        
        # Generate content for each file in the batch concurrently
        tasks = []
        for file in batch:
            # Load previous file contents for dependencies
            dependencies_content = {}
            for dep_path in file.dependencies:
                # Find the dependent file
                for dep_file in project.files:
                    if dep_file.path == dep_path and dep_file.content:
                        dependencies_content[dep_path] = dep_file.content
            
            task = self._generate_file_content(
                file, 
                project, 
                dependencies_content,
                context
            )
            tasks.append(task)
        
        # Wait for all tasks in this batch to complete
        results = await asyncio.gather(*tasks)
        
        # Update file contents
        for file, content in zip(batch, results):
            file.content = content
    
    return project

async def _generate_file_content(
    self, 
    file: CodeFile, 
    project: CodeProject,
    dependencies_content: Dict[str, str],
    context: Dict[str, Any]
) -> str:
    """
    Generate content for a single file.
    
    Args:
        file: CodeFile to generate content for
        project: Parent CodeProject
        dependencies_content: Content of files this depends on
        context: Additional context information
        
    Returns:
        Generated file content
    """
    self._logger.debug(f"Generating content for file: {file.path}")
    
    # Build prompt for file content generation
    prompt = self._build_file_content_prompt(file, project, dependencies_content)
    
    # Call AI service to generate file content
    api_request = GeminiRequest(
        prompt=prompt,
        max_tokens=4000,
        temperature=0.2
    )
    
    response = await gemini_client.generate_text(api_request)
    
    # Extract code from the response
    content = self._extract_code_from_response(response.text, file.path)
    
    # Validate the generated code
    is_valid, validation_message = validate_code(content, file.path)
    
    # If validation failed, try once more with the error message
    if not is_valid:
        self._logger.warning(f"Validation failed for {file.path}: {validation_message}")
        
        # Build a new prompt with the validation error
        fix_prompt = f"""
The code you generated has an issue that needs to be fixed:
{validation_message}
Here is the original code:
{content}
Please provide the corrected code for file '{file.path}'.
Only respond with the corrected code, nothing else.
"""
        # Call AI service to fix the code
        fix_request = GeminiRequest(
            prompt=fix_prompt,
            max_tokens=4000,
            temperature=0.1
        )
        
        fix_response = await gemini_client.generate_text(fix_request)
        
        # Extract fixed code
        fixed_content = self._extract_code_from_response(fix_response.text, file.path)
        
        # Validate again
        is_valid, _ = validate_code(fixed_content, file.path)
        if is_valid:
            content = fixed_content
    
    return content

def _build_file_content_prompt(
    self, 
    file: CodeFile, 
    project: CodeProject,
    dependencies_content: Dict[str, str]
) -> str:
    """
    Build a prompt for generating file content.
    
    Args:
        file: CodeFile to generate content for
        project: Parent CodeProject
        dependencies_content: Content of files this depends on
        
    Returns:
        Prompt string for the AI service
    """
    # Add language context based on file extension
    language_hints = ""
    if file.language:
        language_hints = f"The file should be written in {file.language}."
    
    # Add dependencies context
    dependencies_context = ""
    if dependencies_content:
        dependencies_context = "This file depends on the following files:\n\n"
        
        for dep_path, content in dependencies_content.items():
            # Limit content size to avoid token limits
            if len(content) > 1000:
                content = content[:1000] + "\n... (truncated)"
            
            dependencies_context += f"File: {dep_path}\n```\n{content}\n```\n\n"
    
    prompt = f"""
You are an expert software developer working on a {project.project_type} project named "{project.name}".
{project.description}
You need to create the file "{file.path}" with the following purpose:
{file.purpose}
{language_hints}
The project has the following overall structure:
{project.structure_explanation}
{dependencies_context}
Generate only the code for this file. The code should be well-structured, properly formatted, and follow best practices for its language. Include appropriate comments and documentation.
Only return the file content, nothing else.
"""
    return prompt

def _extract_code_from_response(self, response: str, file_path: str) -> str:
    """
    Extract code from the AI response.
    
    Args:
        response: AI response text
        file_path: Path of the file being generated
        
    Returns:
        Extracted code content
    """
    # Try to extract code from markdown code blocks
    code_match = re.search(r'```(?:\w+)?\s*(.*?)\s*```', response, re.DOTALL)
    if code_match:
        return code_match.group(1)
    
    # No code block found, use the entire response
    return response.strip()

def _build_dependency_graph(self, files: List[CodeFile]) -> Dict[str, Set[str]]:
    """
    Build a dependency graph for the files.
    
    Args:
        files: List of files to process
        
    Returns:
        Dictionary mapping file paths to sets of dependent file paths
    """
    # Map file paths to indices
    path_to_index = {file.path: i for i, file in enumerate(files)}
    
    # Initialize the graph
    graph = {}
    for file in files:
        graph[file.path] = set()
        for dep_path in file.dependencies:
            if dep_path in path_to_index:
                graph[file.path].add(dep_path)
    
    return graph

def _get_ordered_files(
    self, 
    files: List[CodeFile], 
    graph: Dict[str, Set[str]]
) -> List[CodeFile]:
    """
    Get files in dependency order (topological sort).
    
    Args:
        files: List of files to order
        graph: Dependency graph
        
    Returns:
        Ordered list of files
    """
    # Map file paths to objects
    path_to_file = {file.path: file for file in files}
    
    # Keep track of visited and ordered nodes
    visited = set()
    ordered = []
    
    def visit(path):
        """DFS visit function for topological sort."""
        if path in visited:
            return
        
        visited.add(path)
        
        # Visit dependencies first
        for dep_path in graph.get(path, set()):
            visit(dep_path)
        
        # Add to ordered list
        if path in path_to_file:
            ordered.append(path_to_file[path])
    
    # Visit all nodes
    for file in files:
        visit(file.path)
    
    return ordered

def _create_file_batches(
    self, 
    files: List[CodeFile], 
    graph: Dict[str, Set[str]]
) -> List[List[CodeFile]]:
    """
    Create batches of files that can be generated concurrently.
    
    Args:
        files: List of files to batch
        graph: Dependency graph
        
    Returns:
        List of file batches
    """
    # Get files in dependency order
    ordered_files = self._get_ordered_files(files, graph)
    
    # Group files by their dependency level
    levels = {}
    path_to_level = {}
    
    # Compute the dependency level for each file
    for file in ordered_files:
        # The level is 1 + the maximum level of dependencies
        max_dep_level = 0
        for dep_path in file.dependencies:
            if dep_path in path_to_level:
                max_dep_level = max(max_dep_level, path_to_level[dep_path])
        
        level = max_dep_level + 1
        path_to_level[file.path] = level
        
        if level not in levels:
            levels[level] = []
        
        levels[level].append(file)
    
    # Create batches from levels
    batches = []
    for level in sorted(levels.keys()):
        batches.append(levels[level])
    
    return batches

async def _validate_project_plan(
    self, 
    project: CodeProject
) -> Tuple[bool, List[str]]:
    """
    Validate a project plan for consistency.
    
    Args:
        project: CodeProject to validate
        
    Returns:
        Tuple of (is_valid, list_of_errors)
    """
    errors = []
    
    # Check for duplicate file paths
    paths = [file.path for file in project.files]
    if len(paths) != len(set(paths)):
        duplicate_paths = [path for path in paths if paths.count(path) > 1]
        errors.append(f"Duplicate file paths: {set(duplicate_paths)}")
    
    # Check for circular dependencies
    try:
        graph = self._build_dependency_graph(project.files)
        self._get_ordered_files(project.files, graph)
    except Exception as e:
        errors.append(f"Circular dependencies detected: {str(e)}")
    
    # Check for missing dependencies
    path_set = set(paths)
    for file in project.files:
        for dep_path in file.dependencies:
            if dep_path not in path_set:
                errors.append(f"File {file.path} depends on non-existent file {dep_path}")
    
    return len(errors) == 0, errors

async def _fix_validation_errors(
    self, 
    project: CodeProject, 
    errors: List[str]
) -> CodeProject:
    """
    Try to fix validation errors in a project plan.
    
    Args:
        project: The project plan to fix
        errors: List of validation errors
        
    Returns:
        Fixed CodeProject
    """
    self._logger.info(f"Attempting to fix {len(errors)} validation errors")
    
    # Handle duplicate paths
    if any("Duplicate file paths" in error for error in errors):
        # Create a map of paths to files
        path_to_files = {}
        for file in project.files:
            if file.path not in path_to_files:
                path_to_files[file.path] = []
            path_to_files[file.path].append(file)
        
        # Keep only the first instance of each duplicate
        new_files = []
        for path, files in path_to_files.items():
            new_files.append(files[0])
        
        project.files = new_files
    
    # Handle circular dependencies
    if any("Circular dependencies" in error for error in errors):
        # Remove dependencies that create cycles
        graph = {}
        for file in project.files:
            graph[file.path] = set(file.dependencies)
        
        # Find and break cycles
        visited = set()
        path = []
        
        def find_cycles(node):
            if node in path:
                # Cycle detected, break it
                cycle_start = path.index(node)
                cycle = path[cycle_start:] + [node]
                
                # Remove the last dependency in the cycle
                source = cycle[-2]
                target = cycle[-1]
                for file in project.files:
                    if file.path == source:
                        if target in file.dependencies:
                            file.dependencies.remove(target)
                            self._logger.debug(f"Removed dependency from {source} to {target} to break cycle")
                
                return True
            
            if node in visited:
                return False
            
            visited.add(node)
            path.append(node)
            
            for neighbor in graph.get(node, set()):
                if find_cycles(neighbor):
                    return True
            
            path.pop()
            return False
        
        # Find and fix all cycles
        for node in list(graph.keys()):
            while find_cycles(node):
                visited = set()
                path = []
        
    # Handle missing dependencies
    if any("depends on non-existent file" in error for error in errors):
        # Remove dependencies that don't exist
        valid_paths = {file.path for file in project.files}
        for file in project.files:
            file.dependencies = [dep for dep in file.dependencies if dep in valid_paths]
    
    return project




async def add_feature_to_project(
    self, 
    description: str, 
    project_dir: Union[str, Path],
    context: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    Add a new feature to an existing project.
    
    Args:
        description: Natural language description of the feature to add
        project_dir: Path to the project directory
        context: Additional context information
        
    Returns:
        Dictionary with information about the added feature
    """
    self._logger.info(f"Adding feature to project: {description}")
    
    # Get context if not provided
    if context is None:
        context = context_manager.get_context_dict()
        context = await context_enhancer.enrich_context(context)
    
    # Convert to Path object
    project_path = Path(project_dir)
    
    # Step 1: Analyze existing project structure
    project_analysis = await self._analyze_existing_project(project_path, context)
    project_type = project_analysis.get("project_type")
    
    if not project_type:
        self._logger.error("Could not determine project type")
        return {
            "success": False,
            "error": "Could not determine project type",
            "project_dir": str(project_path)
        }
    
    # Step 2: Generate feature plan based on description and existing project
    feature_plan = await self._generate_feature_plan(description, project_analysis, context)
    
    # Step 3: Generate file contents for new/modified files
    feature_files = await self._generate_feature_files(feature_plan, project_analysis, context)
    
    # Step 4: Apply changes to the project
    result = await self._apply_feature_changes(feature_files, project_path)
    
    return {
        "success": result.get("success", False),
        "description": description,
        "project_type": project_type,
        "new_files": result.get("created_files", []),
        "modified_files": result.get("modified_files", []),
        "errors": result.get("errors", []),
        "project_dir": str(project_path)
    }

async def _analyze_existing_project(
    self, 
    project_path: Path, 
    context: Dict[str, Any]
) -> Dict[str, Any]:
    """
    Analyze an existing project structure.
    
    Args:
        project_path: Path to the project directory
        context: Context information
        
    Returns:
        Dictionary with project analysis information
    """
    self._logger.info(f"Analyzing existing project structure at {project_path}")
    
    # Get project information from context if available
    project_info = {}
    
    if "enhanced_project" in context:
        project_info = {
            "project_type": context["enhanced_project"].get("type", "unknown"),
            "frameworks": context["enhanced_project"].get("frameworks", {}),
            "dependencies": context["enhanced_project"].get("dependencies", {})
        }
    
    # If project type is unknown or not in context, detect it
    if project_info.get("project_type") == "unknown" or not project_info:
        # Import here to avoid circular imports
        from angela.toolchain.ci_cd import ci_cd_integration
        detection_result = await ci_cd_integration.detect_project_type(project_path)
        project_info["project_type"] = detection_result.get("project_type")
    
    # Get file structure
    files = []
    for root, _, filenames in os.walk(project_path):
        for filename in filenames:
            # Skip common directories to ignore
            if any(ignored in root for ignored in [".git", "__pycache__", "node_modules", "venv"]):
                continue
                
            file_path = Path(root) / filename
            rel_path = file_path.relative_to(project_path)
            
            # Get basic file info
            file_info = {
                "path": str(rel_path),
                "full_path": str(file_path),
                "type": None,
                "language": None,
                "content": None
            }
            
            # Try to determine file type and language
            try:
                from angela.context.file_detector import detect_file_type
                type_info = detect_file_type(file_path)
                file_info["type"] = type_info.get("type")
                file_info["language"] = type_info.get("language")
                
                # Read content for source code files (limit to prevent memory issues)
                if type_info.get("type") == "source_code" and file_path.stat().st_size < 100000:
                    with open(file_path, 'r', encoding='utf-8', errors='replace') as f:
                        file_info["content"] = f.read()
            except Exception as e:
                self._logger.debug(f"Error analyzing file {file_path}: {str(e)}")
            
            files.append(file_info)
    
    # Add files to project info
    project_info["files"] = files
    project_info["main_files"] = []
    
    # Try to identify important files based on project type
    if project_info.get("project_type") == "python":
        # Look for main Python files
        for file_info in files:
            if file_info["path"].endswith(".py"):
                if any(name in file_info["path"].lower() for name in ["main", "app", "index", "server"]):
                    project_info["main_files"].append(file_info["path"])
    elif project_info.get("project_type") == "node":
        # Look for main JavaScript/TypeScript files
        for file_info in files:
            if file_info["path"].endswith((".js", ".ts", ".jsx", ".tsx")):
                if any(name in file_info["path"].lower() for name in ["main", "app", "index", "server"]):
                    project_info["main_files"].append(file_info["path"])
    
    return project_info

async def _generate_feature_plan(
    self, 
    description: str,
    project_analysis: Dict[str, Any],
    context: Dict[str, Any]
) -> Dict[str, Any]:
    """
    Generate a plan for adding a feature to the project.
    
    Args:
        description: Feature description
        project_analysis: Analysis of the existing project
        context: Context information
        
    Returns:
        Dictionary with the feature plan
    """
    self._logger.info(f"Generating feature plan for: {description}")
    
    project_type = project_analysis.get("project_type", "unknown")
    
    # Build a prompt for the AI to generate a feature plan
    prompt = f"""
You are an expert software developer tasked with planning how to add a new feature to an existing {project_type} project.

Feature description: "{description}"

Based on the existing project structure, determine:
1. What new files need to be created
2. What existing files need to be modified
3. How the new feature integrates with the existing codebase

Project Information:
- Project Type: {project_type}
- Main Files: {project_analysis.get('main_files', [])}
- Frameworks: {project_analysis.get('frameworks', {})}

Project Structure:
"""
    
    # Add information about existing files
    files_by_type = {}
    for file_info in project_analysis.get("files", []):
        file_type = file_info.get("type", "unknown")
        if file_type not in files_by_type:
            files_by_type[file_type] = []
        files_by_type[file_type].append(file_info["path"])
    
    for file_type, files in files_by_type.items():
        prompt += f"\n{file_type.upper()} FILES:\n"
        for file_path in files[:10]:  # Limit to 10 files per type to avoid token limits
            prompt += f"- {file_path}\n"
        if len(files) > 10:
            prompt += f"- ... and {len(files) - 10} more {file_type} files\n"
    
    # Add content of main files to give context
    prompt += "\nMain File Contents:\n"
    for file_path in project_analysis.get("main_files", [])[:3]:  # Limit to 3 main files
        for file_info in project_analysis.get("files", []):
            if file_info["path"] == file_path and file_info.get("content"):
                content = file_info["content"]
                if len(content) > 1000:  # Limit content size
                    content = content[:1000] + "\n... (truncated)"
                prompt += f"\nFile: {file_path}\n```\n{content}\n```\n"
    
    prompt += """
Provide your response as a JSON object with this structure:
```json
{
  "new_files": [
    {
      "path": "relative/path/to/file.ext",
      "purpose": "description of the file's purpose",
      "content_template": "template for file content with {{placeholders}}",
      "language": "programming language"
    }
  ],
  "modified_files": [
    {
      "path": "relative/path/to/existing/file.ext",
      "purpose": "description of the modifications",
      "modifications": [
        {
          "type": "add_import",
          "content": "import statement to add",
          "line": 0
        },
        {
          "type": "add_function",
          "content": "function to add",
          "after": "existing function or pattern"
        },
        {
          "type": "replace",
          "search": "code to search for",
          "replace": "replacement code"
        }
      ]
    }
  ],
  "integration_points": [
    "Description of how the feature integrates with existing code"
  ]
}
```
Focus on creating a clean, maintainable implementation that follows the project's existing patterns and best practices.
"""
    
    # Call AI service
    api_request = GeminiRequest(
        prompt=prompt,
        max_tokens=8000,
        temperature=0.2
    )
    
    self._logger.debug("Sending feature plan request to AI service")
    response = await gemini_client.generate_text(api_request)
    
    # Parse the response
    plan = await self._parse_feature_plan(response.text)
    
    return plan

async def _parse_feature_plan(self, response: str) -> Dict[str, Any]:
    """
    Parse the AI response to extract the feature plan.
    
    Args:
        response: AI response text
        
    Returns:
        Dictionary with the feature plan
    """
    # Look for JSON block in the response
    try:
        json_match = re.search(r'```(?:json)?\s*(.*?)\s*```', response, re.DOTALL)
        if json_match:
            json_str = json_match.group(1)
        else:
            # Try to find JSON without code blocks
            json_match = re.search(r'({.*})', response, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
            else:
                # Assume the entire response is JSON
                json_str = response
        
        # Parse the JSON
        plan_data = json.loads(json_str)
        
        return plan_data
    
    except Exception as e:
        self._logger.exception(f"Error parsing feature plan: {str(e)}")
        
        # Return a minimal fallback plan
        return {
            "new_files": [],
            "modified_files": [],
            "integration_points": [
                "Unable to parse AI response. Consider providing more specific feature description."
            ]
        }

async def _generate_feature_files(
    self, 
    feature_plan: Dict[str, Any],
    project_analysis: Dict[str, Any],
    context: Dict[str, Any]
) -> Dict[str, Any]:
    """
    Generate content for new files and modifications for existing files.
    
    Args:
        feature_plan: Feature plan from _generate_feature_plan
        project_analysis: Analysis of the existing project
        context: Context information
        
    Returns:
        Dictionary with file contents and modifications
    """
    self._logger.info("Generating feature file contents")
    
    feature_files = {
        "new_files": [],
        "modified_files": []
    }
    
    # Process new files
    for file_info in feature_plan.get("new_files", []):
        # Generate content for the new file
        content = await self._generate_new_file_content(
            file_info,
            project_analysis,
            feature_plan,
            context
        )
        
        feature_files["new_files"].append({
            "path": file_info["path"],
            "content": content,
            "purpose": file_info.get("purpose", "")
        })
    
    # Process modified files
    for file_info in feature_plan.get("modified_files", []):
        # Get original content
        original_content = self._get_file_content(file_info["path"], project_analysis)
        
        if original_content is None:
            self._logger.warning(f"Could not find content for file: {file_info['path']}")
            continue
        
        # Apply modifications
        modified_content = await self._apply_file_modifications(
            original_content,
            file_info.get("modifications", []),
            file_info,
            project_analysis,
            feature_plan,
            context
        )
        
        feature_files["modified_files"].append({
            "path": file_info["path"],
            "original_content": original_content,
            "modified_content": modified_content,
            "purpose": file_info.get("purpose", "")
        })
    
    return feature_files

def _get_file_content(self, file_path: str, project_analysis: Dict[str, Any]) -> Optional[str]:
    """
    Get the content of a file from the project analysis.
    
    Args:
        file_path: Path to the file
        project_analysis: Analysis of the existing project
        
    Returns:
        File content or None if not found
    """
    for file_info in project_analysis.get("files", []):
        if file_info["path"] == file_path:
            return file_info.get("content")
    return None

async def _generate_new_file_content(
    self, 
    file_info: Dict[str, Any],
    project_analysis: Dict[str, Any],
    feature_plan: Dict[str, Any],
    context: Dict[str, Any]
) -> str:
    """
    Generate content for a new file.
    
    Args:
        file_info: Information about the new file
        project_analysis: Analysis of the existing project
        feature_plan: Overall feature plan
        context: Context information
        
    Returns:
        Generated file content
    """
    self._logger.debug(f"Generating content for new file: {file_info['path']}")
    
    # Get template if provided
    template = file_info.get("content_template", "")
    
    # If template has placeholders, we should fill them in
    # This is simplified; in a real implementation you would have more context
    if template and "{{" in template:
        # Process template with placeholders
        # This is just a simple example
        template = template.replace("{{project_type}}", project_analysis.get("project_type", ""))
    
    # If template is not provided or is minimal, generate content with AI
    if len(template.strip()) < 50:  # Arbitrary threshold
        # Build prompt for file generation
        prompt = f"""
Generate the content for a new file in a {project_analysis.get('project_type', 'unknown')} project.

File path: {file_info['path']}
File purpose: {file_info.get('purpose', 'Unknown')}

This file is part of a new feature described as:
{feature_plan.get('integration_points', ['Unknown'])[0] if feature_plan.get('integration_points') else 'Unknown'}

The project already has files like:
"""
        # Add a few relevant existing files for context
        file_extension = Path(file_info['path']).suffix
        for existing_file in project_analysis.get("files", [])[:5]:
            if existing_file.get("path", "").endswith(file_extension):
                prompt += f"- {existing_file['path']}\n"
        
        # Add content of a similar file for style reference
        similar_files = [f for f in project_analysis.get("files", []) 
                        if f.get("path", "").endswith(file_extension) and f.get("content")]
        
        if similar_files:
            similar_file = similar_files[0]
            content = similar_file.get("content", "")
            if len(content) > 1000:  # Limit content size
                content = content[:1000] + "\n... (truncated)"
            prompt += f"\nReference file ({similar_file['path']}) for style consistency:\n"
            prompt += f"```\n{content}\n```\n"
        
        prompt += "\nGenerate the complete content for the new file, following the project's style and conventions."
        
        # Call AI service
        api_request = GeminiRequest(
            prompt=prompt,
            max_tokens=4000,
            temperature=0.2
        )
        
        response = await gemini_client.generate_text(api_request)
        
        # Extract code from the response
        content = self._extract_code_from_response(response.text, file_info['path'])
        return content
    
    return template

async def _apply_file_modifications(
    self, 
    original_content: str,
    modifications: List[Dict[str, Any]],
    file_info: Dict[str, Any],
    project_analysis: Dict[str, Any],
    feature_plan: Dict[str, Any],
    context: Dict[str, Any]
) -> str:
    """
    Apply modifications to an existing file.
    
    Args:
        original_content: Original file content
        modifications: List of modifications to apply
        file_info: Information about the file
        project_analysis: Analysis of the existing project
        feature_plan: Overall feature plan
        context: Context information
        
    Returns:
        Modified file content
    """
    self._logger.debug(f"Applying modifications to file: {file_info['path']}")
    
    modified_content = original_content
    
    # Apply each modification in sequence
    for mod in modifications:
        mod_type = mod.get("type", "")
        
        if mod_type == "add_import":
            # Add import statement at the top
            import_stmt = mod.get("content", "")
            if import_stmt:
                # Find where imports end
                lines = modified_content.splitlines()
                import_end_line = 0
                
                # Look for existing imports
                for i, line in enumerate(lines):
                    if line.strip().startswith(("import ", "from ")):
                        import_end_line = i + 1
                
                # Insert import at the right position
                lines.insert(import_end_line, import_stmt)
                modified_content = "\n".join(lines)
        
        elif mod_type == "add_function":
            # Add function/method to the file
            function_content = mod.get("content", "")
            after_pattern = mod.get("after", "")
            
            if function_content:
                if after_pattern and after_pattern in modified_content:
                    # Insert after specific pattern
                    parts = modified_content.split(after_pattern, 1)
                    modified_content = parts[0] + after_pattern + "\n\n" + function_content + "\n" + parts[1]
                else:
                    # Append to the end of the file
                    if not modified_content.endswith("\n"):
                        modified_content += "\n"
                    modified_content += "\n" + function_content + "\n"
        
        elif mod_type == "replace":
            # Replace text in the file
            search_text = mod.get("search", "")
            replace_text = mod.get("replace", "")
            
            if search_text and replace_text:
                modified_content = modified_content.replace(search_text, replace_text)
    
    # If no modifications were applied successfully or instructions were unclear,
    # use AI to apply the modifications
    if modified_content == original_content:
        modified_content = await self._generate_file_modifications_with_ai(
            original_content,
            file_info,
            project_analysis,
            feature_plan,
            context
        )
    
    return modified_content

async def _generate_file_modifications_with_ai(
    self, 
    original_content: str,
    file_info: Dict[str, Any],
    project_analysis: Dict[str, Any],
    feature_plan: Dict[str, Any],
    context: Dict[str, Any]
) -> str:
    """
    Use AI to generate modifications for a file when structured modifications fail.
    
    Args:
        original_content: Original file content
        file_info: Information about the file
        project_analysis: Analysis of the existing project
        feature_plan: Overall feature plan
        context: Context information
        
    Returns:
        Modified file content
    """
    self._logger.debug(f"Using AI to generate modifications for: {file_info['path']}")
    
    # Build prompt for generating modifications
    prompt = f"""
Modify the content of an existing file in a {project_analysis.get('project_type', 'unknown')} project to implement a new feature.

File path: {file_info['path']}
Modification purpose: {file_info.get('purpose', 'Unknown')}

This modification is part of a new feature described as:
{feature_plan.get('integration_points', ['Unknown'])[0] if feature_plan.get('integration_points') else 'Unknown'}

Original file content:
```
{original_content}
```

Your task is to modify this file to implement the specified feature. Return the complete modified content.
Follow the project's existing coding style and patterns.
"""
    
    # Call AI service
    api_request = GeminiRequest(
        prompt=prompt,
        max_tokens=8000,
        temperature=0.2
    )
    
    response = await gemini_client.generate_text(api_request)
    
    # Extract code from the response
    modified_content = self._extract_code_from_response(response.text, file_info['path'])
    return modified_content

async def _apply_feature_changes(
    self, 
    feature_files: Dict[str, Any],
    project_path: Path
) -> Dict[str, Any]:
    """
    Apply the generated feature changes to the project.
    
    Args:
        feature_files: Generated file contents and modifications
        project_path: Path to the project directory
        
    Returns:
        Dictionary with application results
    """
    self._logger.info("Applying feature changes to project")
    
    result = {
        "success": True,
        "created_files": [],
        "modified_files": [],
        "errors": []
    }
    
    # Create new files
    for file_info in feature_files.get("new_files", []):
        file_path = project_path / file_info["path"]
        
        try:
            # Create parent directories if needed
            await create_directory(file_path.parent, parents=True)
            
            # Write file content
            await write_file(file_path, file_info["content"])
            
            result["created_files"].append(str(file_path))
            self._logger.debug(f"Created new file: {file_path}")
        except Exception as e:
            self._logger.error(f"Error creating file {file_path}: {str(e)}")
            result["errors"].append({"path": str(file_path), "error": str(e)})
            result["success"] = False
    
    # Modify existing files
    for file_info in feature_files.get("modified_files", []):
        file_path = project_path / file_info["path"]
        
        try:
            # Check if file exists
            if not file_path.exists():
                raise FileNotFoundError(f"File not found: {file_path}")
            
            # Write modified content
            await write_file(file_path, file_info["modified_content"])
            
            result["modified_files"].append(str(file_path))
            self._logger.debug(f"Modified file: {file_path}")
        except Exception as e:
            self._logger.error(f"Error modifying file {file_path}: {str(e)}")
            result["errors"].append({"path": str(file_path), "error": str(e)})
            result["success"] = False
    
    return result


async def _extract_dependencies_from_feature(
    self, 
    feature_files: Dict[str, Any],
    project_type: str
) -> Dict[str, List[str]]:
    """
    Extract dependencies from newly added or modified feature files.
    
    Args:
        feature_files: Dictionary with new and modified files
        project_type: Type of the project (python, node, etc.)
        
    Returns:
        Dictionary with runtime and development dependencies
    """
    self._logger.info("Extracting dependencies from feature files")
    
    dependencies = {
        "runtime": [],
        "development": []
    }
    
    # Process based on project type
    if project_type == "python":
        # Look for Python import statements in new files
        for file_info in feature_files.get("new_files", []):
            if file_info["path"].endswith(".py"):
                content = file_info["content"]
                
                # Extract import statements using regex
                import_lines = re.findall(r'^(?:import|from)\s+([^\s.]+)(?:\.|.*?import)', content, re.MULTILINE)
                
                # Filter out standard library modules
                for module in import_lines:
                    if module not in sys.modules or (hasattr(sys.modules[module], '__file__') and 
                                                    sys.modules[module].__file__ and 
                                                    'site-packages' in sys.modules[module].__file__):
                        if module not in dependencies["runtime"] and module not in ["__future__", "typing", "os", "sys", "re", "json", "time", "datetime"]:
                            dependencies["runtime"].append(module)
        
        # Also check modified files for new imports
        for file_info in feature_files.get("modified_files", []):
            if file_info["path"].endswith(".py"):
                original_content = file_info["original_content"]
                modified_content = file_info["modified_content"]
                
                # Extract imports from original and modified content
                original_imports = set(re.findall(r'^(?:import|from)\s+([^\s.]+)(?:\.|.*?import)', original_content, re.MULTILINE))
                modified_imports = set(re.findall(r'^(?:import|from)\s+([^\s.]+)(?:\.|.*?import)', modified_content, re.MULTILINE))
                
                # Find new imports
                new_imports = modified_imports - original_imports
                
                # Add to dependencies list
                for module in new_imports:
                    if module not in dependencies["runtime"] and module not in ["__future__", "typing", "os", "sys", "re", "json", "time", "datetime"]:
                        dependencies["runtime"].append(module)
                        
    elif project_type == "node":
        # Look for import/require statements in JavaScript/TypeScript files
        js_extensions = [".js", ".jsx", ".ts", ".tsx"]
        
        for file_info in feature_files.get("new_files", []):
            if any(file_info["path"].endswith(ext) for ext in js_extensions):
                content = file_info["content"]
                
                # Look for ES6 imports
                es6_imports = re.findall(r'import\s+.*?from\s+[\'"]([^\'".][^\'"]*)[\'"]\s*;?', content)
                
                # Look for require statements
                require_imports = re.findall(r'(?:const|let|var)\s+.*?=\s+require\([\'"]([^\'".][^\'"]*)[\'"]\)\s*;?', content)
                
                # Combine all found imports
                all_imports = es6_imports + require_imports
                
                # Filter out relative imports
                for module in all_imports:
                    if not module.startswith(".") and module not in dependencies["runtime"]:
                        dependencies["runtime"].append(module)
        
        # Also check modified files
        for file_info in feature_files.get("modified_files", []):
            if any(file_info["path"].endswith(ext) for ext in js_extensions):
                original_content = file_info["original_content"]
                modified_content = file_info["modified_content"]
                
                # Extract imports from original content
                original_es6 = set(re.findall(r'import\s+.*?from\s+[\'"]([^\'".][^\'"]*)[\'"]\s*;?', original_content))
                original_require = set(re.findall(r'(?:const|let|var)\s+.*?=\s+require\([\'"]([^\'".][^\'"]*)[\'"]\)\s*;?', original_content))
                original_imports = original_es6.union(original_require)
                
                # Extract imports from modified content
                modified_es6 = set(re.findall(r'import\s+.*?from\s+[\'"]([^\'".][^\'"]*)[\'"]\s*;?', modified_content))
                modified_require = set(re.findall(r'(?:const|let|var)\s+.*?=\s+require\([\'"]([^\'".][^\'"]*)[\'"]\)\s*;?', modified_content))
                modified_imports = modified_es6.union(modified_require)
                
                # Find new imports
                new_imports = modified_imports - original_imports
                
                # Add to dependencies list
                for module in new_imports:
                    if not module.startswith(".") and module not in dependencies["runtime"]:
                        dependencies["runtime"].append(module)
    
    # Add common testing libraries based on project type
    if project_type == "python":
        dependencies["development"] = ["pytest", "pytest-cov"]
    elif project_type == "node":
        dependencies["development"] = ["jest", "eslint"]
    
    return dependencies



code_generation_engine = CodeGenerationEngine()
</file>

<file path="angela/cli/main.py">
"""
Main command-line interface for Angela CLI.
"""
import sys
import asyncio
from typing import List, Optional

import typer
from rich.console import Console
from rich.panel import Panel
from rich.syntax import Syntax
from rich import print as rich_print

from angela import __version__
from angela.config import config_manager
from angela.context import context_manager
from angela.orchestrator import orchestrator
from angela.execution.engine import execution_engine
from angela.utils.logging import setup_logging, get_logger
from angela.shell.formatter import terminal_formatter, OutputType
from angela.ai.analyzer import error_analyzer
from angela.context.session import session_manager

# Create the app
app = typer.Typer(help="Angela: AI-powered command-line assistant")
logger = get_logger(__name__)
console = Console()


def version_callback(value: bool):
    """Display version information and exit."""
    if value:
        console.print(f"Angela CLI version: {__version__}")
        sys.exit(0)


@app.callback()
def main(
    debug: bool = typer.Option(
        False, "--debug", "-d", help="Enable debug mode"
    ),
    version: bool = typer.Option(
        False, "--version", "-v", callback=version_callback, help="Show version and exit"
    ),
    monitor: bool = typer.Option(
        False, "--monitor", "-m", help="Enable background monitoring for proactive assistance"
    ),
):
    """Angela: AI-powered command-line assistant"""
    # Set debug mode
    config_manager.config.debug = debug
    
    # Configure logging
    setup_logging(debug=debug)
    
    # Start background monitoring if requested
    if monitor:
        # Import here to avoid circular imports
        from angela.monitoring.background import background_monitor
        background_monitor.start_monitoring()


@app.command()
def request(
    request_text: List[str] = typer.Argument(
        ..., help="The natural language request for Angela."
    ),
    suggest_only: bool = typer.Option(
        False, "--suggest-only", "-s", help="Only suggest commands without executing."
    ),
    dry_run: bool = typer.Option(
        False, "--dry-run", help="Preview command execution without making changes."
    ),
    force: bool = typer.Option(
        False, "--force", "-f", help="Execute without confirmation, even for risky operations."
    ),
):
    """Send a natural language request to Angela."""
    # Combine all arguments into a single request string
    full_request = " ".join(request_text)
    
    try:
        # If forcing execution, set this in the session
        if force:
            session_manager.add_entity("force_execution", "preference", "true")
        
        # Process the request - note execute=True is now the default
        # Only switch to false if suggest_only is True
        execute = not suggest_only
        
        # Call the orchestrator to process the request
        result = asyncio.run(orchestrator.process_request(
            full_request, execute=execute, dry_run=dry_run
        ))
        
        if "suggestion" in result:
            suggestion = result["suggestion"]
            
            # Display the suggestion with rich formatting
            terminal_formatter.print_command(suggestion.command, title="Command")
            
            # Show confidence if available
            if "confidence" in result:
                confidence = result["confidence"]
                confidence_color = "green" if confidence > 0.8 else "yellow" if confidence > 0.6 else "red"
                console.print(f"[bold]Confidence:[/bold] [{confidence_color}]{confidence:.2f}[/{confidence_color}]")
            
            # Show explanation
            console.print("\n[bold]Explanation:[/bold]")
            console.print(suggestion.explanation)
            
            # Show execution results if executed
            if "execution" in result:
                execution = result["execution"]
                console.print("\n[bold]Command Output:[/bold]")
                
                if execution["success"]:
                    if execution["stdout"].strip():
                        terminal_formatter.print_output(
                            execution["stdout"],
                            OutputType.STDOUT,
                            title="Output"
                        )
                    else:
                        console.print("[green]Command executed successfully with no output.[/green]")
                else:
                    console.print("[bold red]Command failed[/bold red]")
                    if execution["stderr"].strip():
                        terminal_formatter.print_output(
                            execution["stderr"],
                            OutputType.STDERR,
                            title="Error"
                        )
                    
                    # Show error analysis if available
                    if "error_analysis" in result:
                        terminal_formatter.print_error_analysis(result["error_analysis"])
                        
                    # Show fix suggestions if available
                    if "fix_suggestions" in execution:
                        console.print("\n[bold]Suggested fixes:[/bold]")
                        for suggestion in execution["fix_suggestions"]:
                            console.print(f"• {suggestion}")
            
        else:
            # Fall back to simple response if no suggestion
            panel_content = result.get("response", "I couldn't process that request.")
            console.print(Panel(panel_content, title="Angela", expand=False))
        
        # In debug mode, show context information
        if config_manager.config.debug:
            context_text = "\n".join([f"{k}: {v}" for k, v in result["context"].items()])
            rich_print("[bold blue]Context:[/bold blue]")
            rich_print(context_text)
            
    except Exception as e:
        logger.exception("Error processing request")
        console.print(f"[bold red]Error:[/bold red] {str(e)}")
        if config_manager.config.debug:
            import traceback
            console.print(traceback.format_exc())
        sys.exit(1)


@app.command()
def init():
    """Initialize Angela CLI with configuration."""
    console.print("Initializing Angela CLI...")
    
    # Check if API key is already set
    if config_manager.config.api.gemini_api_key:
        console.print("[green]API key already configured.[/green]")
    else:
        console.print("Google Gemini API key is required for Angela to function.")
        api_key = typer.prompt("Enter your Gemini API key", hide_input=True)
        config_manager.config.api.gemini_api_key = api_key
    
    # Configure safety options
    confirm_all = typer.confirm("Require confirmation for all operations?", default=False)
    config_manager.config.user.confirm_all_actions = confirm_all
    
    # Configure project root
    set_project_root = typer.confirm("Set a default project root?", default=False)
    if set_project_root:
        project_root = typer.prompt("Enter the path to your default project root")
        config_manager.config.user.default_project_root = project_root
    
    # Save the configuration
    config_manager.save_config()
    
    console.print("[green]Configuration saved successfully![/green]")
    console.print("\nAngela CLI is now initialized. You can use the following commands:")
    console.print("  [blue]angela <your request>[/blue] - Process a natural language request")
    console.print("  [blue]angela files <command>[/blue] - Perform file operations")
    console.print("  [blue]angela --help[/blue] - Show help")


@app.command("status")
def show_status():
    """Show the status of Angela CLI features and components."""
    from rich.table import Table
    
    # Get integration status
    from angela.integrations import phase_integration
    status = asyncio.run(phase_integration.status())
    
    # Display general status
    console.print(Panel(
        f"Angela CLI - Phase {status['phase']}\n"
        f"{status['description']}",
        title="Status",
        expand=False
    ))
    
    # Display enabled features
    if status.get("enabled_features"):
        console.print("\n[bold]Enabled Features:[/bold]")
        for feature in status["enabled_features"]:
            console.print(f"• {feature}")
    
    # Display project information if available
    if status.get("project"):
        project = status["project"]
        console.print("\n[bold]Project Information:[/bold]")
        console.print(f"• Type: {project['type']}")
        if project.get("frameworks"):
            console.print(f"• Frameworks: {', '.join(project['frameworks'])}")
        if "dependencies_count" in project:
            console.print(f"• Dependencies: {project['dependencies_count']}")
    
    # Display network monitoring status if available
    if status.get("network_monitoring"):
        network = status["network_monitoring"]
        console.print("\n[bold]Network Monitoring:[/bold]")
        console.print(f"• Status: {network['status']}")
        console.print(f"• Services Monitored: {network['services_monitored']}")
        console.print(f"• Dependency Updates: {network['dependency_updates']}")
    
    console.print("\n[bold]System Information:[/bold]")
    console.print(f"• Current Directory: {context_manager.cwd}")
    if context_manager.project_root:
        console.print(f"• Project Root: {context_manager.project_root}")



# Add this to angela/cli/main.py

@app.command("--notify", hidden=True)
def notify(
    notification_type: str = typer.Argument(..., help="Type of notification"),
    args: List[str] = typer.Argument(None, help="Additional arguments")
):
    """
    Handle notifications from shell hooks.
    This is an internal command not meant to be called directly by users.
    """
    # Import here to avoid circular imports
    from angela.monitoring.notification_handler import notification_handler
    
    try:
        # Run the notification handler asynchronously
        asyncio.run(notification_handler.handle_notification(notification_type, *args))
    except Exception as e:
        logger.exception(f"Error handling notification: {str(e)}")
        # Swallow the exception to avoid disrupting the shell
        pass
    
    # Always exit cleanly - we don't want to disrupt the shell
    return

@app.command("--completions", hidden=True)
def completions(
    args: List[str] = typer.Argument(None, help="Current command line arguments")
):
    """
    Generate completions for the angela command.
    This is an internal command used by shell completion.
    """
    try:
        # Import here to avoid circular imports
        from angela.shell.completion import completion_handler
        
        # Get the completions
        result = asyncio.run(completion_handler.get_completions(args))
        
        # Print the completions directly to stdout for shell consumption
        print(" ".join(result))
    except Exception as e:
        logger.exception(f"Error generating completions: {str(e)}")
        # Return empty result on error
        print("")
    
    return



@app.command()
def shell():
    """Launch an interactive shell with Angela."""
    from prompt_toolkit import PromptSession
    from prompt_toolkit.history import FileHistory
    from prompt_toolkit.auto_suggest import AutoSuggestFromHistory
    from prompt_toolkit.completion import WordCompleter
    
    # Create a history file
    history_file = config_manager.CONFIG_DIR / "shell_history.txt"
    history_file.parent.mkdir(parents=True, exist_ok=True)
    
    # Create session with history
    session = PromptSession(
        history=FileHistory(str(history_file)),
        auto_suggest=AutoSuggestFromHistory(),
    )
    
    console.print(Panel(
        "Welcome to Angela's interactive shell!\n"
        "Type your requests directly and press Enter.\n"
        "Type 'exit' or press Ctrl+D to exit.",
        title="Angela Interactive Shell",
        expand=False
    ))
    
    # Main interaction loop
    while True:
        try:
            # Get input from the user
            text = session.prompt("angela> ")
            
            # Check for exit command
            if text.lower() in ("exit", "quit", "bye"):
                break
            
            # Skip empty input
            if not text.strip():
                continue
            
            # Process the request
            result = asyncio.run(orchestrator.process_request(text))
            
            # Display the response
            if "suggestion" in result:
                suggestion = result["suggestion"]
                
                # Show the command suggestion
                console.print("[bold]I suggest:[/bold]")
                command_syntax = Syntax(suggestion.command, "bash", theme="monokai")
                console.print(Panel(command_syntax, title="Command", expand=False))
                
                # Show explanation
                console.print(suggestion.explanation)
                
                # Ask if the user wants to execute the command
                execute_command = typer.confirm("Execute this command?", default=False)
                if execute_command:
                    # Execute the command
                    stdout, stderr, return_code = asyncio.run(
                        execution_engine.execute_command(suggestion.command)
                    )
                    
                    # Display the results
                    if return_code == 0:
                        if stdout:
                            console.print(Panel(stdout, title="Output", expand=False))
                        else:
                            console.print("[green]Command executed successfully with no output.[/green]")
                    else:
                        console.print("[bold red]Command failed:[/bold red]")
                        if stderr:
                            console.print(Panel(stderr, title="Error", expand=False))
            
            else:
                # Fall back to simple response
                console.print(result.get("response", "I couldn't process that request."))
            
            # Add a separator between interactions
            console.print("─" * console.width)
            
        except KeyboardInterrupt:
            # Handle Ctrl+C gracefully
            continue
        except EOFError:
            # Handle Ctrl+D (exit)
            break
        except Exception as e:
            logger.exception("Error in interactive shell")
            console.print(f"[bold red]Error:[/bold red] {str(e)}")
    
    console.print("Goodbye!")
</file>

<file path="angela/__init__.py">
def init_application():
    """Initialize all application components."""
    # Import components here to avoid early imports during module loading
    from angela.execution.engine import execution_engine
    from angela.execution.adaptive_engine import adaptive_engine
    from angela.safety import check_command_safety, validate_command_safety
    from angela.orchestrator import orchestrator
    from angela.toolchain.docker import docker_integration
    
    # Import enhanced planner integration
    from angela.integrations.enhanced_planner_integration import apply_enhanced_planner_integration
    
    # This import might be missing, let's check if it exists
    try:
        from angela.integrations.semantic_integration import apply_semantic_integration
        has_semantic_integration = True
    except ImportError:
        has_semantic_integration = False
    
    from angela.context.enhancer import context_enhancer    
    
    # Register core services
    registry.register("execution_engine", execution_engine)
    registry.register("adaptive_engine", adaptive_engine)
    registry.register("check_command_safety", check_command_safety)
    registry.register("validate_command_safety", validate_command_safety)
    registry.register("orchestrator", orchestrator)
    registry.register("context_enhancer", context_enhancer)
    registry.register("docker_integration", docker_integration)

    # Apply integrations
    apply_enhanced_planner_integration()
    
    # Apply semantic integration if available
    if has_semantic_integration:
        apply_semantic_integration()
</file>

<file path="README.md">
# Angela-CLI
1.  **I want an AI partner so deeply woven into my shell that its presence feels almost ambient, yet instantly responsive.** It's more than just a keyword trigger; I want the boundary between my standard shell commands and my instructions to "Angela" to blur. When I type `Angela refactor the main loop in processor.py for clarity`, I want the shell's response mechanism itself to feel like it *understands* this isn't a literal command named "Angela" but an invocation of this embedded intelligence. The transition should be frictionless, immediate, and devoid of the clunkiness of launching a separate process or waiting for a distinct interface. It should feel less like I'm *running a tool* and more like the shell itself has gained a natural language understanding layer.
2.  **I want Angela's contextual awareness to be profound and dynamic.** Defining a project root is just the start. I want her to potentially infer the *type* of project (Is this a Node.js app? A Python library? A Hugo static site?) and leverage that knowledge. If I say `Angela add a dependency for 'requests'`, she should know to use `pip install requests` and update `requirements.txt` in a Python project, or `npm install requests` and update `package.json` in a Node project and more
3.  **I want to express complex, multi-step intentions, not just simple tasks.** My goal isn't just mapping single sentences to single commands. I want to be able to articulate workflows: `Angela, create a new feature branch named 'user-auth', switch to it, create a 'auth.py' file in the 'services' directory with a basic Flask blueprint structure, and then stage that new file.` Angela should be able to decompose this complex request into the necessary sequence of `git checkout -b`, `cd`, `touch`, code generation, and `git add` commands, presenting the entire plan for my approval. I want her to handle conditional logic implicitly
4.  **I want Angela's versatility to extend across my entire development ecosystem.** She shouldn't just be limited to file operations and code generation. I want her to be my natural language interface to other CLI tools I use daily:
    *   **Version Control:** `Angela, show me the differences in the last commit`, `Angela, revert the changes to 'config.yaml'`, `Angela, squash the last 3 commits into one`.
    *   **Containers:** `Angela, restart the 'webserver' docker container`, `Angela, show me the logs for the database container`.
    *   **Cloud Services:** `Angela, list my S3 buckets`, `Angela, deploy the latest changes to the staging environment` (invoking the necessary `gcloud`, `aws`, or `az` commands).
    *   **Databases:** (With appropriate configuration/safety) `Angela, show me the schema for the 'users' table`.
    She should become the universal translator for the myriad of CLI tools I interact with.

Ultimately, **I'm aiming for nothing less than a paradigm shift in command-line interaction.** I want to build an AI entity that lives within my terminal, understands my projects and my natural language goals deeply, and translates those goals into actions across my entire digital workspace. It's about creating an environment where the power of the command line is accessible through intuitive conversation, making me fundamentally more effective, creative, and less encumbered by technical minutiae. It's about building the command-line partner I've always wished I had. Imagine only a very very advanced genius programmer could create such a project
**Act as an expert Principal Software Architect.**
---------------
## Phases-- This is just a core struccture but will be expaned on 10x fold
## Brief Roadmap
## Implementation Plan
### Step 1: Project Setup & Shell Hook
1. Initialize project structure with core directories
2. Implement basic configuration loading (API keys)
3. Create shell function in `angela.bash`/`angela.zsh`:
   ```bash
   # Basic shell hook
   angela() {
     python -m angela "$@"
   }
   ```
4. Implement CLI entry point with argument parsing
5. Create simple echo capability that passes request to Python backend
### Step 2: Orchestration & Context
1. Build orchestrator to manage request flow
2. Implement working directory tracking
3. Create project root detection via markers (.git, etc.)
4. Add basic logging and error handling
5. Design data models for requests/responses
6. Implement testing framework
### Step 3: Gemini API Integration
1. Create Gemini API client class
2. Design initial prompt templates with context injection
3. Implement response parsing and error handling
4. Build basic intent classification (command vs. file operation)
5. Add simple command suggestion capability (non-executing
### Step 4: Smarter Single Commands & Richer Interaction
1.  Advanced NLU for complex/ambiguous commands with interactive clarification.
2.  Real-time, rich feedback & asynchronous output streaming.
3.  Context-aware adaptive confirmation (risk-based).
4.  Robust file/directory operations (recursive, pattern matching, type detection).
### Step 5: Autonomous Multi-Step Tasks & Proactive Help
1.  Decompose & orchestrate multi-step tasks from high-level goals.
2.  Session memory for conversational context (follow-up commands).
3.  AI understanding & manipulation of file content (refactoring, updates).
4.  User-defined workflows via natural language.
5.  Proactive monitoring, suggestions & advanced multi-step rollback.
### Step 6: Enhanced Project Context
1. Implement project type inference
2. Add dependency detection in projects
3. Create file reference resolution from natural language
4. Implement recent activity tracking
5. massivly Enhance prompt engineering with project context
### Step 7: Developer Tool Integration (MAIN ASPECTY OF THIS WHOLE THING WERE IT COMES ALL TOGETHOR)
1. Add Git commands integration
2. Implement Docker support
3. Create code generation flow. it should be able to create 8000 word code files, or small websites/apps etc etc. its essntially a code agent capapbale of great coding stregths. if teh user sasy "create me a porfolio website" it shoud be able to udnertand that and go ahead and create a whole directory/tree structure with files and even code those files in full and have it fully ready for developement.
# *********WHAT I WANT TO ACHEIVE (BRIEF OVERVIEW) - IT WILL BE SOEM OF THIS BUT EVEN MORE AND AT AN EVEN HIGHER LEVEL, WERE ESSENRTIALLY RECREATING TEH MOST INTELLEGENT AND CAPABLE OPERATING SYSTEM, TERMINAL, SOFTWARE DEVELOPER, DEVOPS ENGINEER, AI AGENT, AND MORE< WERE CREATING AGI BUT IN A TERMINAL. TEH WORLDS FIRST AGI WILL BE CREATED BY ME AND WILL LIVE IN A TERMINAL*****
**Phase 8: Seamless Shell Integration & Enhanced Interaction**

*   **Goal:** Make Angela feel like an intrinsic part of the shell, blurring the lines between standard commands and AI interactions. Improve the core user experience for invoking and interacting with Angela.
*   **Key Objectives:**
    *   **Advanced Shell Hooking:** Investigate and implement deeper shell integration beyond simple aliases. Explore options like:
        *   Zsh/Bash plugins for more sophisticated input interception or pre-command hooks.
        *   Potential integration with terminal multiplexers (like tmux or Zellij) if feasible.
        *   Using `PROMPT_COMMAND` (Bash) or `precmd`/`preexec` (Zsh) hooks for contextual awareness *before* a command is run or *after* it finishes.
    *   **Natural Invocation:** Design mechanisms where Angela can be invoked more naturally, perhaps even implicitly based on command patterns or specific keywords within a command line, rather than always requiring the `angela` prefix. (e.g., detecting `git commit -m "refactor login logic based on ticket #123"` and offering AI assistance).
    *   **Inline Feedback & Interaction:** Enhance `shell/formatter.py` to allow Angela to provide feedback or ask clarifying questions *inline* within the terminal session, potentially modifying the current command line or presenting interactive prompts without breaking the user's flow entirely.
    *   **Contextual Auto-Completion:** Develop AI-powered auto-completion suggestions that leverage Angela's understanding of the project context, recent files, and user intent.

**Phase 9: Deep Contextual Understanding & Semantic Awareness**

*   **Goal:** Elevate Angela's understanding from file paths and types to the *semantic meaning* of code, project state, and complex user intentions.
*   **Key Objectives:**
    *   **Code Semantic Analysis:** Integrate more advanced static analysis tools (like tree-sitter or language servers) or leverage the LLM's code understanding capabilities more deeply to parse functions, classes, dependencies within code files.
    *   **Project State Inference:** Move beyond basic type detection. Infer the *state* of the project (e.g., current Git branch status, pending migrations, test coverage status, build health).
    *   **Fine-Grained Activity Tracking:** Enhance `context/file_activity.py` to track not just file access, but potentially specific function/class modifications (might require IDE integration or file watching with parsing).
    *   **Advanced Intent Decomposition:** Improve `intent/enhanced_task_planner.py` to handle more ambiguous, multi-stage goals. Develop strategies for the LLM to ask clarifying questions when decomposition is uncertain.
    *   **Contextual Prompting V2:** Refine `ai/prompts.py` to feed semantic code information, detailed project state, and nuanced user history to the LLM for significantly more informed responses.

**Phase 10: Expanded Ecosystem Integration (Core Developer Tools)**

*   **Goal:** Enable Angela to understand and interact with a wider range of essential developer tools beyond basic Git and package managers.
*   **Key Objectives:**
    *   **Docker Integration:** Implement understanding and execution of common Docker commands (`build`, `run`, `ps`, `logs`, `stop`, `rm`). Allow requests like "Angela, show me the logs for the webserver container" or "Rebuild the backend Docker image". Requires specific command generation logic and potentially parsing Docker output.
  
    *   **Toolchain Module Enhancement:** Refactor and expand `angela/toolchain/` to include dedicated modules for Docker, abstracting the interaction logic.

**Phase 11: Autonomous Multi-File Code Generation & Refinement**

*   **Goal:** Enable Angela to generate and modify entire multi-file codebases based on high-level descriptions, including interactive refinement.
*   **Key Objectives:**
    *   **Multi-File Planning:** Enhance `generation/planner.py` and `generation/architecture.py` to plan complex directory structures and inter-file dependencies for larger projects (e.g., full web applications).
    *   **Coherent Code Generation:** Improve `generation/engine.py` to generate consistent code across multiple files, ensuring imports, function calls, and data structures align. This likely involves iterative generation and passing context between file generation steps.
    *   **Massive Context Handling:** Implement strategies (e.g., RAG with code context, summarization, iterative prompting) to manage the large context required for generating substantial codebases with the LLM.
    *   **Interactive Refinement Loop:** Integrate `review/feedback.py` and `review/diff_manager.py` more deeply. After generation, present a summary/diff to the user and allow natural language feedback (e.g., "Change the database model to include an email field", "Use functional components instead of class components in React") to trigger regeneration/modification cycles.
    *   **Framework Specialization:** Enhance `generation/frameworks.py` to support generating more complete and idiomatic code for the specific frameworks detected in Phase 9/10.

**Phase 12: Advanced Orchestration & Universal Tool Translation**

*   **Goal:** Achieve near-AGI capability within the terminal by enabling complex task orchestration across *any* CLI tool and automating full CI/CD pipelines.
*   **Key Objectives:**
    *   **Universal CLI Translator:** Develop a robust mechanism (likely LLM-driven with sophisticated prompting and validation) to translate natural language requests into commands for *arbitrary* CLI tools, leveraging `--help` output, man pages, or general knowledge. This requires strong safety validation (`safety/validator.py`).
    *   **Complex Workflow Orchestration:** Enhance the `Orchestrator` and `EnhancedTaskPlanner` to handle workflows involving sequences of commands across different tools (e.g., Git -> Docker -> Cloud CLI -> kubectl).
    *   **Automated CI/CD Pipeline Execution:** Integrate `toolchain/ci_cd.py` fully. Allow requests like "Set up a full CI/CD pipeline for this Node.js project on GitHub Actions, including build, test, lint, and deploy to staging". This involves generating complex configuration *and* potentially triggering initial pipeline runs or setup commands.
    *   **Self-Correction & Learning:** Implement mechanisms for Angela to learn from failed commands or workflows, potentially attempting self-correction or refining its understanding of specific tools based on error messages and successful outcomes.
    *   **Proactive Assistance V2:** Enhance `monitoring/background.py` to offer more complex suggestions based on combined context (e.g., "Your tests failed after the last commit, want me to try reverting and rerunning?", "Your cloud deployment seems to be unhealthy, want me to check the logs?").

These 5 phases provide a structured approach to tackling the remaining challenges, moving from foundational UX improvements and deeper understanding towards complex actions and broad tool integration, culminating in the advanced orchestration required for the AGI-like vision.

These 5 phases provide a structured approach to tackling the remaining challenges, moving from foundational UX improvements and deeper understanding towards complex actions and broad tool integration, culminating in the advanced orchestration required for the AGI-like vision.



This will establish the core infrastructure before integrating AI capabilities, ensuring a solid foundation for the more complex features to follow, to ocomplish IT WILL BE SOEM OF THIS BUT EVEN MORE AND AT AN EVEN HIGHER LEVEL, WERE ESSENRTIALLY RECREATING TEH MOST INTELLEGENT AND CAPABLE OPERATING SYSTEM, TERMINAL, SOFTWARE DEVELOPER, DEVOPS ENGINEER, AI AGENT, AND MORE< WERE CREATING AGI BUT IN A TERMINAL. TEH WORLDS FIRST AGI WILL BE CREATED BY ME AND WILL LIVE IN A TERMINAL*****
</file>

<file path="angela/orchestrator.py">
"""
Main orchestration service for Angela CLI.

This module coordinates all the components of Angela CLI, from receiving
user requests to executing commands with safety checks.
"""
import asyncio
import re
from typing import Dict, Any, Optional, List, Tuple, Union
from pathlib import Path
from enum import Enum
import uuid
from rich.console import Console


from angela.ai.client import gemini_client, GeminiRequest
from angela.ai.prompts import build_prompt
from angela.ai.parser import parse_ai_response, CommandSuggestion
from angela.ai.file_integration import extract_file_operation, execute_file_operation
from angela.ai.content_analyzer import content_analyzer
from angela.ai.content_analyzer_extensions import EnhancedContentAnalyzer
from angela.context import context_manager
from angela.context.session import session_manager
from angela.context.history import history_manager
from angela.execution.engine import execution_engine
from angela.execution.adaptive_engine import adaptive_engine
from angela.ai.analyzer import error_analyzer
from angela.ai.intent_analyzer import intent_analyzer
from angela.intent.models import AdvancedTaskPlan, TaskPlan
from angela.ai.confidence import confidence_scorer
from angela.intent.planner import task_planner
from angela.workflows.manager import workflow_manager
from angela.utils.logging import get_logger
from angela.shell.formatter import terminal_formatter, OutputType
from angela.execution.error_recovery import ErrorRecoveryManager
from angela.context.enhancer import context_enhancer
from angela.context.file_resolver import file_resolver
from angela.context.file_activity import file_activity_tracker, ActivityType
from angela.execution.hooks import execution_hooks
from angela.core.registry import registry
from angela.shell import advanced_formatter
from angela.monitoring.background import background_monitor
from angela.monitoring.network_monitor import network_monitor
from angela.execution.rollback import rollback_manager  
from angela.safety.classifier import classify_command_risk, analyze_command_impact 
from angela.context.preferences import preferences_manager  
from angela.safety.adaptive_confirmation import get_adaptive_confirmation
from angela.toolchain.docker import docker_integration


logger = get_logger(__name__)

class RequestType(Enum):
    """Types of requests that can be handled by the orchestrator."""
    COMMAND = "command"                # Single command suggestion
    MULTI_STEP = "multi_step"          # Multi-step operation
    FILE_CONTENT = "file_content"      # File content analysis/manipulation
    WORKFLOW_DEFINITION = "workflow"   # Define a new workflow
    WORKFLOW_EXECUTION = "run_workflow" # Execute a workflow
    CLARIFICATION = "clarification"    # Request for clarification
    CODE_GENERATION = "code_generation" # Generate a complete project
    FEATURE_ADDITION = "feature_addition" # Add feature to existing project
    TOOLCHAIN_OPERATION = "toolchain_operation" # DevOps operations (CI/CD, etc.)
    CODE_REFINEMENT = "code_refinement" # Refine/improve existing code
    CODE_ARCHITECTURE = "code_architecture" # Analyze or enhance architecture
    UNKNOWN = "unknown"                # Unknown request type
    
class Orchestrator:
    """Main orchestration service for Angela CLI."""
    
    def __init__(self):
        """Initialize the orchestrator."""
        self._logger = logger
        self._background_tasks = set()
        self._error_recovery_manager = ErrorRecoveryManager()
        self._background_monitor = background_monitor
        self._network_monitor = network_monitor
        
        
        self._background_monitor.register_insight_callback(self._handle_monitoring_insight)
        
    async def process_request(
        self, 
        request: str, 
        execute: bool = True,
        dry_run: bool = False
    ) -> Dict[str, Any]:
        '''
        Process a request from the user with enhanced context.
        
        Args:
            request: The user request
            execute: Whether to execute commands
            dry_run: Whether to simulate execution without making changes
            
        Returns:
            Dictionary with processing results
        '''
        # Initialize dependencies we'll need (getting from registry avoids circular imports)
        if self._error_recovery_manager is None:
            self._error_recovery_manager = registry.get("error_recovery_manager")
            
        # Get context enhancer from registry
        context_enhancer = registry.get("context_enhancer")
        # Refresh context to ensure we have the latest information
        context_manager.refresh_context()
        context = context_manager.get_context_dict()
        
        # Add session context for continuity across requests
        session_context = session_manager.get_context()
        context["session"] = session_context
        
        # Enhance context with project information, dependencies, and recent activity
        context = await context_enhancer.enrich_context(context)
        
        self._logger.info(f"Processing request: {request}")
        self._logger.debug(f"Enhanced context with {len(context)} keys")
        
        # Extract and resolve file references
        file_references = await file_resolver.extract_references(request, context)
        if file_references:
            # Add resolved file references to context
            context["resolved_files"] = [
                {"reference": ref, "path": str(path) if path else None}
                for ref, path in file_references
            ]
            self._logger.debug(f"Resolved {len(file_references)} file references")
        
        try:
            # Analyze the request to determine its type
            request_type = await self._determine_request_type(request, context)
            self._logger.info(f"Determined request type: {request_type.value}")
            
            # Process the request based on its type
            if request_type == RequestType.COMMAND:
                # Handle single command request
                return await self._process_command_request(request, context, execute, dry_run)
                
            elif request_type == RequestType.MULTI_STEP:
                # Handle multi-step operation
                return await self._process_multi_step_request(request, context, execute, dry_run)
                
            elif request_type == RequestType.FILE_CONTENT:
                # Handle file content analysis/manipulation
                return await self._process_file_content_request(request, context, execute, dry_run)
                
            elif request_type == RequestType.WORKFLOW_DEFINITION:
                # Handle workflow definition
                return await self._process_workflow_definition(request, context)
                
            elif request_type == RequestType.WORKFLOW_EXECUTION:
                # Handle workflow execution
                return await self._process_workflow_execution(request, context, execute, dry_run)
                
            elif request_type == RequestType.CLARIFICATION:
                # Handle request for clarification
                return await self._process_clarification_request(request, context)
                               
            # Phase 7 integration points
            elif request_type == RequestType.CODE_GENERATION:
                return await self._process_code_generation_request(request, context, execute, dry_run)
                
            elif request_type == RequestType.FEATURE_ADDITION:
                return await self._process_feature_addition_request(request, context, execute, dry_run)
                
            elif request_type == RequestType.TOOLCHAIN_OPERATION:
                return await self._process_toolchain_operation(request, context, execute, dry_run)
                
            elif request_type == RequestType.CODE_REFINEMENT:
                return await self._process_code_refinement_request(request, context, execute, dry_run)
                
            elif request_type == RequestType.CODE_ARCHITECTURE:
                return await self._process_code_architecture_request(request, context, execute, dry_run)
                
            elif request_type == RequestType.CLARIFICATION:
                return await self._process_clarification_request(request, context)
                
            else:
                # Handle unknown request type
                return await self._process_unknown_request(request, context)
            
         
        except Exception as e:
            self._logger.exception(f"Error processing request: {str(e)}")
            # Fallback behavior
            return {
                "request": request,
                "response": f"An error occurred while processing your request: {str(e)}",
                "error": str(e),
                "context": context,
            }
    
    async def _determine_request_type(
            self, 
            request: str, 
            context: Dict[str, Any]
        ) -> RequestType:
            """
            Determine the type of request.
            
            Args:
                request: The user request
                context: Context information
                
            Returns:
                RequestType enum value
            """
            # Check for keywords and patterns indicating different request types
            
            # Workflow definition patterns
            workflow_def_patterns = [
                r'\b(?:define|create|make|add)\s+(?:a\s+)?(?:new\s+)?workflow\b',
                r'\bworkflow\s+(?:called|named)\b',
                r'\bsave\s+(?:this|these)\s+(?:as\s+(?:a\s+)?)?workflow\b',
            ]
            
            # Workflow execution patterns
            workflow_exec_patterns = [
                r'\brun\s+(?:the\s+)?workflow\b',
                r'\bexecute\s+(?:the\s+)?workflow\b',
                r'\bstart\s+(?:the\s+)?workflow\b',
            ]
            
            # File content patterns
            file_content_patterns = [
                r'\b(?:analyze|understand|summarize|examine)\s+(?:the\s+)?(?:content|code|text)\b',
                r'\b(?:modify|change|update|edit|refactor)\s+(?:the\s+)?(?:content|code|text|file)\b',
                r'\bfind\s+(?:in|inside|within)\s+(?:the\s+)?file\b',
            ]
            
            # Multi-step operation patterns
            multi_step_patterns = [
                r'\b(?:multiple steps|sequence|series|several|many)\b',
                r'\band then\b',
                r'\bafter that\b',
                r'\bone by one\b',
                r'\bstep by step\b',
                r'\bautomatically\b',
            ]
     
            # Docker operation patterns
            docker_patterns = [
                r'\bdocker\b',
                r'\bcontainer\b',
                r'\bdockerfile\b',
                r'\bdocker-compose\b',
                r'\bdocker\s+compose\b',
                r'\bimage\b.+\b(?:build|run|pull|push)\b',
                r'\b(?:build|run|pull|push)\b.+\bimage\b',
                r'\b(?:start|stop|restart|remove)\b.+\bcontainer\b',
                r'\bcontainer\b.+\b(?:start|stop|restart|remove)\b',
                r'\bgenerate\b.+\b(?:dockerfile|docker-compose)\b',
                r'\bsetup\s+docker\b',
                r'\bdocker\s+(?:ps|logs|images|rmi|exec)\b',
            ]
    
            code_generation_patterns = [
                r'\bcreate\s+(?:a\s+)?(?:new\s+)?(?:project|app|website|application)\b',
                r'\bgenerate\s+(?:a\s+)?(?:new\s+)?(?:project|app|website|application)\b',
                r'\bmake\s+(?:a\s+)?(?:new\s+)?(?:project|app|website|application)\b',
                r'\bbuild\s+(?:a\s+)?(?:whole|complete|full|entire)\b',
            ]
            
            # Feature addition patterns
            feature_addition_patterns = [
                r'\badd\s+(?:a\s+)?(?:new\s+)?feature\b',
                r'\bimplement\s+(?:a\s+)?(?:new\s+)?feature\b',
                r'\bcreate\s+(?:a\s+)?(?:new\s+)?feature\b',
                r'\bextend\s+(?:the\s+)?(?:project|app|code|application)\b',
            ]
            
            # Toolchain operation patterns
            toolchain_patterns = [
                r'\bsetup\s+(?:ci|cd|ci/cd|cicd|continuous integration|deployment)\b',
                r'\bconfigure\s+(?:ci|cd|ci/cd|cicd|continuous integration|deployment|git)\b',
                r'\bgenerate\s+(?:ci|cd|jenkins|gitlab|github)\b',
                r'\binstall\s+dependencies\b',
                r'\binitialize\s+(?:git|repo|repository)\b',
            ]
            
            # Code refinement patterns
            refinement_patterns = [
                r'\brefine\s+(?:the\s+)?code\b',
                r'\bimprove\s+(?:the\s+)?code\b',
                r'\boptimize\s+(?:the\s+)?code\b',
                r'\brefactor\s+(?:the\s+)?code\b',
                r'\bupdate\s+(?:the\s+)?code\b',
                r'\benhance\s+(?:the\s+)?code\b',
            ]
            
            # Architecture patterns
            architecture_patterns = [
                r'\banalyze\s+(?:the\s+)?(?:architecture|structure)\b',
                r'\bimprove\s+(?:the\s+)?(?:architecture|structure)\b',
                r'\bredesign\s+(?:the\s+)?(?:architecture|structure)\b',
                r'\bproject\s+structure\b',
            ]
        
        # Check for code generation first (highest priority)
        for pattern in code_generation_patterns:
            if re.search(pattern, request, re.IGNORECASE):
                return RequestType.CODE_GENERATION
        
        # Check for feature addition
        for pattern in feature_addition_patterns:
            if re.search(pattern, request, re.IGNORECASE):
                return RequestType.FEATURE_ADDITION
        
        # Check for toolchain operations
        for pattern in toolchain_patterns:
            if re.search(pattern, request, re.IGNORECASE):
                return RequestType.TOOLCHAIN_OPERATION
        
        # Check for code refinement
        for pattern in refinement_patterns:
            if re.search(pattern, request, re.IGNORECASE):
                return RequestType.CODE_REFINEMENT
        
        # Check for architecture analysis
        for pattern in architecture_patterns:
            if re.search(pattern, request, re.IGNORECASE):
                return RequestType.CODE_ARCHITECTURE
 
        
        # Check for workflow definition
        for pattern in workflow_def_patterns:
            if re.search(pattern, request, re.IGNORECASE):
                return RequestType.WORKFLOW_DEFINITION
        
        # Check for workflow execution
        for pattern in workflow_exec_patterns:
            if re.search(pattern, request, re.IGNORECASE):
                return RequestType.WORKFLOW_EXECUTION

        # Check for Docker operations first
        for pattern in docker_patterns:
            if re.search(pattern, request, re.IGNORECASE):
                return RequestType.TOOLCHAIN_OPERATION

        # Check for code generation (high priority)
        for pattern in code_generation_patterns:
            if re.search(pattern, request, re.IGNORECASE):
                return RequestType.CODE_GENERATION
        
        # Check for feature addition
        for pattern in feature_addition_patterns:
            if re.search(pattern, request, re.IGNORECASE):
                return RequestType.FEATURE_ADDITION
        
        # Check for toolchain operations
        for pattern in toolchain_patterns:
            if re.search(pattern, request, re.IGNORECASE):
                return RequestType.TOOLCHAIN_OPERATION
        
        # Check for code refinement
        for pattern in refinement_patterns:
            if re.search(pattern, request, re.IGNORECASE):
                return RequestType.CODE_REFINEMENT
        
        # Check for architecture analysis
        for pattern in architecture_patterns:
            if re.search(pattern, request, re.IGNORECASE):
                return RequestType.CODE_ARCHITECTURE

        
        # Check for file content analysis/manipulation
        file_mentions = re.search(r'\b(?:file|code|script|document)\b', request, re.IGNORECASE)
        if file_mentions:
            for pattern in file_content_patterns:
                if re.search(pattern, request, re.IGNORECASE):
                    return RequestType.FILE_CONTENT
        
        # Check for multi-step operation
        complexity_indicators = sum(bool(re.search(pattern, request, re.IGNORECASE)) for pattern in multi_step_patterns)
        if complexity_indicators >= 1 or len(request.split()) > 15:
            # Complex requests or longer instructions often imply multi-step operations
            return RequestType.MULTI_STEP
        
        # Default to single command
        return RequestType.COMMAND


    async def _process_code_generation_request(
        self, 
        request: str, 
        context: Dict[str, Any], 
        execute: bool, 
        dry_run: bool
    ) -> Dict[str, Any]:
        """
        Process a code generation request.
        
        Args:
            request: The user request
            context: Context information
            execute: Whether to execute the generation
            dry_run: Whether to simulate without making changes
            
        Returns:
            Dictionary with processing results
        """
        self._logger.info(f"Processing code generation request: {request}")
        
        # Import here to avoid circular imports
        from angela.generation.engine import code_generation_engine
        
        # Project details extraction
        project_details = await self._extract_project_details(request)
        
        # Get output directory (default to current dir)
        output_dir = project_details.get("output_dir", context.get("cwd", "."))
        
        # Get project type if specified
        project_type = project_details.get("project_type")
        
        # Create result structure
        result = {
            "request": request,
            "type": "code_generation",
            "context": context,
            "project_details": project_details
        }
        
        # Skip execution if not requested
        if not execute and not dry_run:
            return result
        
        # Generate the project using the generation engine
        with console.status(f"[bold green]Generating project based on: {request}[/bold green]"):
            project_plan = await code_generation_engine.generate_project(
                description=request,  # Use full request as description
                output_dir=output_dir,
                project_type=project_type,
                context=context
            )
        
        # Add project plan to result
        result["project_plan"] = {
            "name": project_plan.name,
            "description": project_plan.description,
            "project_type": project_plan.project_type,
            "file_count": len(project_plan.files),
            "structure_explanation": project_plan.structure_explanation
        }
        
        # Create files if not in dry run mode
        if not dry_run:
            with console.status("[bold green]Creating project files...[/bold green]"):
                creation_result = await code_generation_engine.create_project_files(project_plan)
                result["creation_result"] = creation_result
        else:
            result["dry_run"] = True
            
        # Add Git initialization if appropriate
        if not dry_run and project_details.get("git_init", True):
            from angela.toolchain.git import git_integration
            
            with console.status("[bold green]Initializing Git repository...[/bold green]"):
                git_result = await git_integration.init_repository(
                    path=output_dir,
                    initial_branch="main",
                    gitignore_template=project_plan.project_type
                )
                result["git_result"] = git_result
        
        return result

    async def _process_feature_addition_request(
        self, 
        request: str, 
        context: Dict[str, Any], 
        execute: bool, 
        dry_run: bool
    ) -> Dict[str, Any]:
        """
        Process a feature addition request.
        
        Args:
            request: The user request
            context: Context information
            execute: Whether to execute the feature addition
            dry_run: Whether to simulate without making changes
            
        Returns:
            Dictionary with processing results
        """
        self._logger.info(f"Processing feature addition request: {request}")
        
        # Import here to avoid circular imports
        from angela.generation.engine import code_generation_engine
        
        # Extract feature details
        feature_details = await self._extract_feature_details(request, context)
        
        # Get project directory (default to current dir)
        project_dir = feature_details.get("project_dir", context.get("cwd", "."))
        
        # Create result structure
        result = {
            "request": request,
            "type": "feature_addition",
            "context": context,
            "feature_details": feature_details
        }
        
        # Skip execution if not requested
        if not execute and not dry_run:
            return result
        
        # Add the feature to the project
        with console.status(f"[bold green]Adding feature to project: {request}[/bold green]"):
            addition_result = await code_generation_engine.add_feature_to_project(
                description=feature_details.get("description", request),
                project_dir=project_dir,
                context=context
            )
        
        result["addition_result"] = addition_result
        
        # Create branch if specified and not in dry run mode
        if not dry_run and feature_details.get("branch"):
            from angela.toolchain.git import git_integration
            
            branch_name = feature_details.get("branch")
            with console.status(f"[bold green]Creating branch: {branch_name}[/bold green]"):
                branch_result = await git_integration.create_branch(
                    path=project_dir,
                    branch_name=branch_name,
                    checkout=True
                )
                result["branch_result"] = branch_result
        
        return result



    async def _process_toolchain_operation(
        self, 
        request: str, 
        context: Dict[str, Any], 
        execute: bool, 
        dry_run: bool
    ) -> Dict[str, Any]:
        """
        Process a toolchain operation request.
        
        Args:
            request: The user request
            context: Context information
            execute: Whether to execute the operation
            dry_run: Whether to simulate without making changes
            
        Returns:
            Dictionary with processing results
        """
        self._logger.info(f"Processing toolchain operation request: {request}")
        
        # Extract operation details
        operation_details = await self._extract_toolchain_operation(request, context)
        
        # Get operation type
        operation_type = operation_details.get("operation_type", "unknown")
        
        # Create result structure
        result = {
            "request": request,
            "type": "toolchain_operation",
            "context": context,
            "operation_details": operation_details,
            "operation_type": operation_type
        }
        
        # Skip execution if not requested
        if not execute and not dry_run:
            return result
        
        # Process based on operation type
        if operation_type == "docker":
            result.update(await self._process_docker_operation(request, operation_details, context, dry_run))
        elif operation_type == "ci_cd":
            result.update(await self._process_ci_cd_operation(operation_details, context, dry_run))
        elif operation_type == "package_management":
            result.update(await self._process_package_operation(operation_details, context, dry_run))
        elif operation_type == "git":
            result.update(await self._process_git_operation(operation_details, context, dry_run))
        elif operation_type == "testing":
            result.update(await self._process_testing_operation(operation_details, context, dry_run))
        else:
            result["error"] = f"Unknown toolchain operation type: {operation_type}"
        
        return result
        
    async def _process_docker_operation(
        self,
        request: str,
        operation_details: Dict[str, Any],
        context: Dict[str, Any],
        dry_run: bool
    ) -> Dict[str, Any]:
        """
        Process a Docker operation request.
        
        Args:
            request: The user request
            operation_details: Details about the operation
            context: Context information
            dry_run: Whether to simulate without making changes
            
        Returns:
            Dictionary with processing results
        """
        self._logger.info(f"Processing Docker operation: {request}")
        
        # Get docker_integration from registry
        docker_integration = registry.get("docker_integration")
        if not docker_integration:
            return {
                "success": False,
                "error": "Docker integration not available in the system."
            }
            
        # Check Docker availability
        docker_available = await docker_integration.is_docker_available()
        if not docker_available:
            return {
                "success": False,
                "error": "Docker is not available on this system. Please install Docker to use this feature."
            }
            
        # Determine specific Docker operation
        docker_action = operation_details.get("docker_action", "")
        
        # Handle different Docker operations
        if "setup" in request.lower() or "generate" in request.lower() or "dockerfile" in request.lower() or "docker-compose" in request.lower():
            # Generate Docker configuration files
            project_dir = operation_details.get("project_dir", context.get("cwd", "."))
            
            result = await docker_integration.setup_docker_project(
                project_directory=project_dir,
                generate_dockerfile="dockerfile" in request.lower() or "setup" in request.lower(),
                generate_compose="compose" in request.lower() or "setup" in request.lower(),
                generate_dockerignore="dockerignore" in request.lower() or "setup" in request.lower(),
                overwrite=False,  # Default to safe operation
                include_databases="database" in request.lower() or "db" in request.lower(),
                build_image="build" in request.lower() and dry_run is False
            )
            
            # Format the result
            formatted_result = {
                "success": result.get("success", False),
                "message": "Docker setup completed",
                "files_generated": result.get("files_generated", []),
                "docker_details": result
            }
            
            return formatted_result
            
        elif "build" in request.lower() or "image" in request.lower():
            # Build Docker image
            project_dir = operation_details.get("project_dir", context.get("cwd", "."))
            image_tag = operation_details.get("image_tag", "app:latest")
            
            result = await docker_integration.build_image(
                context_path=project_dir,
                tag=image_tag,
                no_cache="no cache" in request.lower()
            )
            
            return {
                "success": result.get("success", False),
                "message": f"Docker image build {'completed' if result.get('success', False) else 'failed'}",
                "image_details": result
            }
            
        elif "run" in request.lower() or "start" in request.lower() or "launch" in request.lower():
            # Run Docker container
            image = operation_details.get("image", "")
            if not image:
                # Try to extract image from request
                image_match = re.search(r'(?:run|start|launch)\s+(?:container\s+)?(?:from\s+)?(\S+)(?:\s+image)?', request, re.IGNORECASE)
                if image_match:
                    image = image_match.group(1)
                else:
                    image = "app:latest"  # Default
            
            # Extract ports if mentioned
            ports = []
            ports_match = re.search(r'port[s]?\s+(\d+(?::\d+)?(?:,\s*\d+(?::\d+)?)*)', request, re.IGNORECASE)
            if ports_match:
                ports_str = ports_match.group(1)
                ports = [p.strip() for p in ports_str.split(',')]
            
            # Run container
            result = await docker_integration.run_container(
                image=image,
                ports=ports,
                detach=True,
                remove="remove" in request.lower() or "rm" in request.lower()
            )
            
            return {
                "success": result.get("success", False),
                "message": f"Docker container {'started' if result.get('success', False) else 'failed to start'}",
                "container_details": result
            }
            
        elif "compose" in request.lower() or "up" in request.lower():
            # Docker Compose operation
            project_dir = operation_details.get("project_dir", context.get("cwd", "."))
            
            # Check Docker Compose availability
            compose_available = await docker_integration.is_docker_compose_available()
            if not compose_available:
                return {
                    "success": False,
                    "error": "Docker Compose is not available on this system. Please install Docker Compose to use this feature."
                }
            
            # Determine if it's compose up or down
            if "down" in request.lower() or "stop" in request.lower():
                result = await docker_integration.compose_down(
                    project_directory=project_dir,
                    remove_volumes="volumes" in request.lower(),
                    remove_images="images" in request.lower() or "rmi" in request.lower()
                )
            else:
                # Default to compose up
                result = await docker_integration.compose_up(
                    project_directory=project_dir,
                    detach=True,
                    build="build" in request.lower()
                )
            
            return {
                "success": result.get("success", False),
                "message": f"Docker Compose operation {'completed' if result.get('success', False) else 'failed'}",
                "compose_details": result
            }
            
        else:
            # Generate and execute appropriate Docker command
            suggestion = await self._get_ai_suggestion(request, context)
            
            if not suggestion.command or not suggestion.command.startswith("docker"):
                return {
                    "success": False,
                    "error": "Unable to generate appropriate Docker command for this request.",
                    "suggestion": suggestion
                }
                
            # Execute the command using the engine
            if dry_run:
                return {
                    "success": True,
                    "dry_run": True,
                    "command": suggestion.command,
                    "explanation": suggestion.explanation
                }
                
            stdout, stderr, exit_code = await execution_engine.execute_command(
                suggestion.command,
                check_safety=True
            )
            
            return {
                "success": exit_code == 0,
                "command": suggestion.command,
                "stdout": stdout,
                "stderr": stderr,
                "return_code": exit_code,
                "explanation": suggestion.explanation
            }
    
    async def _extract_toolchain_operation(
        self, 
        request: str,
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Extract toolchain operation details from a request.
        
        Args:
            request: The user request
            context: Context information
            
        Returns:
            Dictionary with operation details
        """
        # First check if this is a Docker request
        for pattern in [r'\bdocker\b', r'\bcontainer\b', r'\bdockerfile\b', r'\bdocker-compose\b']:
            if re.search(pattern, request, re.IGNORECASE):
                docker_details = await self._extract_docker_operation_details(request, context)
                if docker_details:
                    return docker_details
        
        # Use AI to extract operation details for other toolchain operations
        prompt = f"""
    Extract toolchain operation details from this request:
    "{request}"
    
    Return a JSON object with:
    1. operation_type: One of "ci_cd", "package_management", "git", "testing", "docker"
    2. platform: For CI/CD, the platform (e.g., "github_actions", "gitlab_ci")
    3. project_dir: The project directory (default to ".")
    4. dependencies: For package management, list of dependencies
    5. test_framework: For testing, the test framework
    6. docker_action: For Docker, the specific action (e.g., "build", "run", "compose")
    7. image: For Docker run, the image name
    
    Format:
    {{
      "operation_type": "type",
      "platform": "platform",
      "project_dir": "directory",
      "dependencies": ["dep1", "dep2"],
      "test_framework": "framework"
    }}
    
    Only include keys relevant to the operation type.
    """

        try:
            # Call AI service
            api_request = GeminiRequest(prompt=prompt, max_tokens=1000)
            response = await gemini_client.generate_text(api_request)
            
            # Parse the response
            import json
            import re
            
            # Try to find JSON in the response
            json_match = re.search(r'```(?:json)?\s*(.*?)\s*```', response.text, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
            else:
                # Assume the entire response is JSON
                json_str = response.text
            
            # Parse JSON
            details = json.loads(json_str)
            
            # Default project directory to context's project_root if available
            if "project_dir" not in details and context.get("project_root"):
                details["project_dir"] = context.get("project_root")
            
            return details
            
        except Exception as e:
            self._logger.error(f"Error extracting toolchain operation details: {str(e)}")
            # Return minimal details on failure
            return {
                "operation_type": "unknown",
                "project_dir": context.get("project_root", ".")
            }
            
    async def _extract_docker_operation_details(
        self,
        request: str,
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Extract Docker operation details from a request.
        
        Args:
            request: The user request
            context: Context information
            
        Returns:
            Dictionary with Docker operation details
        """
        details = {
            "operation_type": "docker",
            "project_dir": context.get("project_root", context.get("cwd", "."))
        }
        
        # Extract Docker action based on keywords
        if re.search(r'\b(build|create)\b.+\b(image|dockerfile)\b', request, re.IGNORECASE) or re.search(r'\bimage.+\b(build|create)\b', request, re.IGNORECASE):
            details["docker_action"] = "build"
            
            # Try to extract image tag if present
            tag_match = re.search(r'tag\s+(\S+)', request, re.IGNORECASE)
            if tag_match:
                details["image_tag"] = tag_match.group(1)
            else:
                details["image_tag"] = "app:latest"
                
        elif re.search(r'\b(run|start|launch)\b.+\b(container|image)\b', request, re.IGNORECASE) or re.search(r'\b(container|image).+\b(run|start|launch)\b', request, re.IGNORECASE):
            details["docker_action"] = "run"
            
            # Try to extract image if present
            image_match = re.search(r'(image|container)\s+(\S+)', request, re.IGNORECASE)
            if image_match:
                details["image"] = image_match.group(2)
            else:
                # Look for any word that might be an image name
                words = request.split()
                for i, word in enumerate(words):
                    if word.lower() in ["image", "from"] and i < len(words) - 1:
                        details["image"] = words[i+1].strip(",:;")
                        break
            
            # Extract ports if present
            port_match = re.search(r'port\s+(\d+)', request, re.IGNORECASE)
            if port_match:
                port = port_match.group(1)
                details["ports"] = [f"{port}:{port}"]
                
        elif re.search(r'\b(setup|generate|create)\b.+\b(docker|dockerfile|compose)\b', request, re.IGNORECASE):
            details["docker_action"] = "setup"
            
            # Determine which files to generate
            details["generate_dockerfile"] = "dockerfile" in request.lower()
            details["generate_compose"] = "compose" in request.lower()
            details["generate_dockerignore"] = "ignore" in request.lower()
            
            # If not specified, generate all
            if not any([details["generate_dockerfile"], details["generate_compose"], details["generate_dockerignore"]]):
                details["generate_dockerfile"] = True
                details["generate_compose"] = True
                details["generate_dockerignore"] = True
                
        elif re.search(r'\b(compose|docker-compose)\b.+\b(up|start|run)\b', request, re.IGNORECASE):
            details["docker_action"] = "compose_up"
            
            # Extract services if mentioned
            services_match = re.search(r'service[s]?\s+(\w+(?:,\s*\w+)*)', request, re.IGNORECASE)
            if services_match:
                services_str = services_match.group(1)
                details["services"] = [s.strip() for s in services_str.split(',')]
                
        elif re.search(r'\b(compose|docker-compose)\b.+\b(down|stop)\b', request, re.IGNORECASE):
            details["docker_action"] = "compose_down"
            
            # Check for additional options
            details["remove_volumes"] = "volume" in request.lower()
            details["remove_images"] = "image" in request.lower() or "rmi" in request.lower()
            
        elif re.search(r'\b(stop|kill)\b.+\b(container)\b', request, re.IGNORECASE):
            details["docker_action"] = "stop"
            
            # Try to extract container ID or name
            container_match = re.search(r'(container|id|name)\s+(\S+)', request, re.IGNORECASE)
            if container_match:
                details["container"] = container_match.group(2)
                
        elif re.search(r'\b(rm|remove)\b.+\b(container)\b', request, re.IGNORECASE):
            details["docker_action"] = "rm"
            
            # Try to extract container ID or name
            container_match = re.search(r'(container|id|name)\s+(\S+)', request, re.IGNORECASE)
            if container_match:
                details["container"] = container_match.group(2)
                
            # Check for force flag
            details["force"] = "force" in request.lower()
            
        elif re.search(r'\b(ps|list)\b.+\b(container)', request, re.IGNORECASE):
            details["docker_action"] = "ps"
            
            # Check for all flag
            details["all"] = "all" in request.lower()
            
        elif re.search(r'\b(logs|log)\b', request, re.IGNORECASE):
            details["docker_action"] = "logs"
            
            # Try to extract container ID or name
            container_match = re.search(r'(container|id|name)\s+(\S+)', request, re.IGNORECASE)
            if container_match:
                details["container"] = container_match.group(2)
                
            # Check for follow flag
            details["follow"] = "follow" in request.lower() or "tail" in request.lower()
            
        elif re.search(r'\b(exec|execute|run)\b.+\b(command|in)\b', request, re.IGNORECASE):
            details["docker_action"] = "exec"
            
            # Try to extract container ID or name
            container_match = re.search(r'(container|id|name)\s+(\S+)', request, re.IGNORECASE)
            if container_match:
                details["container"] = container_match.group(2)
                
            # Try to extract command
            command_match = re.search(r'command\s+(.+?)$', request, re.IGNORECASE)
            if command_match:
                details["command"] = command_match.group(1)
                
        else:
            # Default to general docker action
            details["docker_action"] = "general"
            
        return details








    
    async def _process_ci_cd_operation(
        self, 
        operation_details: Dict[str, Any],
        context: Dict[str, Any],
        dry_run: bool
    ) -> Dict[str, Any]:
        """
        Process a CI/CD operation request.
        
        Args:
            operation_details: Details about the operation
            context: Context information
            dry_run: Whether to simulate without making changes
            
        Returns:
            Dictionary with processing results
        """
        # Import here to avoid circular imports
        from angela.toolchain.ci_cd import ci_cd_integration
        
        self._logger.info(f"Processing CI/CD operation: {operation_details.get('platform', 'unknown')}")
        
        # Get details
        platform = operation_details.get("platform", "github_actions")
        project_dir = operation_details.get("project_dir", context.get("cwd", "."))
        
        # Execute CI/CD operation
        if dry_run:
            return {
                "success": True,
                "dry_run": True,
                "message": f"Would configure CI/CD for {platform} in {project_dir}"
            }
        
        try:
            result = await ci_cd_integration.generate_ci_configuration(
                path=project_dir,
                platform=platform
            )
            
            return {
                "success": result.get("success", False),
                "message": result.get("message", "CI/CD configuration completed"),
                "ci_cd_details": result
            }
        except Exception as e:
            self._logger.exception(f"Error processing CI/CD operation: {str(e)}")
            return {
                "success": False,
                "error": f"Error processing CI/CD operation: {str(e)}"
            }
    
    async def _process_package_operation(
        self,
        operation_details: Dict[str, Any],
        context: Dict[str, Any],
        dry_run: bool
    ) -> Dict[str, Any]:
        """
        Process a package management operation request.
        
        Args:
            operation_details: Details about the operation
            context: Context information
            dry_run: Whether to simulate without making changes
            
        Returns:
            Dictionary with processing results
        """
        # Import here to avoid circular imports
        from angela.toolchain.package_managers import package_manager_integration
        
        self._logger.info(f"Processing package operation")
        
        # Get details
        project_dir = operation_details.get("project_dir", context.get("cwd", "."))
        dependencies = operation_details.get("dependencies", [])
        dev_dependencies = operation_details.get("dev_dependencies", [])
        
        if not dependencies and not dev_dependencies:
            return {
                "success": False,
                "error": "No dependencies specified for package operation"
            }
        
        # Execute package operation
        if dry_run:
            return {
                "success": True,
                "dry_run": True,
                "message": f"Would install {len(dependencies)} dependencies and {len(dev_dependencies)} dev dependencies in {project_dir}"
            }
        
        try:
            result = await package_manager_integration.install_dependencies(
                path=project_dir,
                dependencies=dependencies,
                dev_dependencies=dev_dependencies
            )
            
            return {
                "success": result.get("success", False),
                "message": result.get("message", "Dependencies installed successfully"),
                "package_details": result
            }
        except Exception as e:
            self._logger.exception(f"Error processing package operation: {str(e)}")
            return {
                "success": False,
                "error": f"Error processing package operation: {str(e)}"
            }
    
    async def _process_git_operation(
        self,
        operation_details: Dict[str, Any],
        context: Dict[str, Any],
        dry_run: bool
    ) -> Dict[str, Any]:
        """
        Process a Git operation request.
        
        Args:
            operation_details: Details about the operation
            context: Context information
            dry_run: Whether to simulate without making changes
            
        Returns:
            Dictionary with processing results
        """
        # Import here to avoid circular imports
        from angela.toolchain.git import git_integration
        
        self._logger.info(f"Processing Git operation: {operation_details.get('git_action', 'unknown')}")
        
        # Get details
        git_action = operation_details.get("git_action", "")
        project_dir = operation_details.get("project_dir", context.get("cwd", "."))
        
        # Handle different Git operations based on git_action
        if git_action == "init":
            return await self._process_git_init(operation_details, project_dir, dry_run)
        elif git_action == "commit":
            return await self._process_git_commit(operation_details, project_dir, dry_run)
        elif git_action == "branch":
            return await self._process_git_branch(operation_details, project_dir, dry_run)
        elif git_action == "status":
            return await self._process_git_status(operation_details, project_dir, dry_run)
        else:
            # Generate and execute appropriate Git command using AI
            suggestion = await self._get_ai_suggestion(
                operation_details.get("request", f"git {git_action}"),
                context
            )
            
            if dry_run:
                return {
                    "success": True,
                    "dry_run": True,
                    "command": suggestion.command,
                    "explanation": suggestion.explanation
                }
            
            # Execute the command
            stdout, stderr, exit_code = await execution_engine.execute_command(
                suggestion.command,
                check_safety=True,
                working_dir=project_dir
            )
            
            return {
                "success": exit_code == 0,
                "command": suggestion.command,
                "stdout": stdout,
                "stderr": stderr,
                "return_code": exit_code,
                "explanation": suggestion.explanation
            }
    
    async def _process_git_init(self, operation_details, project_dir, dry_run):
        """Process git init operation."""
        from angela.toolchain.git import git_integration
        
        if dry_run:
            return {
                "success": True,
                "dry_run": True,
                "message": f"Would initialize Git repository in {project_dir}"
            }
        
        # Get initialization parameters
        branch = operation_details.get("branch", "main")
        gitignore = operation_details.get("gitignore", True)
        
        # Initialize repository
        result = await git_integration.init_repository(
            path=project_dir,
            initial_branch=branch,
            gitignore_template=operation_details.get("gitignore_template")
        )
        
        return {
            "success": result.get("success", False),
            "message": result.get("message", "Git repository initialized"),
            "git_details": result
        }
    
    async def _process_git_commit(self, operation_details, project_dir, dry_run):
        """Process git commit operation."""
        from angela.toolchain.git import git_integration
        
        if dry_run:
            return {
                "success": True,
                "dry_run": True,
                "message": f"Would commit changes in {project_dir}"
            }
        
        # Get commit parameters
        message = operation_details.get("message", "Update via Angela CLI")
        add_all = operation_details.get("add_all", True)
        
        # Stage files if requested
        if add_all:
            await git_integration.stage_files(path=project_dir, files=["."])
        
        # Commit changes
        result = await git_integration.commit_changes(
            path=project_dir,
            message=message
        )
        
        return {
            "success": result.get("success", False),
            "message": result.get("message", "Changes committed successfully"),
            "git_details": result
        }
    
    async def _process_git_branch(self, operation_details, project_dir, dry_run):
        """Process git branch operation."""
        from angela.toolchain.git import git_integration
        
        if dry_run:
            return {
                "success": True,
                "dry_run": True,
                "message": f"Would create/switch branch in {project_dir}"
            }
        
        # Get branch parameters
        branch_name = operation_details.get("branch_name", "")
        if not branch_name:
            return {
                "success": False,
                "error": "Branch name not specified"
            }
        
        checkout = operation_details.get("checkout", True)
        
        # Create branch
        result = await git_integration.create_branch(
            path=project_dir,
            branch_name=branch_name,
            checkout=checkout
        )
        
        return {
            "success": result.get("success", False),
            "message": result.get("message", f"Branch {branch_name} created"),
            "git_details": result
        }
    
    async def _process_git_status(self, operation_details, project_dir, dry_run):
        """Process git status operation."""
        from angela.toolchain.git import git_integration
        
        # Get repository status
        result = await git_integration.get_repository_status(path=project_dir)
        
        return {
            "success": result.get("success", False),
            "message": "Git status retrieved",
            "status": result.get("status", {}),
            "git_details": result
        }
    
    async def _process_testing_operation(
        self,
        operation_details: Dict[str, Any],
        context: Dict[str, Any],
        dry_run: bool
    ) -> Dict[str, Any]:
        """
        Process a testing operation request.
        
        Args:
            operation_details: Details about the operation
            context: Context information
            dry_run: Whether to simulate without making changes
            
        Returns:
            Dictionary with processing results
        """
        self._logger.info(f"Processing testing operation")
        
        # Get details
        project_dir = operation_details.get("project_dir", context.get("cwd", "."))
        test_framework = operation_details.get("test_framework", "")
        test_path = operation_details.get("test_path", "")
        
        # Execute testing operation
        if dry_run:
            return {
                "success": True,
                "dry_run": True,
                "message": f"Would run tests using {test_framework} in {project_dir}"
            }
        
        try:
            # Determine test command based on framework
            command = ""
            if test_framework == "pytest":
                command = f"pytest {test_path}" if test_path else "pytest"
            elif test_framework == "jest":
                command = f"npx jest {test_path}" if test_path else "npx jest"
            elif test_framework == "go":
                command = f"go test {test_path}" if test_path else "go test ./..."
            elif test_framework == "maven":
                command = "mvn test"
            elif test_framework == "gradle":
                command = "./gradlew test"
            else:
                # Default to using AI to generate appropriate test command
                suggestion = await self._get_ai_suggestion(
                    f"run tests for {test_framework} in {project_dir}",
                    context
                )
                command = suggestion.command
            
            # Execute test command
            stdout, stderr, exit_code = await execution_engine.execute_command(
                command,
                check_safety=True,
                working_dir=project_dir
            )
            
            return {
                "success": exit_code == 0,
                "command": command,
                "stdout": stdout,
                "stderr": stderr,
                "return_code": exit_code,
                "message": "Tests completed successfully" if exit_code == 0 else "Tests failed"
            }
        except Exception as e:
            self._logger.exception(f"Error processing testing operation: {str(e)}")
            return {
                "success": False,
                "error": f"Error processing testing operation: {str(e)}"
            }
            
    async def _extract_feature_details(
        self, 
        request: str,
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Extract feature details from a feature addition request.
        
        Args:
            request: The user request
            context: Context information
            
        Returns:
            Dictionary with feature details
        """
        # Use AI to extract feature details
        prompt = f"""
    Extract feature details from this feature addition request:
    "{request}"
    
    Return a JSON object with:
    1. description: A clear description of the feature to add
    2. project_dir: The project directory (default to ".")
    3. branch: A branch name if specified
    
    Format:
    {{
      "description": "feature description",
      "project_dir": "directory",
      "branch": "branch-name"
    }}
    
    Only include keys where you have clear information from the request.
    """
        
        try:
            # Call AI service
            api_request = GeminiRequest(prompt=prompt, max_tokens=1000)
            response = await gemini_client.generate_text(api_request)
            
            # Parse the response
            import json
            import re
            
            # Try to find JSON in the response
            json_match = re.search(r'```(?:json)?\s*(.*?)\s*```', response.text, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
            else:
                # Assume the entire response is JSON
                json_str = response.text
            
            # Parse JSON
            details = json.loads(json_str)
            
            # Default project directory to context's project_root if available
            if "project_dir" not in details and context.get("project_root"):
                details["project_dir"] = context.get("project_root")
            
            return details
            
        except Exception as e:
            self._logger.error(f"Error extracting feature details: {str(e)}")
            # Return minimal details on failure
            return {
                "project_dir": context.get("project_root", "."),
                "description": request
            }


    
    async def _extract_project_details(
        self, 
        request: str
    ) -> Dict[str, Any]:
        """
        Extract project details from a code generation request.
        
        Args:
            request: The user request
            
        Returns:
            Dictionary with project details
        """
        # Use AI to extract project details
        prompt = f"""
    Extract project details from this code generation request:
    "{request}"
    
    Return a JSON object with:
    1. project_type: The type of project (e.g., "python", "node", "java", etc.)
    2. framework: Any specific framework mentioned (e.g., "django", "react", "spring")
    3. output_dir: Where the project should be created (default to ".")
    4. git_init: Whether to initialize a Git repo (default to true)
    5. description: A clear description of what the project should do/be
    
    Format:
    {{
      "project_type": "type",
      "framework": "framework",
      "output_dir": "directory",
      "git_init": true/false,
      "description": "description"
    }}
    
    Only include keys where you have clear information from the request.
    If something is ambiguous, omit the key rather than guessing.
    """
        
        try:
            # Call AI service
            api_request = GeminiRequest(prompt=prompt, max_tokens=1000)
            response = await gemini_client.generate_text(api_request)
            
            # Parse the response
            import json
            import re
            
            # Try to find JSON in the response
            json_match = re.search(r'```(?:json)?\s*(.*?)\s*```', response.text, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
            else:
                # Assume the entire response is JSON
                json_str = response.text
            
            # Parse JSON
            details = json.loads(json_str)
            return details
            
        except Exception as e:
            self._logger.error(f"Error extracting project details: {str(e)}")
            # Return minimal details on failure
            return {
                "output_dir": ".",
                "git_init": True,
                "description": request
            }


    
    async def _process_command_request(
        self, 
        request: str, 
        context: Dict[str, Any], 
        execute: bool, 
        dry_run: bool
    ) -> Dict[str, Any]:
        """
        Process a single command request.
        
        Args:
            request: The user request
            context: Context information
            execute: Whether to execute the command
            dry_run: Whether to simulate execution without making changes
            
        Returns:
            Dictionary with processing results
        """
        # Analyze intent with enhanced NLU
        intent_result = await intent_analyzer.analyze_intent(request)
        
        # Check if we've seen a similar request before
        similar_command = history_manager.search_similar_command(request)
        
        # Get command suggestion from AI
        suggestion = await self._get_ai_suggestion(
            request, 
            context, 
            similar_command, 
            intent_result
        )
        
        # Score confidence in the suggestion
        confidence = confidence_scorer.score_command_confidence(
            request=request,
            command=suggestion.command,
            context=context
        )
        
        # If confidence is low, offer clarification
        if confidence < 0.6 and not dry_run and not context.get("session", {}).get("skip_clarification"):
            # Interactive clarification
            from prompt_toolkit.shortcuts import yes_no_dialog
            should_proceed = yes_no_dialog(
                title="Low Confidence Suggestion",
                text=f"I'm not very confident this is what you meant:\n\n{suggestion.command}\n\nWould you like to proceed with this command?",
            ).run()
            
            if not should_proceed:
                return {
                    "request": request,
                    "response": "Command cancelled due to low confidence.",
                    "context": context,
                }
        
        result = {
            "request": request,
            "suggestion": suggestion,
            "confidence": confidence,
            "intent": intent_result.intent_type if hasattr(intent_result, 'intent_type') else "unknown",
            "context": context,
            "type": "command"
        }
        
        # Execute the command if requested
        if execute or dry_run:
            self._logger.info(f"{'Dry run' if dry_run else 'Executing'} suggested command: {suggestion.command}")
            
            # Execute using the adaptive engine with rich feedback
            execution_result = await adaptive_engine.execute_command(
                command=suggestion.command,
                natural_request=request,
                explanation=suggestion.explanation,
                dry_run=dry_run
            )
            
            result["execution"] = execution_result
            
            # If execution failed, analyze errors and provide suggestions
            if not execution_result.get("success") and execution_result.get("stderr"):
                error_analysis = error_analyzer.analyze_error(
                    suggestion.command, 
                    execution_result["stderr"]
                )
                result["error_analysis"] = error_analysis
                
                # Generate fix suggestions
                fix_suggestions = error_analyzer.generate_fix_suggestions(
                    suggestion.command, 
                    execution_result["stderr"]
                )
                execution_result["fix_suggestions"] = fix_suggestions
                
                # Start background monitoring
                if not dry_run:
                    self._start_background_monitoring(suggestion.command, error_analysis)
        
        return result
    

    async def _process_multi_step_request(
        self, 
        request: str, 
        context: Dict[str, Any], 
        execute: bool, 
        dry_run: bool
    ) -> Dict[str, Any]:
        """
        Process a multi-step operation request with transaction-based rollback support.
        
        Args:
            request: The user request
            context: Context information
            execute: Whether to execute the commands
            dry_run: Whether to simulate execution without making changes
            
        Returns:
            Dictionary with processing results
        """
        self._logger.info(f"Processing multi-step request: {request}")
        
        # Determine if we should use advanced planning
        complexity = await task_planner._determine_complexity(request)
        
        # Start a transaction for this multi-step operation
        transaction_id = None
        if not dry_run:
            transaction_id = await rollback_manager.start_transaction(f"Multi-step plan: {request[:50]}...")
        
        try:
            if complexity == "advanced":
                # Use the advanced planner for complex tasks
                plan = await task_planner.plan_task(request, context, complexity)
                
                # Record the plan in the transaction
                if transaction_id:
                    await rollback_manager.record_plan_execution(
                        plan_id=plan.id,
                        goal=plan.goal,
                        plan_data=plan.dict(),
                        transaction_id=transaction_id
                    )
                
                # Create result with the plan
                if isinstance(plan, AdvancedTaskPlan):
                    # Advanced plan with branching
                    result = {
                        "request": request,
                        "type": "advanced_multi_step",
                        "context": context,
                        "plan": {
                            "id": plan.id,
                            "goal": plan.goal,
                            "description": plan.description,
                            "steps": [
                                {
                                    "id": step_id,
                                    "type": step.type,
                                    "description": step.description,
                                    "command": step.command,
                                    "dependencies": step.dependencies,
                                    "risk": step.estimated_risk
                                }
                                for step_id, step in plan.steps.items()
                            ],
                            "entry_points": plan.entry_points,
                            "step_count": len(plan.steps)
                        }
                    }
                    
                    # Execute the plan if requested
                    if execute or dry_run:
                        # Display the plan with rich formatting
                        await terminal_formatter.display_advanced_plan(plan)
                        
                        # Get confirmation for plan execution
                        confirmed = await self._confirm_advanced_plan(plan, dry_run)
                        
                        if confirmed or dry_run:
                            # Execute the plan with transaction support
                            execution_results = await task_planner.execute_plan(
                                plan, 
                                dry_run=dry_run,
                                transaction_id=transaction_id
                            )
                            result["execution_results"] = execution_results
                            result["success"] = execution_results.get("success", False)
                            
                            # Update transaction status
                            if transaction_id:
                                status = "completed" if result["success"] else "failed"
                                await rollback_manager.end_transaction(transaction_id, status)
                        else:
                            result["cancelled"] = True
                            result["success"] = False
                            
                            # End the transaction as cancelled
                            if transaction_id:
                                await rollback_manager.end_transaction(transaction_id, "cancelled")
                else:
                    # Basic plan (fallback)
                    result = await self._process_basic_multi_step(plan, request, context, execute, dry_run, transaction_id)
            else:
                # Use the basic planner for simple tasks
                plan = await task_planner.plan_task(request, context)
                result = await self._process_basic_multi_step(plan, request, context, execute, dry_run, transaction_id)
            
            return result
        
        except Exception as e:
            # Handle any exceptions and end the transaction
            if transaction_id:
                await rollback_manager.end_transaction(transaction_id, "failed")
            
            self._logger.exception(f"Error processing multi-step request: {str(e)}")
            raise
        
    async def _process_basic_multi_step(
        self,
        plan: TaskPlan,
        request: str,
        context: Dict[str, Any],
        execute: bool,
        dry_run: bool,
        transaction_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Process a basic multi-step plan with transaction support.
        
        Args:
            plan: The task plan
            request: The user request
            context: Context information
            execute: Whether to execute the commands
            dry_run: Whether to simulate execution without making changes
            transaction_id: Transaction ID for tracking operations
            
        Returns:
            Dictionary with processing results
        """
        # Record the plan in the transaction if not already done
        if transaction_id and not dry_run:
            await rollback_manager.record_plan_execution(
                plan_id=getattr(plan, "id", str(uuid.uuid4())),
                goal=plan.goal,
                plan_data=plan.dict(),
                transaction_id=transaction_id
            )
        
        # Create result with the plan
        result = {
            "request": request,
            "type": "multi_step",
            "context": context,
            "plan": {
                "goal": plan.goal,
                "steps": [
                    {
                        "command": step.command,
                        "explanation": step.explanation,
                        "dependencies": step.dependencies,
                        "risk": step.estimated_risk
                    }
                    for step in plan.steps
                ],
                "step_count": len(plan.steps)
            }
        }
        
        # Execute the plan if requested
        if execute or dry_run:
            # Display the plan with rich formatting
            await self._display_plan(plan)
            
            # Get confirmation for plan execution
            confirmed = await self._confirm_plan_execution(plan, dry_run)
            
            if confirmed or dry_run:
                # Execute the plan with transaction support
                execution_results = await task_planner.execute_plan(
                    plan, 
                    dry_run=dry_run,
                    transaction_id=transaction_id
                )
                result["execution_results"] = execution_results
                result["success"] = all(r.get("success", False) for r in execution_results)
                
                # Update transaction status
                if transaction_id:
                    status = "completed" if result["success"] else "failed"
                    await rollback_manager.end_transaction(transaction_id, status)
                
                # Handle errors with recovery
                if not result["success"] and not dry_run:
                    recovered_results = await self._handle_execution_errors(plan, execution_results)
                    result["recovery_attempted"] = True
                    result["recovered_results"] = recovered_results
                    # Update success status if recovery was successful
                    if all(r.get("success", False) for r in recovered_results):
                        result["success"] = True
            else:
                result["cancelled"] = True
                result["success"] = False
                
                # End the transaction as cancelled
                if transaction_id:
                    await rollback_manager.end_transaction(transaction_id, "cancelled")
        
        return result
    
    async def _process_file_content_request(
        self, 
        request: str, 
        context: Dict[str, Any], 
        execute: bool, 
        dry_run: bool
    ) -> Dict[str, Any]:
        """
        Process a file content analysis/manipulation request with transaction support.
        
        Args:
            request: The user request
            context: Context information
            execute: Whether to execute file operations
            dry_run: Whether to simulate execution without making changes
            
        Returns:
            Dictionary with processing results
        """
        self._logger.info(f"Processing file content request: {request}")
        
        # Start a transaction for this operation
        transaction_id = None
        if not dry_run and execute:
            transaction_id = await rollback_manager.start_transaction(f"File content operation: {request[:50]}...")
        
        try:
            # Extract file path from request using file_resolver
            file_path = await self._extract_file_path(request, context)
            
            if not file_path:
                # End the transaction as failed
                if transaction_id:
                    await rollback_manager.end_transaction(transaction_id, "failed")
                    
                return {
                    "request": request,
                    "type": "file_content",
                    "context": context,
                    "error": "Could not determine file path from request",
                    "response": "I couldn't determine which file you're referring to. Please specify the file path."
                }
            
            # Determine if this is analysis or manipulation
            operation_type = await self._determine_file_operation_type(request)
            
            result = {
                "request": request,
                "type": "file_content",
                "context": context,
                "file_path": str(file_path),
                "operation_type": operation_type
            }
            
            if operation_type == "analyze":
                # Analyze file content (no rollback needed)
                analysis_result = await content_analyzer.analyze_content(file_path, request)
                result["analysis"] = analysis_result
                
                # End transaction as completed
                if transaction_id:
                    await rollback_manager.end_transaction(transaction_id, "completed")
                
            elif operation_type == "summarize":
                # Summarize file content (no rollback needed)
                summary_result = await content_analyzer.summarize_content(file_path)
                result["summary"] = summary_result
                
                # End transaction as completed
                if transaction_id:
                    await rollback_manager.end_transaction(transaction_id, "completed")
                
            elif operation_type == "search":
                # Search file content (no rollback needed)
                search_result = await content_analyzer.search_content(file_path, request)
                result["search_results"] = search_result
                
                # End transaction as completed
                if transaction_id:
                    await rollback_manager.end_transaction(transaction_id, "completed")
                
            elif operation_type == "manipulate":
                # Manipulate file content
                manipulation_result = await content_analyzer.manipulate_content(file_path, request)
                result["manipulation"] = manipulation_result
                
                # Apply changes if requested
                if execute and not dry_run and manipulation_result["has_changes"]:
                    # Get confirmation before applying changes
                    confirmed = await self._confirm_file_changes(
                        file_path, 
                        manipulation_result["diff"]
                    )
                    
                    if confirmed:
                        # Read original content for rollback
                        original_content = manipulation_result["original_content"]
                        modified_content = manipulation_result["modified_content"]
                        
                        # Record the content manipulation for rollback
                        if transaction_id:
                            await rollback_manager.record_content_manipulation(
                                file_path=file_path,
                                original_content=original_content,
                                modified_content=modified_content,
                                instruction=request,
                                transaction_id=transaction_id
                            )
                        
                        # Write the changes to the file
                        try:
                            with open(file_path, 'w', encoding='utf-8') as f:
                                f.write(modified_content)
                            result["changes_applied"] = True
                            result["success"] = True
                            
                            # End transaction as completed
                            if transaction_id:
                                await rollback_manager.end_transaction(transaction_id, "completed")
                        except Exception as e:
                            self._logger.error(f"Error applying changes to {file_path}: {str(e)}")
                            result["error"] = f"Error applying changes: {str(e)}"
                            result["changes_applied"] = False
                            result["success"] = False
                            
                            # End transaction as failed
                            if transaction_id:
                                await rollback_manager.end_transaction(transaction_id, "failed")
                    else:
                        result["changes_applied"] = False
                        result["cancelled"] = True
                        
                        # End transaction as cancelled
                        if transaction_id:
                            await rollback_manager.end_transaction(transaction_id, "cancelled")
                elif dry_run and manipulation_result["has_changes"]:
                    result["changes_applied"] = False
                    result["success"] = True
                    result["dry_run"] = True
                    
                    # End transaction as completed for dry run
                    if transaction_id:
                        await rollback_manager.end_transaction(transaction_id, "completed")
                else:
                    # No changes to apply or not executing
                    if transaction_id:
                        await rollback_manager.end_transaction(transaction_id, "completed")
            
            return result
            
        except Exception as e:
            # Handle any exceptions and end the transaction
            if transaction_id:
                await rollback_manager.end_transaction(transaction_id, "failed")
            
            self._logger.exception(f"Error processing file content request: {str(e)}")
            raise
    

    
    async def _handle_execution_errors(
        self,
        plan: TaskPlan,
        execution_results: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        Handle errors in multi-step execution with recovery.
        
        Args:
            plan: The task plan
            execution_results: Original execution results
            
        Returns:
            Updated execution results after recovery attempts
        """
        recovered_results = list(execution_results)  # Copy the original results
        
        # Find failed steps
        for i, result in enumerate(execution_results):
            if not result.get("success", False):
                # Get the corresponding step
                if i < len(plan.steps):
                    step = plan.steps[i]
                    
                    # Attempt recovery
                    recovery_result = await self._error_recovery_manager.handle_error(
                        step, result, {"plan": plan}
                    )
                    
                    # Update the result
                    if recovery_result.get("recovery_success", False):
                        recovered_results[i] = recovery_result
        
        return recovered_results
    
    async def _confirm_advanced_plan(self, plan: AdvancedTaskPlan, dry_run: bool) -> bool:
        """
        Get confirmation to execute an advanced plan.
        
        Args:
            plan: The advanced task plan
            dry_run: Whether this is a dry run
            
        Returns:
            True if confirmed, False otherwise
        """
        if dry_run:
            # No confirmation needed for dry run
            return True
        
        # Check if any steps are high risk
        has_high_risk = any(step.estimated_risk >= 3 for step in plan.steps.values())
        
        # Import here to avoid circular imports
        from rich.console import Console
        from prompt_toolkit.shortcuts import yes_no_dialog
        
        console = Console()
        
        if has_high_risk:
            # Use a more prominent warning for high-risk plans
            console.print(Panel(
                "⚠️  [bold red]This plan includes HIGH RISK operations[/bold red] ⚠️\n"
                "Some of these steps could make significant changes to your system.",
                border_style="red",
                expand=False
            ))
        
        # Show complexity warning for advanced plans
        console.print(Panel(
            "[bold yellow]This is an advanced plan with complex execution flow.[/bold yellow]\n"
            "It may include conditional branching and dependency-based execution.",
            border_style="yellow",
            expand=False
        ))
        
        # Get confirmation
        confirmed = yes_no_dialog(
            title="Confirm Advanced Plan Execution",
            text=f"Do you want to execute this {len(plan.steps)}-step advanced plan?",
        ).run()
        
        return confirmed
    

    
    async def _process_workflow_definition(
        self, 
        request: str, 
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Process a workflow definition request.
        
        Args:
            request: The user request
            context: Context information
            
        Returns:
            Dictionary with processing results
        """
        self._logger.info(f"Processing workflow definition request: {request}")
        
        # Extract workflow information using AI
        workflow_info = await self._extract_workflow_info(request, context)
        
        if not workflow_info or "name" not in workflow_info:
            return {
                "request": request,
                "type": "workflow_definition",
                "context": context,
                "error": "Could not extract workflow information",
                "response": "I couldn't understand the workflow definition. Please provide a name and description."
            }
        
        # Define workflow
        workflow = await workflow_manager.define_workflow_from_natural_language(
            name=workflow_info["name"],
            description=workflow_info.get("description", ""),
            natural_language=workflow_info.get("steps", request),
            context=context
        )
        
        # Return result
        return {
            "request": request,
            "type": "workflow_definition",
            "context": context,
            "workflow": {
                "name": workflow.name,
                "description": workflow.description,
                "steps": [
                    {
                        "command": step.command,
                        "explanation": step.explanation,
                        "optional": step.optional,
                        "requires_confirmation": step.requires_confirmation
                    }
                    for step in workflow.steps
                ],
                "variables": workflow.variables,
                "step_count": len(workflow.steps)
            },
            "success": True,
            "response": f"Successfully defined workflow '{workflow.name}' with {len(workflow.steps)} steps."
        }
    
    async def _process_workflow_execution(
        self, 
        request: str, 
        context: Dict[str, Any], 
        execute: bool, 
        dry_run: bool
    ) -> Dict[str, Any]:
        """
        Process a workflow execution request.
        
        Args:
            request: The user request
            context: Context information
            execute: Whether to execute the workflow
            dry_run: Whether to simulate execution without making changes
            
        Returns:
            Dictionary with processing results
        """
        self._logger.info(f"Processing workflow execution request: {request}")
        
        # Extract workflow name and variables using AI
        workflow_execution_info = await self._extract_workflow_execution_info(request, context)
        
        if not workflow_execution_info or "name" not in workflow_execution_info:
            return {
                "request": request,
                "type": "workflow_execution",
                "context": context,
                "error": "Could not determine workflow name",
                "response": "I couldn't determine which workflow to run. Please specify the workflow name."
            }
        
        workflow_name = workflow_execution_info["name"]
        variables = workflow_execution_info.get("variables", {})
        
        # Check if workflow exists
        workflow = workflow_manager.get_workflow(workflow_name)
        if not workflow:
            available_workflows = workflow_manager.list_workflows()
            if available_workflows:
                workflow_list = ", ".join([w.name for w in available_workflows])
                return {
                    "request": request,
                    "type": "workflow_execution",
                    "context": context,
                    "error": f"Workflow '{workflow_name}' not found",
                    "response": f"Workflow '{workflow_name}' not found. Available workflows: {workflow_list}"
                }
            else:
                return {
                    "request": request,
                    "type": "workflow_execution",
                    "context": context,
                    "error": "No workflows defined",
                    "response": "No workflows have been defined yet. Use 'define workflow' to create one."
                }
        
        result = {
            "request": request,
            "type": "workflow_execution",
            "context": context,
            "workflow": {
                "name": workflow.name,
                "description": workflow.description,
                "steps": [
                    {
                        "command": step.command,
                        "explanation": step.explanation,
                        "optional": step.optional,
                        "requires_confirmation": step.requires_confirmation
                    }
                    for step in workflow.steps
                ],
                "variables": variables,
                "step_count": len(workflow.steps)
            }
        }
        
        # Execute the workflow if requested
        if execute or dry_run:
            # Display workflow with rich formatting
            await self._display_workflow(workflow, variables)
            
            # Get confirmation
            confirmed = await self._confirm_workflow_execution(workflow, variables, dry_run)
            
            if confirmed or dry_run:
                # Execute workflow
                execution_result = await workflow_manager.execute_workflow(
                    workflow_name=workflow_name,
                    variables=variables,
                    context=context,
                    dry_run=dry_run
                )
                
                result["execution_result"] = execution_result
                result["success"] = execution_result.get("success", False)
            else:
                result["cancelled"] = True
                result["success"] = False
        
        return result
    
    async def _process_clarification_request(
        self, 
        request: str, 
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Process a request for clarification.
        
        Args:
            request: The user request
            context: Context information
            
        Returns:
            Dictionary with processing results
        """
        # Get session context for previous commands
        session = session_manager.get_context()
        recent_commands = session.get("recent_commands", [])
        
        # Build prompt for clarification
        prompt = f"""
You are Angela, an AI terminal assistant. The user is asking for clarification regarding a previous interaction.

Recent commands:
{recent_commands}

User request: {request}

Provide a helpful clarification or explanation about the recent commands or operations. Be concise but thorough.
If the user is asking about how to do something, explain the appropriate command or procedure.
"""
        
        # Call AI service
        api_request = GeminiRequest(prompt=prompt, max_tokens=2000)
        response = await gemini_client.generate_text(api_request)
        
        return {
            "request": request,
            "type": "clarification",
            "context": context,
            "response": response.text
        }
    
    async def _process_unknown_request(
        self, 
        request: str, 
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Process an unknown request type.
        
        Args:
            request: The user request
            context: Context information
            
        Returns:
            Dictionary with processing results
        """
        # Try to get a general response from the AI
        prompt = f"""
You are Angela, an AI terminal assistant. The user has made a request that doesn't clearly match a command, multi-step operation, file manipulation, or workflow.

User request: {request}

Provide a helpful response. If appropriate, suggest what kinds of commands or operations might help with what they're trying to do.
Keep your response concise and focused.
"""
        
        # Call AI service
        api_request = GeminiRequest(prompt=prompt, max_tokens=2000)
        response = await gemini_client.generate_text(api_request)
        
        return {
            "request": request,
            "type": "unknown",
            "context": context,
            "response": response.text
        }
    
    async def _get_ai_suggestion(
        self, 
        request: str, 
        context: Dict[str, Any],
        similar_command: Optional[str] = None,
        intent_result: Optional[Any] = None
    ) -> CommandSuggestion:
        """Get a command suggestion from the AI service."""
        # Build prompt with context, including session context if available
        prompt = build_prompt(request, context, similar_command, intent_result)
        
        # Create a request to the Gemini API
        api_request = GeminiRequest(prompt=prompt)
        
        # Call the Gemini API
        self._logger.info("Sending request to Gemini API")
        api_response = await gemini_client.generate_text(api_request)
        
        # Parse the response
        suggestion = parse_ai_response(api_response.text)
        
        self._logger.info(f"Received suggestion: {suggestion.command}")
        return suggestion
    
    async def _extract_file_path(
        self, 
        request: str, 
        context: Dict[str, Any]
    ) -> Optional[Path]:
        """
        Extract a file path from a request using file_resolver.
        
        Args:
            request: The user request
            context: Context information
            
        Returns:
            Path object if found, None otherwise
        """
        self._logger.debug(f"Extracting file path from: {request}")
        
        # Try to extract file references
        file_references = await file_resolver.extract_references(request, context)
        
        # If we found any resolved references, return the first one
        for reference, path in file_references:
            if path:
                # Track as viewed file
                file_activity_tracker.track_file_viewing(path, None, {
                    "request": request,
                    "reference": reference
                })
                return path
        
        # If we found references but couldn't resolve them, use AI extraction as fallback
        if file_references:
            for reference, _ in file_references:
                # Try to resolve with a broader scope
                path = await file_resolver.resolve_reference(
                    reference, 
                    context,
                    search_scope="project"
                )
                if path:
                    # Track as viewed file
                    file_activity_tracker.track_file_viewing(path, None, {
                        "request": request,
                        "reference": reference
                    })
                    return path
        
        # If all else fails, fall back to the original AI method
        # [Existing AI extraction code]
        return None
    
    async def _determine_file_operation_type(self, request: str) -> str:
        """
        Determine the type of file operation requested.
        
        Args:
            request: The user request
            
        Returns:
            String indicating the operation type: "analyze", "summarize", "search", or "manipulate"
        """
        # Check for keywords indicating different operation types
        
        # Manipulation keywords
        manipulation_keywords = [
            "change", "modify", "update", "edit", "replace", "rename", "refactor",
            "convert", "transform", "add", "remove", "delete", "fix"
        ]
        
        # Analysis keywords
        analysis_keywords = [
            "analyze", "explain", "understand", "evaluate", "assess", "examine",
            "review", "check", "audit"
        ]
        
        # Summarization keywords
        summarization_keywords = [
            "summarize", "summary", "overview", "brief", "digress", "gist"
        ]
        
        # Search keywords
        search_keywords = [
            "find", "search", "locate", "grep", "look for", "identify", "pinpoint"
        ]
        
        # Normalize request text
        normalized = request.lower()
        
        # Check for each type of operation
        for keyword in manipulation_keywords:
            if keyword in normalized:
                return "manipulate"
        
        for keyword in summarization_keywords:
            if keyword in normalized:
                return "summarize"
        
        for keyword in search_keywords:
            if keyword in normalized:
                return "search"
        
        # Default to analysis
        return "analyze"
    
    async def _extract_workflow_info(
        self, 
        request: str, 
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Extract workflow information from a request.
        
        Args:
            request: The user request
            context: Context information
            
        Returns:
            Dictionary with workflow name, description, and steps
        """
        prompt = f"""
Extract information about a workflow definition from this user request:
"{request}"

Return a JSON object with:
1. name: The workflow name
2. description: A brief description of what the workflow does
3. steps: The sequence of steps or commands to include in the workflow

Format:
{{
  "name": "workflow_name",
  "description": "What this workflow does",
  "steps": "Detailed description of steps"
}}

Include only the JSON object with no additional text.
"""
        
        api_request = GeminiRequest(prompt=prompt, max_tokens=1000)
        response = await gemini_client.generate_text(api_request)
        
        try:
            # Extract JSON from the response
            import json
            import re
            
            # Try to find JSON in the response
            json_match = re.search(r'```(?:json)?\s*(.*?)\s*```', response.text, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
            else:
                # Assume the entire response is JSON
                json_str = response.text
            
            # Parse JSON
            workflow_info = json.loads(json_str)
            return workflow_info
            
        except Exception as e:
            self._logger.error(f"Error extracting workflow info: {str(e)}")
            return {}
    
    async def _extract_workflow_execution_info(
        self, 
        request: str, 
        context: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Extract workflow execution information from a request.
        
        Args:
            request: The user request
            context: Context information
            
        Returns:
            Dictionary with workflow name and variables
        """
        # Get list of available workflows
        available_workflows = workflow_manager.list_workflows()
        workflow_names = [w.name for w in available_workflows]
        
        prompt = f"""
Extract information about a workflow execution from this user request:
"{request}"

Available workflows: {", ".join(workflow_names) if workflow_names else "None"}

Return a JSON object with:
1. name: The workflow name to execute
2. variables: Any variable values to use (as key-value pairs)

Format:
{{
  "name": "workflow_name",
  "variables": {{
    "var1": "value1",
    "var2": "value2"
  }}
}}

Include only the JSON object with no additional text.
"""
        
        api_request = GeminiRequest(prompt=prompt, max_tokens=1000)
        response = await gemini_client.generate_text(api_request)
        
        try:
            # Extract JSON from the response
            import json
            import re
            
            # Try to find JSON in the response
            json_match = re.search(r'```(?:json)?\s*(.*?)\s*```', response.text, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
            else:
                # Assume the entire response is JSON
                json_str = response.text
            
            # Parse JSON
            execution_info = json.loads(json_str)
            return execution_info
            
        except Exception as e:
            self._logger.error(f"Error extracting workflow execution info: {str(e)}")
            return {}
    
    async def _display_plan(self, plan: Any) -> None:
        """
        Display a task plan with rich formatting.
        
        Args:
            plan: The task plan to display
        """
        # Use the terminal formatter to display the plan
        from angela.shell.formatter import terminal_formatter
        await terminal_formatter.display_task_plan(plan)
    
    async def _confirm_plan_execution(self, plan: Any, dry_run: bool) -> bool:
        """
        Get confirmation to execute a plan.
        
        Args:
            plan: The task plan to execute
            dry_run: Whether this is a dry run
            
        Returns:
            True if confirmed, False otherwise
        """
        if dry_run:
            # No confirmation needed for dry run
            return True
        
        # Check if any steps are high risk
        has_high_risk = any(step.estimated_risk >= 3 for step in plan.steps)
        
        # Import here to avoid circular imports
        from rich.console import Console
        from prompt_toolkit.shortcuts import yes_no_dialog
        
        console = Console()
        
        if has_high_risk:
            # Use a more prominent warning for high-risk plans
            console.print(Panel(
                "⚠️  [bold red]This plan includes HIGH RISK operations[/bold red] ⚠️\n"
                "Some of these steps could make significant changes to your system.",
                border_style="red",
                expand=False
            ))
        
        # Get confirmation
        confirmed = yes_no_dialog(
            title="Confirm Plan Execution",
            text=f"Do you want to execute this {len(plan.steps)}-step plan?",
        ).run()
        
        return confirmed
    
    async def _display_workflow(self, workflow: Any, variables: Dict[str, Any]) -> None:
        """
        Display a workflow with rich formatting.
        
        Args:
            workflow: The workflow to display
            variables: Variables for the workflow
        """
        # Import here to avoid circular imports
        from rich.console import Console
        from rich.table import Table
        from rich.panel import Panel
        from rich.syntax import Syntax
        
        console = Console()
        
        # Create a table for the workflow steps
        table = Table(title=f"Workflow: {workflow.name}")
        table.add_column("#", style="cyan")
        table.add_column("Command", style="green")
        table.add_column("Explanation", style="white")
        table.add_column("Options", style="yellow")
        
        # Add steps to the table
        for i, step in enumerate(workflow.steps):
            # Apply variable substitution
            command = step.command
            for var_name, var_value in variables.items():
                # Remove leading $ if present
                clean_name = var_name[1:] if var_name.startswith('$') else var_name
                
                # Substitute ${VAR} syntax
                command = command.replace(f"${{{clean_name}}}", str(var_value))
                
                # Substitute $VAR syntax
                command = command.replace(f"${clean_name}", str(var_value))
            
            options = []
            if step.optional:
                options.append("Optional")
            if step.requires_confirmation:
                options.append("Requires Confirmation")
            
            table.add_row(
                str(i + 1),
                Syntax(command, "bash", theme="monokai", word_wrap=True).markup,
                step.explanation,
                ", ".join(options) if options else ""
            )
        
        # Display the table
        console.print("\n")
        console.print(Panel(
            workflow.description,
            title=f"Workflow: {workflow.name}",
            border_style="blue"
        ))
        console.print(table)
        
        # Display variables if any
        if variables:
            var_table = Table(title="Variables")
            var_table.add_column("Name", style="cyan")
            var_table.add_column("Value", style="green")
            
            for var_name, var_value in variables.items():
                var_table.add_row(var_name, str(var_value))
            
            console.print(var_table)
    
    async def _confirm_workflow_execution(
        self, 
        workflow: Any, 
        variables: Dict[str, Any], 
        dry_run: bool
    ) -> bool:
        """
        Get confirmation to execute a workflow.
        
        Args:
            workflow: The workflow to execute
            variables: Variables for the workflow
            dry_run: Whether this is a dry run
            
        Returns:
            True if confirmed, False otherwise
        """
        if dry_run:
            # No confirmation needed for dry run
            return True
        
        # Check if any steps require confirmation
        requires_confirmation = any(step.requires_confirmation for step in workflow.steps)
        
        # Import here to avoid circular imports
        from rich.console import Console
        from prompt_toolkit.shortcuts import yes_no_dialog
        
        console = Console()
        
        if requires_confirmation:
            # Use a more prominent warning for confirmation-required workflows
            console.print(Panel(
                "⚠️  [bold yellow]This workflow includes steps that require confirmation[/bold yellow] ⚠️\n"
                "Some of these steps could make significant changes.",
                border_style="yellow",
                expand=False
            ))
        
        # Get confirmation
        confirmed = yes_no_dialog(
            title="Confirm Workflow Execution",
            text=f"Do you want to execute workflow '{workflow.name}' with {len(workflow.steps)} steps?",
        ).run()
        
        return confirmed
    
    async def _confirm_file_changes(self, file_path: Path, diff: str) -> bool:
        """
        Get confirmation for file changes.
        
        Args:
            file_path: Path to the file being changed
            diff: Unified diff of the changes
            
        Returns:
            True if confirmed, False otherwise
        """
        # Import here to avoid circular imports
        from rich.console import Console
        from rich.panel import Panel
        from rich.syntax import Syntax
        from prompt_toolkit.shortcuts import yes_no_dialog
        
        console = Console()
        
        # Display the diff
        console.print("\n")
        console.print(Panel(
            f"Proposed changes to {file_path}:",
            title="File Changes",
            border_style="yellow"
        ))
        console.print(Syntax(diff, "diff", theme="monokai"))
        
        # Get confirmation
        confirmed = yes_no_dialog(
            title="Confirm File Changes",
            text=f"Do you want to apply these changes to {file_path}?",
        ).run()
        
        return confirmed
    
    def _start_background_monitoring(self, command: str, error_analysis: Dict[str, Any]) -> None:
        """
        Start background monitoring for a failed command.
        
        Args:
            command: The failed command
            error_analysis: Analysis of the error
        """
        # Create and start a background task
        task = asyncio.create_task(
            self._monitor_for_suggestions(command, error_analysis)
        )
        
        # Add the task to our set of background tasks
        self._background_tasks.add(task)
        # Remove the task when it's done
        task.add_done_callback(self._background_tasks.discard)
    
    async def _monitor_for_suggestions(self, command: str, error_analysis: Dict[str, Any]) -> None:
        """
        Monitor and provide suggestions for a failed command.
        
        Args:
            command: The failed command
            error_analysis: Analysis of the error
        """
        # Wait a short time before offering suggestions
        await asyncio.sleep(2)
        
        # Import here to avoid circular imports
        from rich.console import Console
        
        console = Console()
        
        # Generate potential fix suggestions
        suggestions = []
        
        # Add suggestions from error analysis
        if "fix_suggestions" in error_analysis:
            suggestions.extend(error_analysis["fix_suggestions"])
        
        # Add historical fixes if available
        if "historical_fixes" in error_analysis:
            suggestions.extend(error_analysis["historical_fixes"])
        
        # If we have suggestions, offer them
        if suggestions:
            console.print("\n")
            console.print("[bold blue]Suggestion:[/bold blue] Try one of these commands to fix the issue:")
            
            for i, suggestion in enumerate(suggestions[:3], 1):  # Limit to top 3
                console.print(f"  {i}. {suggestion}")
            
            console.print("\nUse 'angela try fix 1' to execute the first suggestion, etc.")
    
    async def process_file_operation(
        self, 
        operation: str, 
        parameters: Dict[str, Any],
        dry_run: bool = False
    ) -> Dict[str, Any]:
        """
        Process a file operation request.
        
        Args:
            operation: The type of file operation (e.g., 'create_file', 'read_file').
            parameters: Parameters for the operation.
            dry_run: Whether to simulate the operation without making changes.
            
        Returns:
            A dictionary with the operation results.
        """
        # Execute the file operation
        return await execute_file_operation(operation, parameters, dry_run=dry_run)


    async def execute_command(
        self, 
        command: str,
        natural_request: str,
        explanation: Optional[str] = None,
        dry_run: bool = False
    ) -> Dict[str, Any]:
        '''
        Execute a command with adaptive behavior based on user context.
        
        Args:
            command: The command to execute
            natural_request: The original natural language request
            explanation: AI explanation of what the command does
            dry_run: Whether to simulate the command without execution
            
        Returns:
            Dictionary with execution results
        '''
        self._logger.info(f"Preparing to execute command: {command}")
        
        # Get current context for hooks
        context = context_manager.get_context_dict()
        
        # Call pre-execution hook
        await execution_hooks.pre_execute_command(command, context)
        
        # Analyze command risk and impact
        risk_level, risk_reason = classify_command_risk(command)
        impact = analyze_command_impact(command)
        
        # Add to session context
        session_manager.add_command(command)
        
        # Generate command preview if needed
        from angela.safety.preview import generate_preview
        preview = await generate_preview(command) if preferences_manager.preferences.ui.show_command_preview else None
        
        # Get adaptive confirmation based on risk level and user history
        confirmed = await get_adaptive_confirmation(
            command=command,
            risk_level=risk_level,
            risk_reason=risk_reason,
            impact=impact,
            preview=preview,
            explanation=explanation,
            natural_request=natural_request,
            dry_run=dry_run
        )
        
        if not confirmed and not dry_run:
            self._logger.info(f"Command execution cancelled by user: {command}")
            return {
                "command": command,
                "success": False,
                "cancelled": True,
                "stdout": "",
                "stderr": "Command execution cancelled by user",
                "return_code": 1,
                "dry_run": dry_run
            }
        
        # Execute the command
        result = await self._execute_with_feedback(command, dry_run)
        
        # Call post-execution hook
        await execution_hooks.post_execute_command(command, result, context)
        
        # Add to history
        history_manager.add_command(
            command=command,
            natural_request=natural_request,
            success=result["success"],
            output=result.get("stdout", ""),
            error=result.get("stderr", ""),
            risk_level=risk_level
        )
        
        # If execution failed, analyze error and suggest fixes
        if not result["success"] and result.get("stderr"):
            result["error_analysis"] = error_analyzer.analyze_error(command, result["stderr"])
            result["fix_suggestions"] = error_analyzer.generate_fix_suggestions(command, result["stderr"])
        
        # Offer to learn from successful executions
        if result["success"] and risk_level > 0:
            from angela.safety.adaptive_confirmation import offer_command_learning
            await offer_command_learning(command)
        
        return result


    async def _handle_monitoring_insight(self, insight_type: str, insight_data: Dict[str, Any]):
        """Handle insights from monitoring systems."""
        self._logger.info(f"Received monitoring insight: {insight_type}")
        
        # Store insight in context for future decision making
        session_manager.add_entity(
            f"monitoring_{insight_type}",
            "monitoring_insight", 
            insight_data
        )
        
        # Potentially trigger actions based on insights
        if insight_type == "critical_resource_warning" and insight_data.get("severity") == "high":
            # Take immediate action
            await self._handle_critical_resource_warning(insight_data)

# Global orchestrator instance
orchestrator = Orchestrator()

# Synchronous wrapper for backwards compatibility
def process_request(request: str) -> Dict[str, Any]:
    """Synchronous wrapper for processing a request."""
    return asyncio.run(orchestrator.process_request(request))
</file>

</files>
